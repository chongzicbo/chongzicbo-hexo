{"meta":{"version":1,"warehouse":"5.0.1"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0},{"_id":"themes/hexo-theme-fluid/source/css/gitalk.css","path":"css/gitalk.css","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/css/highlight-dark.styl","path":"css/highlight-dark.styl","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/css/highlight.styl","path":"css/highlight.styl","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/img/avatar.png","path":"img/avatar.png","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/img/daxiong.jpg","path":"img/daxiong.jpg","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/img/default.png","path":"img/default.png","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/img/loading.gif","path":"img/loading.gif","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/img/fluid.png","path":"img/fluid.png","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/img/mao.jpg","path":"img/mao.jpg","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/img/police_beian.png","path":"img/police_beian.png","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/img/wechat_qrcode.jpg","path":"img/wechat_qrcode.jpg","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/xml/local-search.xml","path":"xml/local-search.xml","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/js/boot.js","path":"js/boot.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/js/color-schema.js","path":"js/color-schema.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/js/events.js","path":"js/events.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/js/img-lazyload.js","path":"js/img-lazyload.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/js/leancloud.js","path":"js/leancloud.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/js/local-search.js","path":"js/local-search.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/js/plugins.js","path":"js/plugins.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/js/utils.js","path":"js/utils.js","modified":1,"renderable":1},{"_id":"themes/hexo-theme-fluid/source/js/umami-view.js","path":"js/umami-view.js","modified":1,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"680e2a5454c0ae5b0b48898e1efb817bec19adf2","modified":1735187082758},{"_id":"source/about/index.md","hash":"05e3d203b0115427df94ce07c551cb538f9d7af7","modified":1735187082763},{"_id":"source/_posts/人工智能/multi-modal/论文阅读14：MiniCPM深入解析.md","hash":"0deb10ded89a14b52c5b011f4b9ca5575b9b5db1","modified":1735193947140},{"_id":"source/_posts/开发/Python/Python-001：使用xml.dom.minidom解析xml文件.md","hash":"2d3806515a5a85b4f61cd69e136a33f5c1aad148","modified":1735194046929},{"_id":"source/_posts/人工智能/computer-vision/CV007-YOLO11详解.md","hash":"43483e074e16704e89905ddf8b346500bdcc81c2","modified":1735187082759},{"_id":"source/_posts/开发/Python/Python-002：python开发中常用的工具函数.md","hash":"8924ee0803b5507bb52fa819e369c6754feac431","modified":1735194062973},{"_id":"source/_posts/人工智能/computer-vision/CV008-评估 YOLO （You Only Look Once） 模型的演变：YOLO11 及其前身的全面基准研究.md","hash":"a89441381044e1947c77655a62f484a59d62c724","modified":1735187082759},{"_id":"source/_posts/人工智能/computer-vision/CV010-YOLO V10详解.md","hash":"c8618a15b61136b5720c16834d845706f56f356d","modified":1735187082759},{"_id":"source/_posts/开发/Python/Python-003：Python 日志处理最佳实践：使用logging模块构建高效日志系统.md","hash":"ee3309dffab773e02cd76433e1478bfa31178ab0","modified":1735194068743},{"_id":"source/_posts/开发/Python/Python-004：Python 日志处理最佳实践：使用loguru模块构建高效日志系统.md","hash":"66485aaee8e6205b36de10326eb117f6271d6ba0","modified":1735194077322},{"_id":"source/_posts/开发/cpp/C++基础：C++常量详解.md","hash":"c449e691291df7e5d27cf8499663f67fe5e94b3c","modified":1735195066686},{"_id":"source/_posts/计算机基础/计算机网络/HTTP基础02：了解Web及网络基础.md","hash":"3f0f56adfa433cb1743ee46686d5178f041a3106","modified":1735789549925},{"_id":"source/_posts/开发/音视频/音视频开发01：RGB和YUV颜色模型详解.md","hash":"17a9d3083a4848fc863ae9090e9260278720c071","modified":1735198877402},{"_id":"source/_posts/人工智能/nlp/NLP025-huggingface自定义数据集和模型下载存储目录.md","hash":"11f116f317a4c8dd44d66f0d40c6f6d98c1b8333","modified":1735187082760},{"_id":"source/_posts/开发/cpp/C++基础：C++ 中的 static 关键字：深入理解与应用.md","hash":"e5960b79c046f028deec5457215b3d3cd883ce92","modified":1735195061944},{"_id":"source/_posts/开发/cpp/C++001：C++右值语义详解：从基础到实战.md","hash":"ad4506bd04bddca13277f7b6e2a5fe0dc7bc8005","modified":1735195056909},{"_id":"source/_posts/计算机基础/计算机网络/HTTP基础01：HTTP协议概述.md","hash":"fb1faabbc8325d3c1d0a234925a54c0a653536e5","modified":1735626952924},{"_id":"source/_posts/人工智能/multi-modal/OCR/多模态003：OCR算法、模型综述.md","hash":"eb65f0ff4a2ff2fb7b26d1e32b98a62eef341fed","modified":1735193966722},{"_id":"source/_posts/开发/音视频/音视频开发09：字幕介绍.md","hash":"5d145e5c0c1b7daa5b0dbd1218945edcc44901af","modified":1735195031501},{"_id":"source/_posts/开发/音视频/音视频开发08：音视频开发基本步骤和流程.md","hash":"b4ce8ed472c54e010c84356dab7296c7d2f88d36","modified":1735195035739},{"_id":"source/_posts/计算机基础/计算机网络/HTTP基础03：简单的 HTTP协议.md","hash":"2ddf1be8235bea98e0423b7882f91451db2ff0be","modified":1735789815821},{"_id":"source/_posts/人工智能/nlp/llm/源码解析：llama3源码解析-01：整体代码结构及模块功能.md","hash":"40c0343018bf5f37d152431fa4f5e0f9dd126f30","modified":1735187082760},{"_id":"source/_posts/人工智能/nlp/llm/源码解析：llama3源码解析-02：tokenizer模块解析.md","hash":"d9988d4983145473c364ee6c8eea154f3e433440","modified":1735187082760},{"_id":"source/_posts/人工智能/nlp/llm/源码解析：llama3源码解析-03：model.py模块解析.md","hash":"289de8b7d4524269ff1019f321e8d7f7d165d573","modified":1735530570874},{"_id":"source/_posts/人工智能/nlp/llm/源码解析：llama3源码解析-04：generation.py模块解析.md","hash":"d2ee29006694dc06d7573a916e8d599c4a18233d","modified":1735530837855},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_tag/tag.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1735187082783},{"_id":"themes/hexo-theme-fluid/.editorconfig","hash":"b595159772f3ee1ef5e6780ce307270e741cb309","modified":1735187082763},{"_id":"themes/hexo-theme-fluid/.gitattributes","hash":"3e00e1fb043438cd820d94ee3dc9ffb6718996f3","modified":1735187082763},{"_id":"themes/hexo-theme-fluid/.eslintrc","hash":"3df89453e1f63051fafc90f16a8d83951050e316","modified":1735187082763},{"_id":"themes/hexo-theme-fluid/_config.yml","hash":"85a743101e9dc9378df93bb98b841d25a3378036","modified":1735626750369},{"_id":"themes/hexo-theme-fluid/package.json","hash":"fd6756866314aaf4b15d734a83b85aa09aa0b5ed","modified":1735187082774},{"_id":"themes/hexo-theme-fluid/languages/de.yml","hash":"f814263ded504cb4c50a8b66157bdd71f553be1b","modified":1735187082765},{"_id":"themes/hexo-theme-fluid/languages/eo.yml","hash":"314b97a7e68093328675acfd308d839b1d772ac9","modified":1735187082766},{"_id":"themes/hexo-theme-fluid/languages/en.yml","hash":"415e3403182e1282386f28b9d61343f147519163","modified":1735187082766},{"_id":"themes/hexo-theme-fluid/languages/es.yml","hash":"0ad94ddf1ca868a67b5b84aed257a30572962210","modified":1735187082766},{"_id":"themes/hexo-theme-fluid/languages/ja.yml","hash":"65a90f294f6c73245e8250e87d124630ad10b389","modified":1735187082766},{"_id":"themes/hexo-theme-fluid/languages/ru.yml","hash":"998112b384b574e0e29c6ea16e4c1ebce1c15a4c","modified":1735187082766},{"_id":"themes/hexo-theme-fluid/README.md","hash":"34e3223851da1596b9ff051f2b29c6004edca8a1","modified":1735187082765},{"_id":"themes/hexo-theme-fluid/languages/zh-CN.yml","hash":"497b3dea5058f718da225a7a443e916da895ea10","modified":1735187082766},{"_id":"themes/hexo-theme-fluid/languages/zh-TW.yml","hash":"ded0621e63b1f8b241be21f6e9b52d4f36edbcd0","modified":1735187082767},{"_id":"themes/hexo-theme-fluid/languages/zh-HK.yml","hash":"05418d0bca261de386872be65027bf4498758788","modified":1735187082767},{"_id":"themes/hexo-theme-fluid/layout/404.ejs","hash":"c49974dcbda02fe720498398e9778826335459c0","modified":1735187082767},{"_id":"themes/hexo-theme-fluid/layout/archive.ejs","hash":"c524ce76747042ec2f9ed8d5025f80e01b462b3b","modified":1735187082773},{"_id":"themes/hexo-theme-fluid/layout/categories.ejs","hash":"838a68e210bddfca6d4ba070e1e2f1ca53cb7d06","modified":1735187082773},{"_id":"themes/hexo-theme-fluid/layout/about.ejs","hash":"2f3ea36713f0fa91d8d61d39fcf9e584372de818","modified":1735187082773},{"_id":"themes/hexo-theme-fluid/README_en.md","hash":"85656f2a23cc5e31420f0118bf5541b6e9f058b6","modified":1735187082765},{"_id":"themes/hexo-theme-fluid/layout/category.ejs","hash":"264f68cbf826787e683a30e1377c56c0895c7386","modified":1735187082773},{"_id":"themes/hexo-theme-fluid/layout/links.ejs","hash":"fbed4b3d1e475b3de9d8ce05362abcc658a53408","modified":1735187082773},{"_id":"themes/hexo-theme-fluid/layout/layout.ejs","hash":"d4ffeb7eff398dea154340794bd277f75ddeedef","modified":1735187082773},{"_id":"themes/hexo-theme-fluid/layout/index.ejs","hash":"dde1f6a27c8d09c38850a691089937f181b6c035","modified":1735187082773},{"_id":"themes/hexo-theme-fluid/layout/page.ejs","hash":"8ba210724c023d45a4564415762f3da299bd1d0e","modified":1735187082773},{"_id":"themes/hexo-theme-fluid/LICENSE","hash":"511e49f0bd8282a0d002c527474da8e1e5add393","modified":1735187082765},{"_id":"themes/hexo-theme-fluid/layout/post.ejs","hash":"c8da695dc1b01b715909ae6f1052ccaebdf9db4c","modified":1735187082773},{"_id":"themes/hexo-theme-fluid/layout/tags.ejs","hash":"b7c1a6d8fc1097fc16d2300260297013cb692153","modified":1735187082774},{"_id":"themes/hexo-theme-fluid/layout/tag.ejs","hash":"e87fc58829ea214ac16e8e4f13cd5c389133697b","modified":1735187082773},{"_id":"themes/hexo-theme-fluid/.github/ISSUE_TEMPLATE/feature_request.md","hash":"5cc30e7b6e7b77c8b40b182ba02a5d93d37d2fc2","modified":1735187082764},{"_id":"themes/hexo-theme-fluid/.github/ISSUE_TEMPLATE/question.md","hash":"102213e5d6790d060c0e26b4a3a7ec744d753c52","modified":1735187082764},{"_id":"themes/hexo-theme-fluid/.github/ISSUE_TEMPLATE/feature_request_zh.md","hash":"7db378613df2b7d13e8c428c006399a879a4a852","modified":1735187082764},{"_id":"themes/hexo-theme-fluid/.github/ISSUE_TEMPLATE/bug_report.md","hash":"7d7c1e5a1da6b4f7be6685beb4798ec76d5efd31","modified":1735187082763},{"_id":"themes/hexo-theme-fluid/.github/ISSUE_TEMPLATE/bug_report_zh.md","hash":"fea63a9a5c3befd8783705eed09adf1b596a6203","modified":1735187082764},{"_id":"themes/hexo-theme-fluid/.github/workflows/limit.yaml","hash":"bdbdb66da69ab7353b546f02150a6792f4787975","modified":1735187082764},{"_id":"themes/hexo-theme-fluid/.github/workflows/publish.yaml","hash":"dcdbe1698a6ee61f741c29ef560f859f66ffa32c","modified":1735187082765},{"_id":"themes/hexo-theme-fluid/.github/ISSUE_TEMPLATE/question_zh.md","hash":"07e24578c25fcaca94618fd86569887dadf7a276","modified":1735187082764},{"_id":"themes/hexo-theme-fluid/scripts/events/index.js","hash":"6c3b24207e4ea3ae4edeb715af40ef23711b92b9","modified":1735187082774},{"_id":"themes/hexo-theme-fluid/scripts/filters/default-injects.js","hash":"3d30c722b9e24c33577d6fab822628841fadf992","modified":1735187082775},{"_id":"themes/hexo-theme-fluid/scripts/filters/locals.js","hash":"2340a576635b16fd2456b3494f5afe89cd7764db","modified":1735187082775},{"_id":"themes/hexo-theme-fluid/scripts/filters/post-filter.js","hash":"67637461e3f94f9e9675369eb7ff015355d9ec54","modified":1735187082775},{"_id":"themes/hexo-theme-fluid/scripts/generators/pages.js","hash":"3fb72d3c2224c32d861a6e8a85e78a8b67e6a244","modified":1735187082775},{"_id":"themes/hexo-theme-fluid/scripts/generators/index-generator.js","hash":"3550976efc94500284795f13485f5a1765fc120b","modified":1735187082775},{"_id":"themes/hexo-theme-fluid/scripts/generators/local-search.js","hash":"33427308ca29f1d76336c83e704571c9de75df02","modified":1735187082775},{"_id":"themes/hexo-theme-fluid/scripts/helpers/date.js","hash":"9bc9ba08d1d871394ee1c3a1cc2f21dc343f515a","modified":1735187082776},{"_id":"themes/hexo-theme-fluid/.github/workflows/cr.yaml","hash":"fc31c7c6692424af1e08cd5e273a5a5814f9c577","modified":1735187082764},{"_id":"themes/hexo-theme-fluid/scripts/helpers/engine.js","hash":"96af7e55fdbe0819bacc554ecbfe42375a088df6","modified":1735187082776},{"_id":"themes/hexo-theme-fluid/scripts/helpers/export-config.js","hash":"14a207a7d4e329382ab5d4e1da1ef85ff043daba","modified":1735187082776},{"_id":"themes/hexo-theme-fluid/scripts/helpers/injects.js","hash":"9219d59c51930c7a82fcde918d6efbc5aa572ea2","modified":1735187082776},{"_id":"themes/hexo-theme-fluid/scripts/helpers/page.js","hash":"49b2c6449d7be35739c6cfea3cab4e790580983a","modified":1735187082776},{"_id":"themes/hexo-theme-fluid/scripts/helpers/import.js","hash":"f9821f7789ea6f069977a8c642aa5ccb6d19077c","modified":1735187082776},{"_id":"themes/hexo-theme-fluid/scripts/helpers/wordcount.js","hash":"0bb33314aa5cfe326ab9bb14b545e343e4db4193","modified":1735187082776},{"_id":"themes/hexo-theme-fluid/scripts/helpers/scope.js","hash":"3b67d50050158423c8fa47f1de6aedcfe916637b","modified":1735187082776},{"_id":"themes/hexo-theme-fluid/scripts/helpers/url.js","hash":"f713ddb6c8018ec7b96d3567057f1f932609beea","modified":1735187082776},{"_id":"themes/hexo-theme-fluid/scripts/helpers/utils.js","hash":"f57be245e6e7228673e1dec3a3477e731492c5c1","modified":1735187082776},{"_id":"themes/hexo-theme-fluid/scripts/tags/checkbox.js","hash":"1ff4ea054f2c735dfaccb0be90f1708a2a750bc8","modified":1735187082777},{"_id":"themes/hexo-theme-fluid/scripts/tags/button.js","hash":"e1d0caed12e7cd9a35cf64272c41854b2901a58f","modified":1735187082777},{"_id":"themes/hexo-theme-fluid/scripts/tags/fold.js","hash":"a93e2603021ad38714e870399767bea24e7cbe3e","modified":1735187082777},{"_id":"themes/hexo-theme-fluid/scripts/tags/label.js","hash":"6c5916d86c63795c7e910bf614b0e7ece5073702","modified":1735187082777},{"_id":"themes/hexo-theme-fluid/scripts/utils/compare-versions.js","hash":"37f90bd4e35ce49457dc2a348b9f66e0b242c014","modified":1735187082777},{"_id":"themes/hexo-theme-fluid/scripts/tags/group-image.js","hash":"cc176cc1d7e7cc28cedf8397ae748c691d140be2","modified":1735187082777},{"_id":"themes/hexo-theme-fluid/scripts/tags/mermaid.js","hash":"dbfe59fde77d87b1d7d0c46480a2a729010988eb","modified":1735187082777},{"_id":"themes/hexo-theme-fluid/scripts/tags/note.js","hash":"e300ec4ee6c63464859ab000e987bf8dd7db4025","modified":1735187082777},{"_id":"themes/hexo-theme-fluid/scripts/utils/crypto.js","hash":"474b00a57f43dbe7bc2876d637ece4214d016c06","modified":1735187082777},{"_id":"themes/hexo-theme-fluid/scripts/utils/object.js","hash":"3e03b534e2e92a6e17567b006d7e3eaad4b37598","modified":1735187082778},{"_id":"themes/hexo-theme-fluid/scripts/utils/resolve.js","hash":"a5d70005913ab03cea0a0dc601097628b4dbd5a8","modified":1735187082778},{"_id":"themes/hexo-theme-fluid/scripts/utils/url-join.js","hash":"dbdb10b23fcd3928e86a4cb46fa3455e060b4aa0","modified":1735187082778},{"_id":"themes/hexo-theme-fluid/source/css/main.styl","hash":"9e9171325bb7148c11ceee283d00c137c8a1c5c5","modified":1735187082784},{"_id":"themes/hexo-theme-fluid/source/css/highlight-dark.styl","hash":"c74d7aed425d20f2fa096f386a9521b67b9ab269","modified":1735187082784},{"_id":"themes/hexo-theme-fluid/source/css/highlight.styl","hash":"57ce8b8f95ab1f40612a9dce1793de5ab9b4bbfc","modified":1735187082784},{"_id":"themes/hexo-theme-fluid/source/css/gitalk.css","hash":"1fe60b2ab1d704f5a4f55e700dca5b8785fb390e","modified":1735187082783},{"_id":"themes/hexo-theme-fluid/source/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1735187082786},{"_id":"themes/hexo-theme-fluid/source/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1735187082784},{"_id":"themes/hexo-theme-fluid/source/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1735187082786},{"_id":"themes/hexo-theme-fluid/source/img/daxiong.jpg","hash":"a885de1f65fab29c30a96fcf9cc251993e0483b2","modified":1735187082784},{"_id":"themes/hexo-theme-fluid/source/js/boot.js","hash":"33bb7c8255d2e3c93a1bea8c9221399b3a868a63","modified":1735187082787},{"_id":"themes/hexo-theme-fluid/source/xml/local-search.xml","hash":"85fcc23b4db654a7f91fc55b6fb0442bb3ed3a9a","modified":1735187082789},{"_id":"themes/hexo-theme-fluid/source/js/color-schema.js","hash":"e7addcc88eb73dec4a9a8641a4bb68966a38a65d","modified":1735187082787},{"_id":"themes/hexo-theme-fluid/source/img/mao.jpg","hash":"a589716096025934b5fc6bebf07c87f314575fce","modified":1735187082786},{"_id":"themes/hexo-theme-fluid/source/js/img-lazyload.js","hash":"67f6250f98b36a6599ea982d11cbb060c5ffb92a","modified":1735187082788},{"_id":"themes/hexo-theme-fluid/source/img/wechat_qrcode.jpg","hash":"793f0ffd367f69718fc66ef5750d32f4cf2e05fb","modified":1735187082787},{"_id":"themes/hexo-theme-fluid/source/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1735187082786},{"_id":"themes/hexo-theme-fluid/source/js/events.js","hash":"3efd602cdb694902d6e74c4eb1e5bd70120ac5b1","modified":1735187082787},{"_id":"themes/hexo-theme-fluid/source/js/plugins.js","hash":"753c2cf95f2659fef80277b895f4da10c8888c72","modified":1735187082788},{"_id":"themes/hexo-theme-fluid/source/js/local-search.js","hash":"491021125d2579e841c83f36d3ab790d1eab9d1e","modified":1735187082788},{"_id":"themes/hexo-theme-fluid/layout/_partials/category-chains.ejs","hash":"508254a648d8597e62e4012c8beab44bfa82e904","modified":1735187082767},{"_id":"themes/hexo-theme-fluid/source/js/utils.js","hash":"9d0423db40a787f3b19968205b9ed92a848c9153","modified":1735187082788},{"_id":"themes/hexo-theme-fluid/layout/_partials/archive-list.ejs","hash":"78c34e32746041f23678669bbadfbede15e4c6d2","modified":1735187082767},{"_id":"themes/hexo-theme-fluid/layout/_partials/category-list.ejs","hash":"0c14869e15f7dc615c8353765569644238f38f2d","modified":1735187082767},{"_id":"themes/hexo-theme-fluid/source/js/leancloud.js","hash":"e9ad1b5659f0af867174687daa0ecf4375e40b75","modified":1735187082788},{"_id":"themes/hexo-theme-fluid/layout/_partials/footer.ejs","hash":"6bb3335b5486d4bee2ed42f8bef57903066bc234","modified":1735187082769},{"_id":"themes/hexo-theme-fluid/layout/_partials/comments.ejs","hash":"1ce9094faec6204949cdaf604aaf9200787e4218","modified":1735187082767},{"_id":"themes/hexo-theme-fluid/layout/_partials/css.ejs","hash":"901280e6fb3194c30542751d04f27e78b42d3c6f","modified":1735187082769},{"_id":"themes/hexo-theme-fluid/layout/_partials/header.ejs","hash":"3668304d08c48b68d532532921a12069a2736150","modified":1735187082770},{"_id":"themes/hexo-theme-fluid/layout/_partials/head.ejs","hash":"a0bcbbfc34efaef3b23c6b531e7f3201f2eab2dd","modified":1735187082769},{"_id":"themes/hexo-theme-fluid/layout/_partials/scripts.ejs","hash":"89fc9f663a1091911b79ab9697c09446d16184f9","modified":1735187082772},{"_id":"themes/hexo-theme-fluid/layout/_partials/markdown-plugins.ejs","hash":"b5cd435b27f090939b6051bef41a38a3376044ac","modified":1735187082770},{"_id":"themes/hexo-theme-fluid/scripts/events/lib/footnote.js","hash":"9b1934c61dc78622a07da554413f6ad31854576d","modified":1735187082774},{"_id":"themes/hexo-theme-fluid/layout/_partials/paginator.ejs","hash":"0d443f23c459787338917900f50fec1c8b3b3bdd","modified":1735187082770},{"_id":"themes/hexo-theme-fluid/layout/_partials/search.ejs","hash":"57a0f61242d9ce2bd2c51b2f84193f6dc1377ef9","modified":1735187082772},{"_id":"themes/hexo-theme-fluid/scripts/events/lib/compatible-configs.js","hash":"31208a0db986ba864f756a8ec806b7d254440f9b","modified":1735187082774},{"_id":"themes/hexo-theme-fluid/scripts/events/lib/hello.js","hash":"da987411ae4a4e6896a9b8af1fce6209192af28e","modified":1735187082774},{"_id":"themes/hexo-theme-fluid/scripts/events/lib/highlight.js","hash":"d103e4bf612b2445bb136712d57b81e784a313e2","modified":1735187082774},{"_id":"themes/hexo-theme-fluid/source/js/umami-view.js","hash":"370ab30ab88c596d85327dbd7db3bafd49489fdd","modified":1735187082788},{"_id":"themes/hexo-theme-fluid/source/css/_functions/base.styl","hash":"171697018fd384fce0834875ca94b91f16564cac","modified":1735187082778},{"_id":"themes/hexo-theme-fluid/scripts/events/lib/lazyload.js","hash":"c9696633f77dd8055e900497469f9e64eca4d97f","modified":1735187082775},{"_id":"themes/hexo-theme-fluid/scripts/events/lib/injects.js","hash":"92123b7280695b4ac6650f5e1d7fa0d772c71f5b","modified":1735187082775},{"_id":"themes/hexo-theme-fluid/scripts/events/lib/merge-configs.js","hash":"ec6bf395ccad3dd41f29dc0080aeabf413e30fd9","modified":1735187082775},{"_id":"themes/hexo-theme-fluid/source/css/_mixins/base.styl","hash":"046979dbd8cdabd21d89f9c1d8f1bb3f2fd06d6f","modified":1735187082778},{"_id":"themes/hexo-theme-fluid/source/css/_pages/pages.styl","hash":"92c062cf55457b6549497244d09ec34e9c0c95c2","modified":1735187082783},{"_id":"themes/hexo-theme-fluid/layout/_partials/comments/discuss.ejs","hash":"d400e5721af28cefecaf50b46c82dcdde4cda4a8","modified":1735187082768},{"_id":"themes/hexo-theme-fluid/source/css/_variables/base.styl","hash":"9ea66cf79f1e4356b6b402bc3dc5fb55c9862f1f","modified":1735187082783},{"_id":"themes/hexo-theme-fluid/layout/_partials/comments/changyan.ejs","hash":"0c410ef79785897c8de3da333b057a2936fd569b","modified":1735187082768},{"_id":"themes/hexo-theme-fluid/layout/_partials/comments/cusdis.ejs","hash":"1e93ca89777e4beb0f0e5cb70e03aab48e958542","modified":1735187082768},{"_id":"themes/hexo-theme-fluid/layout/_partials/comments/disqus.ejs","hash":"79ec17eec6e15076c685688e740230e92c66efa9","modified":1735187082768},{"_id":"themes/hexo-theme-fluid/layout/_partials/comments/livere.ejs","hash":"bcceafab01fe695c59951d939f7cef502f3d7b48","modified":1735187082768},{"_id":"themes/hexo-theme-fluid/layout/_partials/comments/giscus.ejs","hash":"66995ec9dab10ed35c2a775010c447113c6848d4","modified":1735187082768},{"_id":"themes/hexo-theme-fluid/layout/_partials/comments/twikoo.ejs","hash":"938eb60413ae8af83ffeaba4d85df88387cdd5be","modified":1735187082768},{"_id":"themes/hexo-theme-fluid/layout/_partials/comments/remark42.ejs","hash":"45c879768b40ba56af62e18ad54bffbf73a6f3a1","modified":1735187082768},{"_id":"themes/hexo-theme-fluid/layout/_partials/comments/gitalk.ejs","hash":"7f04e5c22821bb94da791973d9c6692b03bac81d","modified":1735187082768},{"_id":"themes/hexo-theme-fluid/layout/_partials/comments/waline.ejs","hash":"df6bae1a93827991049f7a33f6a69681c60eab0e","modified":1735187082769},{"_id":"themes/hexo-theme-fluid/layout/_partials/comments/utterances.ejs","hash":"d7bcc183fc31af643e7835b13da10fe2ab8614ce","modified":1735187082769},{"_id":"themes/hexo-theme-fluid/layout/_partials/comments/valine.ejs","hash":"ef04d4fc3f26588ae9d8712938d648304fc05455","modified":1735187082769},{"_id":"themes/hexo-theme-fluid/layout/_partials/footer/statistics.ejs","hash":"047bece1db5cdf96cb78a44c6420ce3e92e6a9ca","modified":1735187082769},{"_id":"themes/hexo-theme-fluid/layout/_partials/header/banner.ejs","hash":"a84d8dcb44f5f6289ef09db4d02ab14de72c2c87","modified":1735187082770},{"_id":"themes/hexo-theme-fluid/layout/_partials/plugins/analytics.ejs","hash":"f8fe8e58b83f627db82c0dbeb663389efc33c1c6","modified":1735187082770},{"_id":"themes/hexo-theme-fluid/layout/_partials/footer/beian.ejs","hash":"77d0c9df31a22ed8a3e341637bde4165a11a7ce9","modified":1735187082769},{"_id":"themes/hexo-theme-fluid/layout/_partials/plugins/anchorjs.ejs","hash":"8a4ea62c46f9a75c94096a27b2d3f5c10a2f82e5","modified":1735187082770},{"_id":"themes/hexo-theme-fluid/layout/_partials/header/navigation.ejs","hash":"e5219b14410066bf8ab491379aca797304b4a914","modified":1735187082770},{"_id":"themes/hexo-theme-fluid/layout/_partials/plugins/highlight.ejs","hash":"502b99e19e496825df7032ca2b0b1a95ebb2b357","modified":1735187082771},{"_id":"themes/hexo-theme-fluid/layout/_partials/plugins/code-widget.ejs","hash":"03c7c69fbb1754fdccfa18671aac23b8637b869e","modified":1735187082770},{"_id":"themes/hexo-theme-fluid/layout/_partials/plugins/encrypt.ejs","hash":"018cab52ff696a6c78ebc01e10237a90a0c33603","modified":1735187082771},{"_id":"themes/hexo-theme-fluid/layout/_partials/plugins/moment.ejs","hash":"acc72c3284fe906a4505132c3d9a4720d80e6fcb","modified":1735187082771},{"_id":"themes/hexo-theme-fluid/layout/_partials/plugins/fancybox.ejs","hash":"3900e54ade140e0e49c571a1955f0b1f3a59b281","modified":1735187082771},{"_id":"themes/hexo-theme-fluid/layout/_partials/plugins/math.ejs","hash":"d0f06fb482e3a8f9a53dfd94c4e4a65a43f1ff34","modified":1735187082771},{"_id":"themes/hexo-theme-fluid/layout/_partials/plugins/nprogress.ejs","hash":"47c1df255aa552ad71ef3e57deca46530a8f2802","modified":1735187082771},{"_id":"themes/hexo-theme-fluid/layout/_partials/plugins/mermaid.ejs","hash":"110e45e2d3433178f00f482adc863110f90c46d6","modified":1735187082771},{"_id":"themes/hexo-theme-fluid/layout/_partials/plugins/typed.ejs","hash":"42850952e8f5858497fe774c2aff87b6563ab01e","modified":1735187082771},{"_id":"themes/hexo-theme-fluid/layout/_partials/post/copyright.ejs","hash":"26905d5862b1531ebcc175af15178dabeecc81c8","modified":1735187082772},{"_id":"themes/hexo-theme-fluid/layout/_partials/post/meta-bottom.ejs","hash":"f0cb813cd03642c9b68cff8b6669f73a61dd10f8","modified":1735187082772},{"_id":"themes/hexo-theme-fluid/layout/_partials/post/sidebar-left.ejs","hash":"db4ecdcc762bb1b1bae5060f0baa6115174779ff","modified":1735187082772},{"_id":"themes/hexo-theme-fluid/layout/_partials/post/meta-top.ejs","hash":"73827074db4e0fc3d52c51a76285df87aa5e5a7f","modified":1735187082772},{"_id":"themes/hexo-theme-fluid/layout/_partials/post/category-bar.ejs","hash":"551ffae43844925beb099c85a9e6d8d9fcbf8086","modified":1735187082772},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_about/about.styl","hash":"8ba5fb6a8ced1de6f7893184bf12f4021fe22595","modified":1735187082778},{"_id":"themes/hexo-theme-fluid/layout/_partials/post/toc.ejs","hash":"1b1eb4c8e163a5d909e86da76ef778948e0e0b77","modified":1735187082772},{"_id":"themes/hexo-theme-fluid/layout/_partials/post/sidebar-right.ejs","hash":"2507cdad08f61cf8c1d9b0ca7f4f1dc8c4e5841b","modified":1735187082772},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/color-schema.styl","hash":"66d5b045c0e54001d3c98c5901d72590fe08acc4","modified":1735187082780},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_archive/archive.styl","hash":"e3846fb429f6732bd15fde40f7c28b3492d786c8","modified":1735187082778},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/base.styl","hash":"cd255079553985722ee80fb1833f6507dde52194","modified":1735187082780},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/print.styl","hash":"571bd018e914bd0f7c5f89df874b5937937e5fa6","modified":1735187082781},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/inline.styl","hash":"96c3bb95dea4b3d3ecd20b810a674bfcef04870c","modified":1735187082781},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/keyframes.styl","hash":"58a7f8f2baea2d58cf5f7edfc91314ee5d7156ca","modified":1735187082781},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_links/links.styl","hash":"d3ef491fd449d89a1b95801dee788a5d9bec4320","modified":1735187082782},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_category/category-chain.styl","hash":"4263f7b930e6b57e13295d17fd3745a9e5c52494","modified":1735187082781},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_index/index.styl","hash":"bac20c8fb20276b08972df5ecc7a5850a72393f4","modified":1735187082782},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_tag/tags.styl","hash":"29e9b72cfda2f2baf9cf2597fcd7f9e66303a9bd","modified":1735187082783},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_category/category-bar.styl","hash":"f35415bd86b5c26fbc71728048d9e1481263554f","modified":1735187082781},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_category/category-list.styl","hash":"d3aeb7bf22d52d7dde59b292090ef8b46943718a","modified":1735187082781},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_post/markdown.styl","hash":"2d12f23b46d0ce07ae810bc4f5635c490a098fa4","modified":1735187082782},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_post/comment.styl","hash":"1fc96d09d52d9502e84e4e2a8d482ea45e8b81ea","modified":1735187082782},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_post/post-tag.styl","hash":"31c64c3fae4a0fc4747d8afeb72f7a9667c5326c","modified":1735187082783},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_post/highlight.styl","hash":"d73cccb65eaa804910884df17442e34736b3f4fb","modified":1735187082782},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_post/post-page.styl","hash":"6a35a450bd0a12f68fd92aac3f88b23475a98d46","modified":1735187082783},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/_widget/banner.styl","hash":"80301db38e448e40e88bb34d0128628b0809b243","modified":1735187082779},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/_widget/anchorjs.styl","hash":"26d65475b1c52a61115044db8883df6739c3a473","modified":1735187082779},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/_widget/code-widget.styl","hash":"417a7388b39c0203178b0032e151febd66a0e9f3","modified":1735187082779},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/_widget/board.styl","hash":"1068d71721baeed76bf0176f9b964d36b5764c9f","modified":1735187082779},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/_widget/copyright.styl","hash":"3ac1eb36e124adef607775aa505386d5680960e2","modified":1735187082779},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/_widget/footnote.styl","hash":"41935973a66c14ab2bea0539d4b1f15c62534fa4","modified":1735187082779},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/_widget/footer.styl","hash":"e6f5921ff9009c1853e7db30c482bc1682433ed9","modified":1735187082779},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/_widget/ngrogress.styl","hash":"48799d3148ef6493be0e05897c635124e9b05d03","modified":1735187082780},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/_widget/modal.styl","hash":"0ca6171ce262339e0e36cfea0978b554d87ae7fc","modified":1735187082780},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/_widget/header.styl","hash":"88c3c2d99a097142a87eeec0c7c65a3789f25117","modified":1735187082779},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/_widget/pagination.styl","hash":"f4ae7cbf2f10f459de7864f8e642553b587df889","modified":1735187082780},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/_widget/noscript.styl","hash":"8fad325e411bc83c8ebdc4115015477eed5f60da","modified":1735187082780},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/_widget/scroll-btn.styl","hash":"e4dbbbb1a2508a72bc04680552d7ebbea0eed0fe","modified":1735187082780},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/_widget/search.styl","hash":"1f4e678d7219815ab62de1b92ec75e021247f90b","modified":1735187082780},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/_widget/qrcode.styl","hash":"04447d3b673be84a1af1dc57933a3c41dd7c0cfe","modified":1735187082780},{"_id":"themes/hexo-theme-fluid/source/css/_pages/_base/_widget/toc.styl","hash":"5defef321e3e933fe84f3f2ca481c88f55381fb0","modified":1735187082780},{"_id":"themes/hexo-theme-fluid/source/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1735187082785},{"_id":"public/local-search.xml","hash":"3088d253c56233fefd2e0d0f74b243bbe1a3bc72","modified":1735790138697},{"_id":"public/about/index.html","hash":"0e07f087286929a70c9f654cd2aa03ee209e148f","modified":1735790138697},{"_id":"public/2025/01/02/计算机基础/计算机网络/HTTP基础03：简单的 HTTP协议/index.html","hash":"d8df905150735606e6b6d746fed03dc866d7bfef","modified":1735790138697},{"_id":"public/2024/12/31/计算机基础/计算机网络/HTTP基础02：了解Web及网络基础/index.html","hash":"453beb93a71fc8dfd3ee3d24deac3a9353b29433","modified":1735790138697},{"_id":"public/2024/12/30/人工智能/nlp/llm/源码解析：llama3源码解析-04：generation.py模块解析/index.html","hash":"5edf8bd7833fe3821b67920f407caaed7ddc4ab2","modified":1735790138697},{"_id":"public/2024/12/30/人工智能/nlp/llm/源码解析：llama3源码解析-03：model.py模块解析/index.html","hash":"0e56ca8434ad96a7b065565fa18aa5951a5592cc","modified":1735790138697},{"_id":"public/2024/12/30/计算机基础/计算机网络/HTTP基础01：HTTP协议概述/index.html","hash":"75f38f9f51da04da08139966f6434f3520c9739c","modified":1735790138697},{"_id":"public/2024/12/26/人工智能/nlp/llm/源码解析：llama3源码解析-02：tokenizer模块解析/index.html","hash":"6d00b350532ed0ef30af716260d285cd81d8ac2f","modified":1735790138697},{"_id":"public/2024/12/26/人工智能/nlp/llm/源码解析：llama3源码解析-01：整体代码结构及模块功能/index.html","hash":"0cdb2a6f8105efe33c39caafd124a0008541be90","modified":1735790138697},{"_id":"public/2024/12/20/人工智能/multi-modal/论文阅读14：MiniCPM深入解析/index.html","hash":"89dd13ea26ff7b52092c6dbb691b50f587dcc016","modified":1735790138697},{"_id":"public/2024/12/21/开发/Python/Python-004：Python 日志处理最佳实践：使用loguru模块构建高效日志系统/index.html","hash":"e04626e8721f311d8bdad5aad1f969aead6c0ddc","modified":1735790138697},{"_id":"public/2024/12/19/开发/cpp/C++001：C++右值语义详解：从基础到实战/index.html","hash":"89483dbdbfc63658db103970d1b6264da10486f4","modified":1735790138697},{"_id":"public/2024/12/18/开发/cpp/C++基础：C++常量详解/index.html","hash":"ca6b584b96ef45cd14d4a390f1e935421f94039c","modified":1735790138697},{"_id":"public/2024/12/17/人工智能/multi-modal/OCR/多模态003：OCR算法、模型综述/index.html","hash":"ccf67fb426a7a0fc487af8cf4d6489d14ef5cb0e","modified":1735790138697},{"_id":"public/2024/12/16/开发/cpp/C++基础：C++ 中的 static 关键字：深入理解与应用/index.html","hash":"91c267c966214cc91f40c939a53cf3df110741d3","modified":1735790138697},{"_id":"public/2024/12/15/开发/Python/Python-003：Python 日志处理最佳实践：使用logging模块构建高效日志系统/index.html","hash":"f49b8d3b695cfcefeae1b1850418e36973a13789","modified":1735790138697},{"_id":"public/2024/12/14/开发/Python/Python-002：python开发中常用的工具函数/index.html","hash":"1c7542d7de70dc4e5616258f2f62dc8ef4ff3d45","modified":1735790138697},{"_id":"public/2024/12/13/开发/Python/Python-001：使用xml.dom.minidom解析xml文件/index.html","hash":"fc037087e5ab084bb75bc9afed0f30885bdad81a","modified":1735790138697},{"_id":"public/2024/12/12/开发/音视频/音视频开发09：字幕介绍/index.html","hash":"7dbc6310b4055e4fd4e0d86b458350c6acc8810d","modified":1735790138697},{"_id":"public/2024/12/11/开发/音视频/音视频开发08：音视频开发基本步骤和流程/index.html","hash":"20335b67d1f5d36151ae065a133cb46509043214","modified":1735790138697},{"_id":"public/2024/12/07/人工智能/computer-vision/CV007-YOLO11详解/index.html","hash":"7968f8881bffb4fcf984278892c2769452b98cfc","modified":1735790138697},{"_id":"public/2024/12/07/人工智能/computer-vision/CV010-YOLO V10详解/index.html","hash":"b65ff223f6866269d0bf7e8d9fca16ad659b89d8","modified":1735790138697},{"_id":"public/2024/12/07/人工智能/nlp/NLP025-huggingface自定义数据集和模型下载存储目录/index.html","hash":"6a8786aad68a6911e5d35efd3937711bd52f2b1e","modified":1735790138697},{"_id":"public/2024/12/07/人工智能/computer-vision/CV008-评估 YOLO （You Only Look Once） 模型的演变：YOLO11 及其前身的全面基准研究/index.html","hash":"2e668f6549181b0ce5fa9cfea8f082ba2a433d63","modified":1735790138697},{"_id":"public/2024/12/05/开发/音视频/音视频开发01：RGB和YUV颜色模型详解/index.html","hash":"c205c7605ac5a22be0e8a7190a337616d3bb691c","modified":1735790138697},{"_id":"public/archives/index.html","hash":"e11a5acf74241b03434d7c91a0e0da5da0afa5ba","modified":1735790138697},{"_id":"public/archives/page/2/index.html","hash":"f0d6669045e26dcb93d8a8391a104c038bbdd3e9","modified":1735790138697},{"_id":"public/archives/page/3/index.html","hash":"05fa904379ff45b89e11122a34ed92f5d4bb10cf","modified":1735790138697},{"_id":"public/archives/2024/index.html","hash":"62817f3ac6b1a1d041a3a20b761888bd0079611c","modified":1735790138697},{"_id":"public/archives/2024/page/2/index.html","hash":"64f07586bd44ee8410a5741ed4866826348548b4","modified":1735790138697},{"_id":"public/archives/2024/page/3/index.html","hash":"cfbdf847c8398cca1c5e83f33ca4961fde046744","modified":1735790138697},{"_id":"public/archives/2024/12/index.html","hash":"a735d2e4e60043da510091380f2aa7fa2c9fef90","modified":1735790138697},{"_id":"public/archives/2024/12/page/2/index.html","hash":"ef5666d1a12c0aab7602933c5a1228889083b1df","modified":1735790138697},{"_id":"public/archives/2024/12/page/3/index.html","hash":"084a2418cccbd4f358c7d35c2d21d1c14d1e017e","modified":1735790138697},{"_id":"public/index.html","hash":"8848d3656cabf86d7421d13d42e8b9fcf4c88fb4","modified":1735790138697},{"_id":"public/archives/2025/index.html","hash":"0276b1f0a3663e6d6636df74d68cf63cc3f77433","modified":1735790138697},{"_id":"public/archives/2025/01/index.html","hash":"9e0973d7348b62758609988afa4fdc19d6222c62","modified":1735790138697},{"_id":"public/page/2/index.html","hash":"f7486686e6789889e48cc8fb0b1a95787dc4fe49","modified":1735790138697},{"_id":"public/page/3/index.html","hash":"654e8e564d6ff29b53c393b5f27e66278d8dadce","modified":1735790138697},{"_id":"public/categories/人工智能/index.html","hash":"406b954592658a1db9524728aba9c7aa8233c88d","modified":1735790138697},{"_id":"public/categories/开发/index.html","hash":"29b575da6b862627f8ae1a207e30fad2560a858e","modified":1735790138697},{"_id":"public/categories/人工智能/computer-vision/index.html","hash":"6fd35f16f798d7691c0e79b6e04646a9861931cc","modified":1735790138697},{"_id":"public/categories/人工智能/multi-modal/index.html","hash":"09c9de84ad8744628b6f63113de92689a7ad5a94","modified":1735790138697},{"_id":"public/categories/人工智能/nlp/index.html","hash":"2f94d5831e461ffcf016684bbfee6466c99ddfdc","modified":1735790138697},{"_id":"public/categories/开发/python/index.html","hash":"7a118b75ad90ff61f5af8ea903e08b7f477c5611","modified":1735790138697},{"_id":"public/categories/计算机基础/index.html","hash":"1987d2670502330c15ec3e38bb2afea2e125df4e","modified":1735790138697},{"_id":"public/categories/开发/cpp/index.html","hash":"f2a6e86e3b2659b7981fbb2ac609980abf957346","modified":1735790138697},{"_id":"public/categories/开发/音视频/index.html","hash":"2aeb0edb00db7b27136da5f0f76a6904f1ba1f68","modified":1735790138697},{"_id":"public/categories/人工智能/multi-modal/OCR/index.html","hash":"2a722d298629a9089b2a831ea2baca695630f1e3","modified":1735790138697},{"_id":"public/categories/计算机基础/计算机网络/index.html","hash":"a9eaeaa3a2165d308988f59af6ed62d0cc3c07d9","modified":1735790138697},{"_id":"public/categories/人工智能/nlp/llm/index.html","hash":"4b18384c52ed49af80a6a662dbc1f0895cb6d984","modified":1735790138697},{"_id":"public/categories/开发/音视频/基础/index.html","hash":"cb7c17aa909b341c96aa0f8fb762ea6ad00d411e","modified":1735790138697},{"_id":"public/tags/人工智能/index.html","hash":"9b5150bf7fa6141de444eeda9bdb5cb83df586be","modified":1735790138697},{"_id":"public/tags/yolo/index.html","hash":"b0bb877288a585c04f2cc18ce1fdf8b644e79c42","modified":1735790138697},{"_id":"public/tags/目标检测/index.html","hash":"b219b31e7271256ff29423d56f5977013e6fee16","modified":1735790138697},{"_id":"public/tags/python/index.html","hash":"8b9261c7713cf8bedd9a2a6b1d4c04630452b50c","modified":1735790138697},{"_id":"public/tags/多模态/index.html","hash":"8ecebfa250fbfba47a2f36c7d31b1c874a034131","modified":1735790138697},{"_id":"public/tags/论文阅读/index.html","hash":"de40ca6cfec38560a2759b5a973b631085329b63","modified":1735790138697},{"_id":"public/tags/huggingface/index.html","hash":"e62acb72506e4ba5e4801aa31dfc73c713677254","modified":1735790138697},{"_id":"public/tags/transformers/index.html","hash":"0434393ae600ede5dfffb05e9ac2309a44952f6d","modified":1735790138697},{"_id":"public/tags/c/index.html","hash":"da5526b7dc67cdb1b12fddf0bfc11c3c367f6524","modified":1735790138697},{"_id":"public/tags/cpp/index.html","hash":"50027f36f1b1f561f166b8e466366691ed442bb2","modified":1735790138697},{"_id":"public/tags/计算机网络/index.html","hash":"5deb45e695d75651c1ed65ad5fa1b19541715e95","modified":1735790138697},{"_id":"public/tags/计算机基础/index.html","hash":"ccd2e61b046a9cf02872e35479e0d17539880914","modified":1735790138697},{"_id":"public/tags/HTTP/index.html","hash":"258def65a85de4e9298e9cb5921477dadf3efe00","modified":1735790138697},{"_id":"public/tags/c-基础/index.html","hash":"6b2437d0f0e89a33502377cadb0c888bd6ebc828","modified":1735790138697},{"_id":"public/tags/音视频开发/index.html","hash":"c5f95378ebfe5180b0db69a6c87cb77e6a723fea","modified":1735790138697},{"_id":"public/tags/音视频基础/index.html","hash":"d637b35412f9bffa489fe1355cb998943ecada77","modified":1735790138697},{"_id":"public/tags/nlp/index.html","hash":"974f12ef0c3bd72b742457da866612232c7d4801","modified":1735790138697},{"_id":"public/tags/llm/index.html","hash":"05f4d33e8076fd1909d62ba91586cc72c23ed2a6","modified":1735790138697},{"_id":"public/tags/llama/index.html","hash":"98f5aa4c7e2a10b9547e5686fee8c508d4a908a6","modified":1735790138697},{"_id":"public/404.html","hash":"8314be3dba729156e22b9af364aec928f1275218","modified":1735790138697},{"_id":"public/tags/OCR/index.html","hash":"a98d26e724425f669928c35f4ce258d4a0e7eb78","modified":1735790138697},{"_id":"public/tags/源码解析/index.html","hash":"7d07a7eed89a73bf43eeca99eb35c5f3e4a16ac7","modified":1735790138697},{"_id":"public/tags/index.html","hash":"a10f19078d8cd8482804b9fc74526010ca781488","modified":1735790138697},{"_id":"public/links/index.html","hash":"a14ad08c0945f0243c36fb3d83a9938f6285a7e5","modified":1735790138697},{"_id":"public/categories/index.html","hash":"df18d1c52b1135ad4bd51741acc9629d3b947217","modified":1735790138697},{"_id":"public/CNAME","hash":"680e2a5454c0ae5b0b48898e1efb817bec19adf2","modified":1735790138697},{"_id":"public/img/fluid.png","hash":"64b215db2cb3af98fe639e94537cb5209f959c78","modified":1735790138697},{"_id":"public/img/loading.gif","hash":"2d2fc0f947940f98c21afafef39ecf226a2e8d55","modified":1735790138697},{"_id":"public/img/avatar.png","hash":"fe739a158cc128f70f780eb5fa96f388b81d478f","modified":1735790138697},{"_id":"public/img/daxiong.jpg","hash":"a885de1f65fab29c30a96fcf9cc251993e0483b2","modified":1735790138697},{"_id":"public/img/police_beian.png","hash":"90efded6baa2dde599a9d6b1387973e8e64923ea","modified":1735790138697},{"_id":"public/img/wechat_qrcode.jpg","hash":"793f0ffd367f69718fc66ef5750d32f4cf2e05fb","modified":1735790138697},{"_id":"public/xml/local-search.xml","hash":"85fcc23b4db654a7f91fc55b6fb0442bb3ed3a9a","modified":1735790138697},{"_id":"public/img/mao.jpg","hash":"a589716096025934b5fc6bebf07c87f314575fce","modified":1735790138697},{"_id":"public/css/highlight-dark.css","hash":"902294bada4323c0f51502d67cba8c3a0298952f","modified":1735790138697},{"_id":"public/css/highlight.css","hash":"04d4ddbb5e1d1007447c2fe293ee05aae9b9563e","modified":1735790138697},{"_id":"public/css/main.css","hash":"14ebd9b515085666cee29bbcbe362ad3604ab62a","modified":1735790138697},{"_id":"public/css/gitalk.css","hash":"a57b3cc8e04a0a4a27aefa07facf5b5e7bca0e76","modified":1735790138697},{"_id":"public/js/boot.js","hash":"38bd26c6b7acdafda86dda3560e6a3ca488d3c76","modified":1735790138697},{"_id":"public/js/leancloud.js","hash":"eff77c7a5c399fcaefda48884980571e15243fc9","modified":1735790138697},{"_id":"public/js/color-schema.js","hash":"1ef88c881b9f942deadde3d890387b94c617342a","modified":1735790138697},{"_id":"public/js/events.js","hash":"6869811f67e4c3de3edfa4b08464bb242b97a402","modified":1735790138697},{"_id":"public/js/img-lazyload.js","hash":"cbdeca434ec4da51f488c821d51b4d23c73294af","modified":1735790138697},{"_id":"public/js/local-search.js","hash":"b9945f76f8682f3ec32edfb285b26eb559f7b7e8","modified":1735790138697},{"_id":"public/js/umami-view.js","hash":"33c4b3883fa747604074ad3921606eeeaeb50716","modified":1735790138697},{"_id":"public/js/plugins.js","hash":"c34916291e392a774ff3e85c55badb83e8661297","modified":1735790138697},{"_id":"public/js/utils.js","hash":"b82e7c289a66dfd36064470fd41c0e96fc598b43","modified":1735790138697},{"_id":"public/img/default.png","hash":"167a12978d80371cf578c8a2e45c24a2eb25b6fb","modified":1735790138697}],"Category":[{"name":"人工智能","_id":"cm5esmr3d0005hghihffdgl7d"},{"name":"开发","_id":"cm5esmr3f000chghi37ze694q"},{"name":"computer-vision","parent":"cm5esmr3d0005hghihffdgl7d","_id":"cm5esmr3h000ghghi6ctc29at"},{"name":"multi-modal","parent":"cm5esmr3d0005hghihffdgl7d","_id":"cm5esmr3j000shghievwq2lnp"},{"name":"nlp","parent":"cm5esmr3d0005hghihffdgl7d","_id":"cm5esmr3o001jhghihrkf1azk"},{"name":"python","parent":"cm5esmr3f000chghi37ze694q","_id":"cm5esmr3p001qhghi0mpg4sul"},{"name":"cpp","parent":"cm5esmr3f000chghi37ze694q","_id":"cm5esmr3p001zhghie3uggp5u"},{"name":"计算机基础","_id":"cm5esmr3p0025hghi0rw5c33n"},{"name":"音视频","parent":"cm5esmr3f000chghi37ze694q","_id":"cm5esmr3q002rhghi8bhchl0y"},{"name":"OCR","parent":"cm5esmr3j000shghievwq2lnp","_id":"cm5esmr3s0038hghigzjdf17a"},{"name":"llm","parent":"cm5esmr3o001jhghihrkf1azk","_id":"cm5esmr3s003jhghi65syb47s"},{"name":"计算机网络","parent":"cm5esmr3p0025hghi0rw5c33n","_id":"cm5esmr3t003rhghi22iqc0oi"},{"name":"基础","parent":"cm5esmr3q002rhghi8bhchl0y","_id":"cm5esmr3u0046hghi5oy77hrb"}],"Data":[],"Page":[{"title":"about me","layout":"about","date":"2024-12-07T13:09:27.000Z","_content":"\n- Github: https://github.com/chongzicbo\n\n- QQ: 963342971\n\n- 公众号\n\n  ![二维码](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)\n\n  \n","source":"about/index.md","raw":"---\ntitle: about me\nlayout: about\ndate: 2024-12-07 21:09:27\n---\n\n- Github: https://github.com/chongzicbo\n\n- QQ: 963342971\n\n- 公众号\n\n  ![二维码](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)\n\n  \n","updated":"2024-12-26T04:24:42.763Z","path":"about/index.html","comments":1,"_id":"cm5esmr370000hghibhdf306w","content":"<ul>\n<li><p>Github: <a href=\"https://github.com/chongzicbo\">https://github.com/chongzicbo</a></p>\n</li>\n<li><p>QQ: 963342971</p>\n</li>\n<li><p>公众号</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"二维码\"></p>\n</li>\n</ul>\n","excerpt":"","more":"<ul>\n<li><p>Github: <a href=\"https://github.com/chongzicbo\">https://github.com/chongzicbo</a></p>\n</li>\n<li><p>QQ: 963342971</p>\n</li>\n<li><p>公众号</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"二维码\"></p>\n</li>\n</ul>\n"}],"Post":[{"title":"YOLO11 详解","date":"2024-12-07T10:30:00.000Z","_content":"\n\n\n2024 年是 YOLO 模型的一年。在 2023 年发布 Ultralytics YOLOv8 之后， YOLOv9 和 YOLOv10也在2024年发布了。但等等，这还不是结束！Ultralytics YOLO11 终于来了，在激动人心的 YOLO Vision 2024 （YV24） 活动中亮相。\n\n![](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/feature.gif)\n\nYOLO11 系列是 YOLO 系列中最先进的 （SOTA）、最轻、最高效的型号，性能优于其前代产品。它由 Ultralytics 创建，该组织发布了 YOLOv8，这是迄今为止最稳定和使用最广泛的 YOLO 变体。现在，YOLO11 将继续 YOLO 系列的传统。在本文中，我们将探讨：\n\n- **什么是 YOLO11？**\n- **YOLO11 能做什么？**\n- **YOLO11 比其他 YOLO 变体更高效吗？**\n- **YOLO11 架构有哪些改进？**\n- **YOLO11 的代码pipeline是如何工作的？**\n- **YOLO11 的基准测试**\n- **YOLO11 快速回顾**\n\n# 什么是YOLO11\n\n![](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-1.png)\n\nYOLO11 是 Ultralytics 的 YOLO 系列的最新版本。YOLO11 配备了超轻量级型号，比以前的 YOLO 更快、更高效。YOLO11 能够执行更广泛的计算机视觉任务。Ultralytics 根据大小发布了 5 个 YOLO11 模型，并在**所有任务中发布了 25 个模型**：\n\n- **YOLO11n** – Nano 适用于小型和轻量级任务。\n- **YOLO11s** – Nano 的小升级，具有一些额外的准确性。\n- **YOLO11m** – 通用型。\n- **YOLO11l** – 大，精度更高，计算量更高。\n- **YOLO11x** – 超大尺寸，可实现最大精度和性能。\n\n![](https://learnopencv.com/wp-content/uploads/2024/10/yolo11-model-table.png)\n\nYOLO11 构建在 Ultralytics YOLOv8 代码库之上，并进行了一些架构修改。它还集成了以前 YOLO（如 YOLOv9 和 YOLOv10）的新功能（改进这些功能）以提高性能。我们将在博客文章的后面部分探讨架构和代码库中的新变化。\n\n# YOLO11的应用\n\nYOLO 以其对象检测模型而闻名。但是，YOLO11 可以执行多个计算机视觉任务，例如 YOLOv8。它包括：\n\n- **对象检测**\n- **实例分段**\n- **图像分类**\n- **姿势估计**\n- **定向目标检测 （OBB）**\n\n让我们来探索所有这些。\n\n### 对象检测\n\n![yolo11-对象检测](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-object-detection.gif)\n\nYOLO11 通过将输入图像传递到 CNN 以提取特征来执行对象检测。然后，网络预测这些网格中对象的边界框和类概率。为了处理多尺度检测，使用图层来确保检测到各种大小的物体。然后使用非极大值抑制 （NMS） 来优化这些预测，以过滤掉重复或低置信度的框，从而获得更准确的对象检测。YOLO11 在 MS-COCO 数据集上进行对象检测训练，其中包括 80 个预训练类。\n\n### 实例分割\n\n![ ](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-instance-segmentation-1-1733102326734-1.png)\n\n除了检测对象之外，YOLO11 还通过添加掩码预测分支扩展到实例分割。这些模型在 MS-COCO 数据集上进行训练，其中包括 80 个预训练类。此分支为每个检测到的对象生成像素级分割掩码，使模型能够区分重叠的对象并提供其形状的精确轮廓。head 中的蒙版分支处理特征映射并输出对象蒙版，从而在识别和区分图像中的对象时实现像素级精度。\n\n### 姿势估计\n\n![YOLO11 姿势](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-pose-estimation.gif)\n\nYOLO11 通过检测和预测物体上的关键点（例如人体的关节）来执行姿态估计。关键点连接起来形成骨架结构，该结构表示姿势。这些模型在 COCO 上进行训练，其中包括一个预先训练的类“person”。\n\n在头部添加姿态估计层，并训练网络预测关键点的坐标。后处理步骤将点连接起来以形成骨架结构，从而实现实时姿势识别。\n\n### 图像分类\n\n![YOLO11 图像分类](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-image-classification.gif)\n\n对于图像分类，YOLO11 使用其深度神经网络从输入图像中提取高级特征，并将其分配给多个预定义类别之一。这些模型在 ImageNet 上进行训练，其中包括 1000 个预训练类。该网络通过多层卷积和池化处理图像，在增强基本特征的同时减少空间维度。网络顶部的分类头输出预测的类，使其适用于需要识别图像整体类别的任务。\n\n### 定向目标检测 （OBB）\n\n![YOLO11-OBB](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-obb-detection-1.gif)\n\nYOLO11 通过整合 OBB 扩展了常规对象检测，使模型能够检测和分类旋转或不规则方向的物体。这对于航空影像分析等应用程序特别有用。这些模型在 DOTAv1 上进行训练，其中包括 15 个预训练类。\n\n![YOLO11-OBB](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-obb-logic-1-1024x615.png)\n\nOBB 模型不仅输出边界框坐标，还输出旋转角度 （θ） 或四个角点。这些坐标用于创建与对象方向对齐的边界框，从而提高旋转对象的检测准确性。\n\n# YOLO11 架构和 YOLO11 中的新增功能\n\nYOLO11 架构是对 YOLOv8 架构的升级，具有一些新的集成和参数调整。在我们继续主要部分之前，您可以查看我们关于 [**YOLOv8**](https://learnopencv.com/ultralytics-yolov8/) 的详细文章以大致了解架构。现在，如果你看一下 YOLO11 的配置文件：\n\n```yaml\n# Parameters\nnc: 80 # number of classes\nscales: # model compound scaling constants, i.e. 'model=yolo11n.yaml' will call yolo11.yaml with scale 'n'\n  # [depth, width, max_channels]\n  n: [0.50, 0.25, 1024] # summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs\n  s: [0.50, 0.50, 1024] # summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs\n  m: [0.50, 1.00, 512] # summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs\n  l: [1.00, 1.00, 512] # summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs\n  x: [1.00, 1.50, 512] # summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs\n \n# YOLO11n backbone\nbackbone:\n  # [from, repeats, module, args]\n  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2\n  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4\n  - [-1, 2, C3k2, [256, False, 0.25]]\n  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8\n  - [-1, 2, C3k2, [512, False, 0.25]]\n  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16\n  - [-1, 2, C3k2, [512, True]]\n  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32\n  - [-1, 2, C3k2, [1024, True]]\n  - [-1, 1, SPPF, [1024, 5]] # 9\n  - [-1, 2, C2PSA, [1024]] # 10\n \n# YOLO11n head\nhead:\n  - [-1, 1, nn.Upsample, [None, 2, \"nearest\"]]\n  - [[-1, 6], 1, Concat, [1]] # cat backbone P4\n  - [-1, 2, C3k2, [512, False]] # 13\n \n  - [-1, 1, nn.Upsample, [None, 2, \"nearest\"]]\n  - [[-1, 4], 1, Concat, [1]] # cat backbone P3\n  - [-1, 2, C3k2, [256, False]] # 16 (P3/8-small)\n \n  - [-1, 1, Conv, [256, 3, 2]]\n  - [[-1, 13], 1, Concat, [1]] # cat head P4\n  - [-1, 2, C3k2, [512, False]] # 19 (P4/16-medium)\n \n  - [-1, 1, Conv, [512, 3, 2]]\n  - [[-1, 10], 1, Concat, [1]] # cat head P5\n  - [-1, 2, C3k2, [1024, True]] # 22 (P5/32-large)\n \n  - [[16, 19, 22], 1, Detect, [nc]] # Detect(P3, P4, P5)\n```\n\n架构级别的变化：\n\n### **1. 骨干**\n\n主干是模型的一部分，用于从多个比例的输入图像中提取特征。它通常涉及堆叠卷积层和块以创建不同分辨率的特征图。\n\n**卷积层：**YOLO11 具有类似的结构，带有初始卷积层来对图像进行下采样：\n\n```\n- [-1, 1, Conv, [64, 3, 2]] # 0-P1/2\n- [-1, 1, Conv, [128, 3, 2]] # 1-P2/4\n```\n\n- **C3k2 区块：**YOLO11 引入了 **C3k2 块，而不是 C2f**，它在计算方面效率更高。此块是 **CSP 瓶颈**的自定义实现，它使用两个卷积，而不是一个大型卷积（如 YOLOv8 中所示）。\n\n  - **CSP （Cross Stage Partial）：**CSP 网络拆分特征图并通过瓶颈层处理一部分，同时将另一部分与瓶颈的输出合并。这减少了计算负载并改善了特征表示。\n\n  ```\n  - [-1, 2, C3k2, [256, False, 0.25]]\n  ```\n\n  - C3k2 块还使用较小的内核大小（由 k2 表示），使其更快，同时保持性能。\n\n  **SPPF 和 C2PSA：**YOLO11 保留了 SPPF 块，但在 SPPF 之后添加了一个新的 **C2PSA** 块：\n\n```\n- [-1, 1, SPPF, [1024, 5]]\n- [-1, 2, C2PSA, [1024]\n```\n\n- **C2PSA （Cross Stage Partial with Spatial Attention）** 模块增强了特征图中的空间注意力，从而提高了模型对图像重要部分的关注。这使模型能够通过在空间上池化特征来更有效地关注特定的感兴趣区域。\n\n### **2. neck**\n\nneck 负责聚合来自不同分辨率的特征，并将它们传递给头部进行预测。它通常涉及来自不同级别的特征图的上采样和连接。\n\n**C3k2 区块：**YOLO11 用 **C3k2** 块替换了颈部的 C2f 块。如前所述，C3k2 是一个更快、更高效的区块。例如，在上采样和串联后，YOLO11 中的 neck 如下所示：\n\n```\n\t\n- [-1, 2, C3k2, [512, False]] # P4/16-medium\n```\n\n- 此更改提高了要素聚合过程的速度和性能。\n- **注意力机制：**YOLO11 通过 **C2PSA** 更侧重于空间注意力，这有助于模型专注于图像中的关键区域，以便更好地检测。这在 YOLOv8 中是缺失的，这使得 YOLO11 在检测较小或被遮挡的对象时可能更准确。\n\n------\n\n### **3. head**\n\nhead 是模型中负责生成最终预测的部分。在对象检测中，这通常意味着生成边界框并对这些框内的对象进行分类。\n\n**C3k2 区块：**与颈部类似，YOLO11 取代了头部的 **C2f** 块。\n\n```\n\t\n- [-1, 2, C3k2, [512, False]] # P4/16-medium\n\n```\n\n**检测层：**最终的 Detect 层与 YOLOv8 中的层相同：\n\n```\n- [[16, 19, 22], 1, Detect, [nc]] # Detect(P3, P4, P5)\n\n```\n\n使用 C3k2 块使模型在推理方面更快，在参数方面更高效。\n那么，让我们看看新块（层）在代码中的样子：\n\n------\n\n那么，让我们看看新块（层）在代码中的样子：\n\n1. **C3k2 区块（从** **blocks.py** 开始**）：**\n   - **C3k2** 是 **CSP 瓶颈**的更快、更高效的变体。它使用两个卷积而不是一个大型卷积，从而加快了特征提取速度。\n\n```\nclass C3k2(C2f):\n    def __init__(self, c1, c2, n=1, c3k=False, e=0.5, g=1, shortcut=True):\n        super().__init__(c1, c2, n, shortcut, g, e)\n        self.m = nn.ModuleList(\n            C3k(self.c, self.c, 2, shortcut, g) if c3k else Bottleneck(self.c, self.c, shortcut, g) for _ in range(n)\n        )\n```\n\n2. **C3k 块（从** **blocks.py** 开始**）**：\n\n- **C3k** 是一个更灵活的瓶颈模块，允许自定义内核大小。这对于提取图像中更详细的特征非常有用。\n\n```\nclass C3k(C3):\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, k=3):\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, k=(k, k), e=1.0) for _ in range(n)))\n```\n\n3. **C2PSA 块（从** **blocks.py** 年起**）：**\n\n- **C2PSA** （Cross Stage Partial with Spatial Attention） 增强了模型的空间注意力能力。此模块增加了对特征图的关注，帮助模型专注于图像的重要区域。\n\n```\nclass C2PSA(nn.Module):\n    def __init__(self, c1, c2, e=0.5):\n        super().__init__()\n        c_ = int(c2 * e)\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c1, c_, 1, 1)\n        self.cv3 = Conv(2 * c_, c2, 1)\n     \n    def forward(self, x):\n        return self.cv3(torch.cat((self.cv1(x), self.cv2(x)), 1))\n```\n\n# YOLO11 pipeline\n\n在 [**ultralytics**](https://github.com/ultralytics/ultralytics) GitHub 仓库中，我们将主要关注：\n\n1. **nn/modules/** 中的模块\n   - **block.py**\n   - **conv.py**\n   - **head.py**\n   - **transformer.py**\n   - **utils.py**\n2. **nn/tasks.py** 文件\n\n### 1. 代码库概述\n\n代码库被构建为多个模块，这些模块定义了 YOLO11 模型中使用的各种神经网络组件。这些组件在 nn/modules/ 目录中被组织到不同的文件中：\n\n- **block.py**：定义模型中使用的各种构建块（模块），例如瓶颈、CSP 模块和注意力机制。\n- **conv.py**：包含卷积模块，包括标准卷积、深度卷积和其他变体。\n- **head.py**：实现负责生成最终预测（例如，边界框、类概率）的模型头。\n- **transformer.py**：包括基于 transformer 的模块，用于注意力机制和高级特征提取。\n- **utils.py**：提供跨模块使用的实用程序函数和帮助程序类。\n\nnn/tasks.py 文件定义了不同的特定于任务的模型（例如，检测、分割、分类），这些模型将这些模块组合成完整的架构。\n\n### 2. nn/modules/ 中的模块\n\n如前所述，YOLO11 构建在 YOLOv8 代码库之上。因此，我们将主要关注更新的脚本：**block.py**、**conv.py** 和 **head.py** 在这里。\n\n#### **block.py**\n\n此文件定义 YOLO11 模型中使用的各种构建块。这些块是构成神经网络层的基本组件。\n\n##### **关键组件：**\n\n1. 瓶颈模块：\n   - **Bottleneck**：具有可选快捷方式连接的标准瓶颈模块。\n   - **Res**：使用一系列卷积和身份快捷方式的残差块。\n\n```\nclass Bottleneck(nn.Module):\n    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):\n        super().__init__()\n        c_ = int(c2 * e)\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_, c2, 3, 1, g=g)\n        self.add = shortcut and c1 == c2\n \n    def forward(self, x):\n        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n\n```\n\n- Bottleneck 类实现了一个 bottleneck 模块，该模块减少了通道的数量（降维），然后再次扩展它们。\n- **组件**：\n  - self.cv1：一个 1×1 卷积，用于减少通道数。\n  - self.cv2：一个 3×3 卷积，用于将通道数增加回原始通道数。\n  - self.add：一个布尔值，指示是否添加快捷方式连接。\n- **Forward Pass**：输入 x 通过 cv1 和 cv2 传递。如果 self.add 为 True，则原始输入 x 将添加到输出（残差连接）。\n\n2. CSP （Cross Stage Partial） 模块：\n\n- **BottleneckCSP：**瓶颈模块的 CSP 版本。\n- **CSPBlock**：具有多个瓶颈层的更复杂的 CSP 模块。\n\n```\nclass BottleneckCSP(nn.Module):\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        super().__init__()\n        c_ = int(c2 * e)\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = nn.Sequential(\n            *[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)]\n        )\n        self.cv3 = Conv(2 * c_, c2, 1)\n        self.add = c1 == c2\n \n    def forward(self, x):\n        y1 = self.cv2(self.cv1(x))\n        y2 = x if self.add else None\n        return self.cv3(torch.cat((y1, y2), 1)) if y2 is not None else self.cv3(y1)\n\n```\n\n- CSPBottleneck 模块将特征图分为两部分。一部分通过一系列瓶颈层，另一部分直接连接到输出，从而降低了计算成本并增强了梯度流。\n- **组件**：\n  - self.cv1：减少通道数。\n  - self.cv2：瓶颈层序列。\n  - self.cv3：合并功能并调整通道数。\n  - self.add：确定是否添加快捷方式连接。\n\n3. 其他模块：\n\n- **SPPF：**Spatial Pyramid Pooling Fast 模块，可在多个比例下执行池化。\n- **Concat**：沿指定维度连接多个 Tensor。\n\n```\nclass SPPF(nn.Module):\n    def __init__(self, c1, c2, k=5):\n        super().__init__()\n        c_ = c1 // 2\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_ * 4, c2, 1, 1)\n        self.m = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)\n \n    def forward(self, x):\n        x = self.cv1(x)\n        y1 = self.m(x)\n        y2 = self.m(y1)\n        y3 = self.m(y2)\n        return self.cv2(torch.cat([x, y1, y2, y3], 1))\n```\n\n- SPPF 模块在不同比例下执行最大池化，并将结果连接起来以捕获多个空间比例的要素。\n- **组件**：\n  - self.cv1：减少通道数。\n  - self.cv2：调整拼接后的 Channel 数。\n  - self.m：最大池化层数。\n- **Forward Pass**：输入 x 通过 cv1，然后通过三个连续的最大池化层（y1、y2、y3）。结果被连接并通过 cv2 传递。\n\n##### **了解概念：**\n\n- **瓶颈层**：用于通过在昂贵的操作之前减少通道数并在之后增加通道数来降低计算复杂性。\n- **残差连接**：通过缓解梯度消失问题来帮助训练更深的网络。\n- **CSP 架构**：将特征图分为两部分;一部分发生转换，而另一部分保持不变，从而提高学习能力并减少计算。\n\n#### **conv.py**\n\n此文件包含各种卷积模块，包括标准卷积和专用卷积。\n\n##### **关键组件：**\n\n**标准卷积模块 （Conv）：**\n\n```\nclass Conv(nn.Module):\n    default_act = nn.SiLU()  # default activation\n \n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):\n        super().__init__()\n        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)\n        self.bn = nn.BatchNorm2d(c2)\n        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()\n \n    def forward(self, x):\n        return self.act(self.bn(self.conv(x)))\n```\n\n- 实现具有批量规范化和激活的标准卷积层。\n- **组件**：\n  - self.conv：卷积层。\n  - self.bn：批量规范化。\n  - self.act：激活函数（默认为 nn.SiLU（））的\n- **Forward Pass**：应用卷积，然后进行批量规范化和激活。\n\n**深度卷积 （DWConv）：**\n\n```\nclass DWConv(Conv):\n    def __init__(self, c1, c2, k=1, s=1, d=1, act=True):\n        super().__init__(c1, c2, k, s, g=math.gcd(c1, c2), d=d, act=act)\n```\n\n- 执行深度卷积，其中每个输入通道单独卷积。\n- **组件**：\n  - 继承自 Conv。\n  - 将 groups 参数设置为 c1 和 c2 的最大公约数，从而有效地对每个通道的卷积进行分组。\n\n1. 其他卷积模块：\n   - **Conv2**：RepConv 的简化版本，用于模型压缩和加速。\n   - **GhostConv**：实现 GhostNet 的 ghost 模块，减少特性图中的冗余。\n   - **RepConv**：可重新参数化的卷积层，可以从训练模式转换为推理模式。\n\n##### **了解概念：**\n\n- **自动填充 （****autopad****）：**自动计算保持输出尺寸一致所需的填充。\n- **深度卷积和点卷积**：用于 MobileNet 架构，以减少计算，同时保持准确性。\n- **重新参数化**：RepConv 等技术通过合并层来实现高效的训练和更快的推理。\n\n#### **head.py**\n\n此文件实现了负责生成模型最终预测的 head 模块。\n\n##### **关键组件：**\n\n**检测头 （Detect）：**\n\n```\nclass Detect(nn.Module):\n    def __init__(self, nc=80, ch=()):\n        super().__init__()\n        self.nc = nc  # number of classes\n        self.nl = len(ch)  # number of detection layers\n        self.reg_max = 16  # DFL channels\n        self.no = nc + self.reg_max * 4  # number of outputs per anchor\n        self.stride = torch.zeros(self.nl)  # strides computed during build\n \n        # Define layers\n        self.cv2 = nn.ModuleList(\n            nn.Sequential(Conv(x, c2, 3), Conv(c2, c2, 3), nn.Conv2d(c2, 4 * self.reg_max, 1)) for x in ch\n        )\n        self.cv3 = nn.ModuleList(\n            nn.Sequential(\n                nn.Sequential(DWConv(x, x, 3), Conv(x, c3, 1)),\n                nn.Sequential(DWConv(c3, c3, 3), Conv(c3, c3, 1)),\n                nn.Conv2d(c3, self.nc, 1),\n            )\n            for x in ch\n        )\n        self.dfl = DFL(self.reg_max) if self.reg_max > 1 else nn.Identity()\n```\n\n- Detect 类定义输出边界框坐标和类概率的检测头。\n- **组件**：\n  - self.cv2：用于边界框回归的卷积层。\n  - self.cv3：用于分类的卷积层。\n  - self.dfl：用于边界框细化的 Distribution Focal Loss 模块。\n- **Forward Pass**：处理输入特征映射并输出边界框和类的预测。\n\n**分割 （****Segment****）：**\n\n```\nclass Segment(Detect):\n    def __init__(self, nc=80, nm=32, npr=256, ch=()):\n        super().__init__(nc, ch)\n        self.nm = nm  # number of masks\n        self.npr = npr  # number of prototypes\n        self.proto = Proto(ch[0], self.npr, self.nm)  # protos\n \n        c4 = max(ch[0] // 4, self.nm)\n        self.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, 3), Conv(c4, c4, 3), nn.Conv2d(c4, self.nm, 1)) for x in ch)\n\n```\n\n- 扩展 Detect 类以包含分段功能。\n- **组件**：\n  - self.proto：生成掩码原型。\n  - self.cv4：掩码系数的卷积层。\n- **Forward Pass**：输出边界框、类概率和掩码系数。\n\n**姿势估计头部 （Pose）：**\n\n```\nclass Pose(Detect):\n    def __init__(self, nc=80, kpt_shape=(17, 3), ch=()):\n        super().__init__(nc, ch)\n        self.kpt_shape = kpt_shape  # number of keypoints, number of dimensions\n        self.nk = kpt_shape[0] * kpt_shape[1]  # total number of keypoint outputs\n \n        c4 = max(ch[0] // 4, self.nk)\n        self.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, 3), Conv(c4, c4, 3), nn.Conv2d(c4, self.nk, 1)) for x in ch)\n\n```\n\n- 扩展了 Detect 类，用于人体姿势估计任务。\n- **组件**：\n  - self.kpt_shape：关键点的形状（关键点的数量、每个关键点的维度）。\n  - self.cv4：用于关键点回归的卷积层。\n- **Forward Pass**：输出边界框、类概率和关键点坐标。\n\n##### **了解概念：**\n\n- **模块化**：通过扩展 Detect 类，我们可以为不同的任务创建专门的 head，同时重用通用功能。\n- **无锚点检测**：现代对象检测器通常使用无锚点方法，直接预测边界框。\n- **关键点估计**：在姿势估计中，模型预测表示关节或地标的关键点。\n\n### 3. **nn/tasks.py** 文件\n\n```python\n# Ultralytics YOLO <img draggable=\"false\" role=\"img\" class=\"emoji\" alt=\"🚀\" src=\"https://s.w.org/images/core/emoji/15.0.3/svg/1f680.svg\">, AGPL-3.0 license\n \nimport contextlib\nimport pickle\nimport types\nfrom copy import deepcopy\nfrom pathlib import Path\n \nimport torch\nimport torch.nn as nn\n \n# Other imports...\n \nclass BaseModel(nn.Module):\n    \"\"\"The BaseModel class serves as a base class for all the models in the Ultralytics YOLO family.\"\"\"\n \n    def forward(self, x, *args, **kwargs):\n        \"\"\"Handles both training and inference, returns predictions or loss.\"\"\"\n        if isinstance(x, dict):\n            return self.loss(x, *args, **kwargs)  # Training: return loss\n        return self.predict(x, *args, **kwargs)  # Inference: return predictions\n \n    def predict(self, x, profile=False, visualize=False, augment=False, embed=None):\n        \"\"\"Run a forward pass through the network for inference.\"\"\"\n        if augment:\n            return self._predict_augment(x)\n        return self._predict_once(x, profile, visualize, embed)\n     \n    def fuse(self, verbose=True):\n        \"\"\"Fuses Conv and BatchNorm layers for efficiency during inference.\"\"\"\n        for m in self.model.modules():\n            if isinstance(m, (Conv, Conv2, DWConv)) and hasattr(m, \"bn\"):\n                m.conv = fuse_conv_and_bn(m.conv, m.bn)\n                delattr(m, \"bn\")\n                m.forward = m.forward_fuse  # Use the fused forward\n        return self\n     \n    # More BaseModel methods...\n \nclass DetectionModel(BaseModel):\n    \"\"\"YOLOv8 detection model.\"\"\"\n \n    def __init__(self, cfg=\"yolov8n.yaml\", ch=3, nc=None, verbose=True):\n        \"\"\"Initialize the YOLOv8 detection model with config and parameters.\"\"\"\n        super().__init__()\n        self.yaml = cfg if isinstance(cfg, dict) else yaml_model_load(cfg)\n        self.model, self.save = parse_model(deepcopy(self.yaml), ch=ch, verbose=verbose)\n        self.names = {i: f\"{i}\" for i in range(self.yaml[\"nc\"])}  # Class names\n        self.inplace = self.yaml.get(\"inplace\", True)\n \n        # Initialize strides\n        m = self.model[-1]  # Detect() layer\n        if isinstance(m, Detect):\n            s = 256  # Max stride\n            m.stride = torch.tensor([s / x.shape[-2] for x in self._predict_once(torch.zeros(1, ch, s, s))])\n            self.stride = m.stride\n            m.bias_init()  # Initialize biases\n \n    # More DetectionModel methods...\n \nclass SegmentationModel(DetectionModel):\n    \"\"\"YOLOv8 segmentation model.\"\"\"\n \n    def __init__(self, cfg=\"yolov8n-seg.yaml\", ch=3, nc=None, verbose=True):\n        \"\"\"Initialize YOLOv8 segmentation model with given config and parameters.\"\"\"\n        super().__init__(cfg=cfg, ch=ch, nc=nc, verbose=verbose)\n \n    def init_criterion(self):\n        \"\"\"Initialize the loss criterion for the SegmentationModel.\"\"\"\n        return v8SegmentationLoss(self)\n \nclass PoseModel(DetectionModel):\n    \"\"\"YOLOv8 pose model.\"\"\"\n \n    def __init__(self, cfg=\"yolov8n-pose.yaml\", ch=3, nc=None, data_kpt_shape=(None, None), verbose=True):\n        \"\"\"Initialize YOLOv8 Pose model.\"\"\"\n        if not isinstance(cfg, dict):\n            cfg = yaml_model_load(cfg)\n        if list(data_kpt_shape) != list(cfg[\"kpt_shape\"]):\n            cfg[\"kpt_shape\"] = data_kpt_shape\n        super().__init__(cfg=cfg, ch=ch, nc=nc, verbose=verbose)\n \n    def init_criterion(self):\n        \"\"\"Initialize the loss criterion for the PoseModel.\"\"\"\n        return v8PoseLoss(self)\n \nclass ClassificationModel(BaseModel):\n    \"\"\"YOLOv8 classification model.\"\"\"\n \n    def __init__(self, cfg=\"yolov8n-cls.yaml\", ch=3, nc=None, verbose=True):\n        \"\"\"Initialize the YOLOv8 classification model.\"\"\"\n        super().__init__()\n        self._from_yaml(cfg, ch, nc, verbose)\n \n    def _from_yaml(self, cfg, ch, nc, verbose):\n        \"\"\"Set YOLOv8 model configurations and define the model architecture.\"\"\"\n        self.yaml = cfg if isinstance(cfg, dict) else yaml_model_load(cfg)\n        self.model, self.save = parse_model(deepcopy(self.yaml), ch=ch, verbose=verbose)\n        self.names = {i: f\"{i}\" for i in range(self.yaml[\"nc\"])}\n        self.info()\n \n    def reshape_outputs(model, nc):\n        \"\"\"Update a classification model to match the class count (nc).\"\"\"\n        name, m = list((model.model if hasattr(model, \"model\") else model).named_children())[-1]\n        if isinstance(m, nn.Linear):\n            if m.out_features != nc:\n                setattr(model, name, nn.Linear(m.in_features, nc))\n \n    def init_criterion(self):\n        \"\"\"Initialize the loss criterion for the ClassificationModel.\"\"\"\n        return v8ClassificationLoss()\n \nclass Ensemble(nn.ModuleList):\n    \"\"\"Ensemble of models.\"\"\"\n \n    def __init__(self):\n        \"\"\"Initialize an ensemble of models.\"\"\"\n        super().__init__()\n \n    def forward(self, x, augment=False, profile=False, visualize=False):\n        \"\"\"Generate the ensemble’s final layer by combining outputs from each model.\"\"\"\n        y = [module(x, augment, profile, visualize)[0] for module in self]\n        return torch.cat(y, 2), None  # Concatenate outputs along the third dimension\n \n# Functions ------------------------------------------------------------------------------------------------------------\n \ndef parse_model(d, ch, verbose=True):\n    \"\"\"Parse a YOLO model.yaml dictionary into a PyTorch model.\"\"\"\n    import ast\n \n    max_channels = float(\"inf\")\n    nc, act, scales = (d.get(x) for x in (\"nc\", \"activation\", \"scales\"))\n    depth, width, kpt_shape = (d.get(x, 1.0) for x in (\"depth_multiple\", \"width_multiple\", \"kpt_shape\"))\n \n    # Model scaling\n    if scales:\n        scale = d.get(\"scale\")\n        if not scale:networ\n            scale = tuple(scales.keys())[0]\n            LOGGER.warning(f\"WARNING <img draggable=\"false\" role=\"img\" class=\"emoji\" alt=\"⚠️\" src=\"https://s.w.org/images/core/emoji/15.0.3/svg/26a0.svg\"> no model scale passed. Assuming scale='{scale}'.\")\n        depth, width, max_channels = scales[scale]\n \n    if act:\n        Conv.default_act = eval(act)  # redefine default activation\n        if verbose:\n            LOGGER.info(f\"Activation: {act}\")\n \n    # Logging and parsing layers\n    if verbose:\n        LOGGER.info(f\"\\n{'':>3}{'from':>20}{'n':>3}{'params':>10}  {'module':<45}{'arguments':<30}\")\n    ch = [ch]\n    layers, save, c2 = [], [], ch[-1]\n \n    for i, (f, n, m, args) in enumerate(d[\"backbone\"] + d[\"head\"]):  # from, number, module, args\n        m = globals()[m] if m in globals() else getattr(nn, m[3:], m)  # get module\n        for j, a in enumerate(args):\n            if isinstance(a, str):\n                with contextlib.suppress(ValueError):\n                    args[j] = ast.literal_eval(a) if a in locals() else a\n \n        n = max(round(n * depth), 1) if n > 1 else n  # depth gain\n        if m in {Conv, Bottleneck, C2f, C3k2, ...}:  # Module list\n            c1, c2 = ch[f], args[0]\n            c2 = make_divisible(min(c2, max_channels) * width, 8)\n            args = [c1, c2, *args[1:]]\n            if m in {C2f, C3k2, ...}:  # Repeated layers\n                args.insert(2, n)\n                n = 1\n        elif m in {Concat, Detect, ...}:  # Head layers\n            args.append([ch[x] for x in f])\n        # Append layers\n        m_ = nn.Sequential(*(m(*args) for _ in range(n))) if n > 1 else m(*args)\n        layers.append(m_)\n \n        ch.append(c2)\n        save.extend([x % i for x in ([f] if isinstance(f, int) else f) if x != -1])\n \n        if verbose:\n            LOGGER.info(f\"{i:>3}{str(f):>20}{n:>3}{sum(x.numel() for x in m_.parameters()):10.0f}  {str(m):<45}{str(args):<30}\")\n \n    return nn.Sequential(*layers), sorted(save)\n \ndef yaml_model_load(path):\n    \"\"\"Load a YOLO model from a YAML file.\"\"\"\n    path = Path(path)\n    unified_path = path.with_name(path.stem.replace(\"yolov8\", \"yolov\"))\n    yaml_file = check_yaml(str(unified_path), hard=False) or check_yaml(path)\n    d = yaml_load(yaml_file)\n    d[\"scale\"] = guess_model_scale(path)\n    d[\"yaml_file\"] = str(path)\n    return d\n \n# More utility functions...\n \ndef guess_model_scale(model_path):\n    \"\"\"Extract the scale from the YAML file.\"\"\"\n    import re\n    return re.search(r\"yolov\\d+([nslmx])\", Path(model_path).stem).group(1)\n \ndef attempt_load_weights(weights, device=None, inplace=True, fuse=False):\n    \"\"\"Loads weights for a model or an ensemble of models.\"\"\"\n    ensemble = Ensemble()\n    for w in weights if isinstance(weights, list) else [weights]:\n        ckpt, _ = torch_safe_load(w)\n        model = (ckpt.get(\"ema\") or ckpt[\"model\"]).to(device).float()\n        model = model.fuse().eval() if fuse and hasattr(model, \"fuse\") else model.eval()\n        ensemble.append(model)\n \n    return ensemble if len(ensemble) > 1 else ensemble[-1]\n \n```\n\n此 tasks.py 脚本是代码管道的核心部分;它仍然使用 YOLOv8 方法和逻辑;我们只需要将 YOLO11 模型解析到其中。此脚本专为各种计算机视觉任务而设计，例如对象检测、分割、分类、姿势估计、OBB 等。它定义了用于训练、推理和模型管理的基础模型、特定于任务的模型和效用函数。\n\n#### **关键组件：**\n\n- **Imports：**该脚本从 Ultralytics 导入 PyTorch （torch）、神经网络层 （torch.nn） 和实用函数等基本模块。一些关键导入包括：\n  - 对 **C3k2**、**C2PSA**、**C3**、**SPPF、****Concat** 等架构模块进行建模。\n  - 损失函数，如 **v8DetectionLoss**、**v8SegmentationLoss**、**v8ClassificationLoss**、**v8OBBLoss**。\n  - 各种实用程序函数，如 model_info、**fuse_conv_and_bn**、**scale_img** **time_sync**，以帮助进行模型处理、分析和评估。\n\n#### **模型基类：**\n\n1. BaseModel 类：\n   - BaseModel 用作 Ultralytics YOLO 系列中所有模型的基类。\n   - 实现如下基本方法：\n     - **forward（）：**根据输入数据处理训练和推理。\n     - **predict（）：**处理前向传递以进行推理。\n     - **fuse（）：**融合 Conv2d 和 BatchNorm2d 层以提高效率。\n     - **info（）：**提供详细的模型信息。\n   - 此类旨在通过特定于任务的模型（例如检测、分割和分类）进行扩展。\n2. **DetectionModel** **类：**\n   - 扩展 BaseModel，专门用于对象检测任务。\n   - 加载模型配置，初始化检测头（如 Detect 模块）并设置模型步幅。\n   - 它支持使用 YOLOv8 等架构的检测任务，并可以通过 **_predict_augment（）** 执行增强推理。\n\n#### **特定于任务的模型：**\n\n1. **SegmentationModel 的 SegmentationModel** **中：**\n   - 专门用于分割任务（如 YOLOv8 分割）的 DetectionModel 的子类。\n   - 初始化特定于分割的损失函数 （v8SegmentationLoss）。\n2. **PoseModel 的 PoseModel** **中：**\n   - 通过初始化具有关键点检测 （**kpt_shape**） 特定配置的模型来处理姿态估计任务。\n   - 使用 v8PoseLoss 进行特定于姿势的损失计算。\n3. **分类型号****：**\n   - 专为使用 YOLOv8 分类架构的图像分类任务而设计。\n   - 初始化和管理特定于分类的损失 （**v8ClassificationLoss**）。\n   - 它还支持重塑用于分类任务的预训练 TorchVision 模型。\n4. **OBB型号****：**\n   - 用于定向边界框 （OBB） 检测任务。\n   - 实现特定的损失函数 （**v8OBBLoss**） 来处理旋转的边界框。\n5. **世界模型****：**\n   - 此模型处理图像字幕和基于文本的识别等任务。\n   - 利用 CLIP 模型中的文本特征执行基于文本的视觉识别任务。\n   - 包括对文本嵌入 （**txt_feats**） 的特殊处理，用于字幕和世界相关任务。\n\n#### **集成模型：**\n\n1. **集成****：**\n   - 一个简单的 ensemble 类，它将多个模型合并为一个模型。\n   - 允许对不同模型的输出进行平均或串联，以提高整体性能。\n   - 对于组合多个模型的输出提供更好的预测的任务非常有用。\n\n#### **实用功能：**\n\n1. 模型加载和管理：\n   - **attempt_load_weights（）、****attempt_load_one_weight（）**：用于加载模型、管理集成模型以及处理加载预训练权重时的兼容性问题的函数。\n   - 这些功能可确保以适当的步幅、层和配置正确加载模型。\n2. 临时模块重定向：\n   - **temporary_modules（）**：一个上下文管理器，用于临时重定向模块路径，确保在模块位置更改时向后兼容。\n   - 有助于保持与旧型号版本的兼容性。\n3. **Pickle**安全处理：\n   - SafeUnpickler：一个自定义的解封器，可以安全地加载模型检查点，确保未知类被安全的占位符（SafeClass）替换，以避免在加载过程中发生崩溃。\n\n#### **模型解析：**\n\n1. **parse_model（）** **中：**\n   - 此函数将 YAML 文件中的模型配置解析为 PyTorch 模型。\n   - 它处理主干和头架构，解释每个层类型（如 Conv、SPPF、Detect），并构建最终模型。\n   - 支持各种架构，包括 C3k2、C2PSA 等 YOLO11 组件。\n2. YAML 模型加载：\n   - **yaml_model_load（）**）：从 YAML 文件加载模型配置，检测模型比例（例如 n、s、m、l、x）并相应地调整参数。\n   - **guess_model_scale（）、****guess_model_task（）**：用于根据 YAML 文件结构推断模型规模和任务的辅助函数。","source":"_posts/人工智能/computer-vision/CV007-YOLO11详解.md","raw":"---\ntitle: 'YOLO11 详解'\ndate: 2024-12-7 18:30:00\ncategories:\n  - [人工智能,computer-vision]\ntags:\n  - 人工智能\n  - yolo\n  - 目标检测\n\n---\n\n\n\n2024 年是 YOLO 模型的一年。在 2023 年发布 Ultralytics YOLOv8 之后， YOLOv9 和 YOLOv10也在2024年发布了。但等等，这还不是结束！Ultralytics YOLO11 终于来了，在激动人心的 YOLO Vision 2024 （YV24） 活动中亮相。\n\n![](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/feature.gif)\n\nYOLO11 系列是 YOLO 系列中最先进的 （SOTA）、最轻、最高效的型号，性能优于其前代产品。它由 Ultralytics 创建，该组织发布了 YOLOv8，这是迄今为止最稳定和使用最广泛的 YOLO 变体。现在，YOLO11 将继续 YOLO 系列的传统。在本文中，我们将探讨：\n\n- **什么是 YOLO11？**\n- **YOLO11 能做什么？**\n- **YOLO11 比其他 YOLO 变体更高效吗？**\n- **YOLO11 架构有哪些改进？**\n- **YOLO11 的代码pipeline是如何工作的？**\n- **YOLO11 的基准测试**\n- **YOLO11 快速回顾**\n\n# 什么是YOLO11\n\n![](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-1.png)\n\nYOLO11 是 Ultralytics 的 YOLO 系列的最新版本。YOLO11 配备了超轻量级型号，比以前的 YOLO 更快、更高效。YOLO11 能够执行更广泛的计算机视觉任务。Ultralytics 根据大小发布了 5 个 YOLO11 模型，并在**所有任务中发布了 25 个模型**：\n\n- **YOLO11n** – Nano 适用于小型和轻量级任务。\n- **YOLO11s** – Nano 的小升级，具有一些额外的准确性。\n- **YOLO11m** – 通用型。\n- **YOLO11l** – 大，精度更高，计算量更高。\n- **YOLO11x** – 超大尺寸，可实现最大精度和性能。\n\n![](https://learnopencv.com/wp-content/uploads/2024/10/yolo11-model-table.png)\n\nYOLO11 构建在 Ultralytics YOLOv8 代码库之上，并进行了一些架构修改。它还集成了以前 YOLO（如 YOLOv9 和 YOLOv10）的新功能（改进这些功能）以提高性能。我们将在博客文章的后面部分探讨架构和代码库中的新变化。\n\n# YOLO11的应用\n\nYOLO 以其对象检测模型而闻名。但是，YOLO11 可以执行多个计算机视觉任务，例如 YOLOv8。它包括：\n\n- **对象检测**\n- **实例分段**\n- **图像分类**\n- **姿势估计**\n- **定向目标检测 （OBB）**\n\n让我们来探索所有这些。\n\n### 对象检测\n\n![yolo11-对象检测](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-object-detection.gif)\n\nYOLO11 通过将输入图像传递到 CNN 以提取特征来执行对象检测。然后，网络预测这些网格中对象的边界框和类概率。为了处理多尺度检测，使用图层来确保检测到各种大小的物体。然后使用非极大值抑制 （NMS） 来优化这些预测，以过滤掉重复或低置信度的框，从而获得更准确的对象检测。YOLO11 在 MS-COCO 数据集上进行对象检测训练，其中包括 80 个预训练类。\n\n### 实例分割\n\n![ ](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-instance-segmentation-1-1733102326734-1.png)\n\n除了检测对象之外，YOLO11 还通过添加掩码预测分支扩展到实例分割。这些模型在 MS-COCO 数据集上进行训练，其中包括 80 个预训练类。此分支为每个检测到的对象生成像素级分割掩码，使模型能够区分重叠的对象并提供其形状的精确轮廓。head 中的蒙版分支处理特征映射并输出对象蒙版，从而在识别和区分图像中的对象时实现像素级精度。\n\n### 姿势估计\n\n![YOLO11 姿势](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-pose-estimation.gif)\n\nYOLO11 通过检测和预测物体上的关键点（例如人体的关节）来执行姿态估计。关键点连接起来形成骨架结构，该结构表示姿势。这些模型在 COCO 上进行训练，其中包括一个预先训练的类“person”。\n\n在头部添加姿态估计层，并训练网络预测关键点的坐标。后处理步骤将点连接起来以形成骨架结构，从而实现实时姿势识别。\n\n### 图像分类\n\n![YOLO11 图像分类](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-image-classification.gif)\n\n对于图像分类，YOLO11 使用其深度神经网络从输入图像中提取高级特征，并将其分配给多个预定义类别之一。这些模型在 ImageNet 上进行训练，其中包括 1000 个预训练类。该网络通过多层卷积和池化处理图像，在增强基本特征的同时减少空间维度。网络顶部的分类头输出预测的类，使其适用于需要识别图像整体类别的任务。\n\n### 定向目标检测 （OBB）\n\n![YOLO11-OBB](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-obb-detection-1.gif)\n\nYOLO11 通过整合 OBB 扩展了常规对象检测，使模型能够检测和分类旋转或不规则方向的物体。这对于航空影像分析等应用程序特别有用。这些模型在 DOTAv1 上进行训练，其中包括 15 个预训练类。\n\n![YOLO11-OBB](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-obb-logic-1-1024x615.png)\n\nOBB 模型不仅输出边界框坐标，还输出旋转角度 （θ） 或四个角点。这些坐标用于创建与对象方向对齐的边界框，从而提高旋转对象的检测准确性。\n\n# YOLO11 架构和 YOLO11 中的新增功能\n\nYOLO11 架构是对 YOLOv8 架构的升级，具有一些新的集成和参数调整。在我们继续主要部分之前，您可以查看我们关于 [**YOLOv8**](https://learnopencv.com/ultralytics-yolov8/) 的详细文章以大致了解架构。现在，如果你看一下 YOLO11 的配置文件：\n\n```yaml\n# Parameters\nnc: 80 # number of classes\nscales: # model compound scaling constants, i.e. 'model=yolo11n.yaml' will call yolo11.yaml with scale 'n'\n  # [depth, width, max_channels]\n  n: [0.50, 0.25, 1024] # summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs\n  s: [0.50, 0.50, 1024] # summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs\n  m: [0.50, 1.00, 512] # summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs\n  l: [1.00, 1.00, 512] # summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs\n  x: [1.00, 1.50, 512] # summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs\n \n# YOLO11n backbone\nbackbone:\n  # [from, repeats, module, args]\n  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2\n  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4\n  - [-1, 2, C3k2, [256, False, 0.25]]\n  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8\n  - [-1, 2, C3k2, [512, False, 0.25]]\n  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16\n  - [-1, 2, C3k2, [512, True]]\n  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32\n  - [-1, 2, C3k2, [1024, True]]\n  - [-1, 1, SPPF, [1024, 5]] # 9\n  - [-1, 2, C2PSA, [1024]] # 10\n \n# YOLO11n head\nhead:\n  - [-1, 1, nn.Upsample, [None, 2, \"nearest\"]]\n  - [[-1, 6], 1, Concat, [1]] # cat backbone P4\n  - [-1, 2, C3k2, [512, False]] # 13\n \n  - [-1, 1, nn.Upsample, [None, 2, \"nearest\"]]\n  - [[-1, 4], 1, Concat, [1]] # cat backbone P3\n  - [-1, 2, C3k2, [256, False]] # 16 (P3/8-small)\n \n  - [-1, 1, Conv, [256, 3, 2]]\n  - [[-1, 13], 1, Concat, [1]] # cat head P4\n  - [-1, 2, C3k2, [512, False]] # 19 (P4/16-medium)\n \n  - [-1, 1, Conv, [512, 3, 2]]\n  - [[-1, 10], 1, Concat, [1]] # cat head P5\n  - [-1, 2, C3k2, [1024, True]] # 22 (P5/32-large)\n \n  - [[16, 19, 22], 1, Detect, [nc]] # Detect(P3, P4, P5)\n```\n\n架构级别的变化：\n\n### **1. 骨干**\n\n主干是模型的一部分，用于从多个比例的输入图像中提取特征。它通常涉及堆叠卷积层和块以创建不同分辨率的特征图。\n\n**卷积层：**YOLO11 具有类似的结构，带有初始卷积层来对图像进行下采样：\n\n```\n- [-1, 1, Conv, [64, 3, 2]] # 0-P1/2\n- [-1, 1, Conv, [128, 3, 2]] # 1-P2/4\n```\n\n- **C3k2 区块：**YOLO11 引入了 **C3k2 块，而不是 C2f**，它在计算方面效率更高。此块是 **CSP 瓶颈**的自定义实现，它使用两个卷积，而不是一个大型卷积（如 YOLOv8 中所示）。\n\n  - **CSP （Cross Stage Partial）：**CSP 网络拆分特征图并通过瓶颈层处理一部分，同时将另一部分与瓶颈的输出合并。这减少了计算负载并改善了特征表示。\n\n  ```\n  - [-1, 2, C3k2, [256, False, 0.25]]\n  ```\n\n  - C3k2 块还使用较小的内核大小（由 k2 表示），使其更快，同时保持性能。\n\n  **SPPF 和 C2PSA：**YOLO11 保留了 SPPF 块，但在 SPPF 之后添加了一个新的 **C2PSA** 块：\n\n```\n- [-1, 1, SPPF, [1024, 5]]\n- [-1, 2, C2PSA, [1024]\n```\n\n- **C2PSA （Cross Stage Partial with Spatial Attention）** 模块增强了特征图中的空间注意力，从而提高了模型对图像重要部分的关注。这使模型能够通过在空间上池化特征来更有效地关注特定的感兴趣区域。\n\n### **2. neck**\n\nneck 负责聚合来自不同分辨率的特征，并将它们传递给头部进行预测。它通常涉及来自不同级别的特征图的上采样和连接。\n\n**C3k2 区块：**YOLO11 用 **C3k2** 块替换了颈部的 C2f 块。如前所述，C3k2 是一个更快、更高效的区块。例如，在上采样和串联后，YOLO11 中的 neck 如下所示：\n\n```\n\t\n- [-1, 2, C3k2, [512, False]] # P4/16-medium\n```\n\n- 此更改提高了要素聚合过程的速度和性能。\n- **注意力机制：**YOLO11 通过 **C2PSA** 更侧重于空间注意力，这有助于模型专注于图像中的关键区域，以便更好地检测。这在 YOLOv8 中是缺失的，这使得 YOLO11 在检测较小或被遮挡的对象时可能更准确。\n\n------\n\n### **3. head**\n\nhead 是模型中负责生成最终预测的部分。在对象检测中，这通常意味着生成边界框并对这些框内的对象进行分类。\n\n**C3k2 区块：**与颈部类似，YOLO11 取代了头部的 **C2f** 块。\n\n```\n\t\n- [-1, 2, C3k2, [512, False]] # P4/16-medium\n\n```\n\n**检测层：**最终的 Detect 层与 YOLOv8 中的层相同：\n\n```\n- [[16, 19, 22], 1, Detect, [nc]] # Detect(P3, P4, P5)\n\n```\n\n使用 C3k2 块使模型在推理方面更快，在参数方面更高效。\n那么，让我们看看新块（层）在代码中的样子：\n\n------\n\n那么，让我们看看新块（层）在代码中的样子：\n\n1. **C3k2 区块（从** **blocks.py** 开始**）：**\n   - **C3k2** 是 **CSP 瓶颈**的更快、更高效的变体。它使用两个卷积而不是一个大型卷积，从而加快了特征提取速度。\n\n```\nclass C3k2(C2f):\n    def __init__(self, c1, c2, n=1, c3k=False, e=0.5, g=1, shortcut=True):\n        super().__init__(c1, c2, n, shortcut, g, e)\n        self.m = nn.ModuleList(\n            C3k(self.c, self.c, 2, shortcut, g) if c3k else Bottleneck(self.c, self.c, shortcut, g) for _ in range(n)\n        )\n```\n\n2. **C3k 块（从** **blocks.py** 开始**）**：\n\n- **C3k** 是一个更灵活的瓶颈模块，允许自定义内核大小。这对于提取图像中更详细的特征非常有用。\n\n```\nclass C3k(C3):\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, k=3):\n        super().__init__(c1, c2, n, shortcut, g, e)\n        c_ = int(c2 * e)  # hidden channels\n        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, k=(k, k), e=1.0) for _ in range(n)))\n```\n\n3. **C2PSA 块（从** **blocks.py** 年起**）：**\n\n- **C2PSA** （Cross Stage Partial with Spatial Attention） 增强了模型的空间注意力能力。此模块增加了对特征图的关注，帮助模型专注于图像的重要区域。\n\n```\nclass C2PSA(nn.Module):\n    def __init__(self, c1, c2, e=0.5):\n        super().__init__()\n        c_ = int(c2 * e)\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c1, c_, 1, 1)\n        self.cv3 = Conv(2 * c_, c2, 1)\n     \n    def forward(self, x):\n        return self.cv3(torch.cat((self.cv1(x), self.cv2(x)), 1))\n```\n\n# YOLO11 pipeline\n\n在 [**ultralytics**](https://github.com/ultralytics/ultralytics) GitHub 仓库中，我们将主要关注：\n\n1. **nn/modules/** 中的模块\n   - **block.py**\n   - **conv.py**\n   - **head.py**\n   - **transformer.py**\n   - **utils.py**\n2. **nn/tasks.py** 文件\n\n### 1. 代码库概述\n\n代码库被构建为多个模块，这些模块定义了 YOLO11 模型中使用的各种神经网络组件。这些组件在 nn/modules/ 目录中被组织到不同的文件中：\n\n- **block.py**：定义模型中使用的各种构建块（模块），例如瓶颈、CSP 模块和注意力机制。\n- **conv.py**：包含卷积模块，包括标准卷积、深度卷积和其他变体。\n- **head.py**：实现负责生成最终预测（例如，边界框、类概率）的模型头。\n- **transformer.py**：包括基于 transformer 的模块，用于注意力机制和高级特征提取。\n- **utils.py**：提供跨模块使用的实用程序函数和帮助程序类。\n\nnn/tasks.py 文件定义了不同的特定于任务的模型（例如，检测、分割、分类），这些模型将这些模块组合成完整的架构。\n\n### 2. nn/modules/ 中的模块\n\n如前所述，YOLO11 构建在 YOLOv8 代码库之上。因此，我们将主要关注更新的脚本：**block.py**、**conv.py** 和 **head.py** 在这里。\n\n#### **block.py**\n\n此文件定义 YOLO11 模型中使用的各种构建块。这些块是构成神经网络层的基本组件。\n\n##### **关键组件：**\n\n1. 瓶颈模块：\n   - **Bottleneck**：具有可选快捷方式连接的标准瓶颈模块。\n   - **Res**：使用一系列卷积和身份快捷方式的残差块。\n\n```\nclass Bottleneck(nn.Module):\n    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):\n        super().__init__()\n        c_ = int(c2 * e)\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_, c2, 3, 1, g=g)\n        self.add = shortcut and c1 == c2\n \n    def forward(self, x):\n        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))\n\n```\n\n- Bottleneck 类实现了一个 bottleneck 模块，该模块减少了通道的数量（降维），然后再次扩展它们。\n- **组件**：\n  - self.cv1：一个 1×1 卷积，用于减少通道数。\n  - self.cv2：一个 3×3 卷积，用于将通道数增加回原始通道数。\n  - self.add：一个布尔值，指示是否添加快捷方式连接。\n- **Forward Pass**：输入 x 通过 cv1 和 cv2 传递。如果 self.add 为 True，则原始输入 x 将添加到输出（残差连接）。\n\n2. CSP （Cross Stage Partial） 模块：\n\n- **BottleneckCSP：**瓶颈模块的 CSP 版本。\n- **CSPBlock**：具有多个瓶颈层的更复杂的 CSP 模块。\n\n```\nclass BottleneckCSP(nn.Module):\n    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n        super().__init__()\n        c_ = int(c2 * e)\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = nn.Sequential(\n            *[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)]\n        )\n        self.cv3 = Conv(2 * c_, c2, 1)\n        self.add = c1 == c2\n \n    def forward(self, x):\n        y1 = self.cv2(self.cv1(x))\n        y2 = x if self.add else None\n        return self.cv3(torch.cat((y1, y2), 1)) if y2 is not None else self.cv3(y1)\n\n```\n\n- CSPBottleneck 模块将特征图分为两部分。一部分通过一系列瓶颈层，另一部分直接连接到输出，从而降低了计算成本并增强了梯度流。\n- **组件**：\n  - self.cv1：减少通道数。\n  - self.cv2：瓶颈层序列。\n  - self.cv3：合并功能并调整通道数。\n  - self.add：确定是否添加快捷方式连接。\n\n3. 其他模块：\n\n- **SPPF：**Spatial Pyramid Pooling Fast 模块，可在多个比例下执行池化。\n- **Concat**：沿指定维度连接多个 Tensor。\n\n```\nclass SPPF(nn.Module):\n    def __init__(self, c1, c2, k=5):\n        super().__init__()\n        c_ = c1 // 2\n        self.cv1 = Conv(c1, c_, 1, 1)\n        self.cv2 = Conv(c_ * 4, c2, 1, 1)\n        self.m = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)\n \n    def forward(self, x):\n        x = self.cv1(x)\n        y1 = self.m(x)\n        y2 = self.m(y1)\n        y3 = self.m(y2)\n        return self.cv2(torch.cat([x, y1, y2, y3], 1))\n```\n\n- SPPF 模块在不同比例下执行最大池化，并将结果连接起来以捕获多个空间比例的要素。\n- **组件**：\n  - self.cv1：减少通道数。\n  - self.cv2：调整拼接后的 Channel 数。\n  - self.m：最大池化层数。\n- **Forward Pass**：输入 x 通过 cv1，然后通过三个连续的最大池化层（y1、y2、y3）。结果被连接并通过 cv2 传递。\n\n##### **了解概念：**\n\n- **瓶颈层**：用于通过在昂贵的操作之前减少通道数并在之后增加通道数来降低计算复杂性。\n- **残差连接**：通过缓解梯度消失问题来帮助训练更深的网络。\n- **CSP 架构**：将特征图分为两部分;一部分发生转换，而另一部分保持不变，从而提高学习能力并减少计算。\n\n#### **conv.py**\n\n此文件包含各种卷积模块，包括标准卷积和专用卷积。\n\n##### **关键组件：**\n\n**标准卷积模块 （Conv）：**\n\n```\nclass Conv(nn.Module):\n    default_act = nn.SiLU()  # default activation\n \n    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, d=1, act=True):\n        super().__init__()\n        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), groups=g, dilation=d, bias=False)\n        self.bn = nn.BatchNorm2d(c2)\n        self.act = self.default_act if act is True else act if isinstance(act, nn.Module) else nn.Identity()\n \n    def forward(self, x):\n        return self.act(self.bn(self.conv(x)))\n```\n\n- 实现具有批量规范化和激活的标准卷积层。\n- **组件**：\n  - self.conv：卷积层。\n  - self.bn：批量规范化。\n  - self.act：激活函数（默认为 nn.SiLU（））的\n- **Forward Pass**：应用卷积，然后进行批量规范化和激活。\n\n**深度卷积 （DWConv）：**\n\n```\nclass DWConv(Conv):\n    def __init__(self, c1, c2, k=1, s=1, d=1, act=True):\n        super().__init__(c1, c2, k, s, g=math.gcd(c1, c2), d=d, act=act)\n```\n\n- 执行深度卷积，其中每个输入通道单独卷积。\n- **组件**：\n  - 继承自 Conv。\n  - 将 groups 参数设置为 c1 和 c2 的最大公约数，从而有效地对每个通道的卷积进行分组。\n\n1. 其他卷积模块：\n   - **Conv2**：RepConv 的简化版本，用于模型压缩和加速。\n   - **GhostConv**：实现 GhostNet 的 ghost 模块，减少特性图中的冗余。\n   - **RepConv**：可重新参数化的卷积层，可以从训练模式转换为推理模式。\n\n##### **了解概念：**\n\n- **自动填充 （****autopad****）：**自动计算保持输出尺寸一致所需的填充。\n- **深度卷积和点卷积**：用于 MobileNet 架构，以减少计算，同时保持准确性。\n- **重新参数化**：RepConv 等技术通过合并层来实现高效的训练和更快的推理。\n\n#### **head.py**\n\n此文件实现了负责生成模型最终预测的 head 模块。\n\n##### **关键组件：**\n\n**检测头 （Detect）：**\n\n```\nclass Detect(nn.Module):\n    def __init__(self, nc=80, ch=()):\n        super().__init__()\n        self.nc = nc  # number of classes\n        self.nl = len(ch)  # number of detection layers\n        self.reg_max = 16  # DFL channels\n        self.no = nc + self.reg_max * 4  # number of outputs per anchor\n        self.stride = torch.zeros(self.nl)  # strides computed during build\n \n        # Define layers\n        self.cv2 = nn.ModuleList(\n            nn.Sequential(Conv(x, c2, 3), Conv(c2, c2, 3), nn.Conv2d(c2, 4 * self.reg_max, 1)) for x in ch\n        )\n        self.cv3 = nn.ModuleList(\n            nn.Sequential(\n                nn.Sequential(DWConv(x, x, 3), Conv(x, c3, 1)),\n                nn.Sequential(DWConv(c3, c3, 3), Conv(c3, c3, 1)),\n                nn.Conv2d(c3, self.nc, 1),\n            )\n            for x in ch\n        )\n        self.dfl = DFL(self.reg_max) if self.reg_max > 1 else nn.Identity()\n```\n\n- Detect 类定义输出边界框坐标和类概率的检测头。\n- **组件**：\n  - self.cv2：用于边界框回归的卷积层。\n  - self.cv3：用于分类的卷积层。\n  - self.dfl：用于边界框细化的 Distribution Focal Loss 模块。\n- **Forward Pass**：处理输入特征映射并输出边界框和类的预测。\n\n**分割 （****Segment****）：**\n\n```\nclass Segment(Detect):\n    def __init__(self, nc=80, nm=32, npr=256, ch=()):\n        super().__init__(nc, ch)\n        self.nm = nm  # number of masks\n        self.npr = npr  # number of prototypes\n        self.proto = Proto(ch[0], self.npr, self.nm)  # protos\n \n        c4 = max(ch[0] // 4, self.nm)\n        self.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, 3), Conv(c4, c4, 3), nn.Conv2d(c4, self.nm, 1)) for x in ch)\n\n```\n\n- 扩展 Detect 类以包含分段功能。\n- **组件**：\n  - self.proto：生成掩码原型。\n  - self.cv4：掩码系数的卷积层。\n- **Forward Pass**：输出边界框、类概率和掩码系数。\n\n**姿势估计头部 （Pose）：**\n\n```\nclass Pose(Detect):\n    def __init__(self, nc=80, kpt_shape=(17, 3), ch=()):\n        super().__init__(nc, ch)\n        self.kpt_shape = kpt_shape  # number of keypoints, number of dimensions\n        self.nk = kpt_shape[0] * kpt_shape[1]  # total number of keypoint outputs\n \n        c4 = max(ch[0] // 4, self.nk)\n        self.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, 3), Conv(c4, c4, 3), nn.Conv2d(c4, self.nk, 1)) for x in ch)\n\n```\n\n- 扩展了 Detect 类，用于人体姿势估计任务。\n- **组件**：\n  - self.kpt_shape：关键点的形状（关键点的数量、每个关键点的维度）。\n  - self.cv4：用于关键点回归的卷积层。\n- **Forward Pass**：输出边界框、类概率和关键点坐标。\n\n##### **了解概念：**\n\n- **模块化**：通过扩展 Detect 类，我们可以为不同的任务创建专门的 head，同时重用通用功能。\n- **无锚点检测**：现代对象检测器通常使用无锚点方法，直接预测边界框。\n- **关键点估计**：在姿势估计中，模型预测表示关节或地标的关键点。\n\n### 3. **nn/tasks.py** 文件\n\n```python\n# Ultralytics YOLO <img draggable=\"false\" role=\"img\" class=\"emoji\" alt=\"🚀\" src=\"https://s.w.org/images/core/emoji/15.0.3/svg/1f680.svg\">, AGPL-3.0 license\n \nimport contextlib\nimport pickle\nimport types\nfrom copy import deepcopy\nfrom pathlib import Path\n \nimport torch\nimport torch.nn as nn\n \n# Other imports...\n \nclass BaseModel(nn.Module):\n    \"\"\"The BaseModel class serves as a base class for all the models in the Ultralytics YOLO family.\"\"\"\n \n    def forward(self, x, *args, **kwargs):\n        \"\"\"Handles both training and inference, returns predictions or loss.\"\"\"\n        if isinstance(x, dict):\n            return self.loss(x, *args, **kwargs)  # Training: return loss\n        return self.predict(x, *args, **kwargs)  # Inference: return predictions\n \n    def predict(self, x, profile=False, visualize=False, augment=False, embed=None):\n        \"\"\"Run a forward pass through the network for inference.\"\"\"\n        if augment:\n            return self._predict_augment(x)\n        return self._predict_once(x, profile, visualize, embed)\n     \n    def fuse(self, verbose=True):\n        \"\"\"Fuses Conv and BatchNorm layers for efficiency during inference.\"\"\"\n        for m in self.model.modules():\n            if isinstance(m, (Conv, Conv2, DWConv)) and hasattr(m, \"bn\"):\n                m.conv = fuse_conv_and_bn(m.conv, m.bn)\n                delattr(m, \"bn\")\n                m.forward = m.forward_fuse  # Use the fused forward\n        return self\n     \n    # More BaseModel methods...\n \nclass DetectionModel(BaseModel):\n    \"\"\"YOLOv8 detection model.\"\"\"\n \n    def __init__(self, cfg=\"yolov8n.yaml\", ch=3, nc=None, verbose=True):\n        \"\"\"Initialize the YOLOv8 detection model with config and parameters.\"\"\"\n        super().__init__()\n        self.yaml = cfg if isinstance(cfg, dict) else yaml_model_load(cfg)\n        self.model, self.save = parse_model(deepcopy(self.yaml), ch=ch, verbose=verbose)\n        self.names = {i: f\"{i}\" for i in range(self.yaml[\"nc\"])}  # Class names\n        self.inplace = self.yaml.get(\"inplace\", True)\n \n        # Initialize strides\n        m = self.model[-1]  # Detect() layer\n        if isinstance(m, Detect):\n            s = 256  # Max stride\n            m.stride = torch.tensor([s / x.shape[-2] for x in self._predict_once(torch.zeros(1, ch, s, s))])\n            self.stride = m.stride\n            m.bias_init()  # Initialize biases\n \n    # More DetectionModel methods...\n \nclass SegmentationModel(DetectionModel):\n    \"\"\"YOLOv8 segmentation model.\"\"\"\n \n    def __init__(self, cfg=\"yolov8n-seg.yaml\", ch=3, nc=None, verbose=True):\n        \"\"\"Initialize YOLOv8 segmentation model with given config and parameters.\"\"\"\n        super().__init__(cfg=cfg, ch=ch, nc=nc, verbose=verbose)\n \n    def init_criterion(self):\n        \"\"\"Initialize the loss criterion for the SegmentationModel.\"\"\"\n        return v8SegmentationLoss(self)\n \nclass PoseModel(DetectionModel):\n    \"\"\"YOLOv8 pose model.\"\"\"\n \n    def __init__(self, cfg=\"yolov8n-pose.yaml\", ch=3, nc=None, data_kpt_shape=(None, None), verbose=True):\n        \"\"\"Initialize YOLOv8 Pose model.\"\"\"\n        if not isinstance(cfg, dict):\n            cfg = yaml_model_load(cfg)\n        if list(data_kpt_shape) != list(cfg[\"kpt_shape\"]):\n            cfg[\"kpt_shape\"] = data_kpt_shape\n        super().__init__(cfg=cfg, ch=ch, nc=nc, verbose=verbose)\n \n    def init_criterion(self):\n        \"\"\"Initialize the loss criterion for the PoseModel.\"\"\"\n        return v8PoseLoss(self)\n \nclass ClassificationModel(BaseModel):\n    \"\"\"YOLOv8 classification model.\"\"\"\n \n    def __init__(self, cfg=\"yolov8n-cls.yaml\", ch=3, nc=None, verbose=True):\n        \"\"\"Initialize the YOLOv8 classification model.\"\"\"\n        super().__init__()\n        self._from_yaml(cfg, ch, nc, verbose)\n \n    def _from_yaml(self, cfg, ch, nc, verbose):\n        \"\"\"Set YOLOv8 model configurations and define the model architecture.\"\"\"\n        self.yaml = cfg if isinstance(cfg, dict) else yaml_model_load(cfg)\n        self.model, self.save = parse_model(deepcopy(self.yaml), ch=ch, verbose=verbose)\n        self.names = {i: f\"{i}\" for i in range(self.yaml[\"nc\"])}\n        self.info()\n \n    def reshape_outputs(model, nc):\n        \"\"\"Update a classification model to match the class count (nc).\"\"\"\n        name, m = list((model.model if hasattr(model, \"model\") else model).named_children())[-1]\n        if isinstance(m, nn.Linear):\n            if m.out_features != nc:\n                setattr(model, name, nn.Linear(m.in_features, nc))\n \n    def init_criterion(self):\n        \"\"\"Initialize the loss criterion for the ClassificationModel.\"\"\"\n        return v8ClassificationLoss()\n \nclass Ensemble(nn.ModuleList):\n    \"\"\"Ensemble of models.\"\"\"\n \n    def __init__(self):\n        \"\"\"Initialize an ensemble of models.\"\"\"\n        super().__init__()\n \n    def forward(self, x, augment=False, profile=False, visualize=False):\n        \"\"\"Generate the ensemble’s final layer by combining outputs from each model.\"\"\"\n        y = [module(x, augment, profile, visualize)[0] for module in self]\n        return torch.cat(y, 2), None  # Concatenate outputs along the third dimension\n \n# Functions ------------------------------------------------------------------------------------------------------------\n \ndef parse_model(d, ch, verbose=True):\n    \"\"\"Parse a YOLO model.yaml dictionary into a PyTorch model.\"\"\"\n    import ast\n \n    max_channels = float(\"inf\")\n    nc, act, scales = (d.get(x) for x in (\"nc\", \"activation\", \"scales\"))\n    depth, width, kpt_shape = (d.get(x, 1.0) for x in (\"depth_multiple\", \"width_multiple\", \"kpt_shape\"))\n \n    # Model scaling\n    if scales:\n        scale = d.get(\"scale\")\n        if not scale:networ\n            scale = tuple(scales.keys())[0]\n            LOGGER.warning(f\"WARNING <img draggable=\"false\" role=\"img\" class=\"emoji\" alt=\"⚠️\" src=\"https://s.w.org/images/core/emoji/15.0.3/svg/26a0.svg\"> no model scale passed. Assuming scale='{scale}'.\")\n        depth, width, max_channels = scales[scale]\n \n    if act:\n        Conv.default_act = eval(act)  # redefine default activation\n        if verbose:\n            LOGGER.info(f\"Activation: {act}\")\n \n    # Logging and parsing layers\n    if verbose:\n        LOGGER.info(f\"\\n{'':>3}{'from':>20}{'n':>3}{'params':>10}  {'module':<45}{'arguments':<30}\")\n    ch = [ch]\n    layers, save, c2 = [], [], ch[-1]\n \n    for i, (f, n, m, args) in enumerate(d[\"backbone\"] + d[\"head\"]):  # from, number, module, args\n        m = globals()[m] if m in globals() else getattr(nn, m[3:], m)  # get module\n        for j, a in enumerate(args):\n            if isinstance(a, str):\n                with contextlib.suppress(ValueError):\n                    args[j] = ast.literal_eval(a) if a in locals() else a\n \n        n = max(round(n * depth), 1) if n > 1 else n  # depth gain\n        if m in {Conv, Bottleneck, C2f, C3k2, ...}:  # Module list\n            c1, c2 = ch[f], args[0]\n            c2 = make_divisible(min(c2, max_channels) * width, 8)\n            args = [c1, c2, *args[1:]]\n            if m in {C2f, C3k2, ...}:  # Repeated layers\n                args.insert(2, n)\n                n = 1\n        elif m in {Concat, Detect, ...}:  # Head layers\n            args.append([ch[x] for x in f])\n        # Append layers\n        m_ = nn.Sequential(*(m(*args) for _ in range(n))) if n > 1 else m(*args)\n        layers.append(m_)\n \n        ch.append(c2)\n        save.extend([x % i for x in ([f] if isinstance(f, int) else f) if x != -1])\n \n        if verbose:\n            LOGGER.info(f\"{i:>3}{str(f):>20}{n:>3}{sum(x.numel() for x in m_.parameters()):10.0f}  {str(m):<45}{str(args):<30}\")\n \n    return nn.Sequential(*layers), sorted(save)\n \ndef yaml_model_load(path):\n    \"\"\"Load a YOLO model from a YAML file.\"\"\"\n    path = Path(path)\n    unified_path = path.with_name(path.stem.replace(\"yolov8\", \"yolov\"))\n    yaml_file = check_yaml(str(unified_path), hard=False) or check_yaml(path)\n    d = yaml_load(yaml_file)\n    d[\"scale\"] = guess_model_scale(path)\n    d[\"yaml_file\"] = str(path)\n    return d\n \n# More utility functions...\n \ndef guess_model_scale(model_path):\n    \"\"\"Extract the scale from the YAML file.\"\"\"\n    import re\n    return re.search(r\"yolov\\d+([nslmx])\", Path(model_path).stem).group(1)\n \ndef attempt_load_weights(weights, device=None, inplace=True, fuse=False):\n    \"\"\"Loads weights for a model or an ensemble of models.\"\"\"\n    ensemble = Ensemble()\n    for w in weights if isinstance(weights, list) else [weights]:\n        ckpt, _ = torch_safe_load(w)\n        model = (ckpt.get(\"ema\") or ckpt[\"model\"]).to(device).float()\n        model = model.fuse().eval() if fuse and hasattr(model, \"fuse\") else model.eval()\n        ensemble.append(model)\n \n    return ensemble if len(ensemble) > 1 else ensemble[-1]\n \n```\n\n此 tasks.py 脚本是代码管道的核心部分;它仍然使用 YOLOv8 方法和逻辑;我们只需要将 YOLO11 模型解析到其中。此脚本专为各种计算机视觉任务而设计，例如对象检测、分割、分类、姿势估计、OBB 等。它定义了用于训练、推理和模型管理的基础模型、特定于任务的模型和效用函数。\n\n#### **关键组件：**\n\n- **Imports：**该脚本从 Ultralytics 导入 PyTorch （torch）、神经网络层 （torch.nn） 和实用函数等基本模块。一些关键导入包括：\n  - 对 **C3k2**、**C2PSA**、**C3**、**SPPF、****Concat** 等架构模块进行建模。\n  - 损失函数，如 **v8DetectionLoss**、**v8SegmentationLoss**、**v8ClassificationLoss**、**v8OBBLoss**。\n  - 各种实用程序函数，如 model_info、**fuse_conv_and_bn**、**scale_img** **time_sync**，以帮助进行模型处理、分析和评估。\n\n#### **模型基类：**\n\n1. BaseModel 类：\n   - BaseModel 用作 Ultralytics YOLO 系列中所有模型的基类。\n   - 实现如下基本方法：\n     - **forward（）：**根据输入数据处理训练和推理。\n     - **predict（）：**处理前向传递以进行推理。\n     - **fuse（）：**融合 Conv2d 和 BatchNorm2d 层以提高效率。\n     - **info（）：**提供详细的模型信息。\n   - 此类旨在通过特定于任务的模型（例如检测、分割和分类）进行扩展。\n2. **DetectionModel** **类：**\n   - 扩展 BaseModel，专门用于对象检测任务。\n   - 加载模型配置，初始化检测头（如 Detect 模块）并设置模型步幅。\n   - 它支持使用 YOLOv8 等架构的检测任务，并可以通过 **_predict_augment（）** 执行增强推理。\n\n#### **特定于任务的模型：**\n\n1. **SegmentationModel 的 SegmentationModel** **中：**\n   - 专门用于分割任务（如 YOLOv8 分割）的 DetectionModel 的子类。\n   - 初始化特定于分割的损失函数 （v8SegmentationLoss）。\n2. **PoseModel 的 PoseModel** **中：**\n   - 通过初始化具有关键点检测 （**kpt_shape**） 特定配置的模型来处理姿态估计任务。\n   - 使用 v8PoseLoss 进行特定于姿势的损失计算。\n3. **分类型号****：**\n   - 专为使用 YOLOv8 分类架构的图像分类任务而设计。\n   - 初始化和管理特定于分类的损失 （**v8ClassificationLoss**）。\n   - 它还支持重塑用于分类任务的预训练 TorchVision 模型。\n4. **OBB型号****：**\n   - 用于定向边界框 （OBB） 检测任务。\n   - 实现特定的损失函数 （**v8OBBLoss**） 来处理旋转的边界框。\n5. **世界模型****：**\n   - 此模型处理图像字幕和基于文本的识别等任务。\n   - 利用 CLIP 模型中的文本特征执行基于文本的视觉识别任务。\n   - 包括对文本嵌入 （**txt_feats**） 的特殊处理，用于字幕和世界相关任务。\n\n#### **集成模型：**\n\n1. **集成****：**\n   - 一个简单的 ensemble 类，它将多个模型合并为一个模型。\n   - 允许对不同模型的输出进行平均或串联，以提高整体性能。\n   - 对于组合多个模型的输出提供更好的预测的任务非常有用。\n\n#### **实用功能：**\n\n1. 模型加载和管理：\n   - **attempt_load_weights（）、****attempt_load_one_weight（）**：用于加载模型、管理集成模型以及处理加载预训练权重时的兼容性问题的函数。\n   - 这些功能可确保以适当的步幅、层和配置正确加载模型。\n2. 临时模块重定向：\n   - **temporary_modules（）**：一个上下文管理器，用于临时重定向模块路径，确保在模块位置更改时向后兼容。\n   - 有助于保持与旧型号版本的兼容性。\n3. **Pickle**安全处理：\n   - SafeUnpickler：一个自定义的解封器，可以安全地加载模型检查点，确保未知类被安全的占位符（SafeClass）替换，以避免在加载过程中发生崩溃。\n\n#### **模型解析：**\n\n1. **parse_model（）** **中：**\n   - 此函数将 YAML 文件中的模型配置解析为 PyTorch 模型。\n   - 它处理主干和头架构，解释每个层类型（如 Conv、SPPF、Detect），并构建最终模型。\n   - 支持各种架构，包括 C3k2、C2PSA 等 YOLO11 组件。\n2. YAML 模型加载：\n   - **yaml_model_load（）**）：从 YAML 文件加载模型配置，检测模型比例（例如 n、s、m、l、x）并相应地调整参数。\n   - **guess_model_scale（）、****guess_model_task（）**：用于根据 YAML 文件结构推断模型规模和任务的辅助函数。","slug":"人工智能/computer-vision/CV007-YOLO11详解","published":1,"updated":"2024-12-26T04:24:42.759Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr380001hghi7d0f4grd","content":"<p>2024 年是 YOLO 模型的一年。在 2023 年发布 Ultralytics YOLOv8 之后， YOLOv9 和 YOLOv10也在2024年发布了。但等等，这还不是结束！Ultralytics YOLO11 终于来了，在激动人心的 YOLO Vision 2024 （YV24） 活动中亮相。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/feature.gif\"></p>\n<p>YOLO11 系列是 YOLO 系列中最先进的 （SOTA）、最轻、最高效的型号，性能优于其前代产品。它由 Ultralytics 创建，该组织发布了 YOLOv8，这是迄今为止最稳定和使用最广泛的 YOLO 变体。现在，YOLO11 将继续 YOLO 系列的传统。在本文中，我们将探讨：</p>\n<ul>\n<li><strong>什么是 YOLO11？</strong></li>\n<li><strong>YOLO11 能做什么？</strong></li>\n<li><strong>YOLO11 比其他 YOLO 变体更高效吗？</strong></li>\n<li><strong>YOLO11 架构有哪些改进？</strong></li>\n<li><strong>YOLO11 的代码pipeline是如何工作的？</strong></li>\n<li><strong>YOLO11 的基准测试</strong></li>\n<li><strong>YOLO11 快速回顾</strong></li>\n</ul>\n<h1 id=\"什么是YOLO11\"><a href=\"#什么是YOLO11\" class=\"headerlink\" title=\"什么是YOLO11\"></a>什么是YOLO11</h1><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-1.png\"></p>\n<p>YOLO11 是 Ultralytics 的 YOLO 系列的最新版本。YOLO11 配备了超轻量级型号，比以前的 YOLO 更快、更高效。YOLO11 能够执行更广泛的计算机视觉任务。Ultralytics 根据大小发布了 5 个 YOLO11 模型，并在<strong>所有任务中发布了 25 个模型</strong>：</p>\n<ul>\n<li><strong>YOLO11n</strong> – Nano 适用于小型和轻量级任务。</li>\n<li><strong>YOLO11s</strong> – Nano 的小升级，具有一些额外的准确性。</li>\n<li><strong>YOLO11m</strong> – 通用型。</li>\n<li><strong>YOLO11l</strong> – 大，精度更高，计算量更高。</li>\n<li><strong>YOLO11x</strong> – 超大尺寸，可实现最大精度和性能。</li>\n</ul>\n<p><img src=\"https://learnopencv.com/wp-content/uploads/2024/10/yolo11-model-table.png\"></p>\n<p>YOLO11 构建在 Ultralytics YOLOv8 代码库之上，并进行了一些架构修改。它还集成了以前 YOLO（如 YOLOv9 和 YOLOv10）的新功能（改进这些功能）以提高性能。我们将在博客文章的后面部分探讨架构和代码库中的新变化。</p>\n<h1 id=\"YOLO11的应用\"><a href=\"#YOLO11的应用\" class=\"headerlink\" title=\"YOLO11的应用\"></a>YOLO11的应用</h1><p>YOLO 以其对象检测模型而闻名。但是，YOLO11 可以执行多个计算机视觉任务，例如 YOLOv8。它包括：</p>\n<ul>\n<li><strong>对象检测</strong></li>\n<li><strong>实例分段</strong></li>\n<li><strong>图像分类</strong></li>\n<li><strong>姿势估计</strong></li>\n<li><strong>定向目标检测 （OBB）</strong></li>\n</ul>\n<p>让我们来探索所有这些。</p>\n<h3 id=\"对象检测\"><a href=\"#对象检测\" class=\"headerlink\" title=\"对象检测\"></a>对象检测</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-object-detection.gif\" alt=\"yolo11-对象检测\"></p>\n<p>YOLO11 通过将输入图像传递到 CNN 以提取特征来执行对象检测。然后，网络预测这些网格中对象的边界框和类概率。为了处理多尺度检测，使用图层来确保检测到各种大小的物体。然后使用非极大值抑制 （NMS） 来优化这些预测，以过滤掉重复或低置信度的框，从而获得更准确的对象检测。YOLO11 在 MS-COCO 数据集上进行对象检测训练，其中包括 80 个预训练类。</p>\n<h3 id=\"实例分割\"><a href=\"#实例分割\" class=\"headerlink\" title=\"实例分割\"></a>实例分割</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-instance-segmentation-1-1733102326734-1.png\" alt=\" \"></p>\n<p>除了检测对象之外，YOLO11 还通过添加掩码预测分支扩展到实例分割。这些模型在 MS-COCO 数据集上进行训练，其中包括 80 个预训练类。此分支为每个检测到的对象生成像素级分割掩码，使模型能够区分重叠的对象并提供其形状的精确轮廓。head 中的蒙版分支处理特征映射并输出对象蒙版，从而在识别和区分图像中的对象时实现像素级精度。</p>\n<h3 id=\"姿势估计\"><a href=\"#姿势估计\" class=\"headerlink\" title=\"姿势估计\"></a>姿势估计</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-pose-estimation.gif\" alt=\"YOLO11 姿势\"></p>\n<p>YOLO11 通过检测和预测物体上的关键点（例如人体的关节）来执行姿态估计。关键点连接起来形成骨架结构，该结构表示姿势。这些模型在 COCO 上进行训练，其中包括一个预先训练的类“person”。</p>\n<p>在头部添加姿态估计层，并训练网络预测关键点的坐标。后处理步骤将点连接起来以形成骨架结构，从而实现实时姿势识别。</p>\n<h3 id=\"图像分类\"><a href=\"#图像分类\" class=\"headerlink\" title=\"图像分类\"></a>图像分类</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-image-classification.gif\" alt=\"YOLO11 图像分类\"></p>\n<p>对于图像分类，YOLO11 使用其深度神经网络从输入图像中提取高级特征，并将其分配给多个预定义类别之一。这些模型在 ImageNet 上进行训练，其中包括 1000 个预训练类。该网络通过多层卷积和池化处理图像，在增强基本特征的同时减少空间维度。网络顶部的分类头输出预测的类，使其适用于需要识别图像整体类别的任务。</p>\n<h3 id=\"定向目标检测-（OBB）\"><a href=\"#定向目标检测-（OBB）\" class=\"headerlink\" title=\"定向目标检测 （OBB）\"></a>定向目标检测 （OBB）</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-obb-detection-1.gif\" alt=\"YOLO11-OBB\"></p>\n<p>YOLO11 通过整合 OBB 扩展了常规对象检测，使模型能够检测和分类旋转或不规则方向的物体。这对于航空影像分析等应用程序特别有用。这些模型在 DOTAv1 上进行训练，其中包括 15 个预训练类。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-obb-logic-1-1024x615.png\" alt=\"YOLO11-OBB\"></p>\n<p>OBB 模型不仅输出边界框坐标，还输出旋转角度 （θ） 或四个角点。这些坐标用于创建与对象方向对齐的边界框，从而提高旋转对象的检测准确性。</p>\n<h1 id=\"YOLO11-架构和-YOLO11-中的新增功能\"><a href=\"#YOLO11-架构和-YOLO11-中的新增功能\" class=\"headerlink\" title=\"YOLO11 架构和 YOLO11 中的新增功能\"></a>YOLO11 架构和 YOLO11 中的新增功能</h1><p>YOLO11 架构是对 YOLOv8 架构的升级，具有一些新的集成和参数调整。在我们继续主要部分之前，您可以查看我们关于 <a href=\"https://learnopencv.com/ultralytics-yolov8/\"><strong>YOLOv8</strong></a> 的详细文章以大致了解架构。现在，如果你看一下 YOLO11 的配置文件：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-comment\"># Parameters</span><br><span class=\"hljs-attr\">nc:</span> <span class=\"hljs-number\">80</span> <span class=\"hljs-comment\"># number of classes</span><br><span class=\"hljs-attr\">scales:</span> <span class=\"hljs-comment\"># model compound scaling constants, i.e. &#x27;model=yolo11n.yaml&#x27; will call yolo11.yaml with scale &#x27;n&#x27;</span><br>  <span class=\"hljs-comment\"># [depth, width, max_channels]</span><br>  <span class=\"hljs-attr\">n:</span> [<span class=\"hljs-number\">0.50</span>, <span class=\"hljs-number\">0.25</span>, <span class=\"hljs-number\">1024</span>] <span class=\"hljs-comment\"># summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs</span><br>  <span class=\"hljs-attr\">s:</span> [<span class=\"hljs-number\">0.50</span>, <span class=\"hljs-number\">0.50</span>, <span class=\"hljs-number\">1024</span>] <span class=\"hljs-comment\"># summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs</span><br>  <span class=\"hljs-attr\">m:</span> [<span class=\"hljs-number\">0.50</span>, <span class=\"hljs-number\">1.00</span>, <span class=\"hljs-number\">512</span>] <span class=\"hljs-comment\"># summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs</span><br>  <span class=\"hljs-attr\">l:</span> [<span class=\"hljs-number\">1.00</span>, <span class=\"hljs-number\">1.00</span>, <span class=\"hljs-number\">512</span>] <span class=\"hljs-comment\"># summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs</span><br>  <span class=\"hljs-attr\">x:</span> [<span class=\"hljs-number\">1.00</span>, <span class=\"hljs-number\">1.50</span>, <span class=\"hljs-number\">512</span>] <span class=\"hljs-comment\"># summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs</span><br> <br><span class=\"hljs-comment\"># YOLO11n backbone</span><br><span class=\"hljs-attr\">backbone:</span><br>  <span class=\"hljs-comment\"># [from, repeats, module, args]</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Conv</span>, [<span class=\"hljs-number\">64</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]] <span class=\"hljs-comment\"># 0-P1/2</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Conv</span>, [<span class=\"hljs-number\">128</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]] <span class=\"hljs-comment\"># 1-P2/4</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C3k2</span>, [<span class=\"hljs-number\">256</span>, <span class=\"hljs-literal\">False</span>, <span class=\"hljs-number\">0.25</span>]]<br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Conv</span>, [<span class=\"hljs-number\">256</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]] <span class=\"hljs-comment\"># 3-P3/8</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C3k2</span>, [<span class=\"hljs-number\">512</span>, <span class=\"hljs-literal\">False</span>, <span class=\"hljs-number\">0.25</span>]]<br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Conv</span>, [<span class=\"hljs-number\">512</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]] <span class=\"hljs-comment\"># 5-P4/16</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C3k2</span>, [<span class=\"hljs-number\">512</span>, <span class=\"hljs-literal\">True</span>]]<br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Conv</span>, [<span class=\"hljs-number\">1024</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]] <span class=\"hljs-comment\"># 7-P5/32</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C3k2</span>, [<span class=\"hljs-number\">1024</span>, <span class=\"hljs-literal\">True</span>]]<br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">SPPF</span>, [<span class=\"hljs-number\">1024</span>, <span class=\"hljs-number\">5</span>]] <span class=\"hljs-comment\"># 9</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C2PSA</span>, [<span class=\"hljs-number\">1024</span>]] <span class=\"hljs-comment\"># 10</span><br> <br><span class=\"hljs-comment\"># YOLO11n head</span><br><span class=\"hljs-attr\">head:</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">nn.Upsample</span>, [<span class=\"hljs-string\">None</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">&quot;nearest&quot;</span>]]<br>  <span class=\"hljs-bullet\">-</span> [[<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">6</span>], <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Concat</span>, [<span class=\"hljs-number\">1</span>]] <span class=\"hljs-comment\"># cat backbone P4</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C3k2</span>, [<span class=\"hljs-number\">512</span>, <span class=\"hljs-literal\">False</span>]] <span class=\"hljs-comment\"># 13</span><br> <br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">nn.Upsample</span>, [<span class=\"hljs-string\">None</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">&quot;nearest&quot;</span>]]<br>  <span class=\"hljs-bullet\">-</span> [[<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">4</span>], <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Concat</span>, [<span class=\"hljs-number\">1</span>]] <span class=\"hljs-comment\"># cat backbone P3</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C3k2</span>, [<span class=\"hljs-number\">256</span>, <span class=\"hljs-literal\">False</span>]] <span class=\"hljs-comment\"># 16 (P3/8-small)</span><br> <br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Conv</span>, [<span class=\"hljs-number\">256</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]]<br>  <span class=\"hljs-bullet\">-</span> [[<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">13</span>], <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Concat</span>, [<span class=\"hljs-number\">1</span>]] <span class=\"hljs-comment\"># cat head P4</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C3k2</span>, [<span class=\"hljs-number\">512</span>, <span class=\"hljs-literal\">False</span>]] <span class=\"hljs-comment\"># 19 (P4/16-medium)</span><br> <br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Conv</span>, [<span class=\"hljs-number\">512</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]]<br>  <span class=\"hljs-bullet\">-</span> [[<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">10</span>], <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Concat</span>, [<span class=\"hljs-number\">1</span>]] <span class=\"hljs-comment\"># cat head P5</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C3k2</span>, [<span class=\"hljs-number\">1024</span>, <span class=\"hljs-literal\">True</span>]] <span class=\"hljs-comment\"># 22 (P5/32-large)</span><br> <br>  <span class=\"hljs-bullet\">-</span> [[<span class=\"hljs-number\">16</span>, <span class=\"hljs-number\">19</span>, <span class=\"hljs-number\">22</span>], <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Detect</span>, [<span class=\"hljs-string\">nc</span>]] <span class=\"hljs-comment\"># Detect(P3, P4, P5)</span><br></code></pre></td></tr></table></figure>\n\n<p>架构级别的变化：</p>\n<h3 id=\"1-骨干\"><a href=\"#1-骨干\" class=\"headerlink\" title=\"1. 骨干\"></a><strong>1. 骨干</strong></h3><p>主干是模型的一部分，用于从多个比例的输入图像中提取特征。它通常涉及堆叠卷积层和块以创建不同分辨率的特征图。</p>\n<p><strong>卷积层：</strong>YOLO11 具有类似的结构，带有初始卷积层来对图像进行下采样：</p>\n<figure class=\"highlight gauss\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gauss\">- [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-built_in\">Conv</span>, [<span class=\"hljs-number\">64</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]] <span class=\"hljs-meta\"># 0-P1/2</span><br>- [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-built_in\">Conv</span>, [<span class=\"hljs-number\">128</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]] <span class=\"hljs-meta\"># 1-P2/4</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li><p><strong>C3k2 区块：</strong>YOLO11 引入了 <strong>C3k2 块，而不是 C2f</strong>，它在计算方面效率更高。此块是 <strong>CSP 瓶颈</strong>的自定义实现，它使用两个卷积，而不是一个大型卷积（如 YOLOv8 中所示）。</p>\n<ul>\n<li><strong>CSP （Cross Stage Partial）：</strong>CSP 网络拆分特征图并通过瓶颈层处理一部分，同时将另一部分与瓶颈的输出合并。这减少了计算负载并改善了特征表示。</li>\n</ul>\n<figure class=\"highlight inform7\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs inform7\">- <span class=\"hljs-comment\">[-1, 2, C3k2, <span class=\"hljs-comment\">[256, False, 0.25]</span>]</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>C3k2 块还使用较小的内核大小（由 k2 表示），使其更快，同时保持性能。</li>\n</ul>\n<p><strong>SPPF 和 C2PSA：</strong>YOLO11 保留了 SPPF 块，但在 SPPF 之后添加了一个新的 <strong>C2PSA</strong> 块：</p>\n</li>\n</ul>\n<figure class=\"highlight inform7\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs inform7\">- <span class=\"hljs-comment\">[-1, 1, SPPF, <span class=\"hljs-comment\">[1024, 5]</span>]</span><br>- <span class=\"hljs-comment\">[-1, 2, C2PSA, <span class=\"hljs-comment\">[1024]</span></span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li><strong>C2PSA （Cross Stage Partial with Spatial Attention）</strong> 模块增强了特征图中的空间注意力，从而提高了模型对图像重要部分的关注。这使模型能够通过在空间上池化特征来更有效地关注特定的感兴趣区域。</li>\n</ul>\n<h3 id=\"2-neck\"><a href=\"#2-neck\" class=\"headerlink\" title=\"2. neck\"></a><strong>2. neck</strong></h3><p>neck 负责聚合来自不同分辨率的特征，并将它们传递给头部进行预测。它通常涉及来自不同级别的特征图的上采样和连接。</p>\n<p><strong>C3k2 区块：</strong>YOLO11 用 <strong>C3k2</strong> 块替换了颈部的 C2f 块。如前所述，C3k2 是一个更快、更高效的区块。例如，在上采样和串联后，YOLO11 中的 neck 如下所示：</p>\n<figure class=\"highlight autoit\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs autoit\">\t<br>- [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, C3k2, [<span class=\"hljs-number\">512</span>, <span class=\"hljs-literal\">False</span>]] <span class=\"hljs-meta\"># P4/16-medium</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>此更改提高了要素聚合过程的速度和性能。</li>\n<li><strong>注意力机制：</strong>YOLO11 通过 <strong>C2PSA</strong> 更侧重于空间注意力，这有助于模型专注于图像中的关键区域，以便更好地检测。这在 YOLOv8 中是缺失的，这使得 YOLO11 在检测较小或被遮挡的对象时可能更准确。</li>\n</ul>\n<hr>\n<h3 id=\"3-head\"><a href=\"#3-head\" class=\"headerlink\" title=\"3. head\"></a><strong>3. head</strong></h3><p>head 是模型中负责生成最终预测的部分。在对象检测中，这通常意味着生成边界框并对这些框内的对象进行分类。</p>\n<p><strong>C3k2 区块：</strong>与颈部类似，YOLO11 取代了头部的 <strong>C2f</strong> 块。</p>\n<figure class=\"highlight autoit\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs autoit\">\t<br>- [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, C3k2, [<span class=\"hljs-number\">512</span>, <span class=\"hljs-literal\">False</span>]] <span class=\"hljs-meta\"># P4/16-medium</span><br><br></code></pre></td></tr></table></figure>\n\n<p><strong>检测层：</strong>最终的 Detect 层与 YOLOv8 中的层相同：</p>\n<figure class=\"highlight lua\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs lua\">- <span class=\"hljs-string\">[[16, 19, 22], 1, Detect, [nc]]</span> # Detect(P3, P4, P5)<br><br></code></pre></td></tr></table></figure>\n\n<p>使用 C3k2 块使模型在推理方面更快，在参数方面更高效。<br>那么，让我们看看新块（层）在代码中的样子：</p>\n<hr>\n<p>那么，让我们看看新块（层）在代码中的样子：</p>\n<ol>\n<li><strong>C3k2 区块（从</strong> <strong>blocks.py</strong> 开始<strong>）：</strong><ul>\n<li><strong>C3k2</strong> 是 <strong>CSP 瓶颈</strong>的更快、更高效的变体。它使用两个卷积而不是一个大型卷积，从而加快了特征提取速度。</li>\n</ul>\n</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">C3k2</span>(<span class=\"hljs-title class_ inherited__\">C2f</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, c1, c2, n=<span class=\"hljs-number\">1</span>, c3k=<span class=\"hljs-literal\">False</span>, e=<span class=\"hljs-number\">0.5</span>, g=<span class=\"hljs-number\">1</span>, shortcut=<span class=\"hljs-literal\">True</span></span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__(c1, c2, n, shortcut, g, e)<br>        <span class=\"hljs-variable language_\">self</span>.m = nn.ModuleList(<br>            C3k(<span class=\"hljs-variable language_\">self</span>.c, <span class=\"hljs-variable language_\">self</span>.c, <span class=\"hljs-number\">2</span>, shortcut, g) <span class=\"hljs-keyword\">if</span> c3k <span class=\"hljs-keyword\">else</span> Bottleneck(<span class=\"hljs-variable language_\">self</span>.c, <span class=\"hljs-variable language_\">self</span>.c, shortcut, g) <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(n)<br>        )<br></code></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li><strong>C3k 块（从</strong> <strong>blocks.py</strong> 开始<strong>）</strong>：</li>\n</ol>\n<ul>\n<li><strong>C3k</strong> 是一个更灵活的瓶颈模块，允许自定义内核大小。这对于提取图像中更详细的特征非常有用。</li>\n</ul>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">class C3k(C3):<br>    def __init__(self, c1, c2, <span class=\"hljs-attribute\">n</span>=1, <span class=\"hljs-attribute\">shortcut</span>=<span class=\"hljs-literal\">True</span>, <span class=\"hljs-attribute\">g</span>=1, <span class=\"hljs-attribute\">e</span>=0.5, <span class=\"hljs-attribute\">k</span>=3):<br>        super().__init__(c1, c2, n, shortcut, g, e)<br>        c_ = int(c2 * e)  # hidden channels<br>        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, k=(k, k), <span class=\"hljs-attribute\">e</span>=1.0) <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> range(n)))<br></code></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li><strong>C2PSA 块（从</strong> <strong>blocks.py</strong> 年起<strong>）：</strong></li>\n</ol>\n<ul>\n<li><strong>C2PSA</strong> （Cross Stage Partial with Spatial Attention） 增强了模型的空间注意力能力。此模块增加了对特征图的关注，帮助模型专注于图像的重要区域。</li>\n</ul>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ruby\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">C2</span>PSA(nn.<span class=\"hljs-title class_\">Module</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span>, c1, c2, e=<span class=\"hljs-number\">0.5</span></span>):<br>        <span class=\"hljs-variable language_\">super</span>().__init__()<br>        c_ = int(c2 * e)<br>        <span class=\"hljs-variable language_\">self</span>.cv1 = <span class=\"hljs-title class_\">Conv</span>(c1, c_, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-variable language_\">self</span>.cv2 = <span class=\"hljs-title class_\">Conv</span>(c1, c_, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-variable language_\">self</span>.cv3 = <span class=\"hljs-title class_\">Conv</span>(<span class=\"hljs-number\">2</span> * c_, c2, <span class=\"hljs-number\">1</span>)<br>     <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span>, x</span>):<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>.cv3(torch.cat((<span class=\"hljs-variable language_\">self</span>.cv1(x), <span class=\"hljs-variable language_\">self</span>.cv2(x)), <span class=\"hljs-number\">1</span>))<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"YOLO11-pipeline\"><a href=\"#YOLO11-pipeline\" class=\"headerlink\" title=\"YOLO11 pipeline\"></a>YOLO11 pipeline</h1><p>在 <a href=\"https://github.com/ultralytics/ultralytics\"><strong>ultralytics</strong></a> GitHub 仓库中，我们将主要关注：</p>\n<ol>\n<li><strong>nn&#x2F;modules&#x2F;</strong> 中的模块<ul>\n<li><strong>block.py</strong></li>\n<li><strong>conv.py</strong></li>\n<li><strong>head.py</strong></li>\n<li><strong>transformer.py</strong></li>\n<li><strong>utils.py</strong></li>\n</ul>\n</li>\n<li><strong>nn&#x2F;tasks.py</strong> 文件</li>\n</ol>\n<h3 id=\"1-代码库概述\"><a href=\"#1-代码库概述\" class=\"headerlink\" title=\"1. 代码库概述\"></a>1. 代码库概述</h3><p>代码库被构建为多个模块，这些模块定义了 YOLO11 模型中使用的各种神经网络组件。这些组件在 nn&#x2F;modules&#x2F; 目录中被组织到不同的文件中：</p>\n<ul>\n<li><strong>block.py</strong>：定义模型中使用的各种构建块（模块），例如瓶颈、CSP 模块和注意力机制。</li>\n<li><strong>conv.py</strong>：包含卷积模块，包括标准卷积、深度卷积和其他变体。</li>\n<li><strong>head.py</strong>：实现负责生成最终预测（例如，边界框、类概率）的模型头。</li>\n<li><strong>transformer.py</strong>：包括基于 transformer 的模块，用于注意力机制和高级特征提取。</li>\n<li><strong>utils.py</strong>：提供跨模块使用的实用程序函数和帮助程序类。</li>\n</ul>\n<p>nn&#x2F;tasks.py 文件定义了不同的特定于任务的模型（例如，检测、分割、分类），这些模型将这些模块组合成完整的架构。</p>\n<h3 id=\"2-nn-modules-中的模块\"><a href=\"#2-nn-modules-中的模块\" class=\"headerlink\" title=\"2. nn&#x2F;modules&#x2F; 中的模块\"></a>2. nn&#x2F;modules&#x2F; 中的模块</h3><p>如前所述，YOLO11 构建在 YOLOv8 代码库之上。因此，我们将主要关注更新的脚本：<strong>block.py</strong>、<strong>conv.py</strong> 和 <strong>head.py</strong> 在这里。</p>\n<h4 id=\"block-py\"><a href=\"#block-py\" class=\"headerlink\" title=\"block.py\"></a><strong>block.py</strong></h4><p>此文件定义 YOLO11 模型中使用的各种构建块。这些块是构成神经网络层的基本组件。</p>\n<h5 id=\"关键组件：\"><a href=\"#关键组件：\" class=\"headerlink\" title=\"关键组件：\"></a><strong>关键组件：</strong></h5><ol>\n<li>瓶颈模块：<ul>\n<li><strong>Bottleneck</strong>：具有可选快捷方式连接的标准瓶颈模块。</li>\n<li><strong>Res</strong>：使用一系列卷积和身份快捷方式的残差块。</li>\n</ul>\n</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Bottleneck</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, c1, c2, shortcut=<span class=\"hljs-literal\">True</span>, g=<span class=\"hljs-number\">1</span>, e=<span class=\"hljs-number\">0.5</span></span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        c_ = <span class=\"hljs-built_in\">int</span>(c2 * e)<br>        <span class=\"hljs-variable language_\">self</span>.cv1 = Conv(c1, c_, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-variable language_\">self</span>.cv2 = Conv(c_, c2, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">1</span>, g=g)<br>        <span class=\"hljs-variable language_\">self</span>.add = shortcut <span class=\"hljs-keyword\">and</span> c1 == c2<br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        <span class=\"hljs-keyword\">return</span> x + <span class=\"hljs-variable language_\">self</span>.cv2(<span class=\"hljs-variable language_\">self</span>.cv1(x)) <span class=\"hljs-keyword\">if</span> <span class=\"hljs-variable language_\">self</span>.add <span class=\"hljs-keyword\">else</span> <span class=\"hljs-variable language_\">self</span>.cv2(<span class=\"hljs-variable language_\">self</span>.cv1(x))<br><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>Bottleneck 类实现了一个 bottleneck 模块，该模块减少了通道的数量（降维），然后再次扩展它们。</li>\n<li><strong>组件</strong>：<ul>\n<li>self.cv1：一个 1×1 卷积，用于减少通道数。</li>\n<li>self.cv2：一个 3×3 卷积，用于将通道数增加回原始通道数。</li>\n<li>self.add：一个布尔值，指示是否添加快捷方式连接。</li>\n</ul>\n</li>\n<li><strong>Forward Pass</strong>：输入 x 通过 cv1 和 cv2 传递。如果 self.add 为 True，则原始输入 x 将添加到输出（残差连接）。</li>\n</ul>\n<ol start=\"2\">\n<li>CSP （Cross Stage Partial） 模块：</li>\n</ol>\n<ul>\n<li><strong>BottleneckCSP：</strong>瓶颈模块的 CSP 版本。</li>\n<li><strong>CSPBlock</strong>：具有多个瓶颈层的更复杂的 CSP 模块。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">BottleneckCSP</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, c1, c2, n=<span class=\"hljs-number\">1</span>, shortcut=<span class=\"hljs-literal\">True</span>, g=<span class=\"hljs-number\">1</span>, e=<span class=\"hljs-number\">0.5</span></span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        c_ = <span class=\"hljs-built_in\">int</span>(c2 * e)<br>        <span class=\"hljs-variable language_\">self</span>.cv1 = Conv(c1, c_, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-variable language_\">self</span>.cv2 = nn.Sequential(<br>            *[Bottleneck(c_, c_, shortcut, g, e=<span class=\"hljs-number\">1.0</span>) <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(n)]<br>        )<br>        <span class=\"hljs-variable language_\">self</span>.cv3 = Conv(<span class=\"hljs-number\">2</span> * c_, c2, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-variable language_\">self</span>.add = c1 == c2<br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        y1 = <span class=\"hljs-variable language_\">self</span>.cv2(<span class=\"hljs-variable language_\">self</span>.cv1(x))<br>        y2 = x <span class=\"hljs-keyword\">if</span> <span class=\"hljs-variable language_\">self</span>.add <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span><br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>.cv3(torch.cat((y1, y2), <span class=\"hljs-number\">1</span>)) <span class=\"hljs-keyword\">if</span> y2 <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\">None</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-variable language_\">self</span>.cv3(y1)<br><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>CSPBottleneck 模块将特征图分为两部分。一部分通过一系列瓶颈层，另一部分直接连接到输出，从而降低了计算成本并增强了梯度流。</li>\n<li><strong>组件</strong>：<ul>\n<li>self.cv1：减少通道数。</li>\n<li>self.cv2：瓶颈层序列。</li>\n<li>self.cv3：合并功能并调整通道数。</li>\n<li>self.add：确定是否添加快捷方式连接。</li>\n</ul>\n</li>\n</ul>\n<ol start=\"3\">\n<li>其他模块：</li>\n</ol>\n<ul>\n<li><strong>SPPF：</strong>Spatial Pyramid Pooling Fast 模块，可在多个比例下执行池化。</li>\n<li><strong>Concat</strong>：沿指定维度连接多个 Tensor。</li>\n</ul>\n<figure class=\"highlight gml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gml\">class SPPF(nn.Module):<br>    def __init__(<span class=\"hljs-symbol\">self</span>, c1, c2, k=<span class=\"hljs-number\">5</span>):<br>        super().__init__()<br>        c_ = c1 <span class=\"hljs-comment\">// 2</span><br>        <span class=\"hljs-symbol\">self</span>.cv1 = Conv(c1, c_, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-symbol\">self</span>.cv2 = Conv(c_ * <span class=\"hljs-number\">4</span>, c2, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-symbol\">self</span>.m = nn.MaxPool2d(kernel_size=k, stride=<span class=\"hljs-number\">1</span>, padding=k <span class=\"hljs-comment\">// 2)</span><br> <br>    def forward(<span class=\"hljs-symbol\">self</span>, <span class=\"hljs-variable language_\">x</span>):<br>        <span class=\"hljs-variable language_\">x</span> = <span class=\"hljs-symbol\">self</span>.cv1(<span class=\"hljs-variable language_\">x</span>)<br>        y1 = <span class=\"hljs-symbol\">self</span>.m(<span class=\"hljs-variable language_\">x</span>)<br>        y2 = <span class=\"hljs-symbol\">self</span>.m(y1)<br>        y3 = <span class=\"hljs-symbol\">self</span>.m(y2)<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-symbol\">self</span>.cv2(torch.cat([<span class=\"hljs-variable language_\">x</span>, y1, y2, y3], <span class=\"hljs-number\">1</span>))<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>SPPF 模块在不同比例下执行最大池化，并将结果连接起来以捕获多个空间比例的要素。</li>\n<li><strong>组件</strong>：<ul>\n<li>self.cv1：减少通道数。</li>\n<li>self.cv2：调整拼接后的 Channel 数。</li>\n<li>self.m：最大池化层数。</li>\n</ul>\n</li>\n<li><strong>Forward Pass</strong>：输入 x 通过 cv1，然后通过三个连续的最大池化层（y1、y2、y3）。结果被连接并通过 cv2 传递。</li>\n</ul>\n<h5 id=\"了解概念：\"><a href=\"#了解概念：\" class=\"headerlink\" title=\"了解概念：\"></a><strong>了解概念：</strong></h5><ul>\n<li><strong>瓶颈层</strong>：用于通过在昂贵的操作之前减少通道数并在之后增加通道数来降低计算复杂性。</li>\n<li><strong>残差连接</strong>：通过缓解梯度消失问题来帮助训练更深的网络。</li>\n<li><strong>CSP 架构</strong>：将特征图分为两部分;一部分发生转换，而另一部分保持不变，从而提高学习能力并减少计算。</li>\n</ul>\n<h4 id=\"conv-py\"><a href=\"#conv-py\" class=\"headerlink\" title=\"conv.py\"></a><strong>conv.py</strong></h4><p>此文件包含各种卷积模块，包括标准卷积和专用卷积。</p>\n<h5 id=\"关键组件：-1\"><a href=\"#关键组件：-1\" class=\"headerlink\" title=\"关键组件：\"></a><strong>关键组件：</strong></h5><p><strong>标准卷积模块 （Conv）：</strong></p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">class Conv(nn.Module):<br>    default_act = nn.SiLU()  #<span class=\"hljs-built_in\"> default </span>activation<br> <br>    def __init__(self, c1, c2, <span class=\"hljs-attribute\">k</span>=1, <span class=\"hljs-attribute\">s</span>=1, <span class=\"hljs-attribute\">p</span>=None, <span class=\"hljs-attribute\">g</span>=1, <span class=\"hljs-attribute\">d</span>=1, <span class=\"hljs-attribute\">act</span>=<span class=\"hljs-literal\">True</span>):<br>        super().__init__()<br>        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), <span class=\"hljs-attribute\">groups</span>=g, <span class=\"hljs-attribute\">dilation</span>=d, <span class=\"hljs-attribute\">bias</span>=<span class=\"hljs-literal\">False</span>)<br>        self.bn = nn.BatchNorm2d(c2)<br>        self.act = self.default_act <span class=\"hljs-keyword\">if</span> act is <span class=\"hljs-literal\">True</span> <span class=\"hljs-keyword\">else</span> act <span class=\"hljs-keyword\">if</span> isinstance(act, nn.Module) <span class=\"hljs-keyword\">else</span> nn.Identity()<br> <br>    def forward(self, x):<br>        return self.act(self.bn(self.conv(x)))<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>实现具有批量规范化和激活的标准卷积层。</li>\n<li><strong>组件</strong>：<ul>\n<li>self.conv：卷积层。</li>\n<li>self.bn：批量规范化。</li>\n<li>self.act：激活函数（默认为 nn.SiLU（））的</li>\n</ul>\n</li>\n<li><strong>Forward Pass</strong>：应用卷积，然后进行批量规范化和激活。</li>\n</ul>\n<p><strong>深度卷积 （DWConv）：</strong></p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">class DWConv(Conv):<br>    def __init__(self, c1, c2, <span class=\"hljs-attribute\">k</span>=1, <span class=\"hljs-attribute\">s</span>=1, <span class=\"hljs-attribute\">d</span>=1, <span class=\"hljs-attribute\">act</span>=<span class=\"hljs-literal\">True</span>):<br>        super().__init__(c1, c2, k, s, <span class=\"hljs-attribute\">g</span>=math.gcd(c1, c2), <span class=\"hljs-attribute\">d</span>=d, <span class=\"hljs-attribute\">act</span>=act)<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>执行深度卷积，其中每个输入通道单独卷积。</li>\n<li><strong>组件</strong>：<ul>\n<li>继承自 Conv。</li>\n<li>将 groups 参数设置为 c1 和 c2 的最大公约数，从而有效地对每个通道的卷积进行分组。</li>\n</ul>\n</li>\n</ul>\n<ol>\n<li>其他卷积模块：<ul>\n<li><strong>Conv2</strong>：RepConv 的简化版本，用于模型压缩和加速。</li>\n<li><strong>GhostConv</strong>：实现 GhostNet 的 ghost 模块，减少特性图中的冗余。</li>\n<li><strong>RepConv</strong>：可重新参数化的卷积层，可以从训练模式转换为推理模式。</li>\n</ul>\n</li>\n</ol>\n<h5 id=\"了解概念：-1\"><a href=\"#了解概念：-1\" class=\"headerlink\" title=\"了解概念：\"></a><strong>了解概念：</strong></h5><ul>\n<li><strong>自动填充 （<strong><strong>autopad</strong></strong>）：</strong>自动计算保持输出尺寸一致所需的填充。</li>\n<li><strong>深度卷积和点卷积</strong>：用于 MobileNet 架构，以减少计算，同时保持准确性。</li>\n<li><strong>重新参数化</strong>：RepConv 等技术通过合并层来实现高效的训练和更快的推理。</li>\n</ul>\n<h4 id=\"head-py\"><a href=\"#head-py\" class=\"headerlink\" title=\"head.py\"></a><strong>head.py</strong></h4><p>此文件实现了负责生成模型最终预测的 head 模块。</p>\n<h5 id=\"关键组件：-2\"><a href=\"#关键组件：-2\" class=\"headerlink\" title=\"关键组件：\"></a><strong>关键组件：</strong></h5><p><strong>检测头 （Detect）：</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Detect</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, nc=<span class=\"hljs-number\">80</span>, ch=(<span class=\"hljs-params\"></span>)</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        <span class=\"hljs-variable language_\">self</span>.nc = nc  <span class=\"hljs-comment\"># number of classes</span><br>        <span class=\"hljs-variable language_\">self</span>.nl = <span class=\"hljs-built_in\">len</span>(ch)  <span class=\"hljs-comment\"># number of detection layers</span><br>        <span class=\"hljs-variable language_\">self</span>.reg_max = <span class=\"hljs-number\">16</span>  <span class=\"hljs-comment\"># DFL channels</span><br>        <span class=\"hljs-variable language_\">self</span>.no = nc + <span class=\"hljs-variable language_\">self</span>.reg_max * <span class=\"hljs-number\">4</span>  <span class=\"hljs-comment\"># number of outputs per anchor</span><br>        <span class=\"hljs-variable language_\">self</span>.stride = torch.zeros(<span class=\"hljs-variable language_\">self</span>.nl)  <span class=\"hljs-comment\"># strides computed during build</span><br> <br>        <span class=\"hljs-comment\"># Define layers</span><br>        <span class=\"hljs-variable language_\">self</span>.cv2 = nn.ModuleList(<br>            nn.Sequential(Conv(x, c2, <span class=\"hljs-number\">3</span>), Conv(c2, c2, <span class=\"hljs-number\">3</span>), nn.Conv2d(c2, <span class=\"hljs-number\">4</span> * <span class=\"hljs-variable language_\">self</span>.reg_max, <span class=\"hljs-number\">1</span>)) <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> ch<br>        )<br>        <span class=\"hljs-variable language_\">self</span>.cv3 = nn.ModuleList(<br>            nn.Sequential(<br>                nn.Sequential(DWConv(x, x, <span class=\"hljs-number\">3</span>), Conv(x, c3, <span class=\"hljs-number\">1</span>)),<br>                nn.Sequential(DWConv(c3, c3, <span class=\"hljs-number\">3</span>), Conv(c3, c3, <span class=\"hljs-number\">1</span>)),<br>                nn.Conv2d(c3, <span class=\"hljs-variable language_\">self</span>.nc, <span class=\"hljs-number\">1</span>),<br>            )<br>            <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> ch<br>        )<br>        <span class=\"hljs-variable language_\">self</span>.dfl = DFL(<span class=\"hljs-variable language_\">self</span>.reg_max) <span class=\"hljs-keyword\">if</span> <span class=\"hljs-variable language_\">self</span>.reg_max &gt; <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">else</span> nn.Identity()<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>Detect 类定义输出边界框坐标和类概率的检测头。</li>\n<li><strong>组件</strong>：<ul>\n<li>self.cv2：用于边界框回归的卷积层。</li>\n<li>self.cv3：用于分类的卷积层。</li>\n<li>self.dfl：用于边界框细化的 Distribution Focal Loss 模块。</li>\n</ul>\n</li>\n<li><strong>Forward Pass</strong>：处理输入特征映射并输出边界框和类的预测。</li>\n</ul>\n<p><strong>分割 （<strong><strong>Segment</strong></strong>）：</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Segment</span>(<span class=\"hljs-title class_ inherited__\">Detect</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, nc=<span class=\"hljs-number\">80</span>, nm=<span class=\"hljs-number\">32</span>, npr=<span class=\"hljs-number\">256</span>, ch=(<span class=\"hljs-params\"></span>)</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__(nc, ch)<br>        <span class=\"hljs-variable language_\">self</span>.nm = nm  <span class=\"hljs-comment\"># number of masks</span><br>        <span class=\"hljs-variable language_\">self</span>.npr = npr  <span class=\"hljs-comment\"># number of prototypes</span><br>        <span class=\"hljs-variable language_\">self</span>.proto = Proto(ch[<span class=\"hljs-number\">0</span>], <span class=\"hljs-variable language_\">self</span>.npr, <span class=\"hljs-variable language_\">self</span>.nm)  <span class=\"hljs-comment\"># protos</span><br> <br>        c4 = <span class=\"hljs-built_in\">max</span>(ch[<span class=\"hljs-number\">0</span>] // <span class=\"hljs-number\">4</span>, <span class=\"hljs-variable language_\">self</span>.nm)<br>        <span class=\"hljs-variable language_\">self</span>.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, <span class=\"hljs-number\">3</span>), Conv(c4, c4, <span class=\"hljs-number\">3</span>), nn.Conv2d(c4, <span class=\"hljs-variable language_\">self</span>.nm, <span class=\"hljs-number\">1</span>)) <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> ch)<br><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>扩展 Detect 类以包含分段功能。</li>\n<li><strong>组件</strong>：<ul>\n<li>self.proto：生成掩码原型。</li>\n<li>self.cv4：掩码系数的卷积层。</li>\n</ul>\n</li>\n<li><strong>Forward Pass</strong>：输出边界框、类概率和掩码系数。</li>\n</ul>\n<p><strong>姿势估计头部 （Pose）：</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Pose</span>(<span class=\"hljs-title class_ inherited__\">Detect</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, nc=<span class=\"hljs-number\">80</span>, kpt_shape=(<span class=\"hljs-params\"><span class=\"hljs-number\">17</span>, <span class=\"hljs-number\">3</span></span>), ch=(<span class=\"hljs-params\"></span>)</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__(nc, ch)<br>        <span class=\"hljs-variable language_\">self</span>.kpt_shape = kpt_shape  <span class=\"hljs-comment\"># number of keypoints, number of dimensions</span><br>        <span class=\"hljs-variable language_\">self</span>.nk = kpt_shape[<span class=\"hljs-number\">0</span>] * kpt_shape[<span class=\"hljs-number\">1</span>]  <span class=\"hljs-comment\"># total number of keypoint outputs</span><br> <br>        c4 = <span class=\"hljs-built_in\">max</span>(ch[<span class=\"hljs-number\">0</span>] // <span class=\"hljs-number\">4</span>, <span class=\"hljs-variable language_\">self</span>.nk)<br>        <span class=\"hljs-variable language_\">self</span>.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, <span class=\"hljs-number\">3</span>), Conv(c4, c4, <span class=\"hljs-number\">3</span>), nn.Conv2d(c4, <span class=\"hljs-variable language_\">self</span>.nk, <span class=\"hljs-number\">1</span>)) <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> ch)<br><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>扩展了 Detect 类，用于人体姿势估计任务。</li>\n<li><strong>组件</strong>：<ul>\n<li>self.kpt_shape：关键点的形状（关键点的数量、每个关键点的维度）。</li>\n<li>self.cv4：用于关键点回归的卷积层。</li>\n</ul>\n</li>\n<li><strong>Forward Pass</strong>：输出边界框、类概率和关键点坐标。</li>\n</ul>\n<h5 id=\"了解概念：-2\"><a href=\"#了解概念：-2\" class=\"headerlink\" title=\"了解概念：\"></a><strong>了解概念：</strong></h5><ul>\n<li><strong>模块化</strong>：通过扩展 Detect 类，我们可以为不同的任务创建专门的 head，同时重用通用功能。</li>\n<li><strong>无锚点检测</strong>：现代对象检测器通常使用无锚点方法，直接预测边界框。</li>\n<li><strong>关键点估计</strong>：在姿势估计中，模型预测表示关节或地标的关键点。</li>\n</ul>\n<h3 id=\"3-nn-tasks-py-文件\"><a href=\"#3-nn-tasks-py-文件\" class=\"headerlink\" title=\"3. nn&#x2F;tasks.py 文件\"></a>3. <strong>nn&#x2F;tasks.py</strong> 文件</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># Ultralytics YOLO &lt;img draggable=&quot;false&quot; role=&quot;img&quot; class=&quot;emoji&quot; alt=&quot;🚀&quot; src=&quot;https://s.w.org/images/core/emoji/15.0.3/svg/1f680.svg&quot;&gt;, AGPL-3.0 license</span><br> <br><span class=\"hljs-keyword\">import</span> contextlib<br><span class=\"hljs-keyword\">import</span> pickle<br><span class=\"hljs-keyword\">import</span> types<br><span class=\"hljs-keyword\">from</span> copy <span class=\"hljs-keyword\">import</span> deepcopy<br><span class=\"hljs-keyword\">from</span> pathlib <span class=\"hljs-keyword\">import</span> Path<br> <br><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br> <br><span class=\"hljs-comment\"># Other imports...</span><br> <br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">BaseModel</span>(nn.Module):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;The BaseModel class serves as a base class for all the models in the Ultralytics YOLO family.&quot;&quot;&quot;</span><br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x, *args, **kwargs</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Handles both training and inference, returns predictions or loss.&quot;&quot;&quot;</span><br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(x, <span class=\"hljs-built_in\">dict</span>):<br>            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>.loss(x, *args, **kwargs)  <span class=\"hljs-comment\"># Training: return loss</span><br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>.predict(x, *args, **kwargs)  <span class=\"hljs-comment\"># Inference: return predictions</span><br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">predict</span>(<span class=\"hljs-params\">self, x, profile=<span class=\"hljs-literal\">False</span>, visualize=<span class=\"hljs-literal\">False</span>, augment=<span class=\"hljs-literal\">False</span>, embed=<span class=\"hljs-literal\">None</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Run a forward pass through the network for inference.&quot;&quot;&quot;</span><br>        <span class=\"hljs-keyword\">if</span> augment:<br>            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>._predict_augment(x)<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>._predict_once(x, profile, visualize, embed)<br>     <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">fuse</span>(<span class=\"hljs-params\">self, verbose=<span class=\"hljs-literal\">True</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Fuses Conv and BatchNorm layers for efficiency during inference.&quot;&quot;&quot;</span><br>        <span class=\"hljs-keyword\">for</span> m <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>.model.modules():<br>            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(m, (Conv, Conv2, DWConv)) <span class=\"hljs-keyword\">and</span> <span class=\"hljs-built_in\">hasattr</span>(m, <span class=\"hljs-string\">&quot;bn&quot;</span>):<br>                m.conv = fuse_conv_and_bn(m.conv, m.bn)<br>                <span class=\"hljs-built_in\">delattr</span>(m, <span class=\"hljs-string\">&quot;bn&quot;</span>)<br>                m.forward = m.forward_fuse  <span class=\"hljs-comment\"># Use the fused forward</span><br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span><br>     <br>    <span class=\"hljs-comment\"># More BaseModel methods...</span><br> <br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">DetectionModel</span>(<span class=\"hljs-title class_ inherited__\">BaseModel</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;YOLOv8 detection model.&quot;&quot;&quot;</span><br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, cfg=<span class=\"hljs-string\">&quot;yolov8n.yaml&quot;</span>, ch=<span class=\"hljs-number\">3</span>, nc=<span class=\"hljs-literal\">None</span>, verbose=<span class=\"hljs-literal\">True</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize the YOLOv8 detection model with config and parameters.&quot;&quot;&quot;</span><br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        <span class=\"hljs-variable language_\">self</span>.yaml = cfg <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(cfg, <span class=\"hljs-built_in\">dict</span>) <span class=\"hljs-keyword\">else</span> yaml_model_load(cfg)<br>        <span class=\"hljs-variable language_\">self</span>.model, <span class=\"hljs-variable language_\">self</span>.save = parse_model(deepcopy(<span class=\"hljs-variable language_\">self</span>.yaml), ch=ch, verbose=verbose)<br>        <span class=\"hljs-variable language_\">self</span>.names = &#123;i: <span class=\"hljs-string\">f&quot;<span class=\"hljs-subst\">&#123;i&#125;</span>&quot;</span> <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-variable language_\">self</span>.yaml[<span class=\"hljs-string\">&quot;nc&quot;</span>])&#125;  <span class=\"hljs-comment\"># Class names</span><br>        <span class=\"hljs-variable language_\">self</span>.inplace = <span class=\"hljs-variable language_\">self</span>.yaml.get(<span class=\"hljs-string\">&quot;inplace&quot;</span>, <span class=\"hljs-literal\">True</span>)<br> <br>        <span class=\"hljs-comment\"># Initialize strides</span><br>        m = <span class=\"hljs-variable language_\">self</span>.model[-<span class=\"hljs-number\">1</span>]  <span class=\"hljs-comment\"># Detect() layer</span><br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(m, Detect):<br>            s = <span class=\"hljs-number\">256</span>  <span class=\"hljs-comment\"># Max stride</span><br>            m.stride = torch.tensor([s / x.shape[-<span class=\"hljs-number\">2</span>] <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>._predict_once(torch.zeros(<span class=\"hljs-number\">1</span>, ch, s, s))])<br>            <span class=\"hljs-variable language_\">self</span>.stride = m.stride<br>            m.bias_init()  <span class=\"hljs-comment\"># Initialize biases</span><br> <br>    <span class=\"hljs-comment\"># More DetectionModel methods...</span><br> <br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">SegmentationModel</span>(<span class=\"hljs-title class_ inherited__\">DetectionModel</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;YOLOv8 segmentation model.&quot;&quot;&quot;</span><br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, cfg=<span class=\"hljs-string\">&quot;yolov8n-seg.yaml&quot;</span>, ch=<span class=\"hljs-number\">3</span>, nc=<span class=\"hljs-literal\">None</span>, verbose=<span class=\"hljs-literal\">True</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize YOLOv8 segmentation model with given config and parameters.&quot;&quot;&quot;</span><br>        <span class=\"hljs-built_in\">super</span>().__init__(cfg=cfg, ch=ch, nc=nc, verbose=verbose)<br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">init_criterion</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize the loss criterion for the SegmentationModel.&quot;&quot;&quot;</span><br>        <span class=\"hljs-keyword\">return</span> v8SegmentationLoss(<span class=\"hljs-variable language_\">self</span>)<br> <br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">PoseModel</span>(<span class=\"hljs-title class_ inherited__\">DetectionModel</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;YOLOv8 pose model.&quot;&quot;&quot;</span><br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, cfg=<span class=\"hljs-string\">&quot;yolov8n-pose.yaml&quot;</span>, ch=<span class=\"hljs-number\">3</span>, nc=<span class=\"hljs-literal\">None</span>, data_kpt_shape=(<span class=\"hljs-params\"><span class=\"hljs-literal\">None</span>, <span class=\"hljs-literal\">None</span></span>), verbose=<span class=\"hljs-literal\">True</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize YOLOv8 Pose model.&quot;&quot;&quot;</span><br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-built_in\">isinstance</span>(cfg, <span class=\"hljs-built_in\">dict</span>):<br>            cfg = yaml_model_load(cfg)<br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">list</span>(data_kpt_shape) != <span class=\"hljs-built_in\">list</span>(cfg[<span class=\"hljs-string\">&quot;kpt_shape&quot;</span>]):<br>            cfg[<span class=\"hljs-string\">&quot;kpt_shape&quot;</span>] = data_kpt_shape<br>        <span class=\"hljs-built_in\">super</span>().__init__(cfg=cfg, ch=ch, nc=nc, verbose=verbose)<br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">init_criterion</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize the loss criterion for the PoseModel.&quot;&quot;&quot;</span><br>        <span class=\"hljs-keyword\">return</span> v8PoseLoss(<span class=\"hljs-variable language_\">self</span>)<br> <br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ClassificationModel</span>(<span class=\"hljs-title class_ inherited__\">BaseModel</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;YOLOv8 classification model.&quot;&quot;&quot;</span><br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, cfg=<span class=\"hljs-string\">&quot;yolov8n-cls.yaml&quot;</span>, ch=<span class=\"hljs-number\">3</span>, nc=<span class=\"hljs-literal\">None</span>, verbose=<span class=\"hljs-literal\">True</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize the YOLOv8 classification model.&quot;&quot;&quot;</span><br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        <span class=\"hljs-variable language_\">self</span>._from_yaml(cfg, ch, nc, verbose)<br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">_from_yaml</span>(<span class=\"hljs-params\">self, cfg, ch, nc, verbose</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Set YOLOv8 model configurations and define the model architecture.&quot;&quot;&quot;</span><br>        <span class=\"hljs-variable language_\">self</span>.yaml = cfg <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(cfg, <span class=\"hljs-built_in\">dict</span>) <span class=\"hljs-keyword\">else</span> yaml_model_load(cfg)<br>        <span class=\"hljs-variable language_\">self</span>.model, <span class=\"hljs-variable language_\">self</span>.save = parse_model(deepcopy(<span class=\"hljs-variable language_\">self</span>.yaml), ch=ch, verbose=verbose)<br>        <span class=\"hljs-variable language_\">self</span>.names = &#123;i: <span class=\"hljs-string\">f&quot;<span class=\"hljs-subst\">&#123;i&#125;</span>&quot;</span> <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-variable language_\">self</span>.yaml[<span class=\"hljs-string\">&quot;nc&quot;</span>])&#125;<br>        <span class=\"hljs-variable language_\">self</span>.info()<br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">reshape_outputs</span>(<span class=\"hljs-params\">model, nc</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Update a classification model to match the class count (nc).&quot;&quot;&quot;</span><br>        name, m = <span class=\"hljs-built_in\">list</span>((model.model <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">hasattr</span>(model, <span class=\"hljs-string\">&quot;model&quot;</span>) <span class=\"hljs-keyword\">else</span> model).named_children())[-<span class=\"hljs-number\">1</span>]<br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(m, nn.Linear):<br>            <span class=\"hljs-keyword\">if</span> m.out_features != nc:<br>                <span class=\"hljs-built_in\">setattr</span>(model, name, nn.Linear(m.in_features, nc))<br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">init_criterion</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize the loss criterion for the ClassificationModel.&quot;&quot;&quot;</span><br>        <span class=\"hljs-keyword\">return</span> v8ClassificationLoss()<br> <br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Ensemble</span>(nn.ModuleList):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;Ensemble of models.&quot;&quot;&quot;</span><br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize an ensemble of models.&quot;&quot;&quot;</span><br>        <span class=\"hljs-built_in\">super</span>().__init__()<br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x, augment=<span class=\"hljs-literal\">False</span>, profile=<span class=\"hljs-literal\">False</span>, visualize=<span class=\"hljs-literal\">False</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Generate the ensemble’s final layer by combining outputs from each model.&quot;&quot;&quot;</span><br>        y = [module(x, augment, profile, visualize)[<span class=\"hljs-number\">0</span>] <span class=\"hljs-keyword\">for</span> module <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>]<br>        <span class=\"hljs-keyword\">return</span> torch.cat(y, <span class=\"hljs-number\">2</span>), <span class=\"hljs-literal\">None</span>  <span class=\"hljs-comment\"># Concatenate outputs along the third dimension</span><br> <br><span class=\"hljs-comment\"># Functions ------------------------------------------------------------------------------------------------------------</span><br> <br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">parse_model</span>(<span class=\"hljs-params\">d, ch, verbose=<span class=\"hljs-literal\">True</span></span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;Parse a YOLO model.yaml dictionary into a PyTorch model.&quot;&quot;&quot;</span><br>    <span class=\"hljs-keyword\">import</span> ast<br> <br>    max_channels = <span class=\"hljs-built_in\">float</span>(<span class=\"hljs-string\">&quot;inf&quot;</span>)<br>    nc, act, scales = (d.get(x) <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> (<span class=\"hljs-string\">&quot;nc&quot;</span>, <span class=\"hljs-string\">&quot;activation&quot;</span>, <span class=\"hljs-string\">&quot;scales&quot;</span>))<br>    depth, width, kpt_shape = (d.get(x, <span class=\"hljs-number\">1.0</span>) <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> (<span class=\"hljs-string\">&quot;depth_multiple&quot;</span>, <span class=\"hljs-string\">&quot;width_multiple&quot;</span>, <span class=\"hljs-string\">&quot;kpt_shape&quot;</span>))<br> <br>    <span class=\"hljs-comment\"># Model scaling</span><br>    <span class=\"hljs-keyword\">if</span> scales:<br>        scale = d.get(<span class=\"hljs-string\">&quot;scale&quot;</span>)<br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> scale:networ<br>            scale = <span class=\"hljs-built_in\">tuple</span>(scales.keys())[<span class=\"hljs-number\">0</span>]<br>            LOGGER.warning(<span class=\"hljs-string\">f&quot;WARNING &lt;img draggable=&quot;</span>false<span class=\"hljs-string\">&quot; role=&quot;</span>img<span class=\"hljs-string\">&quot; class=&quot;</span>emoji<span class=\"hljs-string\">&quot; alt=&quot;</span>⚠️<span class=\"hljs-string\">&quot; src=&quot;</span>https://s.w.org/images/core/emoji/<span class=\"hljs-number\">15.0</span><span class=\"hljs-number\">.3</span>/svg/26a0.svg<span class=\"hljs-string\">&quot;&gt; no model scale passed. Assuming scale=&#x27;&#123;scale&#125;&#x27;.&quot;</span>)<br>        depth, width, max_channels = scales[scale]<br> <br>    <span class=\"hljs-keyword\">if</span> act:<br>        Conv.default_act = <span class=\"hljs-built_in\">eval</span>(act)  <span class=\"hljs-comment\"># redefine default activation</span><br>        <span class=\"hljs-keyword\">if</span> verbose:<br>            LOGGER.info(<span class=\"hljs-string\">f&quot;Activation: <span class=\"hljs-subst\">&#123;act&#125;</span>&quot;</span>)<br> <br>    <span class=\"hljs-comment\"># Logging and parsing layers</span><br>    <span class=\"hljs-keyword\">if</span> verbose:<br>        LOGGER.info(<span class=\"hljs-string\">f&quot;\\n<span class=\"hljs-subst\">&#123;<span class=\"hljs-string\">&#x27;&#x27;</span>:&gt;<span class=\"hljs-number\">3</span>&#125;</span><span class=\"hljs-subst\">&#123;<span class=\"hljs-string\">&#x27;from&#x27;</span>:&gt;<span class=\"hljs-number\">20</span>&#125;</span><span class=\"hljs-subst\">&#123;<span class=\"hljs-string\">&#x27;n&#x27;</span>:&gt;<span class=\"hljs-number\">3</span>&#125;</span><span class=\"hljs-subst\">&#123;<span class=\"hljs-string\">&#x27;params&#x27;</span>:&gt;<span class=\"hljs-number\">10</span>&#125;</span>  <span class=\"hljs-subst\">&#123;<span class=\"hljs-string\">&#x27;module&#x27;</span>:&lt;<span class=\"hljs-number\">45</span>&#125;</span><span class=\"hljs-subst\">&#123;<span class=\"hljs-string\">&#x27;arguments&#x27;</span>:&lt;<span class=\"hljs-number\">30</span>&#125;</span>&quot;</span>)<br>    ch = [ch]<br>    layers, save, c2 = [], [], ch[-<span class=\"hljs-number\">1</span>]<br> <br>    <span class=\"hljs-keyword\">for</span> i, (f, n, m, args) <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(d[<span class=\"hljs-string\">&quot;backbone&quot;</span>] + d[<span class=\"hljs-string\">&quot;head&quot;</span>]):  <span class=\"hljs-comment\"># from, number, module, args</span><br>        m = <span class=\"hljs-built_in\">globals</span>()[m] <span class=\"hljs-keyword\">if</span> m <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">globals</span>() <span class=\"hljs-keyword\">else</span> <span class=\"hljs-built_in\">getattr</span>(nn, m[<span class=\"hljs-number\">3</span>:], m)  <span class=\"hljs-comment\"># get module</span><br>        <span class=\"hljs-keyword\">for</span> j, a <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(args):<br>            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(a, <span class=\"hljs-built_in\">str</span>):<br>                <span class=\"hljs-keyword\">with</span> contextlib.suppress(ValueError):<br>                    args[j] = ast.literal_eval(a) <span class=\"hljs-keyword\">if</span> a <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">locals</span>() <span class=\"hljs-keyword\">else</span> a<br> <br>        n = <span class=\"hljs-built_in\">max</span>(<span class=\"hljs-built_in\">round</span>(n * depth), <span class=\"hljs-number\">1</span>) <span class=\"hljs-keyword\">if</span> n &gt; <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">else</span> n  <span class=\"hljs-comment\"># depth gain</span><br>        <span class=\"hljs-keyword\">if</span> m <span class=\"hljs-keyword\">in</span> &#123;Conv, Bottleneck, C2f, C3k2, ...&#125;:  <span class=\"hljs-comment\"># Module list</span><br>            c1, c2 = ch[f], args[<span class=\"hljs-number\">0</span>]<br>            c2 = make_divisible(<span class=\"hljs-built_in\">min</span>(c2, max_channels) * width, <span class=\"hljs-number\">8</span>)<br>            args = [c1, c2, *args[<span class=\"hljs-number\">1</span>:]]<br>            <span class=\"hljs-keyword\">if</span> m <span class=\"hljs-keyword\">in</span> &#123;C2f, C3k2, ...&#125;:  <span class=\"hljs-comment\"># Repeated layers</span><br>                args.insert(<span class=\"hljs-number\">2</span>, n)<br>                n = <span class=\"hljs-number\">1</span><br>        <span class=\"hljs-keyword\">elif</span> m <span class=\"hljs-keyword\">in</span> &#123;Concat, Detect, ...&#125;:  <span class=\"hljs-comment\"># Head layers</span><br>            args.append([ch[x] <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> f])<br>        <span class=\"hljs-comment\"># Append layers</span><br>        m_ = nn.Sequential(*(m(*args) <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(n))) <span class=\"hljs-keyword\">if</span> n &gt; <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">else</span> m(*args)<br>        layers.append(m_)<br> <br>        ch.append(c2)<br>        save.extend([x % i <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> ([f] <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(f, <span class=\"hljs-built_in\">int</span>) <span class=\"hljs-keyword\">else</span> f) <span class=\"hljs-keyword\">if</span> x != -<span class=\"hljs-number\">1</span>])<br> <br>        <span class=\"hljs-keyword\">if</span> verbose:<br>            LOGGER.info(<span class=\"hljs-string\">f&quot;<span class=\"hljs-subst\">&#123;i:&gt;<span class=\"hljs-number\">3</span>&#125;</span><span class=\"hljs-subst\">&#123;<span class=\"hljs-built_in\">str</span>(f):&gt;<span class=\"hljs-number\">20</span>&#125;</span><span class=\"hljs-subst\">&#123;n:&gt;<span class=\"hljs-number\">3</span>&#125;</span><span class=\"hljs-subst\">&#123;<span class=\"hljs-built_in\">sum</span>(x.numel() <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> m_.parameters()):<span class=\"hljs-number\">10.0</span>f&#125;</span>  <span class=\"hljs-subst\">&#123;<span class=\"hljs-built_in\">str</span>(m):&lt;<span class=\"hljs-number\">45</span>&#125;</span><span class=\"hljs-subst\">&#123;<span class=\"hljs-built_in\">str</span>(args):&lt;<span class=\"hljs-number\">30</span>&#125;</span>&quot;</span>)<br> <br>    <span class=\"hljs-keyword\">return</span> nn.Sequential(*layers), <span class=\"hljs-built_in\">sorted</span>(save)<br> <br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">yaml_model_load</span>(<span class=\"hljs-params\">path</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;Load a YOLO model from a YAML file.&quot;&quot;&quot;</span><br>    path = Path(path)<br>    unified_path = path.with_name(path.stem.replace(<span class=\"hljs-string\">&quot;yolov8&quot;</span>, <span class=\"hljs-string\">&quot;yolov&quot;</span>))<br>    yaml_file = check_yaml(<span class=\"hljs-built_in\">str</span>(unified_path), hard=<span class=\"hljs-literal\">False</span>) <span class=\"hljs-keyword\">or</span> check_yaml(path)<br>    d = yaml_load(yaml_file)<br>    d[<span class=\"hljs-string\">&quot;scale&quot;</span>] = guess_model_scale(path)<br>    d[<span class=\"hljs-string\">&quot;yaml_file&quot;</span>] = <span class=\"hljs-built_in\">str</span>(path)<br>    <span class=\"hljs-keyword\">return</span> d<br> <br><span class=\"hljs-comment\"># More utility functions...</span><br> <br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">guess_model_scale</span>(<span class=\"hljs-params\">model_path</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;Extract the scale from the YAML file.&quot;&quot;&quot;</span><br>    <span class=\"hljs-keyword\">import</span> re<br>    <span class=\"hljs-keyword\">return</span> re.search(<span class=\"hljs-string\">r&quot;yolov\\d+([nslmx])&quot;</span>, Path(model_path).stem).group(<span class=\"hljs-number\">1</span>)<br> <br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">attempt_load_weights</span>(<span class=\"hljs-params\">weights, device=<span class=\"hljs-literal\">None</span>, inplace=<span class=\"hljs-literal\">True</span>, fuse=<span class=\"hljs-literal\">False</span></span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;Loads weights for a model or an ensemble of models.&quot;&quot;&quot;</span><br>    ensemble = Ensemble()<br>    <span class=\"hljs-keyword\">for</span> w <span class=\"hljs-keyword\">in</span> weights <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(weights, <span class=\"hljs-built_in\">list</span>) <span class=\"hljs-keyword\">else</span> [weights]:<br>        ckpt, _ = torch_safe_load(w)<br>        model = (ckpt.get(<span class=\"hljs-string\">&quot;ema&quot;</span>) <span class=\"hljs-keyword\">or</span> ckpt[<span class=\"hljs-string\">&quot;model&quot;</span>]).to(device).<span class=\"hljs-built_in\">float</span>()<br>        model = model.fuse().<span class=\"hljs-built_in\">eval</span>() <span class=\"hljs-keyword\">if</span> fuse <span class=\"hljs-keyword\">and</span> <span class=\"hljs-built_in\">hasattr</span>(model, <span class=\"hljs-string\">&quot;fuse&quot;</span>) <span class=\"hljs-keyword\">else</span> model.<span class=\"hljs-built_in\">eval</span>()<br>        ensemble.append(model)<br> <br>    <span class=\"hljs-keyword\">return</span> ensemble <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(ensemble) &gt; <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">else</span> ensemble[-<span class=\"hljs-number\">1</span>]<br> <br></code></pre></td></tr></table></figure>\n\n<p>此 tasks.py 脚本是代码管道的核心部分;它仍然使用 YOLOv8 方法和逻辑;我们只需要将 YOLO11 模型解析到其中。此脚本专为各种计算机视觉任务而设计，例如对象检测、分割、分类、姿势估计、OBB 等。它定义了用于训练、推理和模型管理的基础模型、特定于任务的模型和效用函数。</p>\n<h4 id=\"关键组件：-3\"><a href=\"#关键组件：-3\" class=\"headerlink\" title=\"关键组件：\"></a><strong>关键组件：</strong></h4><ul>\n<li><strong>Imports：</strong>该脚本从 Ultralytics 导入 PyTorch （torch）、神经网络层 （torch.nn） 和实用函数等基本模块。一些关键导入包括：<ul>\n<li>对 <strong>C3k2</strong>、<strong>C2PSA</strong>、<strong>C3</strong>、<strong>SPPF、****Concat</strong> 等架构模块进行建模。</li>\n<li>损失函数，如 <strong>v8DetectionLoss</strong>、<strong>v8SegmentationLoss</strong>、<strong>v8ClassificationLoss</strong>、<strong>v8OBBLoss</strong>。</li>\n<li>各种实用程序函数，如 model_info、<strong>fuse_conv_and_bn</strong>、<strong>scale_img</strong> <strong>time_sync</strong>，以帮助进行模型处理、分析和评估。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"模型基类：\"><a href=\"#模型基类：\" class=\"headerlink\" title=\"模型基类：\"></a><strong>模型基类：</strong></h4><ol>\n<li>BaseModel 类：<ul>\n<li>BaseModel 用作 Ultralytics YOLO 系列中所有模型的基类。</li>\n<li>实现如下基本方法：<ul>\n<li><strong>forward（）：</strong>根据输入数据处理训练和推理。</li>\n<li><strong>predict（）：</strong>处理前向传递以进行推理。</li>\n<li><strong>fuse（）：</strong>融合 Conv2d 和 BatchNorm2d 层以提高效率。</li>\n<li><strong>info（）：</strong>提供详细的模型信息。</li>\n</ul>\n</li>\n<li>此类旨在通过特定于任务的模型（例如检测、分割和分类）进行扩展。</li>\n</ul>\n</li>\n<li><strong>DetectionModel</strong> <strong>类：</strong><ul>\n<li>扩展 BaseModel，专门用于对象检测任务。</li>\n<li>加载模型配置，初始化检测头（如 Detect 模块）并设置模型步幅。</li>\n<li>它支持使用 YOLOv8 等架构的检测任务，并可以通过 <strong>_predict_augment（）</strong> 执行增强推理。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"特定于任务的模型：\"><a href=\"#特定于任务的模型：\" class=\"headerlink\" title=\"特定于任务的模型：\"></a><strong>特定于任务的模型：</strong></h4><ol>\n<li><strong>SegmentationModel 的 SegmentationModel</strong> <strong>中：</strong><ul>\n<li>专门用于分割任务（如 YOLOv8 分割）的 DetectionModel 的子类。</li>\n<li>初始化特定于分割的损失函数 （v8SegmentationLoss）。</li>\n</ul>\n</li>\n<li><strong>PoseModel 的 PoseModel</strong> <strong>中：</strong><ul>\n<li>通过初始化具有关键点检测 （<strong>kpt_shape</strong>） 特定配置的模型来处理姿态估计任务。</li>\n<li>使用 v8PoseLoss 进行特定于姿势的损失计算。</li>\n</ul>\n</li>\n<li><strong>分类型号****：</strong><ul>\n<li>专为使用 YOLOv8 分类架构的图像分类任务而设计。</li>\n<li>初始化和管理特定于分类的损失 （<strong>v8ClassificationLoss</strong>）。</li>\n<li>它还支持重塑用于分类任务的预训练 TorchVision 模型。</li>\n</ul>\n</li>\n<li><strong>OBB型号****：</strong><ul>\n<li>用于定向边界框 （OBB） 检测任务。</li>\n<li>实现特定的损失函数 （<strong>v8OBBLoss</strong>） 来处理旋转的边界框。</li>\n</ul>\n</li>\n<li><strong>世界模型****：</strong><ul>\n<li>此模型处理图像字幕和基于文本的识别等任务。</li>\n<li>利用 CLIP 模型中的文本特征执行基于文本的视觉识别任务。</li>\n<li>包括对文本嵌入 （<strong>txt_feats</strong>） 的特殊处理，用于字幕和世界相关任务。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"集成模型：\"><a href=\"#集成模型：\" class=\"headerlink\" title=\"集成模型：\"></a><strong>集成模型：</strong></h4><ol>\n<li><strong>集成****：</strong><ul>\n<li>一个简单的 ensemble 类，它将多个模型合并为一个模型。</li>\n<li>允许对不同模型的输出进行平均或串联，以提高整体性能。</li>\n<li>对于组合多个模型的输出提供更好的预测的任务非常有用。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"实用功能：\"><a href=\"#实用功能：\" class=\"headerlink\" title=\"实用功能：\"></a><strong>实用功能：</strong></h4><ol>\n<li>模型加载和管理：<ul>\n<li><strong>attempt_load_weights（）、****attempt_load_one_weight（）</strong>：用于加载模型、管理集成模型以及处理加载预训练权重时的兼容性问题的函数。</li>\n<li>这些功能可确保以适当的步幅、层和配置正确加载模型。</li>\n</ul>\n</li>\n<li>临时模块重定向：<ul>\n<li><strong>temporary_modules（）</strong>：一个上下文管理器，用于临时重定向模块路径，确保在模块位置更改时向后兼容。</li>\n<li>有助于保持与旧型号版本的兼容性。</li>\n</ul>\n</li>\n<li><strong>Pickle</strong>安全处理：<ul>\n<li>SafeUnpickler：一个自定义的解封器，可以安全地加载模型检查点，确保未知类被安全的占位符（SafeClass）替换，以避免在加载过程中发生崩溃。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"模型解析：\"><a href=\"#模型解析：\" class=\"headerlink\" title=\"模型解析：\"></a><strong>模型解析：</strong></h4><ol>\n<li><strong>parse_model（）</strong> <strong>中：</strong><ul>\n<li>此函数将 YAML 文件中的模型配置解析为 PyTorch 模型。</li>\n<li>它处理主干和头架构，解释每个层类型（如 Conv、SPPF、Detect），并构建最终模型。</li>\n<li>支持各种架构，包括 C3k2、C2PSA 等 YOLO11 组件。</li>\n</ul>\n</li>\n<li>YAML 模型加载：<ul>\n<li><strong>yaml_model_load（）</strong>）：从 YAML 文件加载模型配置，检测模型比例（例如 n、s、m、l、x）并相应地调整参数。</li>\n<li><strong>guess_model_scale（）、****guess_model_task（）</strong>：用于根据 YAML 文件结构推断模型规模和任务的辅助函数。</li>\n</ul>\n</li>\n</ol>\n","excerpt":"","more":"<p>2024 年是 YOLO 模型的一年。在 2023 年发布 Ultralytics YOLOv8 之后， YOLOv9 和 YOLOv10也在2024年发布了。但等等，这还不是结束！Ultralytics YOLO11 终于来了，在激动人心的 YOLO Vision 2024 （YV24） 活动中亮相。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/feature.gif\"></p>\n<p>YOLO11 系列是 YOLO 系列中最先进的 （SOTA）、最轻、最高效的型号，性能优于其前代产品。它由 Ultralytics 创建，该组织发布了 YOLOv8，这是迄今为止最稳定和使用最广泛的 YOLO 变体。现在，YOLO11 将继续 YOLO 系列的传统。在本文中，我们将探讨：</p>\n<ul>\n<li><strong>什么是 YOLO11？</strong></li>\n<li><strong>YOLO11 能做什么？</strong></li>\n<li><strong>YOLO11 比其他 YOLO 变体更高效吗？</strong></li>\n<li><strong>YOLO11 架构有哪些改进？</strong></li>\n<li><strong>YOLO11 的代码pipeline是如何工作的？</strong></li>\n<li><strong>YOLO11 的基准测试</strong></li>\n<li><strong>YOLO11 快速回顾</strong></li>\n</ul>\n<h1 id=\"什么是YOLO11\"><a href=\"#什么是YOLO11\" class=\"headerlink\" title=\"什么是YOLO11\"></a>什么是YOLO11</h1><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-1.png\"></p>\n<p>YOLO11 是 Ultralytics 的 YOLO 系列的最新版本。YOLO11 配备了超轻量级型号，比以前的 YOLO 更快、更高效。YOLO11 能够执行更广泛的计算机视觉任务。Ultralytics 根据大小发布了 5 个 YOLO11 模型，并在<strong>所有任务中发布了 25 个模型</strong>：</p>\n<ul>\n<li><strong>YOLO11n</strong> – Nano 适用于小型和轻量级任务。</li>\n<li><strong>YOLO11s</strong> – Nano 的小升级，具有一些额外的准确性。</li>\n<li><strong>YOLO11m</strong> – 通用型。</li>\n<li><strong>YOLO11l</strong> – 大，精度更高，计算量更高。</li>\n<li><strong>YOLO11x</strong> – 超大尺寸，可实现最大精度和性能。</li>\n</ul>\n<p><img src=\"https://learnopencv.com/wp-content/uploads/2024/10/yolo11-model-table.png\"></p>\n<p>YOLO11 构建在 Ultralytics YOLOv8 代码库之上，并进行了一些架构修改。它还集成了以前 YOLO（如 YOLOv9 和 YOLOv10）的新功能（改进这些功能）以提高性能。我们将在博客文章的后面部分探讨架构和代码库中的新变化。</p>\n<h1 id=\"YOLO11的应用\"><a href=\"#YOLO11的应用\" class=\"headerlink\" title=\"YOLO11的应用\"></a>YOLO11的应用</h1><p>YOLO 以其对象检测模型而闻名。但是，YOLO11 可以执行多个计算机视觉任务，例如 YOLOv8。它包括：</p>\n<ul>\n<li><strong>对象检测</strong></li>\n<li><strong>实例分段</strong></li>\n<li><strong>图像分类</strong></li>\n<li><strong>姿势估计</strong></li>\n<li><strong>定向目标检测 （OBB）</strong></li>\n</ul>\n<p>让我们来探索所有这些。</p>\n<h3 id=\"对象检测\"><a href=\"#对象检测\" class=\"headerlink\" title=\"对象检测\"></a>对象检测</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-object-detection.gif\" alt=\"yolo11-对象检测\"></p>\n<p>YOLO11 通过将输入图像传递到 CNN 以提取特征来执行对象检测。然后，网络预测这些网格中对象的边界框和类概率。为了处理多尺度检测，使用图层来确保检测到各种大小的物体。然后使用非极大值抑制 （NMS） 来优化这些预测，以过滤掉重复或低置信度的框，从而获得更准确的对象检测。YOLO11 在 MS-COCO 数据集上进行对象检测训练，其中包括 80 个预训练类。</p>\n<h3 id=\"实例分割\"><a href=\"#实例分割\" class=\"headerlink\" title=\"实例分割\"></a>实例分割</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-instance-segmentation-1-1733102326734-1.png\" alt=\" \"></p>\n<p>除了检测对象之外，YOLO11 还通过添加掩码预测分支扩展到实例分割。这些模型在 MS-COCO 数据集上进行训练，其中包括 80 个预训练类。此分支为每个检测到的对象生成像素级分割掩码，使模型能够区分重叠的对象并提供其形状的精确轮廓。head 中的蒙版分支处理特征映射并输出对象蒙版，从而在识别和区分图像中的对象时实现像素级精度。</p>\n<h3 id=\"姿势估计\"><a href=\"#姿势估计\" class=\"headerlink\" title=\"姿势估计\"></a>姿势估计</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-pose-estimation.gif\" alt=\"YOLO11 姿势\"></p>\n<p>YOLO11 通过检测和预测物体上的关键点（例如人体的关节）来执行姿态估计。关键点连接起来形成骨架结构，该结构表示姿势。这些模型在 COCO 上进行训练，其中包括一个预先训练的类“person”。</p>\n<p>在头部添加姿态估计层，并训练网络预测关键点的坐标。后处理步骤将点连接起来以形成骨架结构，从而实现实时姿势识别。</p>\n<h3 id=\"图像分类\"><a href=\"#图像分类\" class=\"headerlink\" title=\"图像分类\"></a>图像分类</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-image-classification.gif\" alt=\"YOLO11 图像分类\"></p>\n<p>对于图像分类，YOLO11 使用其深度神经网络从输入图像中提取高级特征，并将其分配给多个预定义类别之一。这些模型在 ImageNet 上进行训练，其中包括 1000 个预训练类。该网络通过多层卷积和池化处理图像，在增强基本特征的同时减少空间维度。网络顶部的分类头输出预测的类，使其适用于需要识别图像整体类别的任务。</p>\n<h3 id=\"定向目标检测-（OBB）\"><a href=\"#定向目标检测-（OBB）\" class=\"headerlink\" title=\"定向目标检测 （OBB）\"></a>定向目标检测 （OBB）</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-obb-detection-1.gif\" alt=\"YOLO11-OBB\"></p>\n<p>YOLO11 通过整合 OBB 扩展了常规对象检测，使模型能够检测和分类旋转或不规则方向的物体。这对于航空影像分析等应用程序特别有用。这些模型在 DOTAv1 上进行训练，其中包括 15 个预训练类。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/yolo11-obb-logic-1-1024x615.png\" alt=\"YOLO11-OBB\"></p>\n<p>OBB 模型不仅输出边界框坐标，还输出旋转角度 （θ） 或四个角点。这些坐标用于创建与对象方向对齐的边界框，从而提高旋转对象的检测准确性。</p>\n<h1 id=\"YOLO11-架构和-YOLO11-中的新增功能\"><a href=\"#YOLO11-架构和-YOLO11-中的新增功能\" class=\"headerlink\" title=\"YOLO11 架构和 YOLO11 中的新增功能\"></a>YOLO11 架构和 YOLO11 中的新增功能</h1><p>YOLO11 架构是对 YOLOv8 架构的升级，具有一些新的集成和参数调整。在我们继续主要部分之前，您可以查看我们关于 <a href=\"https://learnopencv.com/ultralytics-yolov8/\"><strong>YOLOv8</strong></a> 的详细文章以大致了解架构。现在，如果你看一下 YOLO11 的配置文件：</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-comment\"># Parameters</span><br><span class=\"hljs-attr\">nc:</span> <span class=\"hljs-number\">80</span> <span class=\"hljs-comment\"># number of classes</span><br><span class=\"hljs-attr\">scales:</span> <span class=\"hljs-comment\"># model compound scaling constants, i.e. &#x27;model=yolo11n.yaml&#x27; will call yolo11.yaml with scale &#x27;n&#x27;</span><br>  <span class=\"hljs-comment\"># [depth, width, max_channels]</span><br>  <span class=\"hljs-attr\">n:</span> [<span class=\"hljs-number\">0.50</span>, <span class=\"hljs-number\">0.25</span>, <span class=\"hljs-number\">1024</span>] <span class=\"hljs-comment\"># summary: 319 layers, 2624080 parameters, 2624064 gradients, 6.6 GFLOPs</span><br>  <span class=\"hljs-attr\">s:</span> [<span class=\"hljs-number\">0.50</span>, <span class=\"hljs-number\">0.50</span>, <span class=\"hljs-number\">1024</span>] <span class=\"hljs-comment\"># summary: 319 layers, 9458752 parameters, 9458736 gradients, 21.7 GFLOPs</span><br>  <span class=\"hljs-attr\">m:</span> [<span class=\"hljs-number\">0.50</span>, <span class=\"hljs-number\">1.00</span>, <span class=\"hljs-number\">512</span>] <span class=\"hljs-comment\"># summary: 409 layers, 20114688 parameters, 20114672 gradients, 68.5 GFLOPs</span><br>  <span class=\"hljs-attr\">l:</span> [<span class=\"hljs-number\">1.00</span>, <span class=\"hljs-number\">1.00</span>, <span class=\"hljs-number\">512</span>] <span class=\"hljs-comment\"># summary: 631 layers, 25372160 parameters, 25372144 gradients, 87.6 GFLOPs</span><br>  <span class=\"hljs-attr\">x:</span> [<span class=\"hljs-number\">1.00</span>, <span class=\"hljs-number\">1.50</span>, <span class=\"hljs-number\">512</span>] <span class=\"hljs-comment\"># summary: 631 layers, 56966176 parameters, 56966160 gradients, 196.0 GFLOPs</span><br> <br><span class=\"hljs-comment\"># YOLO11n backbone</span><br><span class=\"hljs-attr\">backbone:</span><br>  <span class=\"hljs-comment\"># [from, repeats, module, args]</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Conv</span>, [<span class=\"hljs-number\">64</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]] <span class=\"hljs-comment\"># 0-P1/2</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Conv</span>, [<span class=\"hljs-number\">128</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]] <span class=\"hljs-comment\"># 1-P2/4</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C3k2</span>, [<span class=\"hljs-number\">256</span>, <span class=\"hljs-literal\">False</span>, <span class=\"hljs-number\">0.25</span>]]<br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Conv</span>, [<span class=\"hljs-number\">256</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]] <span class=\"hljs-comment\"># 3-P3/8</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C3k2</span>, [<span class=\"hljs-number\">512</span>, <span class=\"hljs-literal\">False</span>, <span class=\"hljs-number\">0.25</span>]]<br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Conv</span>, [<span class=\"hljs-number\">512</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]] <span class=\"hljs-comment\"># 5-P4/16</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C3k2</span>, [<span class=\"hljs-number\">512</span>, <span class=\"hljs-literal\">True</span>]]<br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Conv</span>, [<span class=\"hljs-number\">1024</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]] <span class=\"hljs-comment\"># 7-P5/32</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C3k2</span>, [<span class=\"hljs-number\">1024</span>, <span class=\"hljs-literal\">True</span>]]<br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">SPPF</span>, [<span class=\"hljs-number\">1024</span>, <span class=\"hljs-number\">5</span>]] <span class=\"hljs-comment\"># 9</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C2PSA</span>, [<span class=\"hljs-number\">1024</span>]] <span class=\"hljs-comment\"># 10</span><br> <br><span class=\"hljs-comment\"># YOLO11n head</span><br><span class=\"hljs-attr\">head:</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">nn.Upsample</span>, [<span class=\"hljs-string\">None</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">&quot;nearest&quot;</span>]]<br>  <span class=\"hljs-bullet\">-</span> [[<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">6</span>], <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Concat</span>, [<span class=\"hljs-number\">1</span>]] <span class=\"hljs-comment\"># cat backbone P4</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C3k2</span>, [<span class=\"hljs-number\">512</span>, <span class=\"hljs-literal\">False</span>]] <span class=\"hljs-comment\"># 13</span><br> <br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">nn.Upsample</span>, [<span class=\"hljs-string\">None</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">&quot;nearest&quot;</span>]]<br>  <span class=\"hljs-bullet\">-</span> [[<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">4</span>], <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Concat</span>, [<span class=\"hljs-number\">1</span>]] <span class=\"hljs-comment\"># cat backbone P3</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C3k2</span>, [<span class=\"hljs-number\">256</span>, <span class=\"hljs-literal\">False</span>]] <span class=\"hljs-comment\"># 16 (P3/8-small)</span><br> <br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Conv</span>, [<span class=\"hljs-number\">256</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]]<br>  <span class=\"hljs-bullet\">-</span> [[<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">13</span>], <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Concat</span>, [<span class=\"hljs-number\">1</span>]] <span class=\"hljs-comment\"># cat head P4</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C3k2</span>, [<span class=\"hljs-number\">512</span>, <span class=\"hljs-literal\">False</span>]] <span class=\"hljs-comment\"># 19 (P4/16-medium)</span><br> <br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Conv</span>, [<span class=\"hljs-number\">512</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]]<br>  <span class=\"hljs-bullet\">-</span> [[<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">10</span>], <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Concat</span>, [<span class=\"hljs-number\">1</span>]] <span class=\"hljs-comment\"># cat head P5</span><br>  <span class=\"hljs-bullet\">-</span> [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">C3k2</span>, [<span class=\"hljs-number\">1024</span>, <span class=\"hljs-literal\">True</span>]] <span class=\"hljs-comment\"># 22 (P5/32-large)</span><br> <br>  <span class=\"hljs-bullet\">-</span> [[<span class=\"hljs-number\">16</span>, <span class=\"hljs-number\">19</span>, <span class=\"hljs-number\">22</span>], <span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">Detect</span>, [<span class=\"hljs-string\">nc</span>]] <span class=\"hljs-comment\"># Detect(P3, P4, P5)</span><br></code></pre></td></tr></table></figure>\n\n<p>架构级别的变化：</p>\n<h3 id=\"1-骨干\"><a href=\"#1-骨干\" class=\"headerlink\" title=\"1. 骨干\"></a><strong>1. 骨干</strong></h3><p>主干是模型的一部分，用于从多个比例的输入图像中提取特征。它通常涉及堆叠卷积层和块以创建不同分辨率的特征图。</p>\n<p><strong>卷积层：</strong>YOLO11 具有类似的结构，带有初始卷积层来对图像进行下采样：</p>\n<figure class=\"highlight gauss\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gauss\">- [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-built_in\">Conv</span>, [<span class=\"hljs-number\">64</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]] <span class=\"hljs-meta\"># 0-P1/2</span><br>- [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">1</span>, <span class=\"hljs-built_in\">Conv</span>, [<span class=\"hljs-number\">128</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">2</span>]] <span class=\"hljs-meta\"># 1-P2/4</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li><p><strong>C3k2 区块：</strong>YOLO11 引入了 <strong>C3k2 块，而不是 C2f</strong>，它在计算方面效率更高。此块是 <strong>CSP 瓶颈</strong>的自定义实现，它使用两个卷积，而不是一个大型卷积（如 YOLOv8 中所示）。</p>\n<ul>\n<li><strong>CSP （Cross Stage Partial）：</strong>CSP 网络拆分特征图并通过瓶颈层处理一部分，同时将另一部分与瓶颈的输出合并。这减少了计算负载并改善了特征表示。</li>\n</ul>\n<figure class=\"highlight inform7\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs inform7\">- <span class=\"hljs-comment\">[-1, 2, C3k2, <span class=\"hljs-comment\">[256, False, 0.25]</span>]</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>C3k2 块还使用较小的内核大小（由 k2 表示），使其更快，同时保持性能。</li>\n</ul>\n<p><strong>SPPF 和 C2PSA：</strong>YOLO11 保留了 SPPF 块，但在 SPPF 之后添加了一个新的 <strong>C2PSA</strong> 块：</p>\n</li>\n</ul>\n<figure class=\"highlight inform7\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs inform7\">- <span class=\"hljs-comment\">[-1, 1, SPPF, <span class=\"hljs-comment\">[1024, 5]</span>]</span><br>- <span class=\"hljs-comment\">[-1, 2, C2PSA, <span class=\"hljs-comment\">[1024]</span></span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li><strong>C2PSA （Cross Stage Partial with Spatial Attention）</strong> 模块增强了特征图中的空间注意力，从而提高了模型对图像重要部分的关注。这使模型能够通过在空间上池化特征来更有效地关注特定的感兴趣区域。</li>\n</ul>\n<h3 id=\"2-neck\"><a href=\"#2-neck\" class=\"headerlink\" title=\"2. neck\"></a><strong>2. neck</strong></h3><p>neck 负责聚合来自不同分辨率的特征，并将它们传递给头部进行预测。它通常涉及来自不同级别的特征图的上采样和连接。</p>\n<p><strong>C3k2 区块：</strong>YOLO11 用 <strong>C3k2</strong> 块替换了颈部的 C2f 块。如前所述，C3k2 是一个更快、更高效的区块。例如，在上采样和串联后，YOLO11 中的 neck 如下所示：</p>\n<figure class=\"highlight autoit\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs autoit\">\t<br>- [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, C3k2, [<span class=\"hljs-number\">512</span>, <span class=\"hljs-literal\">False</span>]] <span class=\"hljs-meta\"># P4/16-medium</span><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>此更改提高了要素聚合过程的速度和性能。</li>\n<li><strong>注意力机制：</strong>YOLO11 通过 <strong>C2PSA</strong> 更侧重于空间注意力，这有助于模型专注于图像中的关键区域，以便更好地检测。这在 YOLOv8 中是缺失的，这使得 YOLO11 在检测较小或被遮挡的对象时可能更准确。</li>\n</ul>\n<hr>\n<h3 id=\"3-head\"><a href=\"#3-head\" class=\"headerlink\" title=\"3. head\"></a><strong>3. head</strong></h3><p>head 是模型中负责生成最终预测的部分。在对象检测中，这通常意味着生成边界框并对这些框内的对象进行分类。</p>\n<p><strong>C3k2 区块：</strong>与颈部类似，YOLO11 取代了头部的 <strong>C2f</strong> 块。</p>\n<figure class=\"highlight autoit\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs autoit\">\t<br>- [<span class=\"hljs-number\">-1</span>, <span class=\"hljs-number\">2</span>, C3k2, [<span class=\"hljs-number\">512</span>, <span class=\"hljs-literal\">False</span>]] <span class=\"hljs-meta\"># P4/16-medium</span><br><br></code></pre></td></tr></table></figure>\n\n<p><strong>检测层：</strong>最终的 Detect 层与 YOLOv8 中的层相同：</p>\n<figure class=\"highlight lua\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs lua\">- <span class=\"hljs-string\">[[16, 19, 22], 1, Detect, [nc]]</span> # Detect(P3, P4, P5)<br><br></code></pre></td></tr></table></figure>\n\n<p>使用 C3k2 块使模型在推理方面更快，在参数方面更高效。<br>那么，让我们看看新块（层）在代码中的样子：</p>\n<hr>\n<p>那么，让我们看看新块（层）在代码中的样子：</p>\n<ol>\n<li><strong>C3k2 区块（从</strong> <strong>blocks.py</strong> 开始<strong>）：</strong><ul>\n<li><strong>C3k2</strong> 是 <strong>CSP 瓶颈</strong>的更快、更高效的变体。它使用两个卷积而不是一个大型卷积，从而加快了特征提取速度。</li>\n</ul>\n</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">C3k2</span>(<span class=\"hljs-title class_ inherited__\">C2f</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, c1, c2, n=<span class=\"hljs-number\">1</span>, c3k=<span class=\"hljs-literal\">False</span>, e=<span class=\"hljs-number\">0.5</span>, g=<span class=\"hljs-number\">1</span>, shortcut=<span class=\"hljs-literal\">True</span></span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__(c1, c2, n, shortcut, g, e)<br>        <span class=\"hljs-variable language_\">self</span>.m = nn.ModuleList(<br>            C3k(<span class=\"hljs-variable language_\">self</span>.c, <span class=\"hljs-variable language_\">self</span>.c, <span class=\"hljs-number\">2</span>, shortcut, g) <span class=\"hljs-keyword\">if</span> c3k <span class=\"hljs-keyword\">else</span> Bottleneck(<span class=\"hljs-variable language_\">self</span>.c, <span class=\"hljs-variable language_\">self</span>.c, shortcut, g) <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(n)<br>        )<br></code></pre></td></tr></table></figure>\n\n<ol start=\"2\">\n<li><strong>C3k 块（从</strong> <strong>blocks.py</strong> 开始<strong>）</strong>：</li>\n</ol>\n<ul>\n<li><strong>C3k</strong> 是一个更灵活的瓶颈模块，允许自定义内核大小。这对于提取图像中更详细的特征非常有用。</li>\n</ul>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">class C3k(C3):<br>    def __init__(self, c1, c2, <span class=\"hljs-attribute\">n</span>=1, <span class=\"hljs-attribute\">shortcut</span>=<span class=\"hljs-literal\">True</span>, <span class=\"hljs-attribute\">g</span>=1, <span class=\"hljs-attribute\">e</span>=0.5, <span class=\"hljs-attribute\">k</span>=3):<br>        super().__init__(c1, c2, n, shortcut, g, e)<br>        c_ = int(c2 * e)  # hidden channels<br>        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, k=(k, k), <span class=\"hljs-attribute\">e</span>=1.0) <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> range(n)))<br></code></pre></td></tr></table></figure>\n\n<ol start=\"3\">\n<li><strong>C2PSA 块（从</strong> <strong>blocks.py</strong> 年起<strong>）：</strong></li>\n</ol>\n<ul>\n<li><strong>C2PSA</strong> （Cross Stage Partial with Spatial Attention） 增强了模型的空间注意力能力。此模块增加了对特征图的关注，帮助模型专注于图像的重要区域。</li>\n</ul>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ruby\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">C2</span>PSA(nn.<span class=\"hljs-title class_\">Module</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span>, c1, c2, e=<span class=\"hljs-number\">0.5</span></span>):<br>        <span class=\"hljs-variable language_\">super</span>().__init__()<br>        c_ = int(c2 * e)<br>        <span class=\"hljs-variable language_\">self</span>.cv1 = <span class=\"hljs-title class_\">Conv</span>(c1, c_, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-variable language_\">self</span>.cv2 = <span class=\"hljs-title class_\">Conv</span>(c1, c_, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-variable language_\">self</span>.cv3 = <span class=\"hljs-title class_\">Conv</span>(<span class=\"hljs-number\">2</span> * c_, c2, <span class=\"hljs-number\">1</span>)<br>     <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span>, x</span>):<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>.cv3(torch.cat((<span class=\"hljs-variable language_\">self</span>.cv1(x), <span class=\"hljs-variable language_\">self</span>.cv2(x)), <span class=\"hljs-number\">1</span>))<br></code></pre></td></tr></table></figure>\n\n<h1 id=\"YOLO11-pipeline\"><a href=\"#YOLO11-pipeline\" class=\"headerlink\" title=\"YOLO11 pipeline\"></a>YOLO11 pipeline</h1><p>在 <a href=\"https://github.com/ultralytics/ultralytics\"><strong>ultralytics</strong></a> GitHub 仓库中，我们将主要关注：</p>\n<ol>\n<li><strong>nn&#x2F;modules&#x2F;</strong> 中的模块<ul>\n<li><strong>block.py</strong></li>\n<li><strong>conv.py</strong></li>\n<li><strong>head.py</strong></li>\n<li><strong>transformer.py</strong></li>\n<li><strong>utils.py</strong></li>\n</ul>\n</li>\n<li><strong>nn&#x2F;tasks.py</strong> 文件</li>\n</ol>\n<h3 id=\"1-代码库概述\"><a href=\"#1-代码库概述\" class=\"headerlink\" title=\"1. 代码库概述\"></a>1. 代码库概述</h3><p>代码库被构建为多个模块，这些模块定义了 YOLO11 模型中使用的各种神经网络组件。这些组件在 nn&#x2F;modules&#x2F; 目录中被组织到不同的文件中：</p>\n<ul>\n<li><strong>block.py</strong>：定义模型中使用的各种构建块（模块），例如瓶颈、CSP 模块和注意力机制。</li>\n<li><strong>conv.py</strong>：包含卷积模块，包括标准卷积、深度卷积和其他变体。</li>\n<li><strong>head.py</strong>：实现负责生成最终预测（例如，边界框、类概率）的模型头。</li>\n<li><strong>transformer.py</strong>：包括基于 transformer 的模块，用于注意力机制和高级特征提取。</li>\n<li><strong>utils.py</strong>：提供跨模块使用的实用程序函数和帮助程序类。</li>\n</ul>\n<p>nn&#x2F;tasks.py 文件定义了不同的特定于任务的模型（例如，检测、分割、分类），这些模型将这些模块组合成完整的架构。</p>\n<h3 id=\"2-nn-modules-中的模块\"><a href=\"#2-nn-modules-中的模块\" class=\"headerlink\" title=\"2. nn&#x2F;modules&#x2F; 中的模块\"></a>2. nn&#x2F;modules&#x2F; 中的模块</h3><p>如前所述，YOLO11 构建在 YOLOv8 代码库之上。因此，我们将主要关注更新的脚本：<strong>block.py</strong>、<strong>conv.py</strong> 和 <strong>head.py</strong> 在这里。</p>\n<h4 id=\"block-py\"><a href=\"#block-py\" class=\"headerlink\" title=\"block.py\"></a><strong>block.py</strong></h4><p>此文件定义 YOLO11 模型中使用的各种构建块。这些块是构成神经网络层的基本组件。</p>\n<h5 id=\"关键组件：\"><a href=\"#关键组件：\" class=\"headerlink\" title=\"关键组件：\"></a><strong>关键组件：</strong></h5><ol>\n<li>瓶颈模块：<ul>\n<li><strong>Bottleneck</strong>：具有可选快捷方式连接的标准瓶颈模块。</li>\n<li><strong>Res</strong>：使用一系列卷积和身份快捷方式的残差块。</li>\n</ul>\n</li>\n</ol>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Bottleneck</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, c1, c2, shortcut=<span class=\"hljs-literal\">True</span>, g=<span class=\"hljs-number\">1</span>, e=<span class=\"hljs-number\">0.5</span></span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        c_ = <span class=\"hljs-built_in\">int</span>(c2 * e)<br>        <span class=\"hljs-variable language_\">self</span>.cv1 = Conv(c1, c_, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-variable language_\">self</span>.cv2 = Conv(c_, c2, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">1</span>, g=g)<br>        <span class=\"hljs-variable language_\">self</span>.add = shortcut <span class=\"hljs-keyword\">and</span> c1 == c2<br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        <span class=\"hljs-keyword\">return</span> x + <span class=\"hljs-variable language_\">self</span>.cv2(<span class=\"hljs-variable language_\">self</span>.cv1(x)) <span class=\"hljs-keyword\">if</span> <span class=\"hljs-variable language_\">self</span>.add <span class=\"hljs-keyword\">else</span> <span class=\"hljs-variable language_\">self</span>.cv2(<span class=\"hljs-variable language_\">self</span>.cv1(x))<br><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>Bottleneck 类实现了一个 bottleneck 模块，该模块减少了通道的数量（降维），然后再次扩展它们。</li>\n<li><strong>组件</strong>：<ul>\n<li>self.cv1：一个 1×1 卷积，用于减少通道数。</li>\n<li>self.cv2：一个 3×3 卷积，用于将通道数增加回原始通道数。</li>\n<li>self.add：一个布尔值，指示是否添加快捷方式连接。</li>\n</ul>\n</li>\n<li><strong>Forward Pass</strong>：输入 x 通过 cv1 和 cv2 传递。如果 self.add 为 True，则原始输入 x 将添加到输出（残差连接）。</li>\n</ul>\n<ol start=\"2\">\n<li>CSP （Cross Stage Partial） 模块：</li>\n</ol>\n<ul>\n<li><strong>BottleneckCSP：</strong>瓶颈模块的 CSP 版本。</li>\n<li><strong>CSPBlock</strong>：具有多个瓶颈层的更复杂的 CSP 模块。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">BottleneckCSP</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, c1, c2, n=<span class=\"hljs-number\">1</span>, shortcut=<span class=\"hljs-literal\">True</span>, g=<span class=\"hljs-number\">1</span>, e=<span class=\"hljs-number\">0.5</span></span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        c_ = <span class=\"hljs-built_in\">int</span>(c2 * e)<br>        <span class=\"hljs-variable language_\">self</span>.cv1 = Conv(c1, c_, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-variable language_\">self</span>.cv2 = nn.Sequential(<br>            *[Bottleneck(c_, c_, shortcut, g, e=<span class=\"hljs-number\">1.0</span>) <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(n)]<br>        )<br>        <span class=\"hljs-variable language_\">self</span>.cv3 = Conv(<span class=\"hljs-number\">2</span> * c_, c2, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-variable language_\">self</span>.add = c1 == c2<br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        y1 = <span class=\"hljs-variable language_\">self</span>.cv2(<span class=\"hljs-variable language_\">self</span>.cv1(x))<br>        y2 = x <span class=\"hljs-keyword\">if</span> <span class=\"hljs-variable language_\">self</span>.add <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span><br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>.cv3(torch.cat((y1, y2), <span class=\"hljs-number\">1</span>)) <span class=\"hljs-keyword\">if</span> y2 <span class=\"hljs-keyword\">is</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-literal\">None</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-variable language_\">self</span>.cv3(y1)<br><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>CSPBottleneck 模块将特征图分为两部分。一部分通过一系列瓶颈层，另一部分直接连接到输出，从而降低了计算成本并增强了梯度流。</li>\n<li><strong>组件</strong>：<ul>\n<li>self.cv1：减少通道数。</li>\n<li>self.cv2：瓶颈层序列。</li>\n<li>self.cv3：合并功能并调整通道数。</li>\n<li>self.add：确定是否添加快捷方式连接。</li>\n</ul>\n</li>\n</ul>\n<ol start=\"3\">\n<li>其他模块：</li>\n</ol>\n<ul>\n<li><strong>SPPF：</strong>Spatial Pyramid Pooling Fast 模块，可在多个比例下执行池化。</li>\n<li><strong>Concat</strong>：沿指定维度连接多个 Tensor。</li>\n</ul>\n<figure class=\"highlight gml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs gml\">class SPPF(nn.Module):<br>    def __init__(<span class=\"hljs-symbol\">self</span>, c1, c2, k=<span class=\"hljs-number\">5</span>):<br>        super().__init__()<br>        c_ = c1 <span class=\"hljs-comment\">// 2</span><br>        <span class=\"hljs-symbol\">self</span>.cv1 = Conv(c1, c_, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-symbol\">self</span>.cv2 = Conv(c_ * <span class=\"hljs-number\">4</span>, c2, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-symbol\">self</span>.m = nn.MaxPool2d(kernel_size=k, stride=<span class=\"hljs-number\">1</span>, padding=k <span class=\"hljs-comment\">// 2)</span><br> <br>    def forward(<span class=\"hljs-symbol\">self</span>, <span class=\"hljs-variable language_\">x</span>):<br>        <span class=\"hljs-variable language_\">x</span> = <span class=\"hljs-symbol\">self</span>.cv1(<span class=\"hljs-variable language_\">x</span>)<br>        y1 = <span class=\"hljs-symbol\">self</span>.m(<span class=\"hljs-variable language_\">x</span>)<br>        y2 = <span class=\"hljs-symbol\">self</span>.m(y1)<br>        y3 = <span class=\"hljs-symbol\">self</span>.m(y2)<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-symbol\">self</span>.cv2(torch.cat([<span class=\"hljs-variable language_\">x</span>, y1, y2, y3], <span class=\"hljs-number\">1</span>))<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>SPPF 模块在不同比例下执行最大池化，并将结果连接起来以捕获多个空间比例的要素。</li>\n<li><strong>组件</strong>：<ul>\n<li>self.cv1：减少通道数。</li>\n<li>self.cv2：调整拼接后的 Channel 数。</li>\n<li>self.m：最大池化层数。</li>\n</ul>\n</li>\n<li><strong>Forward Pass</strong>：输入 x 通过 cv1，然后通过三个连续的最大池化层（y1、y2、y3）。结果被连接并通过 cv2 传递。</li>\n</ul>\n<h5 id=\"了解概念：\"><a href=\"#了解概念：\" class=\"headerlink\" title=\"了解概念：\"></a><strong>了解概念：</strong></h5><ul>\n<li><strong>瓶颈层</strong>：用于通过在昂贵的操作之前减少通道数并在之后增加通道数来降低计算复杂性。</li>\n<li><strong>残差连接</strong>：通过缓解梯度消失问题来帮助训练更深的网络。</li>\n<li><strong>CSP 架构</strong>：将特征图分为两部分;一部分发生转换，而另一部分保持不变，从而提高学习能力并减少计算。</li>\n</ul>\n<h4 id=\"conv-py\"><a href=\"#conv-py\" class=\"headerlink\" title=\"conv.py\"></a><strong>conv.py</strong></h4><p>此文件包含各种卷积模块，包括标准卷积和专用卷积。</p>\n<h5 id=\"关键组件：-1\"><a href=\"#关键组件：-1\" class=\"headerlink\" title=\"关键组件：\"></a><strong>关键组件：</strong></h5><p><strong>标准卷积模块 （Conv）：</strong></p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">class Conv(nn.Module):<br>    default_act = nn.SiLU()  #<span class=\"hljs-built_in\"> default </span>activation<br> <br>    def __init__(self, c1, c2, <span class=\"hljs-attribute\">k</span>=1, <span class=\"hljs-attribute\">s</span>=1, <span class=\"hljs-attribute\">p</span>=None, <span class=\"hljs-attribute\">g</span>=1, <span class=\"hljs-attribute\">d</span>=1, <span class=\"hljs-attribute\">act</span>=<span class=\"hljs-literal\">True</span>):<br>        super().__init__()<br>        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p, d), <span class=\"hljs-attribute\">groups</span>=g, <span class=\"hljs-attribute\">dilation</span>=d, <span class=\"hljs-attribute\">bias</span>=<span class=\"hljs-literal\">False</span>)<br>        self.bn = nn.BatchNorm2d(c2)<br>        self.act = self.default_act <span class=\"hljs-keyword\">if</span> act is <span class=\"hljs-literal\">True</span> <span class=\"hljs-keyword\">else</span> act <span class=\"hljs-keyword\">if</span> isinstance(act, nn.Module) <span class=\"hljs-keyword\">else</span> nn.Identity()<br> <br>    def forward(self, x):<br>        return self.act(self.bn(self.conv(x)))<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>实现具有批量规范化和激活的标准卷积层。</li>\n<li><strong>组件</strong>：<ul>\n<li>self.conv：卷积层。</li>\n<li>self.bn：批量规范化。</li>\n<li>self.act：激活函数（默认为 nn.SiLU（））的</li>\n</ul>\n</li>\n<li><strong>Forward Pass</strong>：应用卷积，然后进行批量规范化和激活。</li>\n</ul>\n<p><strong>深度卷积 （DWConv）：</strong></p>\n<figure class=\"highlight routeros\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs routeros\">class DWConv(Conv):<br>    def __init__(self, c1, c2, <span class=\"hljs-attribute\">k</span>=1, <span class=\"hljs-attribute\">s</span>=1, <span class=\"hljs-attribute\">d</span>=1, <span class=\"hljs-attribute\">act</span>=<span class=\"hljs-literal\">True</span>):<br>        super().__init__(c1, c2, k, s, <span class=\"hljs-attribute\">g</span>=math.gcd(c1, c2), <span class=\"hljs-attribute\">d</span>=d, <span class=\"hljs-attribute\">act</span>=act)<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>执行深度卷积，其中每个输入通道单独卷积。</li>\n<li><strong>组件</strong>：<ul>\n<li>继承自 Conv。</li>\n<li>将 groups 参数设置为 c1 和 c2 的最大公约数，从而有效地对每个通道的卷积进行分组。</li>\n</ul>\n</li>\n</ul>\n<ol>\n<li>其他卷积模块：<ul>\n<li><strong>Conv2</strong>：RepConv 的简化版本，用于模型压缩和加速。</li>\n<li><strong>GhostConv</strong>：实现 GhostNet 的 ghost 模块，减少特性图中的冗余。</li>\n<li><strong>RepConv</strong>：可重新参数化的卷积层，可以从训练模式转换为推理模式。</li>\n</ul>\n</li>\n</ol>\n<h5 id=\"了解概念：-1\"><a href=\"#了解概念：-1\" class=\"headerlink\" title=\"了解概念：\"></a><strong>了解概念：</strong></h5><ul>\n<li><strong>自动填充 （<strong><strong>autopad</strong></strong>）：</strong>自动计算保持输出尺寸一致所需的填充。</li>\n<li><strong>深度卷积和点卷积</strong>：用于 MobileNet 架构，以减少计算，同时保持准确性。</li>\n<li><strong>重新参数化</strong>：RepConv 等技术通过合并层来实现高效的训练和更快的推理。</li>\n</ul>\n<h4 id=\"head-py\"><a href=\"#head-py\" class=\"headerlink\" title=\"head.py\"></a><strong>head.py</strong></h4><p>此文件实现了负责生成模型最终预测的 head 模块。</p>\n<h5 id=\"关键组件：-2\"><a href=\"#关键组件：-2\" class=\"headerlink\" title=\"关键组件：\"></a><strong>关键组件：</strong></h5><p><strong>检测头 （Detect）：</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Detect</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, nc=<span class=\"hljs-number\">80</span>, ch=(<span class=\"hljs-params\"></span>)</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        <span class=\"hljs-variable language_\">self</span>.nc = nc  <span class=\"hljs-comment\"># number of classes</span><br>        <span class=\"hljs-variable language_\">self</span>.nl = <span class=\"hljs-built_in\">len</span>(ch)  <span class=\"hljs-comment\"># number of detection layers</span><br>        <span class=\"hljs-variable language_\">self</span>.reg_max = <span class=\"hljs-number\">16</span>  <span class=\"hljs-comment\"># DFL channels</span><br>        <span class=\"hljs-variable language_\">self</span>.no = nc + <span class=\"hljs-variable language_\">self</span>.reg_max * <span class=\"hljs-number\">4</span>  <span class=\"hljs-comment\"># number of outputs per anchor</span><br>        <span class=\"hljs-variable language_\">self</span>.stride = torch.zeros(<span class=\"hljs-variable language_\">self</span>.nl)  <span class=\"hljs-comment\"># strides computed during build</span><br> <br>        <span class=\"hljs-comment\"># Define layers</span><br>        <span class=\"hljs-variable language_\">self</span>.cv2 = nn.ModuleList(<br>            nn.Sequential(Conv(x, c2, <span class=\"hljs-number\">3</span>), Conv(c2, c2, <span class=\"hljs-number\">3</span>), nn.Conv2d(c2, <span class=\"hljs-number\">4</span> * <span class=\"hljs-variable language_\">self</span>.reg_max, <span class=\"hljs-number\">1</span>)) <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> ch<br>        )<br>        <span class=\"hljs-variable language_\">self</span>.cv3 = nn.ModuleList(<br>            nn.Sequential(<br>                nn.Sequential(DWConv(x, x, <span class=\"hljs-number\">3</span>), Conv(x, c3, <span class=\"hljs-number\">1</span>)),<br>                nn.Sequential(DWConv(c3, c3, <span class=\"hljs-number\">3</span>), Conv(c3, c3, <span class=\"hljs-number\">1</span>)),<br>                nn.Conv2d(c3, <span class=\"hljs-variable language_\">self</span>.nc, <span class=\"hljs-number\">1</span>),<br>            )<br>            <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> ch<br>        )<br>        <span class=\"hljs-variable language_\">self</span>.dfl = DFL(<span class=\"hljs-variable language_\">self</span>.reg_max) <span class=\"hljs-keyword\">if</span> <span class=\"hljs-variable language_\">self</span>.reg_max &gt; <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">else</span> nn.Identity()<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>Detect 类定义输出边界框坐标和类概率的检测头。</li>\n<li><strong>组件</strong>：<ul>\n<li>self.cv2：用于边界框回归的卷积层。</li>\n<li>self.cv3：用于分类的卷积层。</li>\n<li>self.dfl：用于边界框细化的 Distribution Focal Loss 模块。</li>\n</ul>\n</li>\n<li><strong>Forward Pass</strong>：处理输入特征映射并输出边界框和类的预测。</li>\n</ul>\n<p><strong>分割 （<strong><strong>Segment</strong></strong>）：</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Segment</span>(<span class=\"hljs-title class_ inherited__\">Detect</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, nc=<span class=\"hljs-number\">80</span>, nm=<span class=\"hljs-number\">32</span>, npr=<span class=\"hljs-number\">256</span>, ch=(<span class=\"hljs-params\"></span>)</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__(nc, ch)<br>        <span class=\"hljs-variable language_\">self</span>.nm = nm  <span class=\"hljs-comment\"># number of masks</span><br>        <span class=\"hljs-variable language_\">self</span>.npr = npr  <span class=\"hljs-comment\"># number of prototypes</span><br>        <span class=\"hljs-variable language_\">self</span>.proto = Proto(ch[<span class=\"hljs-number\">0</span>], <span class=\"hljs-variable language_\">self</span>.npr, <span class=\"hljs-variable language_\">self</span>.nm)  <span class=\"hljs-comment\"># protos</span><br> <br>        c4 = <span class=\"hljs-built_in\">max</span>(ch[<span class=\"hljs-number\">0</span>] // <span class=\"hljs-number\">4</span>, <span class=\"hljs-variable language_\">self</span>.nm)<br>        <span class=\"hljs-variable language_\">self</span>.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, <span class=\"hljs-number\">3</span>), Conv(c4, c4, <span class=\"hljs-number\">3</span>), nn.Conv2d(c4, <span class=\"hljs-variable language_\">self</span>.nm, <span class=\"hljs-number\">1</span>)) <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> ch)<br><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>扩展 Detect 类以包含分段功能。</li>\n<li><strong>组件</strong>：<ul>\n<li>self.proto：生成掩码原型。</li>\n<li>self.cv4：掩码系数的卷积层。</li>\n</ul>\n</li>\n<li><strong>Forward Pass</strong>：输出边界框、类概率和掩码系数。</li>\n</ul>\n<p><strong>姿势估计头部 （Pose）：</strong></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Pose</span>(<span class=\"hljs-title class_ inherited__\">Detect</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, nc=<span class=\"hljs-number\">80</span>, kpt_shape=(<span class=\"hljs-params\"><span class=\"hljs-number\">17</span>, <span class=\"hljs-number\">3</span></span>), ch=(<span class=\"hljs-params\"></span>)</span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__(nc, ch)<br>        <span class=\"hljs-variable language_\">self</span>.kpt_shape = kpt_shape  <span class=\"hljs-comment\"># number of keypoints, number of dimensions</span><br>        <span class=\"hljs-variable language_\">self</span>.nk = kpt_shape[<span class=\"hljs-number\">0</span>] * kpt_shape[<span class=\"hljs-number\">1</span>]  <span class=\"hljs-comment\"># total number of keypoint outputs</span><br> <br>        c4 = <span class=\"hljs-built_in\">max</span>(ch[<span class=\"hljs-number\">0</span>] // <span class=\"hljs-number\">4</span>, <span class=\"hljs-variable language_\">self</span>.nk)<br>        <span class=\"hljs-variable language_\">self</span>.cv4 = nn.ModuleList(nn.Sequential(Conv(x, c4, <span class=\"hljs-number\">3</span>), Conv(c4, c4, <span class=\"hljs-number\">3</span>), nn.Conv2d(c4, <span class=\"hljs-variable language_\">self</span>.nk, <span class=\"hljs-number\">1</span>)) <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> ch)<br><br></code></pre></td></tr></table></figure>\n\n<ul>\n<li>扩展了 Detect 类，用于人体姿势估计任务。</li>\n<li><strong>组件</strong>：<ul>\n<li>self.kpt_shape：关键点的形状（关键点的数量、每个关键点的维度）。</li>\n<li>self.cv4：用于关键点回归的卷积层。</li>\n</ul>\n</li>\n<li><strong>Forward Pass</strong>：输出边界框、类概率和关键点坐标。</li>\n</ul>\n<h5 id=\"了解概念：-2\"><a href=\"#了解概念：-2\" class=\"headerlink\" title=\"了解概念：\"></a><strong>了解概念：</strong></h5><ul>\n<li><strong>模块化</strong>：通过扩展 Detect 类，我们可以为不同的任务创建专门的 head，同时重用通用功能。</li>\n<li><strong>无锚点检测</strong>：现代对象检测器通常使用无锚点方法，直接预测边界框。</li>\n<li><strong>关键点估计</strong>：在姿势估计中，模型预测表示关节或地标的关键点。</li>\n</ul>\n<h3 id=\"3-nn-tasks-py-文件\"><a href=\"#3-nn-tasks-py-文件\" class=\"headerlink\" title=\"3. nn&#x2F;tasks.py 文件\"></a>3. <strong>nn&#x2F;tasks.py</strong> 文件</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># Ultralytics YOLO &lt;img draggable=&quot;false&quot; role=&quot;img&quot; class=&quot;emoji&quot; alt=&quot;🚀&quot; src=&quot;https://s.w.org/images/core/emoji/15.0.3/svg/1f680.svg&quot;&gt;, AGPL-3.0 license</span><br> <br><span class=\"hljs-keyword\">import</span> contextlib<br><span class=\"hljs-keyword\">import</span> pickle<br><span class=\"hljs-keyword\">import</span> types<br><span class=\"hljs-keyword\">from</span> copy <span class=\"hljs-keyword\">import</span> deepcopy<br><span class=\"hljs-keyword\">from</span> pathlib <span class=\"hljs-keyword\">import</span> Path<br> <br><span class=\"hljs-keyword\">import</span> torch<br><span class=\"hljs-keyword\">import</span> torch.nn <span class=\"hljs-keyword\">as</span> nn<br> <br><span class=\"hljs-comment\"># Other imports...</span><br> <br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">BaseModel</span>(nn.Module):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;The BaseModel class serves as a base class for all the models in the Ultralytics YOLO family.&quot;&quot;&quot;</span><br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x, *args, **kwargs</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Handles both training and inference, returns predictions or loss.&quot;&quot;&quot;</span><br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(x, <span class=\"hljs-built_in\">dict</span>):<br>            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>.loss(x, *args, **kwargs)  <span class=\"hljs-comment\"># Training: return loss</span><br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>.predict(x, *args, **kwargs)  <span class=\"hljs-comment\"># Inference: return predictions</span><br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">predict</span>(<span class=\"hljs-params\">self, x, profile=<span class=\"hljs-literal\">False</span>, visualize=<span class=\"hljs-literal\">False</span>, augment=<span class=\"hljs-literal\">False</span>, embed=<span class=\"hljs-literal\">None</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Run a forward pass through the network for inference.&quot;&quot;&quot;</span><br>        <span class=\"hljs-keyword\">if</span> augment:<br>            <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>._predict_augment(x)<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>._predict_once(x, profile, visualize, embed)<br>     <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">fuse</span>(<span class=\"hljs-params\">self, verbose=<span class=\"hljs-literal\">True</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Fuses Conv and BatchNorm layers for efficiency during inference.&quot;&quot;&quot;</span><br>        <span class=\"hljs-keyword\">for</span> m <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>.model.modules():<br>            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(m, (Conv, Conv2, DWConv)) <span class=\"hljs-keyword\">and</span> <span class=\"hljs-built_in\">hasattr</span>(m, <span class=\"hljs-string\">&quot;bn&quot;</span>):<br>                m.conv = fuse_conv_and_bn(m.conv, m.bn)<br>                <span class=\"hljs-built_in\">delattr</span>(m, <span class=\"hljs-string\">&quot;bn&quot;</span>)<br>                m.forward = m.forward_fuse  <span class=\"hljs-comment\"># Use the fused forward</span><br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span><br>     <br>    <span class=\"hljs-comment\"># More BaseModel methods...</span><br> <br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">DetectionModel</span>(<span class=\"hljs-title class_ inherited__\">BaseModel</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;YOLOv8 detection model.&quot;&quot;&quot;</span><br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, cfg=<span class=\"hljs-string\">&quot;yolov8n.yaml&quot;</span>, ch=<span class=\"hljs-number\">3</span>, nc=<span class=\"hljs-literal\">None</span>, verbose=<span class=\"hljs-literal\">True</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize the YOLOv8 detection model with config and parameters.&quot;&quot;&quot;</span><br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        <span class=\"hljs-variable language_\">self</span>.yaml = cfg <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(cfg, <span class=\"hljs-built_in\">dict</span>) <span class=\"hljs-keyword\">else</span> yaml_model_load(cfg)<br>        <span class=\"hljs-variable language_\">self</span>.model, <span class=\"hljs-variable language_\">self</span>.save = parse_model(deepcopy(<span class=\"hljs-variable language_\">self</span>.yaml), ch=ch, verbose=verbose)<br>        <span class=\"hljs-variable language_\">self</span>.names = &#123;i: <span class=\"hljs-string\">f&quot;<span class=\"hljs-subst\">&#123;i&#125;</span>&quot;</span> <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-variable language_\">self</span>.yaml[<span class=\"hljs-string\">&quot;nc&quot;</span>])&#125;  <span class=\"hljs-comment\"># Class names</span><br>        <span class=\"hljs-variable language_\">self</span>.inplace = <span class=\"hljs-variable language_\">self</span>.yaml.get(<span class=\"hljs-string\">&quot;inplace&quot;</span>, <span class=\"hljs-literal\">True</span>)<br> <br>        <span class=\"hljs-comment\"># Initialize strides</span><br>        m = <span class=\"hljs-variable language_\">self</span>.model[-<span class=\"hljs-number\">1</span>]  <span class=\"hljs-comment\"># Detect() layer</span><br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(m, Detect):<br>            s = <span class=\"hljs-number\">256</span>  <span class=\"hljs-comment\"># Max stride</span><br>            m.stride = torch.tensor([s / x.shape[-<span class=\"hljs-number\">2</span>] <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>._predict_once(torch.zeros(<span class=\"hljs-number\">1</span>, ch, s, s))])<br>            <span class=\"hljs-variable language_\">self</span>.stride = m.stride<br>            m.bias_init()  <span class=\"hljs-comment\"># Initialize biases</span><br> <br>    <span class=\"hljs-comment\"># More DetectionModel methods...</span><br> <br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">SegmentationModel</span>(<span class=\"hljs-title class_ inherited__\">DetectionModel</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;YOLOv8 segmentation model.&quot;&quot;&quot;</span><br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, cfg=<span class=\"hljs-string\">&quot;yolov8n-seg.yaml&quot;</span>, ch=<span class=\"hljs-number\">3</span>, nc=<span class=\"hljs-literal\">None</span>, verbose=<span class=\"hljs-literal\">True</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize YOLOv8 segmentation model with given config and parameters.&quot;&quot;&quot;</span><br>        <span class=\"hljs-built_in\">super</span>().__init__(cfg=cfg, ch=ch, nc=nc, verbose=verbose)<br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">init_criterion</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize the loss criterion for the SegmentationModel.&quot;&quot;&quot;</span><br>        <span class=\"hljs-keyword\">return</span> v8SegmentationLoss(<span class=\"hljs-variable language_\">self</span>)<br> <br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">PoseModel</span>(<span class=\"hljs-title class_ inherited__\">DetectionModel</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;YOLOv8 pose model.&quot;&quot;&quot;</span><br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, cfg=<span class=\"hljs-string\">&quot;yolov8n-pose.yaml&quot;</span>, ch=<span class=\"hljs-number\">3</span>, nc=<span class=\"hljs-literal\">None</span>, data_kpt_shape=(<span class=\"hljs-params\"><span class=\"hljs-literal\">None</span>, <span class=\"hljs-literal\">None</span></span>), verbose=<span class=\"hljs-literal\">True</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize YOLOv8 Pose model.&quot;&quot;&quot;</span><br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-built_in\">isinstance</span>(cfg, <span class=\"hljs-built_in\">dict</span>):<br>            cfg = yaml_model_load(cfg)<br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">list</span>(data_kpt_shape) != <span class=\"hljs-built_in\">list</span>(cfg[<span class=\"hljs-string\">&quot;kpt_shape&quot;</span>]):<br>            cfg[<span class=\"hljs-string\">&quot;kpt_shape&quot;</span>] = data_kpt_shape<br>        <span class=\"hljs-built_in\">super</span>().__init__(cfg=cfg, ch=ch, nc=nc, verbose=verbose)<br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">init_criterion</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize the loss criterion for the PoseModel.&quot;&quot;&quot;</span><br>        <span class=\"hljs-keyword\">return</span> v8PoseLoss(<span class=\"hljs-variable language_\">self</span>)<br> <br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ClassificationModel</span>(<span class=\"hljs-title class_ inherited__\">BaseModel</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;YOLOv8 classification model.&quot;&quot;&quot;</span><br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, cfg=<span class=\"hljs-string\">&quot;yolov8n-cls.yaml&quot;</span>, ch=<span class=\"hljs-number\">3</span>, nc=<span class=\"hljs-literal\">None</span>, verbose=<span class=\"hljs-literal\">True</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize the YOLOv8 classification model.&quot;&quot;&quot;</span><br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        <span class=\"hljs-variable language_\">self</span>._from_yaml(cfg, ch, nc, verbose)<br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">_from_yaml</span>(<span class=\"hljs-params\">self, cfg, ch, nc, verbose</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Set YOLOv8 model configurations and define the model architecture.&quot;&quot;&quot;</span><br>        <span class=\"hljs-variable language_\">self</span>.yaml = cfg <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(cfg, <span class=\"hljs-built_in\">dict</span>) <span class=\"hljs-keyword\">else</span> yaml_model_load(cfg)<br>        <span class=\"hljs-variable language_\">self</span>.model, <span class=\"hljs-variable language_\">self</span>.save = parse_model(deepcopy(<span class=\"hljs-variable language_\">self</span>.yaml), ch=ch, verbose=verbose)<br>        <span class=\"hljs-variable language_\">self</span>.names = &#123;i: <span class=\"hljs-string\">f&quot;<span class=\"hljs-subst\">&#123;i&#125;</span>&quot;</span> <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-variable language_\">self</span>.yaml[<span class=\"hljs-string\">&quot;nc&quot;</span>])&#125;<br>        <span class=\"hljs-variable language_\">self</span>.info()<br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">reshape_outputs</span>(<span class=\"hljs-params\">model, nc</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Update a classification model to match the class count (nc).&quot;&quot;&quot;</span><br>        name, m = <span class=\"hljs-built_in\">list</span>((model.model <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">hasattr</span>(model, <span class=\"hljs-string\">&quot;model&quot;</span>) <span class=\"hljs-keyword\">else</span> model).named_children())[-<span class=\"hljs-number\">1</span>]<br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(m, nn.Linear):<br>            <span class=\"hljs-keyword\">if</span> m.out_features != nc:<br>                <span class=\"hljs-built_in\">setattr</span>(model, name, nn.Linear(m.in_features, nc))<br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">init_criterion</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize the loss criterion for the ClassificationModel.&quot;&quot;&quot;</span><br>        <span class=\"hljs-keyword\">return</span> v8ClassificationLoss()<br> <br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Ensemble</span>(nn.ModuleList):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;Ensemble of models.&quot;&quot;&quot;</span><br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize an ensemble of models.&quot;&quot;&quot;</span><br>        <span class=\"hljs-built_in\">super</span>().__init__()<br> <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x, augment=<span class=\"hljs-literal\">False</span>, profile=<span class=\"hljs-literal\">False</span>, visualize=<span class=\"hljs-literal\">False</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Generate the ensemble’s final layer by combining outputs from each model.&quot;&quot;&quot;</span><br>        y = [module(x, augment, profile, visualize)[<span class=\"hljs-number\">0</span>] <span class=\"hljs-keyword\">for</span> module <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>]<br>        <span class=\"hljs-keyword\">return</span> torch.cat(y, <span class=\"hljs-number\">2</span>), <span class=\"hljs-literal\">None</span>  <span class=\"hljs-comment\"># Concatenate outputs along the third dimension</span><br> <br><span class=\"hljs-comment\"># Functions ------------------------------------------------------------------------------------------------------------</span><br> <br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">parse_model</span>(<span class=\"hljs-params\">d, ch, verbose=<span class=\"hljs-literal\">True</span></span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;Parse a YOLO model.yaml dictionary into a PyTorch model.&quot;&quot;&quot;</span><br>    <span class=\"hljs-keyword\">import</span> ast<br> <br>    max_channels = <span class=\"hljs-built_in\">float</span>(<span class=\"hljs-string\">&quot;inf&quot;</span>)<br>    nc, act, scales = (d.get(x) <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> (<span class=\"hljs-string\">&quot;nc&quot;</span>, <span class=\"hljs-string\">&quot;activation&quot;</span>, <span class=\"hljs-string\">&quot;scales&quot;</span>))<br>    depth, width, kpt_shape = (d.get(x, <span class=\"hljs-number\">1.0</span>) <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> (<span class=\"hljs-string\">&quot;depth_multiple&quot;</span>, <span class=\"hljs-string\">&quot;width_multiple&quot;</span>, <span class=\"hljs-string\">&quot;kpt_shape&quot;</span>))<br> <br>    <span class=\"hljs-comment\"># Model scaling</span><br>    <span class=\"hljs-keyword\">if</span> scales:<br>        scale = d.get(<span class=\"hljs-string\">&quot;scale&quot;</span>)<br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> scale:networ<br>            scale = <span class=\"hljs-built_in\">tuple</span>(scales.keys())[<span class=\"hljs-number\">0</span>]<br>            LOGGER.warning(<span class=\"hljs-string\">f&quot;WARNING &lt;img draggable=&quot;</span>false<span class=\"hljs-string\">&quot; role=&quot;</span>img<span class=\"hljs-string\">&quot; class=&quot;</span>emoji<span class=\"hljs-string\">&quot; alt=&quot;</span>⚠️<span class=\"hljs-string\">&quot; src=&quot;</span>https://s.w.org/images/core/emoji/<span class=\"hljs-number\">15.0</span><span class=\"hljs-number\">.3</span>/svg/26a0.svg<span class=\"hljs-string\">&quot;&gt; no model scale passed. Assuming scale=&#x27;&#123;scale&#125;&#x27;.&quot;</span>)<br>        depth, width, max_channels = scales[scale]<br> <br>    <span class=\"hljs-keyword\">if</span> act:<br>        Conv.default_act = <span class=\"hljs-built_in\">eval</span>(act)  <span class=\"hljs-comment\"># redefine default activation</span><br>        <span class=\"hljs-keyword\">if</span> verbose:<br>            LOGGER.info(<span class=\"hljs-string\">f&quot;Activation: <span class=\"hljs-subst\">&#123;act&#125;</span>&quot;</span>)<br> <br>    <span class=\"hljs-comment\"># Logging and parsing layers</span><br>    <span class=\"hljs-keyword\">if</span> verbose:<br>        LOGGER.info(<span class=\"hljs-string\">f&quot;\\n<span class=\"hljs-subst\">&#123;<span class=\"hljs-string\">&#x27;&#x27;</span>:&gt;<span class=\"hljs-number\">3</span>&#125;</span><span class=\"hljs-subst\">&#123;<span class=\"hljs-string\">&#x27;from&#x27;</span>:&gt;<span class=\"hljs-number\">20</span>&#125;</span><span class=\"hljs-subst\">&#123;<span class=\"hljs-string\">&#x27;n&#x27;</span>:&gt;<span class=\"hljs-number\">3</span>&#125;</span><span class=\"hljs-subst\">&#123;<span class=\"hljs-string\">&#x27;params&#x27;</span>:&gt;<span class=\"hljs-number\">10</span>&#125;</span>  <span class=\"hljs-subst\">&#123;<span class=\"hljs-string\">&#x27;module&#x27;</span>:&lt;<span class=\"hljs-number\">45</span>&#125;</span><span class=\"hljs-subst\">&#123;<span class=\"hljs-string\">&#x27;arguments&#x27;</span>:&lt;<span class=\"hljs-number\">30</span>&#125;</span>&quot;</span>)<br>    ch = [ch]<br>    layers, save, c2 = [], [], ch[-<span class=\"hljs-number\">1</span>]<br> <br>    <span class=\"hljs-keyword\">for</span> i, (f, n, m, args) <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(d[<span class=\"hljs-string\">&quot;backbone&quot;</span>] + d[<span class=\"hljs-string\">&quot;head&quot;</span>]):  <span class=\"hljs-comment\"># from, number, module, args</span><br>        m = <span class=\"hljs-built_in\">globals</span>()[m] <span class=\"hljs-keyword\">if</span> m <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">globals</span>() <span class=\"hljs-keyword\">else</span> <span class=\"hljs-built_in\">getattr</span>(nn, m[<span class=\"hljs-number\">3</span>:], m)  <span class=\"hljs-comment\"># get module</span><br>        <span class=\"hljs-keyword\">for</span> j, a <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(args):<br>            <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(a, <span class=\"hljs-built_in\">str</span>):<br>                <span class=\"hljs-keyword\">with</span> contextlib.suppress(ValueError):<br>                    args[j] = ast.literal_eval(a) <span class=\"hljs-keyword\">if</span> a <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">locals</span>() <span class=\"hljs-keyword\">else</span> a<br> <br>        n = <span class=\"hljs-built_in\">max</span>(<span class=\"hljs-built_in\">round</span>(n * depth), <span class=\"hljs-number\">1</span>) <span class=\"hljs-keyword\">if</span> n &gt; <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">else</span> n  <span class=\"hljs-comment\"># depth gain</span><br>        <span class=\"hljs-keyword\">if</span> m <span class=\"hljs-keyword\">in</span> &#123;Conv, Bottleneck, C2f, C3k2, ...&#125;:  <span class=\"hljs-comment\"># Module list</span><br>            c1, c2 = ch[f], args[<span class=\"hljs-number\">0</span>]<br>            c2 = make_divisible(<span class=\"hljs-built_in\">min</span>(c2, max_channels) * width, <span class=\"hljs-number\">8</span>)<br>            args = [c1, c2, *args[<span class=\"hljs-number\">1</span>:]]<br>            <span class=\"hljs-keyword\">if</span> m <span class=\"hljs-keyword\">in</span> &#123;C2f, C3k2, ...&#125;:  <span class=\"hljs-comment\"># Repeated layers</span><br>                args.insert(<span class=\"hljs-number\">2</span>, n)<br>                n = <span class=\"hljs-number\">1</span><br>        <span class=\"hljs-keyword\">elif</span> m <span class=\"hljs-keyword\">in</span> &#123;Concat, Detect, ...&#125;:  <span class=\"hljs-comment\"># Head layers</span><br>            args.append([ch[x] <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> f])<br>        <span class=\"hljs-comment\"># Append layers</span><br>        m_ = nn.Sequential(*(m(*args) <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(n))) <span class=\"hljs-keyword\">if</span> n &gt; <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">else</span> m(*args)<br>        layers.append(m_)<br> <br>        ch.append(c2)<br>        save.extend([x % i <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> ([f] <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(f, <span class=\"hljs-built_in\">int</span>) <span class=\"hljs-keyword\">else</span> f) <span class=\"hljs-keyword\">if</span> x != -<span class=\"hljs-number\">1</span>])<br> <br>        <span class=\"hljs-keyword\">if</span> verbose:<br>            LOGGER.info(<span class=\"hljs-string\">f&quot;<span class=\"hljs-subst\">&#123;i:&gt;<span class=\"hljs-number\">3</span>&#125;</span><span class=\"hljs-subst\">&#123;<span class=\"hljs-built_in\">str</span>(f):&gt;<span class=\"hljs-number\">20</span>&#125;</span><span class=\"hljs-subst\">&#123;n:&gt;<span class=\"hljs-number\">3</span>&#125;</span><span class=\"hljs-subst\">&#123;<span class=\"hljs-built_in\">sum</span>(x.numel() <span class=\"hljs-keyword\">for</span> x <span class=\"hljs-keyword\">in</span> m_.parameters()):<span class=\"hljs-number\">10.0</span>f&#125;</span>  <span class=\"hljs-subst\">&#123;<span class=\"hljs-built_in\">str</span>(m):&lt;<span class=\"hljs-number\">45</span>&#125;</span><span class=\"hljs-subst\">&#123;<span class=\"hljs-built_in\">str</span>(args):&lt;<span class=\"hljs-number\">30</span>&#125;</span>&quot;</span>)<br> <br>    <span class=\"hljs-keyword\">return</span> nn.Sequential(*layers), <span class=\"hljs-built_in\">sorted</span>(save)<br> <br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">yaml_model_load</span>(<span class=\"hljs-params\">path</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;Load a YOLO model from a YAML file.&quot;&quot;&quot;</span><br>    path = Path(path)<br>    unified_path = path.with_name(path.stem.replace(<span class=\"hljs-string\">&quot;yolov8&quot;</span>, <span class=\"hljs-string\">&quot;yolov&quot;</span>))<br>    yaml_file = check_yaml(<span class=\"hljs-built_in\">str</span>(unified_path), hard=<span class=\"hljs-literal\">False</span>) <span class=\"hljs-keyword\">or</span> check_yaml(path)<br>    d = yaml_load(yaml_file)<br>    d[<span class=\"hljs-string\">&quot;scale&quot;</span>] = guess_model_scale(path)<br>    d[<span class=\"hljs-string\">&quot;yaml_file&quot;</span>] = <span class=\"hljs-built_in\">str</span>(path)<br>    <span class=\"hljs-keyword\">return</span> d<br> <br><span class=\"hljs-comment\"># More utility functions...</span><br> <br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">guess_model_scale</span>(<span class=\"hljs-params\">model_path</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;Extract the scale from the YAML file.&quot;&quot;&quot;</span><br>    <span class=\"hljs-keyword\">import</span> re<br>    <span class=\"hljs-keyword\">return</span> re.search(<span class=\"hljs-string\">r&quot;yolov\\d+([nslmx])&quot;</span>, Path(model_path).stem).group(<span class=\"hljs-number\">1</span>)<br> <br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">attempt_load_weights</span>(<span class=\"hljs-params\">weights, device=<span class=\"hljs-literal\">None</span>, inplace=<span class=\"hljs-literal\">True</span>, fuse=<span class=\"hljs-literal\">False</span></span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;Loads weights for a model or an ensemble of models.&quot;&quot;&quot;</span><br>    ensemble = Ensemble()<br>    <span class=\"hljs-keyword\">for</span> w <span class=\"hljs-keyword\">in</span> weights <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">isinstance</span>(weights, <span class=\"hljs-built_in\">list</span>) <span class=\"hljs-keyword\">else</span> [weights]:<br>        ckpt, _ = torch_safe_load(w)<br>        model = (ckpt.get(<span class=\"hljs-string\">&quot;ema&quot;</span>) <span class=\"hljs-keyword\">or</span> ckpt[<span class=\"hljs-string\">&quot;model&quot;</span>]).to(device).<span class=\"hljs-built_in\">float</span>()<br>        model = model.fuse().<span class=\"hljs-built_in\">eval</span>() <span class=\"hljs-keyword\">if</span> fuse <span class=\"hljs-keyword\">and</span> <span class=\"hljs-built_in\">hasattr</span>(model, <span class=\"hljs-string\">&quot;fuse&quot;</span>) <span class=\"hljs-keyword\">else</span> model.<span class=\"hljs-built_in\">eval</span>()<br>        ensemble.append(model)<br> <br>    <span class=\"hljs-keyword\">return</span> ensemble <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(ensemble) &gt; <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">else</span> ensemble[-<span class=\"hljs-number\">1</span>]<br> <br></code></pre></td></tr></table></figure>\n\n<p>此 tasks.py 脚本是代码管道的核心部分;它仍然使用 YOLOv8 方法和逻辑;我们只需要将 YOLO11 模型解析到其中。此脚本专为各种计算机视觉任务而设计，例如对象检测、分割、分类、姿势估计、OBB 等。它定义了用于训练、推理和模型管理的基础模型、特定于任务的模型和效用函数。</p>\n<h4 id=\"关键组件：-3\"><a href=\"#关键组件：-3\" class=\"headerlink\" title=\"关键组件：\"></a><strong>关键组件：</strong></h4><ul>\n<li><strong>Imports：</strong>该脚本从 Ultralytics 导入 PyTorch （torch）、神经网络层 （torch.nn） 和实用函数等基本模块。一些关键导入包括：<ul>\n<li>对 <strong>C3k2</strong>、<strong>C2PSA</strong>、<strong>C3</strong>、<strong>SPPF、****Concat</strong> 等架构模块进行建模。</li>\n<li>损失函数，如 <strong>v8DetectionLoss</strong>、<strong>v8SegmentationLoss</strong>、<strong>v8ClassificationLoss</strong>、<strong>v8OBBLoss</strong>。</li>\n<li>各种实用程序函数，如 model_info、<strong>fuse_conv_and_bn</strong>、<strong>scale_img</strong> <strong>time_sync</strong>，以帮助进行模型处理、分析和评估。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"模型基类：\"><a href=\"#模型基类：\" class=\"headerlink\" title=\"模型基类：\"></a><strong>模型基类：</strong></h4><ol>\n<li>BaseModel 类：<ul>\n<li>BaseModel 用作 Ultralytics YOLO 系列中所有模型的基类。</li>\n<li>实现如下基本方法：<ul>\n<li><strong>forward（）：</strong>根据输入数据处理训练和推理。</li>\n<li><strong>predict（）：</strong>处理前向传递以进行推理。</li>\n<li><strong>fuse（）：</strong>融合 Conv2d 和 BatchNorm2d 层以提高效率。</li>\n<li><strong>info（）：</strong>提供详细的模型信息。</li>\n</ul>\n</li>\n<li>此类旨在通过特定于任务的模型（例如检测、分割和分类）进行扩展。</li>\n</ul>\n</li>\n<li><strong>DetectionModel</strong> <strong>类：</strong><ul>\n<li>扩展 BaseModel，专门用于对象检测任务。</li>\n<li>加载模型配置，初始化检测头（如 Detect 模块）并设置模型步幅。</li>\n<li>它支持使用 YOLOv8 等架构的检测任务，并可以通过 <strong>_predict_augment（）</strong> 执行增强推理。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"特定于任务的模型：\"><a href=\"#特定于任务的模型：\" class=\"headerlink\" title=\"特定于任务的模型：\"></a><strong>特定于任务的模型：</strong></h4><ol>\n<li><strong>SegmentationModel 的 SegmentationModel</strong> <strong>中：</strong><ul>\n<li>专门用于分割任务（如 YOLOv8 分割）的 DetectionModel 的子类。</li>\n<li>初始化特定于分割的损失函数 （v8SegmentationLoss）。</li>\n</ul>\n</li>\n<li><strong>PoseModel 的 PoseModel</strong> <strong>中：</strong><ul>\n<li>通过初始化具有关键点检测 （<strong>kpt_shape</strong>） 特定配置的模型来处理姿态估计任务。</li>\n<li>使用 v8PoseLoss 进行特定于姿势的损失计算。</li>\n</ul>\n</li>\n<li><strong>分类型号****：</strong><ul>\n<li>专为使用 YOLOv8 分类架构的图像分类任务而设计。</li>\n<li>初始化和管理特定于分类的损失 （<strong>v8ClassificationLoss</strong>）。</li>\n<li>它还支持重塑用于分类任务的预训练 TorchVision 模型。</li>\n</ul>\n</li>\n<li><strong>OBB型号****：</strong><ul>\n<li>用于定向边界框 （OBB） 检测任务。</li>\n<li>实现特定的损失函数 （<strong>v8OBBLoss</strong>） 来处理旋转的边界框。</li>\n</ul>\n</li>\n<li><strong>世界模型****：</strong><ul>\n<li>此模型处理图像字幕和基于文本的识别等任务。</li>\n<li>利用 CLIP 模型中的文本特征执行基于文本的视觉识别任务。</li>\n<li>包括对文本嵌入 （<strong>txt_feats</strong>） 的特殊处理，用于字幕和世界相关任务。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"集成模型：\"><a href=\"#集成模型：\" class=\"headerlink\" title=\"集成模型：\"></a><strong>集成模型：</strong></h4><ol>\n<li><strong>集成****：</strong><ul>\n<li>一个简单的 ensemble 类，它将多个模型合并为一个模型。</li>\n<li>允许对不同模型的输出进行平均或串联，以提高整体性能。</li>\n<li>对于组合多个模型的输出提供更好的预测的任务非常有用。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"实用功能：\"><a href=\"#实用功能：\" class=\"headerlink\" title=\"实用功能：\"></a><strong>实用功能：</strong></h4><ol>\n<li>模型加载和管理：<ul>\n<li><strong>attempt_load_weights（）、****attempt_load_one_weight（）</strong>：用于加载模型、管理集成模型以及处理加载预训练权重时的兼容性问题的函数。</li>\n<li>这些功能可确保以适当的步幅、层和配置正确加载模型。</li>\n</ul>\n</li>\n<li>临时模块重定向：<ul>\n<li><strong>temporary_modules（）</strong>：一个上下文管理器，用于临时重定向模块路径，确保在模块位置更改时向后兼容。</li>\n<li>有助于保持与旧型号版本的兼容性。</li>\n</ul>\n</li>\n<li><strong>Pickle</strong>安全处理：<ul>\n<li>SafeUnpickler：一个自定义的解封器，可以安全地加载模型检查点，确保未知类被安全的占位符（SafeClass）替换，以避免在加载过程中发生崩溃。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"模型解析：\"><a href=\"#模型解析：\" class=\"headerlink\" title=\"模型解析：\"></a><strong>模型解析：</strong></h4><ol>\n<li><strong>parse_model（）</strong> <strong>中：</strong><ul>\n<li>此函数将 YAML 文件中的模型配置解析为 PyTorch 模型。</li>\n<li>它处理主干和头架构，解释每个层类型（如 Conv、SPPF、Detect），并构建最终模型。</li>\n<li>支持各种架构，包括 C3k2、C2PSA 等 YOLO11 组件。</li>\n</ul>\n</li>\n<li>YAML 模型加载：<ul>\n<li><strong>yaml_model_load（）</strong>）：从 YAML 文件加载模型配置，检测模型比例（例如 n、s、m、l、x）并相应地调整参数。</li>\n<li><strong>guess_model_scale（）、****guess_model_task（）</strong>：用于根据 YAML 文件结构推断模型规模和任务的辅助函数。</li>\n</ul>\n</li>\n</ol>\n"},{"title":"YOLO V10 详解","date":"2024-12-07T10:30:00.000Z","_content":"\n\n\n# 引言\n\n### 背景介绍\n\n实时物体检测一直是计算机视觉领域的研究热点，旨在低延迟下准确预测图像中物体的类别和位置。该技术广泛应用于自动驾驶、机器人导航和物体跟踪等实际应用中。近年来，基于卷积神经网络（CNN）的物体检测器因其高效的性能而受到广泛关注，其中YOLO系列因其出色的性能和效率平衡而脱颖而出。\n\n### 研究内容\n\n本文旨在解决YOLO系列在实际部署中依赖非极大值抑制（NMS）导致的推理延迟问题，并通过优化模型架构进一步提升其性能和效率。具体来说，本文提出了以下两个主要目标：\n\n1. 提出一种无需NMS训练的一致双分配策略，以实现高效的端到端检测。\n2. 提出一种全面的效率-准确性驱动的模型设计策略，从后处理和模型架构两方面提升YOLO的性能和效率。\n\n### 研究难点\n\nYOLO系列在实际应用中面临的主要挑战包括：\n\n1. **NMS依赖性**：传统的YOLO训练过程中采用一对多标签分配策略，导致推理过程中需要依赖NMS进行后处理，这不仅增加了推理延迟，还使得模型对NMS超参数敏感，难以实现最优的端到端部署。\n2. **模型架构设计**：尽管已有大量研究探索了不同的模型架构设计策略，但YOLO系列在各个组件的设计上仍存在计算冗余，限制了模型的性能和效率。\n\n### 相关工作\n\n本文回顾了现有的实时物体检测器和端到端物体检测器的相关研究：\n\n1. **传统YOLO系列**：YOLOv1、YOLOv2和YOLOv3是典型的三部分检测架构，包括主干、颈部和头部。后续的YOLOv4和YOLOv5引入了CSPNet设计，并结合数据增强策略和多种模型尺度。YOLOv6、YOLOv7和YOLOv8分别提出了BiC、E-ELAN和C2f等新的组件设计。\n2. **端到端物体检测器**：DETR系列通过引入Transformer架构和匈牙利损失实现了一对一匹配预测，消除了手工设计的组件和后处理。其他研究如Learnable NMS和关系网络也尝试通过不同的方法实现端到端检测。\n\n### 研究方法\n\n本文提出了一种无需NMS训练的一致双分配策略和全面的效率-准确性驱动的模型设计策略：\n\n1. **一致双分配策略**：通过引入双标签分配和一致的匹配度量，结合一对多和一对一标签分配的优势，实现高效的端到端检测。\n2. **效率-准确性驱动的模型设计策略**：从模型架构的各个组件入手，提出了轻量级分类头、空间-通道解耦下采样和排名引导的块设计等优化方法，减少计算冗余并提升模型性能。\n\n### 实验设计\n\n本文在COCO数据集上对提出的YOLOv10模型进行了广泛的实验验证，具体包括：\n\n1. **数据集**：使用COCO数据集进行训练和评估，采用标准的训练-验证-测试划分。\n2. **实验设置**：所有模型在8块NVIDIA 3090 GPU上进行训练，采用SGD优化器，并结合Mosaic、Mixup和复制粘贴等数据增强策略。\n3. **评估指标**：使用标准平均精度（AP）和不同IoU阈值下的AP值评估模型性能，并测量推理延迟以评估效率。\n\n### 结果与分析\n\n实验结果表明，YOLOv10在多个模型尺度上均取得了显著的性能和效率提升：\n\n1. **性能提升**：YOLOv10-S在相似的AP下比RT-DETR-R18快1.8倍，YOLOv10-B在相同性能下比YOLOv9-C减少了46%的延迟。\n2. **参数和计算量减少**：YOLOv10-S和YOLOv10-B分别比RT-DETR-R18和YOLOv9-C减少了2.8倍和25%的参数数量和FLOPs。\n3. **全面优势**：YOLOv10在多个模型尺度上均优于现有先进模型，展示了其在计算-准确性权衡上的优越性。\n\n### 总体结论\n\n本文通过提出一致双分配策略和全面的效率-准确性驱动的模型设计策略，成功提升了YOLO系列的性能和效率。实验结果验证了YOLOv10在多个模型尺度上的优越性，展示了其在实时物体检测领域的潜力。未来的工作将进一步探索减少小模型中一对多训练和无需NMS训练之间的性能差距的方法。\n\n# 研究方法\n\n### 无NMS训练的一致双重分配\n\n![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/5f60bbd9bccdfacc4ce2a53bce9011dc-image.png)\n\n- 双重标签分配。\n\n  为了实现无需NMS的训练，论文提出了一致的双重分配策略。该策略结合一对多和多对一的标签分配策略的优点。具体来说，双重分配策略包括一个多对一的头和一个一对一的头。在训练过程中，两个头共同优化，使得主干和颈部能够享受多对一分配提供的丰富监督信号。在推理过程中，丢弃多对一头，只使用一对一头来做出预测，从而实现无需NMS的高效端到端部署。\n\n- 一致的匹配度量。\n\n为了确保两个头之间的和谐监督，论文提出了一致的匹配度量。该度量公式如下：\n$$\nm(\\alpha,\\beta)=s\\cdot p^{\\alpha}\\cdot IoU(\\hat{b},b)^{\\beta}\n$$\n其中，*p* 是分类分数，$\\hat{b}$ 和 *b* 分别表示预测和实例的边界框，*s* 表示空间先验，指示预测的锚点是否在实例内，*α* 和 *β* 是两个重要的超参数，平衡语义预测任务和位置回归任务的影响。\n\n### 全局效率-准确性驱动的模型设计\n\n除了后处理，YOLOs的模型架构也对效率-准确性权衡提出了巨大挑战[50, 8, 29]。尽管以前的工作探索了各种设计策略，但仍然缺乏对YOLOs中各个组件的全面检查。因此，模型架构展现出不可忽视的计算冗余和受限能力，这阻碍了其实现高效率和性能的潜力。在这里，我们旨在从效率和准确性角度全面执行YOLOs的模型设计。\n\n效率驱动的模型设计。YOLO中的组件包括茎(stem)、下采样层、带有基本构建块的阶段以及头部。茎的计算成本较低，因此我们对其他三个部分采用效率驱动的模型设计。\n\n（1）轻量级分类头部。在YOLO中，分类和回归头部通常共享相同的架构。然而，它们在计算开销上表现出显著的差异。例如，在YOLOv8-S中，分类头部的FLOPs和参数数量分别为回归头部的2.5倍和2.4倍。然而，在分析分类错误和回归错误的影响后（见表6），我们发现回归头部对YOLOs的性能承担了更大的重要性。因此，我们可以减少分类头部的开销，而不用担心会大幅损害性能。因此，我们简单地采用轻量级的架构用于分类头部，它由两个深度可分离的卷积[25, 9]组成，核大小为3x3，然后是一个1x1卷积。\n\n（2）空间通道解耦的下采样。YOLO通常利用常规的3x3标准卷积，步长为2，同时实现空间下采样（从H x W到$\\frac{H}{2} \\times \\frac{W}{2}$）和通道变换（从C到2C）。这引入了不可忽视的计算成本，即O(29*H**W**C*2)，以及参数数量，即O(18$C^2$)。相反，我们提出将空间缩减和通道增加操作解耦，以实现更高效的缩减。具体来说，我们首先利用逐点卷积来调节通道维度，然后利用深度卷积来进行空间缩减。这将计算成本降低到$O(2HWC^2+ \\frac{9}{2}HWC)$，参数数量减少到$O(2C^2+18C)$。同时，在缩减过程中最大化信息保留，从而在延迟减少的同时具有竞争力。\n\n（3）基于rank引导的模块设计：YOLOs通常在所有阶段使用相同的基本构建块，例如YOLOv8中的瓶颈块。为了彻底检查YOLOs的这种同质设计，我们利用内在秩来分析每个阶段的冗余。具体来说，我们计算每个阶段中最后一个基本块的最后一个卷积的数值秩，这计算了大于阈值的奇异值的数量。图3.(a)展示了YOLOv8的结果，表明深层阶段和大型模型更容易表现出更多的冗余。这一观察表明，简单地为所有阶段应用相同的块设计对于最佳的容量-效率权衡是次优的。为了解决这个问题，我们提出了一种基于秩的块设计方案，旨在通过紧凑的架构设计降低被证明是冗余的阶段复杂度。我们首先提出了一个紧凑的倒置块（CIB）结构，它采用廉价的深度可分离卷积进行空间混合，以及成本效益高的点对点卷积进行通道混合，如图3.(b)所示。它可以作为高效的基本构建块，例如嵌入在ELAN结构中（图3.(b)）。然后，我们提倡一种基于秩的块分配策略，以实现最佳效率，同时保持有竞争力的容量。具体来说，给定一个模型，我们根据其内在秩按升序对所有阶段进行排序。我们进一步检查用CIB替换领先阶段的基本块的性能变化。如果与给定模型相比没有性能下降，我们就继续替换下一个阶段，否则就停止该过程。因此，我们可以在不同阶段和模型规模上实现自适应的紧凑块设计，实现更高的效率而不损害性能。\n\n![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/0af9b20597598897c15c90a02d5c1093-1733232140019-3.png)\n\n### 准确性驱动的模型设计。\n\n我们进一步探索大核卷积和自注意力在准确性驱动设计中的应用，旨在以最小的成本提升性能。\n\n（1）大核卷积。采用大核深度卷积是一种有效的方法来扩大感受野并增强模型的能力[10, 40, 39]。然而，简单地在所有阶段都利用它们可能会引入浅层特征中的污染，同时也会在高分辨率阶段引入显著的I/O开销和延迟[8]。因此，我们建议在深度阶段利用CIB中的大核深度卷积。具体来说，我们增加了CIB中第二个3x3深度卷积的核大小为7x7，随后[39]。此外，我们采用结构重参数化技术[11,10,59]来引入另一个3x3深度卷积分支，以缓解优化问题而不增加推理开销。此外，随着模型规模的增加，其感受野自然扩大，使用大核卷积的好处逐渐减弱。因此，我们只在小型模型规模上采用大核卷积。\n\n(2) 部分自注意力(PSA)。自注意力[58]由于其显著的全球建模能力[38, 14, 76]而被广泛应用于各种视觉任务。然而，它表现出高计算复杂性和内存占用。为了解决这个问题，鉴于普遍存在的注意力头重用[69]，我们提出了一个高效的局部自注意力(PSA)模块设计，如图3.(c)所示。具体来说，在1x1卷积之后，我们将通道中的特征均匀划分为两部分。我们只将一部分输入到由多头自注意力模块(MHSA)和前馈网络(FFN)组成的NPSA块中。然后将两部分通过1x1卷积连接并融合。此外，我们遵循[22]的方法，将查询和键的维度分配给MHSA中的值的一半，并用BatchNorm[27]替换LayerNorm[1]以进行快速推理。此外，PSA仅在分辨率最低的第4阶段之后放置，避免了过多的开销。\n\n# 实验\n\n### 实现细节\n\n我们选择YOLOv8[21]作为我们的基线模型，因为它在延迟准确性和各种模型规模的可用性方面表现良好。我们采用了一致的NMS-free训练双重分配，并基于此进行了全体的效率-准确性驱动的模型设计，从而带来了我们的YOLOv10模型。YOLOv10具有与YOLOv8相同的变体，即N/S/M/L/X。此外，我们通过简单增加YOLOv10-M的宽度尺度因子，推导出了一个新的变体YOLOv10-B。我们在相同的全局从零开始设置[21, 65, 62]下，在COCO[35]上验证了所提出的检测器。此外，所有模型的延迟都在T4 GPU和TensorRT FP16上进行测试，遵循[78]的方法。\n\n### 与最先进技术的比较\n\n如表1所示，我们的YOLOv10在各种模型规模上实现了最先进的性能和端到端的延迟。我们首先将YOLOv10与我们基线模型，即YOLOv8进行比较。在N/S/M/L/X五种变体中，我们的YOLOv10实现了1.2%/1.4%/0.5%/0.3%/0.5%的AP改进，参数减少了28%/ 36%/ 41%/ 44%/ 57%，计算减少了23%/ 24%/ 25%/ 27%/ 38%，延迟减少了70%/65%/50%/41%/37%。与其他YOLO相比，\n\n![image-20241203212603338](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203212603338.png)\n\nYOLOv10在准确性和计算成本之间也展现了卓越的权衡。具体来说，对于轻量级和小型的模型，YOLOv10-N/S的性能超过了YOLOv6-3.0-N/S，分别提高了1.5 AP和2.0 AP，参数减少了51%，计算量减少了41%。对于中等规模的模型，与YOLOv9-C/ YOLO-MS相比，YOLOv10-B/M在相同或更好的性能下，延迟降低了46%/62%。对于大型模型，与Gold-YOLO-L相比，我们的YOLOv10-L在参数减少了68%，延迟降低了32%，并且AP显著提高了1.4%。此外，与RT-DETR相比，YOLOv10获得了显著的性能和延迟提升。值得注意的是，在相似的性能下，YOLOv10-S/X的推理速度比RT-DETR-R18/R101快了1.8倍和1.3倍。这些结果充分展示了YOLOv10作为实时端到端检测器的优越性。\n\n我们还使用原始的一对多训练方法将YOLOv10与其他YOLO进行了比较。在这种情况下，我们考虑了模型前向过程（Latencyf）的性能和延迟[62, 21, 60]。如表1所示，YOLOv10在不同模型规模上也展现了最先进的表现和效率，这表明了我们架构设计的有效性。\n\n###  模型分析\n\n![image-20241203212826090](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203212826090.png)\n\n![image-20241203213021438](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203213021438.png)\n\n![image-20241203213123173](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203213123173.png)\n\n![image-20241203213200887](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203213200887.png)\n\n1. **消融研究**：基于YOLOv10-S和YOLOv10-M的消融研究表明，无NMS训练结合一致的双标签分配显著降低了YOLOv10-S的端到端延迟，同时保持了44.3%的AP竞争力。此外，效率驱动的设计减少了参数数量和计算量，并显著降低了延迟。\n\n2. **双标签分配**：双标签分配为无NMS的YOLO提供了丰富的监督信息，并在推理时实现了高效性。一致匹配度量的引入进一步缩小了两个分支之间的监督差距，提高了性能。\n\n3. **效率驱动模型设计**：效率驱动模型设计通过轻量级分类头、空间-通道解耦下采样和紧凑倒置块（CIB）等组件，有效减少了参数数量、FLOPs和延迟，同时保持了竞争性的性能。\n\n4. **准确性驱动模型设计**：准确性驱动模型设计通过大核卷积和部分自注意力（PSA）模块，在不显著增加延迟的情况下提高了性能。\n\n5. **大核卷积**：大核卷积的使用扩大了感受野并增强了模型能力，但在小模型中效果更佳。\n\n6. **部分自注意力模块**：PSA模块通过减少自注意力头中的冗余来缓解优化问题，从而在不牺牲高效率的情况下提升了模型性能。\n\n# YOLOv10代码\n\n### C2fUIB介绍\n\n**C2fUIB只是用CIB结构替换了YOLOv8中 C2f的Bottleneck结构**\n\n**实现代码ultralytics/nn/modules/block.py**\n\n![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/8ed70c479c7530fe3d36f4f44fbbf2d8.png)\n\n![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/a3198a08d3b755ec2e1e85cb8979c2ee.png)\n\n```python\nclass CIB(nn.Module):\n    \"\"\"Standard bottleneck.\"\"\"\n\n    def __init__(self, c1, c2, shortcut=True, e=0.5, lk=False):\n        \"\"\"Initializes a bottleneck module with given input/output channels, shortcut option, group, kernels, and\n        expansion.\n        \"\"\"\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = nn.Sequential(\n            Conv(c1, c1, 3, g=c1),\n            Conv(c1, 2 * c_, 1),\n            Conv(2 * c_, 2 * c_, 3, g=2 * c_) if not lk else RepVGGDW(2 * c_),\n            Conv(2 * c_, c2, 1),\n            Conv(c2, c2, 3, g=c2),\n        )\n\n        self.add = shortcut and c1 == c2\n\n    def forward(self, x):\n        \"\"\"'forward()' applies the YOLO FPN to input data.\"\"\"\n        return x + self.cv1(x) if self.add else self.cv1(x)\n\nclass C2fCIB(C2f):\n    \"\"\"Faster Implementation of CSP Bottleneck with 2 convolutions.\"\"\"\n\n    def __init__(self, c1, c2, n=1, shortcut=False, lk=False, g=1, e=0.5):\n        \"\"\"Initialize CSP bottleneck layer with two convolutions with arguments ch_in, ch_out, number, shortcut, groups,\n        expansion.\n        \"\"\"\n        super().__init__(c1, c2, n, shortcut, g, e)\n        self.m = nn.ModuleList(CIB(self.c, self.c, shortcut, e=1.0, lk=lk) for _ in range(n))\n```\n\n### PSA介绍\n\n具体来说，我们在1×1卷积后将特征均匀地分为两部分。我们只将一部分输入到由多头自注意力模块（MHSA）和前馈网络（FFN）组成的NPSA块中。然后，两部分通过1×1卷积连接并融合。此外，遵循将查询和键的维度分配为值的一半，并用BatchNorm替换LayerNorm以实现快速推理。\n\n**实现代码ultralytics/nn/modules/block.py**\n\n![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/82d0ed0834ac712354683efcb0108bc6.png)\n\n```python\nclass Attention(nn.Module):\n    def __init__(self, dim, num_heads=8,\n                 attn_ratio=0.5):\n        super().__init__()\n        self.num_heads = num_heads\n        self.head_dim = dim // num_heads\n        self.key_dim = int(self.head_dim * attn_ratio)\n        self.scale = self.key_dim ** -0.5\n        nh_kd = nh_kd = self.key_dim * num_heads\n        h = dim + nh_kd * 2\n        self.qkv = Conv(dim, h, 1, act=False)\n        self.proj = Conv(dim, dim, 1, act=False)\n        self.pe = Conv(dim, dim, 3, 1, g=dim, act=False)\n\n    def forward(self, x):\n        B, _, H, W = x.shape\n        N = H * W\n        qkv = self.qkv(x)\n        q, k, v = qkv.view(B, self.num_heads, -1, N).split([self.key_dim, self.key_dim, self.head_dim], dim=2)\n\n        attn = (\n            (q.transpose(-2, -1) @ k) * self.scale\n        )\n        attn = attn.softmax(dim=-1)\n        x = (v @ attn.transpose(-2, -1)).view(B, -1, H, W) + self.pe(v.reshape(B, -1, H, W))\n        x = self.proj(x)\n        return x\n\nclass PSA(nn.Module):\n\n    def __init__(self, c1, c2, e=0.5):\n        super().__init__()\n        assert(c1 == c2)\n        self.c = int(c1 * e)\n        self.cv1 = Conv(c1, 2 * self.c, 1, 1)\n        self.cv2 = Conv(2 * self.c, c1, 1)\n        \n        self.attn = Attention(self.c, attn_ratio=0.5, num_heads=self.c // 64)\n        self.ffn = nn.Sequential(\n            Conv(self.c, self.c*2, 1),\n            Conv(self.c*2, self.c, 1, act=False)\n        )\n        \n    def forward(self, x):\n        a, b = self.cv1(x).split((self.c, self.c), dim=1)\n        b = b + self.attn(b)\n        b = b + self.ffn(b)\n        return self.cv2(torch.cat((a, b), 1))\n```\n\n### SCDown\n\nOLOs通常利用常规的3×3标准卷积，步长为2，同时实现空间下采样（从H×W到H/2×W/2）和通道变换（从C到2C）。这引入了不可忽视的计算成本$O(9HWC^2)$和参数数量O$(18C^2)$。相反，我们提议将空间缩减和通道增加操作解耦，以实现更高效的下采样。具体来说，我们首先利用点对点卷积来调整通道维度，然后利用深度可分离卷积进行空间下采样。这将计算成本降低到O(2HWC^2 + 9HWC)，并将参数数量减少到O(2C^2 + 18C)。同时，它最大限度地保留了下采样过程中的信息，从而在减少延迟的同时保持了有竞争力的性能。\n\n**实现代码ultralytics/nn/modules/block.py**\n\n```\nclass SCDown(nn.Module):\n    def __init__(self, c1, c2, k, s):\n        super().__init__()\n        self.cv1 = Conv(c1, c2, 1, 1)\n        self.cv2 = Conv(c2, c2, k=k, s=s, g=c2, act=False)\n\n    def forward(self, x):\n        return self.cv2(self.cv1(x))\n```\n\n\n\n参考：[YOLOv10真正实时端到端目标检测（原理介绍+代码详见+结构框图）-腾讯云开发者社区-腾讯云](https://cloud.tencent.com/developer/article/2426044)\n\n文章合集：https://github.com/chongzicbo/ReadWriteThink\n\n","source":"_posts/人工智能/computer-vision/CV010-YOLO V10详解.md","raw":"---\ntitle: 'YOLO V10 详解'\ndate: 2024-12-7 18:30:00\ncategories:\n  - [人工智能,computer-vision]\ntags:\n  - 人工智能\n  - yolo\n  - 目标检测\n---\n\n\n\n# 引言\n\n### 背景介绍\n\n实时物体检测一直是计算机视觉领域的研究热点，旨在低延迟下准确预测图像中物体的类别和位置。该技术广泛应用于自动驾驶、机器人导航和物体跟踪等实际应用中。近年来，基于卷积神经网络（CNN）的物体检测器因其高效的性能而受到广泛关注，其中YOLO系列因其出色的性能和效率平衡而脱颖而出。\n\n### 研究内容\n\n本文旨在解决YOLO系列在实际部署中依赖非极大值抑制（NMS）导致的推理延迟问题，并通过优化模型架构进一步提升其性能和效率。具体来说，本文提出了以下两个主要目标：\n\n1. 提出一种无需NMS训练的一致双分配策略，以实现高效的端到端检测。\n2. 提出一种全面的效率-准确性驱动的模型设计策略，从后处理和模型架构两方面提升YOLO的性能和效率。\n\n### 研究难点\n\nYOLO系列在实际应用中面临的主要挑战包括：\n\n1. **NMS依赖性**：传统的YOLO训练过程中采用一对多标签分配策略，导致推理过程中需要依赖NMS进行后处理，这不仅增加了推理延迟，还使得模型对NMS超参数敏感，难以实现最优的端到端部署。\n2. **模型架构设计**：尽管已有大量研究探索了不同的模型架构设计策略，但YOLO系列在各个组件的设计上仍存在计算冗余，限制了模型的性能和效率。\n\n### 相关工作\n\n本文回顾了现有的实时物体检测器和端到端物体检测器的相关研究：\n\n1. **传统YOLO系列**：YOLOv1、YOLOv2和YOLOv3是典型的三部分检测架构，包括主干、颈部和头部。后续的YOLOv4和YOLOv5引入了CSPNet设计，并结合数据增强策略和多种模型尺度。YOLOv6、YOLOv7和YOLOv8分别提出了BiC、E-ELAN和C2f等新的组件设计。\n2. **端到端物体检测器**：DETR系列通过引入Transformer架构和匈牙利损失实现了一对一匹配预测，消除了手工设计的组件和后处理。其他研究如Learnable NMS和关系网络也尝试通过不同的方法实现端到端检测。\n\n### 研究方法\n\n本文提出了一种无需NMS训练的一致双分配策略和全面的效率-准确性驱动的模型设计策略：\n\n1. **一致双分配策略**：通过引入双标签分配和一致的匹配度量，结合一对多和一对一标签分配的优势，实现高效的端到端检测。\n2. **效率-准确性驱动的模型设计策略**：从模型架构的各个组件入手，提出了轻量级分类头、空间-通道解耦下采样和排名引导的块设计等优化方法，减少计算冗余并提升模型性能。\n\n### 实验设计\n\n本文在COCO数据集上对提出的YOLOv10模型进行了广泛的实验验证，具体包括：\n\n1. **数据集**：使用COCO数据集进行训练和评估，采用标准的训练-验证-测试划分。\n2. **实验设置**：所有模型在8块NVIDIA 3090 GPU上进行训练，采用SGD优化器，并结合Mosaic、Mixup和复制粘贴等数据增强策略。\n3. **评估指标**：使用标准平均精度（AP）和不同IoU阈值下的AP值评估模型性能，并测量推理延迟以评估效率。\n\n### 结果与分析\n\n实验结果表明，YOLOv10在多个模型尺度上均取得了显著的性能和效率提升：\n\n1. **性能提升**：YOLOv10-S在相似的AP下比RT-DETR-R18快1.8倍，YOLOv10-B在相同性能下比YOLOv9-C减少了46%的延迟。\n2. **参数和计算量减少**：YOLOv10-S和YOLOv10-B分别比RT-DETR-R18和YOLOv9-C减少了2.8倍和25%的参数数量和FLOPs。\n3. **全面优势**：YOLOv10在多个模型尺度上均优于现有先进模型，展示了其在计算-准确性权衡上的优越性。\n\n### 总体结论\n\n本文通过提出一致双分配策略和全面的效率-准确性驱动的模型设计策略，成功提升了YOLO系列的性能和效率。实验结果验证了YOLOv10在多个模型尺度上的优越性，展示了其在实时物体检测领域的潜力。未来的工作将进一步探索减少小模型中一对多训练和无需NMS训练之间的性能差距的方法。\n\n# 研究方法\n\n### 无NMS训练的一致双重分配\n\n![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/5f60bbd9bccdfacc4ce2a53bce9011dc-image.png)\n\n- 双重标签分配。\n\n  为了实现无需NMS的训练，论文提出了一致的双重分配策略。该策略结合一对多和多对一的标签分配策略的优点。具体来说，双重分配策略包括一个多对一的头和一个一对一的头。在训练过程中，两个头共同优化，使得主干和颈部能够享受多对一分配提供的丰富监督信号。在推理过程中，丢弃多对一头，只使用一对一头来做出预测，从而实现无需NMS的高效端到端部署。\n\n- 一致的匹配度量。\n\n为了确保两个头之间的和谐监督，论文提出了一致的匹配度量。该度量公式如下：\n$$\nm(\\alpha,\\beta)=s\\cdot p^{\\alpha}\\cdot IoU(\\hat{b},b)^{\\beta}\n$$\n其中，*p* 是分类分数，$\\hat{b}$ 和 *b* 分别表示预测和实例的边界框，*s* 表示空间先验，指示预测的锚点是否在实例内，*α* 和 *β* 是两个重要的超参数，平衡语义预测任务和位置回归任务的影响。\n\n### 全局效率-准确性驱动的模型设计\n\n除了后处理，YOLOs的模型架构也对效率-准确性权衡提出了巨大挑战[50, 8, 29]。尽管以前的工作探索了各种设计策略，但仍然缺乏对YOLOs中各个组件的全面检查。因此，模型架构展现出不可忽视的计算冗余和受限能力，这阻碍了其实现高效率和性能的潜力。在这里，我们旨在从效率和准确性角度全面执行YOLOs的模型设计。\n\n效率驱动的模型设计。YOLO中的组件包括茎(stem)、下采样层、带有基本构建块的阶段以及头部。茎的计算成本较低，因此我们对其他三个部分采用效率驱动的模型设计。\n\n（1）轻量级分类头部。在YOLO中，分类和回归头部通常共享相同的架构。然而，它们在计算开销上表现出显著的差异。例如，在YOLOv8-S中，分类头部的FLOPs和参数数量分别为回归头部的2.5倍和2.4倍。然而，在分析分类错误和回归错误的影响后（见表6），我们发现回归头部对YOLOs的性能承担了更大的重要性。因此，我们可以减少分类头部的开销，而不用担心会大幅损害性能。因此，我们简单地采用轻量级的架构用于分类头部，它由两个深度可分离的卷积[25, 9]组成，核大小为3x3，然后是一个1x1卷积。\n\n（2）空间通道解耦的下采样。YOLO通常利用常规的3x3标准卷积，步长为2，同时实现空间下采样（从H x W到$\\frac{H}{2} \\times \\frac{W}{2}$）和通道变换（从C到2C）。这引入了不可忽视的计算成本，即O(29*H**W**C*2)，以及参数数量，即O(18$C^2$)。相反，我们提出将空间缩减和通道增加操作解耦，以实现更高效的缩减。具体来说，我们首先利用逐点卷积来调节通道维度，然后利用深度卷积来进行空间缩减。这将计算成本降低到$O(2HWC^2+ \\frac{9}{2}HWC)$，参数数量减少到$O(2C^2+18C)$。同时，在缩减过程中最大化信息保留，从而在延迟减少的同时具有竞争力。\n\n（3）基于rank引导的模块设计：YOLOs通常在所有阶段使用相同的基本构建块，例如YOLOv8中的瓶颈块。为了彻底检查YOLOs的这种同质设计，我们利用内在秩来分析每个阶段的冗余。具体来说，我们计算每个阶段中最后一个基本块的最后一个卷积的数值秩，这计算了大于阈值的奇异值的数量。图3.(a)展示了YOLOv8的结果，表明深层阶段和大型模型更容易表现出更多的冗余。这一观察表明，简单地为所有阶段应用相同的块设计对于最佳的容量-效率权衡是次优的。为了解决这个问题，我们提出了一种基于秩的块设计方案，旨在通过紧凑的架构设计降低被证明是冗余的阶段复杂度。我们首先提出了一个紧凑的倒置块（CIB）结构，它采用廉价的深度可分离卷积进行空间混合，以及成本效益高的点对点卷积进行通道混合，如图3.(b)所示。它可以作为高效的基本构建块，例如嵌入在ELAN结构中（图3.(b)）。然后，我们提倡一种基于秩的块分配策略，以实现最佳效率，同时保持有竞争力的容量。具体来说，给定一个模型，我们根据其内在秩按升序对所有阶段进行排序。我们进一步检查用CIB替换领先阶段的基本块的性能变化。如果与给定模型相比没有性能下降，我们就继续替换下一个阶段，否则就停止该过程。因此，我们可以在不同阶段和模型规模上实现自适应的紧凑块设计，实现更高的效率而不损害性能。\n\n![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/0af9b20597598897c15c90a02d5c1093-1733232140019-3.png)\n\n### 准确性驱动的模型设计。\n\n我们进一步探索大核卷积和自注意力在准确性驱动设计中的应用，旨在以最小的成本提升性能。\n\n（1）大核卷积。采用大核深度卷积是一种有效的方法来扩大感受野并增强模型的能力[10, 40, 39]。然而，简单地在所有阶段都利用它们可能会引入浅层特征中的污染，同时也会在高分辨率阶段引入显著的I/O开销和延迟[8]。因此，我们建议在深度阶段利用CIB中的大核深度卷积。具体来说，我们增加了CIB中第二个3x3深度卷积的核大小为7x7，随后[39]。此外，我们采用结构重参数化技术[11,10,59]来引入另一个3x3深度卷积分支，以缓解优化问题而不增加推理开销。此外，随着模型规模的增加，其感受野自然扩大，使用大核卷积的好处逐渐减弱。因此，我们只在小型模型规模上采用大核卷积。\n\n(2) 部分自注意力(PSA)。自注意力[58]由于其显著的全球建模能力[38, 14, 76]而被广泛应用于各种视觉任务。然而，它表现出高计算复杂性和内存占用。为了解决这个问题，鉴于普遍存在的注意力头重用[69]，我们提出了一个高效的局部自注意力(PSA)模块设计，如图3.(c)所示。具体来说，在1x1卷积之后，我们将通道中的特征均匀划分为两部分。我们只将一部分输入到由多头自注意力模块(MHSA)和前馈网络(FFN)组成的NPSA块中。然后将两部分通过1x1卷积连接并融合。此外，我们遵循[22]的方法，将查询和键的维度分配给MHSA中的值的一半，并用BatchNorm[27]替换LayerNorm[1]以进行快速推理。此外，PSA仅在分辨率最低的第4阶段之后放置，避免了过多的开销。\n\n# 实验\n\n### 实现细节\n\n我们选择YOLOv8[21]作为我们的基线模型，因为它在延迟准确性和各种模型规模的可用性方面表现良好。我们采用了一致的NMS-free训练双重分配，并基于此进行了全体的效率-准确性驱动的模型设计，从而带来了我们的YOLOv10模型。YOLOv10具有与YOLOv8相同的变体，即N/S/M/L/X。此外，我们通过简单增加YOLOv10-M的宽度尺度因子，推导出了一个新的变体YOLOv10-B。我们在相同的全局从零开始设置[21, 65, 62]下，在COCO[35]上验证了所提出的检测器。此外，所有模型的延迟都在T4 GPU和TensorRT FP16上进行测试，遵循[78]的方法。\n\n### 与最先进技术的比较\n\n如表1所示，我们的YOLOv10在各种模型规模上实现了最先进的性能和端到端的延迟。我们首先将YOLOv10与我们基线模型，即YOLOv8进行比较。在N/S/M/L/X五种变体中，我们的YOLOv10实现了1.2%/1.4%/0.5%/0.3%/0.5%的AP改进，参数减少了28%/ 36%/ 41%/ 44%/ 57%，计算减少了23%/ 24%/ 25%/ 27%/ 38%，延迟减少了70%/65%/50%/41%/37%。与其他YOLO相比，\n\n![image-20241203212603338](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203212603338.png)\n\nYOLOv10在准确性和计算成本之间也展现了卓越的权衡。具体来说，对于轻量级和小型的模型，YOLOv10-N/S的性能超过了YOLOv6-3.0-N/S，分别提高了1.5 AP和2.0 AP，参数减少了51%，计算量减少了41%。对于中等规模的模型，与YOLOv9-C/ YOLO-MS相比，YOLOv10-B/M在相同或更好的性能下，延迟降低了46%/62%。对于大型模型，与Gold-YOLO-L相比，我们的YOLOv10-L在参数减少了68%，延迟降低了32%，并且AP显著提高了1.4%。此外，与RT-DETR相比，YOLOv10获得了显著的性能和延迟提升。值得注意的是，在相似的性能下，YOLOv10-S/X的推理速度比RT-DETR-R18/R101快了1.8倍和1.3倍。这些结果充分展示了YOLOv10作为实时端到端检测器的优越性。\n\n我们还使用原始的一对多训练方法将YOLOv10与其他YOLO进行了比较。在这种情况下，我们考虑了模型前向过程（Latencyf）的性能和延迟[62, 21, 60]。如表1所示，YOLOv10在不同模型规模上也展现了最先进的表现和效率，这表明了我们架构设计的有效性。\n\n###  模型分析\n\n![image-20241203212826090](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203212826090.png)\n\n![image-20241203213021438](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203213021438.png)\n\n![image-20241203213123173](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203213123173.png)\n\n![image-20241203213200887](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203213200887.png)\n\n1. **消融研究**：基于YOLOv10-S和YOLOv10-M的消融研究表明，无NMS训练结合一致的双标签分配显著降低了YOLOv10-S的端到端延迟，同时保持了44.3%的AP竞争力。此外，效率驱动的设计减少了参数数量和计算量，并显著降低了延迟。\n\n2. **双标签分配**：双标签分配为无NMS的YOLO提供了丰富的监督信息，并在推理时实现了高效性。一致匹配度量的引入进一步缩小了两个分支之间的监督差距，提高了性能。\n\n3. **效率驱动模型设计**：效率驱动模型设计通过轻量级分类头、空间-通道解耦下采样和紧凑倒置块（CIB）等组件，有效减少了参数数量、FLOPs和延迟，同时保持了竞争性的性能。\n\n4. **准确性驱动模型设计**：准确性驱动模型设计通过大核卷积和部分自注意力（PSA）模块，在不显著增加延迟的情况下提高了性能。\n\n5. **大核卷积**：大核卷积的使用扩大了感受野并增强了模型能力，但在小模型中效果更佳。\n\n6. **部分自注意力模块**：PSA模块通过减少自注意力头中的冗余来缓解优化问题，从而在不牺牲高效率的情况下提升了模型性能。\n\n# YOLOv10代码\n\n### C2fUIB介绍\n\n**C2fUIB只是用CIB结构替换了YOLOv8中 C2f的Bottleneck结构**\n\n**实现代码ultralytics/nn/modules/block.py**\n\n![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/8ed70c479c7530fe3d36f4f44fbbf2d8.png)\n\n![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/a3198a08d3b755ec2e1e85cb8979c2ee.png)\n\n```python\nclass CIB(nn.Module):\n    \"\"\"Standard bottleneck.\"\"\"\n\n    def __init__(self, c1, c2, shortcut=True, e=0.5, lk=False):\n        \"\"\"Initializes a bottleneck module with given input/output channels, shortcut option, group, kernels, and\n        expansion.\n        \"\"\"\n        super().__init__()\n        c_ = int(c2 * e)  # hidden channels\n        self.cv1 = nn.Sequential(\n            Conv(c1, c1, 3, g=c1),\n            Conv(c1, 2 * c_, 1),\n            Conv(2 * c_, 2 * c_, 3, g=2 * c_) if not lk else RepVGGDW(2 * c_),\n            Conv(2 * c_, c2, 1),\n            Conv(c2, c2, 3, g=c2),\n        )\n\n        self.add = shortcut and c1 == c2\n\n    def forward(self, x):\n        \"\"\"'forward()' applies the YOLO FPN to input data.\"\"\"\n        return x + self.cv1(x) if self.add else self.cv1(x)\n\nclass C2fCIB(C2f):\n    \"\"\"Faster Implementation of CSP Bottleneck with 2 convolutions.\"\"\"\n\n    def __init__(self, c1, c2, n=1, shortcut=False, lk=False, g=1, e=0.5):\n        \"\"\"Initialize CSP bottleneck layer with two convolutions with arguments ch_in, ch_out, number, shortcut, groups,\n        expansion.\n        \"\"\"\n        super().__init__(c1, c2, n, shortcut, g, e)\n        self.m = nn.ModuleList(CIB(self.c, self.c, shortcut, e=1.0, lk=lk) for _ in range(n))\n```\n\n### PSA介绍\n\n具体来说，我们在1×1卷积后将特征均匀地分为两部分。我们只将一部分输入到由多头自注意力模块（MHSA）和前馈网络（FFN）组成的NPSA块中。然后，两部分通过1×1卷积连接并融合。此外，遵循将查询和键的维度分配为值的一半，并用BatchNorm替换LayerNorm以实现快速推理。\n\n**实现代码ultralytics/nn/modules/block.py**\n\n![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/82d0ed0834ac712354683efcb0108bc6.png)\n\n```python\nclass Attention(nn.Module):\n    def __init__(self, dim, num_heads=8,\n                 attn_ratio=0.5):\n        super().__init__()\n        self.num_heads = num_heads\n        self.head_dim = dim // num_heads\n        self.key_dim = int(self.head_dim * attn_ratio)\n        self.scale = self.key_dim ** -0.5\n        nh_kd = nh_kd = self.key_dim * num_heads\n        h = dim + nh_kd * 2\n        self.qkv = Conv(dim, h, 1, act=False)\n        self.proj = Conv(dim, dim, 1, act=False)\n        self.pe = Conv(dim, dim, 3, 1, g=dim, act=False)\n\n    def forward(self, x):\n        B, _, H, W = x.shape\n        N = H * W\n        qkv = self.qkv(x)\n        q, k, v = qkv.view(B, self.num_heads, -1, N).split([self.key_dim, self.key_dim, self.head_dim], dim=2)\n\n        attn = (\n            (q.transpose(-2, -1) @ k) * self.scale\n        )\n        attn = attn.softmax(dim=-1)\n        x = (v @ attn.transpose(-2, -1)).view(B, -1, H, W) + self.pe(v.reshape(B, -1, H, W))\n        x = self.proj(x)\n        return x\n\nclass PSA(nn.Module):\n\n    def __init__(self, c1, c2, e=0.5):\n        super().__init__()\n        assert(c1 == c2)\n        self.c = int(c1 * e)\n        self.cv1 = Conv(c1, 2 * self.c, 1, 1)\n        self.cv2 = Conv(2 * self.c, c1, 1)\n        \n        self.attn = Attention(self.c, attn_ratio=0.5, num_heads=self.c // 64)\n        self.ffn = nn.Sequential(\n            Conv(self.c, self.c*2, 1),\n            Conv(self.c*2, self.c, 1, act=False)\n        )\n        \n    def forward(self, x):\n        a, b = self.cv1(x).split((self.c, self.c), dim=1)\n        b = b + self.attn(b)\n        b = b + self.ffn(b)\n        return self.cv2(torch.cat((a, b), 1))\n```\n\n### SCDown\n\nOLOs通常利用常规的3×3标准卷积，步长为2，同时实现空间下采样（从H×W到H/2×W/2）和通道变换（从C到2C）。这引入了不可忽视的计算成本$O(9HWC^2)$和参数数量O$(18C^2)$。相反，我们提议将空间缩减和通道增加操作解耦，以实现更高效的下采样。具体来说，我们首先利用点对点卷积来调整通道维度，然后利用深度可分离卷积进行空间下采样。这将计算成本降低到O(2HWC^2 + 9HWC)，并将参数数量减少到O(2C^2 + 18C)。同时，它最大限度地保留了下采样过程中的信息，从而在减少延迟的同时保持了有竞争力的性能。\n\n**实现代码ultralytics/nn/modules/block.py**\n\n```\nclass SCDown(nn.Module):\n    def __init__(self, c1, c2, k, s):\n        super().__init__()\n        self.cv1 = Conv(c1, c2, 1, 1)\n        self.cv2 = Conv(c2, c2, k=k, s=s, g=c2, act=False)\n\n    def forward(self, x):\n        return self.cv2(self.cv1(x))\n```\n\n\n\n参考：[YOLOv10真正实时端到端目标检测（原理介绍+代码详见+结构框图）-腾讯云开发者社区-腾讯云](https://cloud.tencent.com/developer/article/2426044)\n\n文章合集：https://github.com/chongzicbo/ReadWriteThink\n\n","slug":"人工智能/computer-vision/CV010-YOLO V10详解","published":1,"updated":"2024-12-26T04:24:42.759Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3a0002hghi6y9bbodj","content":"<h1 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h1><h3 id=\"背景介绍\"><a href=\"#背景介绍\" class=\"headerlink\" title=\"背景介绍\"></a>背景介绍</h3><p>实时物体检测一直是计算机视觉领域的研究热点，旨在低延迟下准确预测图像中物体的类别和位置。该技术广泛应用于自动驾驶、机器人导航和物体跟踪等实际应用中。近年来，基于卷积神经网络（CNN）的物体检测器因其高效的性能而受到广泛关注，其中YOLO系列因其出色的性能和效率平衡而脱颖而出。</p>\n<h3 id=\"研究内容\"><a href=\"#研究内容\" class=\"headerlink\" title=\"研究内容\"></a>研究内容</h3><p>本文旨在解决YOLO系列在实际部署中依赖非极大值抑制（NMS）导致的推理延迟问题，并通过优化模型架构进一步提升其性能和效率。具体来说，本文提出了以下两个主要目标：</p>\n<ol>\n<li>提出一种无需NMS训练的一致双分配策略，以实现高效的端到端检测。</li>\n<li>提出一种全面的效率-准确性驱动的模型设计策略，从后处理和模型架构两方面提升YOLO的性能和效率。</li>\n</ol>\n<h3 id=\"研究难点\"><a href=\"#研究难点\" class=\"headerlink\" title=\"研究难点\"></a>研究难点</h3><p>YOLO系列在实际应用中面临的主要挑战包括：</p>\n<ol>\n<li><strong>NMS依赖性</strong>：传统的YOLO训练过程中采用一对多标签分配策略，导致推理过程中需要依赖NMS进行后处理，这不仅增加了推理延迟，还使得模型对NMS超参数敏感，难以实现最优的端到端部署。</li>\n<li><strong>模型架构设计</strong>：尽管已有大量研究探索了不同的模型架构设计策略，但YOLO系列在各个组件的设计上仍存在计算冗余，限制了模型的性能和效率。</li>\n</ol>\n<h3 id=\"相关工作\"><a href=\"#相关工作\" class=\"headerlink\" title=\"相关工作\"></a>相关工作</h3><p>本文回顾了现有的实时物体检测器和端到端物体检测器的相关研究：</p>\n<ol>\n<li><strong>传统YOLO系列</strong>：YOLOv1、YOLOv2和YOLOv3是典型的三部分检测架构，包括主干、颈部和头部。后续的YOLOv4和YOLOv5引入了CSPNet设计，并结合数据增强策略和多种模型尺度。YOLOv6、YOLOv7和YOLOv8分别提出了BiC、E-ELAN和C2f等新的组件设计。</li>\n<li><strong>端到端物体检测器</strong>：DETR系列通过引入Transformer架构和匈牙利损失实现了一对一匹配预测，消除了手工设计的组件和后处理。其他研究如Learnable NMS和关系网络也尝试通过不同的方法实现端到端检测。</li>\n</ol>\n<h3 id=\"研究方法\"><a href=\"#研究方法\" class=\"headerlink\" title=\"研究方法\"></a>研究方法</h3><p>本文提出了一种无需NMS训练的一致双分配策略和全面的效率-准确性驱动的模型设计策略：</p>\n<ol>\n<li><strong>一致双分配策略</strong>：通过引入双标签分配和一致的匹配度量，结合一对多和一对一标签分配的优势，实现高效的端到端检测。</li>\n<li><strong>效率-准确性驱动的模型设计策略</strong>：从模型架构的各个组件入手，提出了轻量级分类头、空间-通道解耦下采样和排名引导的块设计等优化方法，减少计算冗余并提升模型性能。</li>\n</ol>\n<h3 id=\"实验设计\"><a href=\"#实验设计\" class=\"headerlink\" title=\"实验设计\"></a>实验设计</h3><p>本文在COCO数据集上对提出的YOLOv10模型进行了广泛的实验验证，具体包括：</p>\n<ol>\n<li><strong>数据集</strong>：使用COCO数据集进行训练和评估，采用标准的训练-验证-测试划分。</li>\n<li><strong>实验设置</strong>：所有模型在8块NVIDIA 3090 GPU上进行训练，采用SGD优化器，并结合Mosaic、Mixup和复制粘贴等数据增强策略。</li>\n<li><strong>评估指标</strong>：使用标准平均精度（AP）和不同IoU阈值下的AP值评估模型性能，并测量推理延迟以评估效率。</li>\n</ol>\n<h3 id=\"结果与分析\"><a href=\"#结果与分析\" class=\"headerlink\" title=\"结果与分析\"></a>结果与分析</h3><p>实验结果表明，YOLOv10在多个模型尺度上均取得了显著的性能和效率提升：</p>\n<ol>\n<li><strong>性能提升</strong>：YOLOv10-S在相似的AP下比RT-DETR-R18快1.8倍，YOLOv10-B在相同性能下比YOLOv9-C减少了46%的延迟。</li>\n<li><strong>参数和计算量减少</strong>：YOLOv10-S和YOLOv10-B分别比RT-DETR-R18和YOLOv9-C减少了2.8倍和25%的参数数量和FLOPs。</li>\n<li><strong>全面优势</strong>：YOLOv10在多个模型尺度上均优于现有先进模型，展示了其在计算-准确性权衡上的优越性。</li>\n</ol>\n<h3 id=\"总体结论\"><a href=\"#总体结论\" class=\"headerlink\" title=\"总体结论\"></a>总体结论</h3><p>本文通过提出一致双分配策略和全面的效率-准确性驱动的模型设计策略，成功提升了YOLO系列的性能和效率。实验结果验证了YOLOv10在多个模型尺度上的优越性，展示了其在实时物体检测领域的潜力。未来的工作将进一步探索减少小模型中一对多训练和无需NMS训练之间的性能差距的方法。</p>\n<h1 id=\"研究方法-1\"><a href=\"#研究方法-1\" class=\"headerlink\" title=\"研究方法\"></a>研究方法</h1><h3 id=\"无NMS训练的一致双重分配\"><a href=\"#无NMS训练的一致双重分配\" class=\"headerlink\" title=\"无NMS训练的一致双重分配\"></a>无NMS训练的一致双重分配</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/5f60bbd9bccdfacc4ce2a53bce9011dc-image.png\" alt=\"img\"></p>\n<ul>\n<li><p>双重标签分配。</p>\n<p>为了实现无需NMS的训练，论文提出了一致的双重分配策略。该策略结合一对多和多对一的标签分配策略的优点。具体来说，双重分配策略包括一个多对一的头和一个一对一的头。在训练过程中，两个头共同优化，使得主干和颈部能够享受多对一分配提供的丰富监督信号。在推理过程中，丢弃多对一头，只使用一对一头来做出预测，从而实现无需NMS的高效端到端部署。</p>\n</li>\n<li><p>一致的匹配度量。</p>\n</li>\n</ul>\n<p>为了确保两个头之间的和谐监督，论文提出了一致的匹配度量。该度量公式如下：<br>$$<br>m(\\alpha,\\beta)&#x3D;s\\cdot p^{\\alpha}\\cdot IoU(\\hat{b},b)^{\\beta}<br>$$<br>其中，<em>p</em> 是分类分数，$\\hat{b}$ 和 <em>b</em> 分别表示预测和实例的边界框，<em>s</em> 表示空间先验，指示预测的锚点是否在实例内，<em>α</em> 和 <em>β</em> 是两个重要的超参数，平衡语义预测任务和位置回归任务的影响。</p>\n<h3 id=\"全局效率-准确性驱动的模型设计\"><a href=\"#全局效率-准确性驱动的模型设计\" class=\"headerlink\" title=\"全局效率-准确性驱动的模型设计\"></a>全局效率-准确性驱动的模型设计</h3><p>除了后处理，YOLOs的模型架构也对效率-准确性权衡提出了巨大挑战[50, 8, 29]。尽管以前的工作探索了各种设计策略，但仍然缺乏对YOLOs中各个组件的全面检查。因此，模型架构展现出不可忽视的计算冗余和受限能力，这阻碍了其实现高效率和性能的潜力。在这里，我们旨在从效率和准确性角度全面执行YOLOs的模型设计。</p>\n<p>效率驱动的模型设计。YOLO中的组件包括茎(stem)、下采样层、带有基本构建块的阶段以及头部。茎的计算成本较低，因此我们对其他三个部分采用效率驱动的模型设计。</p>\n<p>（1）轻量级分类头部。在YOLO中，分类和回归头部通常共享相同的架构。然而，它们在计算开销上表现出显著的差异。例如，在YOLOv8-S中，分类头部的FLOPs和参数数量分别为回归头部的2.5倍和2.4倍。然而，在分析分类错误和回归错误的影响后（见表6），我们发现回归头部对YOLOs的性能承担了更大的重要性。因此，我们可以减少分类头部的开销，而不用担心会大幅损害性能。因此，我们简单地采用轻量级的架构用于分类头部，它由两个深度可分离的卷积[25, 9]组成，核大小为3x3，然后是一个1x1卷积。</p>\n<p>（2）空间通道解耦的下采样。YOLO通常利用常规的3x3标准卷积，步长为2，同时实现空间下采样（从H x W到$\\frac{H}{2} \\times \\frac{W}{2}$）和通道变换（从C到2C）。这引入了不可忽视的计算成本，即O(29<em>H<strong>W</strong>C</em>2)，以及参数数量，即O(18$C^2$)。相反，我们提出将空间缩减和通道增加操作解耦，以实现更高效的缩减。具体来说，我们首先利用逐点卷积来调节通道维度，然后利用深度卷积来进行空间缩减。这将计算成本降低到$O(2HWC^2+ \\frac{9}{2}HWC)$，参数数量减少到$O(2C^2+18C)$。同时，在缩减过程中最大化信息保留，从而在延迟减少的同时具有竞争力。</p>\n<p>（3）基于rank引导的模块设计：YOLOs通常在所有阶段使用相同的基本构建块，例如YOLOv8中的瓶颈块。为了彻底检查YOLOs的这种同质设计，我们利用内在秩来分析每个阶段的冗余。具体来说，我们计算每个阶段中最后一个基本块的最后一个卷积的数值秩，这计算了大于阈值的奇异值的数量。图3.(a)展示了YOLOv8的结果，表明深层阶段和大型模型更容易表现出更多的冗余。这一观察表明，简单地为所有阶段应用相同的块设计对于最佳的容量-效率权衡是次优的。为了解决这个问题，我们提出了一种基于秩的块设计方案，旨在通过紧凑的架构设计降低被证明是冗余的阶段复杂度。我们首先提出了一个紧凑的倒置块（CIB）结构，它采用廉价的深度可分离卷积进行空间混合，以及成本效益高的点对点卷积进行通道混合，如图3.(b)所示。它可以作为高效的基本构建块，例如嵌入在ELAN结构中（图3.(b)）。然后，我们提倡一种基于秩的块分配策略，以实现最佳效率，同时保持有竞争力的容量。具体来说，给定一个模型，我们根据其内在秩按升序对所有阶段进行排序。我们进一步检查用CIB替换领先阶段的基本块的性能变化。如果与给定模型相比没有性能下降，我们就继续替换下一个阶段，否则就停止该过程。因此，我们可以在不同阶段和模型规模上实现自适应的紧凑块设计，实现更高的效率而不损害性能。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/0af9b20597598897c15c90a02d5c1093-1733232140019-3.png\" alt=\"img\"></p>\n<h3 id=\"准确性驱动的模型设计。\"><a href=\"#准确性驱动的模型设计。\" class=\"headerlink\" title=\"准确性驱动的模型设计。\"></a>准确性驱动的模型设计。</h3><p>我们进一步探索大核卷积和自注意力在准确性驱动设计中的应用，旨在以最小的成本提升性能。</p>\n<p>（1）大核卷积。采用大核深度卷积是一种有效的方法来扩大感受野并增强模型的能力[10, 40, 39]。然而，简单地在所有阶段都利用它们可能会引入浅层特征中的污染，同时也会在高分辨率阶段引入显著的I&#x2F;O开销和延迟[8]。因此，我们建议在深度阶段利用CIB中的大核深度卷积。具体来说，我们增加了CIB中第二个3x3深度卷积的核大小为7x7，随后[39]。此外，我们采用结构重参数化技术[11,10,59]来引入另一个3x3深度卷积分支，以缓解优化问题而不增加推理开销。此外，随着模型规模的增加，其感受野自然扩大，使用大核卷积的好处逐渐减弱。因此，我们只在小型模型规模上采用大核卷积。</p>\n<p>(2) 部分自注意力(PSA)。自注意力[58]由于其显著的全球建模能力[38, 14, 76]而被广泛应用于各种视觉任务。然而，它表现出高计算复杂性和内存占用。为了解决这个问题，鉴于普遍存在的注意力头重用[69]，我们提出了一个高效的局部自注意力(PSA)模块设计，如图3.(c)所示。具体来说，在1x1卷积之后，我们将通道中的特征均匀划分为两部分。我们只将一部分输入到由多头自注意力模块(MHSA)和前馈网络(FFN)组成的NPSA块中。然后将两部分通过1x1卷积连接并融合。此外，我们遵循[22]的方法，将查询和键的维度分配给MHSA中的值的一半，并用BatchNorm[27]替换LayerNorm[1]以进行快速推理。此外，PSA仅在分辨率最低的第4阶段之后放置，避免了过多的开销。</p>\n<h1 id=\"实验\"><a href=\"#实验\" class=\"headerlink\" title=\"实验\"></a>实验</h1><h3 id=\"实现细节\"><a href=\"#实现细节\" class=\"headerlink\" title=\"实现细节\"></a>实现细节</h3><p>我们选择YOLOv8[21]作为我们的基线模型，因为它在延迟准确性和各种模型规模的可用性方面表现良好。我们采用了一致的NMS-free训练双重分配，并基于此进行了全体的效率-准确性驱动的模型设计，从而带来了我们的YOLOv10模型。YOLOv10具有与YOLOv8相同的变体，即N&#x2F;S&#x2F;M&#x2F;L&#x2F;X。此外，我们通过简单增加YOLOv10-M的宽度尺度因子，推导出了一个新的变体YOLOv10-B。我们在相同的全局从零开始设置[21, 65, 62]下，在COCO[35]上验证了所提出的检测器。此外，所有模型的延迟都在T4 GPU和TensorRT FP16上进行测试，遵循[78]的方法。</p>\n<h3 id=\"与最先进技术的比较\"><a href=\"#与最先进技术的比较\" class=\"headerlink\" title=\"与最先进技术的比较\"></a>与最先进技术的比较</h3><p>如表1所示，我们的YOLOv10在各种模型规模上实现了最先进的性能和端到端的延迟。我们首先将YOLOv10与我们基线模型，即YOLOv8进行比较。在N&#x2F;S&#x2F;M&#x2F;L&#x2F;X五种变体中，我们的YOLOv10实现了1.2%&#x2F;1.4%&#x2F;0.5%&#x2F;0.3%&#x2F;0.5%的AP改进，参数减少了28%&#x2F; 36%&#x2F; 41%&#x2F; 44%&#x2F; 57%，计算减少了23%&#x2F; 24%&#x2F; 25%&#x2F; 27%&#x2F; 38%，延迟减少了70%&#x2F;65%&#x2F;50%&#x2F;41%&#x2F;37%。与其他YOLO相比，</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203212603338.png\" alt=\"image-20241203212603338\"></p>\n<p>YOLOv10在准确性和计算成本之间也展现了卓越的权衡。具体来说，对于轻量级和小型的模型，YOLOv10-N&#x2F;S的性能超过了YOLOv6-3.0-N&#x2F;S，分别提高了1.5 AP和2.0 AP，参数减少了51%，计算量减少了41%。对于中等规模的模型，与YOLOv9-C&#x2F; YOLO-MS相比，YOLOv10-B&#x2F;M在相同或更好的性能下，延迟降低了46%&#x2F;62%。对于大型模型，与Gold-YOLO-L相比，我们的YOLOv10-L在参数减少了68%，延迟降低了32%，并且AP显著提高了1.4%。此外，与RT-DETR相比，YOLOv10获得了显著的性能和延迟提升。值得注意的是，在相似的性能下，YOLOv10-S&#x2F;X的推理速度比RT-DETR-R18&#x2F;R101快了1.8倍和1.3倍。这些结果充分展示了YOLOv10作为实时端到端检测器的优越性。</p>\n<p>我们还使用原始的一对多训练方法将YOLOv10与其他YOLO进行了比较。在这种情况下，我们考虑了模型前向过程（Latencyf）的性能和延迟[62, 21, 60]。如表1所示，YOLOv10在不同模型规模上也展现了最先进的表现和效率，这表明了我们架构设计的有效性。</p>\n<h3 id=\"模型分析\"><a href=\"#模型分析\" class=\"headerlink\" title=\"模型分析\"></a>模型分析</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203212826090.png\" alt=\"image-20241203212826090\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203213021438.png\" alt=\"image-20241203213021438\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203213123173.png\" alt=\"image-20241203213123173\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203213200887.png\" alt=\"image-20241203213200887\"></p>\n<ol>\n<li><p><strong>消融研究</strong>：基于YOLOv10-S和YOLOv10-M的消融研究表明，无NMS训练结合一致的双标签分配显著降低了YOLOv10-S的端到端延迟，同时保持了44.3%的AP竞争力。此外，效率驱动的设计减少了参数数量和计算量，并显著降低了延迟。</p>\n</li>\n<li><p><strong>双标签分配</strong>：双标签分配为无NMS的YOLO提供了丰富的监督信息，并在推理时实现了高效性。一致匹配度量的引入进一步缩小了两个分支之间的监督差距，提高了性能。</p>\n</li>\n<li><p><strong>效率驱动模型设计</strong>：效率驱动模型设计通过轻量级分类头、空间-通道解耦下采样和紧凑倒置块（CIB）等组件，有效减少了参数数量、FLOPs和延迟，同时保持了竞争性的性能。</p>\n</li>\n<li><p><strong>准确性驱动模型设计</strong>：准确性驱动模型设计通过大核卷积和部分自注意力（PSA）模块，在不显著增加延迟的情况下提高了性能。</p>\n</li>\n<li><p><strong>大核卷积</strong>：大核卷积的使用扩大了感受野并增强了模型能力，但在小模型中效果更佳。</p>\n</li>\n<li><p><strong>部分自注意力模块</strong>：PSA模块通过减少自注意力头中的冗余来缓解优化问题，从而在不牺牲高效率的情况下提升了模型性能。</p>\n</li>\n</ol>\n<h1 id=\"YOLOv10代码\"><a href=\"#YOLOv10代码\" class=\"headerlink\" title=\"YOLOv10代码\"></a>YOLOv10代码</h1><h3 id=\"C2fUIB介绍\"><a href=\"#C2fUIB介绍\" class=\"headerlink\" title=\"C2fUIB介绍\"></a>C2fUIB介绍</h3><p><strong>C2fUIB只是用CIB结构替换了YOLOv8中 C2f的Bottleneck结构</strong></p>\n<p><strong>实现代码ultralytics&#x2F;nn&#x2F;modules&#x2F;block.py</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/8ed70c479c7530fe3d36f4f44fbbf2d8.png\" alt=\"img\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/a3198a08d3b755ec2e1e85cb8979c2ee.png\" alt=\"img\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">CIB</span>(nn.Module):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;Standard bottleneck.&quot;&quot;&quot;</span><br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, c1, c2, shortcut=<span class=\"hljs-literal\">True</span>, e=<span class=\"hljs-number\">0.5</span>, lk=<span class=\"hljs-literal\">False</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initializes a bottleneck module with given input/output channels, shortcut option, group, kernels, and</span><br><span class=\"hljs-string\">        expansion.</span><br><span class=\"hljs-string\">        &quot;&quot;&quot;</span><br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        c_ = <span class=\"hljs-built_in\">int</span>(c2 * e)  <span class=\"hljs-comment\"># hidden channels</span><br>        <span class=\"hljs-variable language_\">self</span>.cv1 = nn.Sequential(<br>            Conv(c1, c1, <span class=\"hljs-number\">3</span>, g=c1),<br>            Conv(c1, <span class=\"hljs-number\">2</span> * c_, <span class=\"hljs-number\">1</span>),<br>            Conv(<span class=\"hljs-number\">2</span> * c_, <span class=\"hljs-number\">2</span> * c_, <span class=\"hljs-number\">3</span>, g=<span class=\"hljs-number\">2</span> * c_) <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> lk <span class=\"hljs-keyword\">else</span> RepVGGDW(<span class=\"hljs-number\">2</span> * c_),<br>            Conv(<span class=\"hljs-number\">2</span> * c_, c2, <span class=\"hljs-number\">1</span>),<br>            Conv(c2, c2, <span class=\"hljs-number\">3</span>, g=c2),<br>        )<br><br>        <span class=\"hljs-variable language_\">self</span>.add = shortcut <span class=\"hljs-keyword\">and</span> c1 == c2<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;&#x27;forward()&#x27; applies the YOLO FPN to input data.&quot;&quot;&quot;</span><br>        <span class=\"hljs-keyword\">return</span> x + <span class=\"hljs-variable language_\">self</span>.cv1(x) <span class=\"hljs-keyword\">if</span> <span class=\"hljs-variable language_\">self</span>.add <span class=\"hljs-keyword\">else</span> <span class=\"hljs-variable language_\">self</span>.cv1(x)<br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">C2fCIB</span>(<span class=\"hljs-title class_ inherited__\">C2f</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;Faster Implementation of CSP Bottleneck with 2 convolutions.&quot;&quot;&quot;</span><br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, c1, c2, n=<span class=\"hljs-number\">1</span>, shortcut=<span class=\"hljs-literal\">False</span>, lk=<span class=\"hljs-literal\">False</span>, g=<span class=\"hljs-number\">1</span>, e=<span class=\"hljs-number\">0.5</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize CSP bottleneck layer with two convolutions with arguments ch_in, ch_out, number, shortcut, groups,</span><br><span class=\"hljs-string\">        expansion.</span><br><span class=\"hljs-string\">        &quot;&quot;&quot;</span><br>        <span class=\"hljs-built_in\">super</span>().__init__(c1, c2, n, shortcut, g, e)<br>        <span class=\"hljs-variable language_\">self</span>.m = nn.ModuleList(CIB(<span class=\"hljs-variable language_\">self</span>.c, <span class=\"hljs-variable language_\">self</span>.c, shortcut, e=<span class=\"hljs-number\">1.0</span>, lk=lk) <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(n))<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"PSA介绍\"><a href=\"#PSA介绍\" class=\"headerlink\" title=\"PSA介绍\"></a>PSA介绍</h3><p>具体来说，我们在1×1卷积后将特征均匀地分为两部分。我们只将一部分输入到由多头自注意力模块（MHSA）和前馈网络（FFN）组成的NPSA块中。然后，两部分通过1×1卷积连接并融合。此外，遵循将查询和键的维度分配为值的一半，并用BatchNorm替换LayerNorm以实现快速推理。</p>\n<p><strong>实现代码ultralytics&#x2F;nn&#x2F;modules&#x2F;block.py</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/82d0ed0834ac712354683efcb0108bc6.png\" alt=\"img\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Attention</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, dim, num_heads=<span class=\"hljs-number\">8</span>,</span><br><span class=\"hljs-params\">                 attn_ratio=<span class=\"hljs-number\">0.5</span></span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        <span class=\"hljs-variable language_\">self</span>.num_heads = num_heads<br>        <span class=\"hljs-variable language_\">self</span>.head_dim = dim // num_heads<br>        <span class=\"hljs-variable language_\">self</span>.key_dim = <span class=\"hljs-built_in\">int</span>(<span class=\"hljs-variable language_\">self</span>.head_dim * attn_ratio)<br>        <span class=\"hljs-variable language_\">self</span>.scale = <span class=\"hljs-variable language_\">self</span>.key_dim ** -<span class=\"hljs-number\">0.5</span><br>        nh_kd = nh_kd = <span class=\"hljs-variable language_\">self</span>.key_dim * num_heads<br>        h = dim + nh_kd * <span class=\"hljs-number\">2</span><br>        <span class=\"hljs-variable language_\">self</span>.qkv = Conv(dim, h, <span class=\"hljs-number\">1</span>, act=<span class=\"hljs-literal\">False</span>)<br>        <span class=\"hljs-variable language_\">self</span>.proj = Conv(dim, dim, <span class=\"hljs-number\">1</span>, act=<span class=\"hljs-literal\">False</span>)<br>        <span class=\"hljs-variable language_\">self</span>.pe = Conv(dim, dim, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">1</span>, g=dim, act=<span class=\"hljs-literal\">False</span>)<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        B, _, H, W = x.shape<br>        N = H * W<br>        qkv = <span class=\"hljs-variable language_\">self</span>.qkv(x)<br>        q, k, v = qkv.view(B, <span class=\"hljs-variable language_\">self</span>.num_heads, -<span class=\"hljs-number\">1</span>, N).split([<span class=\"hljs-variable language_\">self</span>.key_dim, <span class=\"hljs-variable language_\">self</span>.key_dim, <span class=\"hljs-variable language_\">self</span>.head_dim], dim=<span class=\"hljs-number\">2</span>)<br><br>        attn = (<br>            (q.transpose(-<span class=\"hljs-number\">2</span>, -<span class=\"hljs-number\">1</span>) @ k) * <span class=\"hljs-variable language_\">self</span>.scale<br>        )<br>        attn = attn.softmax(dim=-<span class=\"hljs-number\">1</span>)<br>        x = (v @ attn.transpose(-<span class=\"hljs-number\">2</span>, -<span class=\"hljs-number\">1</span>)).view(B, -<span class=\"hljs-number\">1</span>, H, W) + <span class=\"hljs-variable language_\">self</span>.pe(v.reshape(B, -<span class=\"hljs-number\">1</span>, H, W))<br>        x = <span class=\"hljs-variable language_\">self</span>.proj(x)<br>        <span class=\"hljs-keyword\">return</span> x<br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">PSA</span>(nn.Module):<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, c1, c2, e=<span class=\"hljs-number\">0.5</span></span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        <span class=\"hljs-keyword\">assert</span>(c1 == c2)<br>        <span class=\"hljs-variable language_\">self</span>.c = <span class=\"hljs-built_in\">int</span>(c1 * e)<br>        <span class=\"hljs-variable language_\">self</span>.cv1 = Conv(c1, <span class=\"hljs-number\">2</span> * <span class=\"hljs-variable language_\">self</span>.c, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-variable language_\">self</span>.cv2 = Conv(<span class=\"hljs-number\">2</span> * <span class=\"hljs-variable language_\">self</span>.c, c1, <span class=\"hljs-number\">1</span>)<br>        <br>        <span class=\"hljs-variable language_\">self</span>.attn = Attention(<span class=\"hljs-variable language_\">self</span>.c, attn_ratio=<span class=\"hljs-number\">0.5</span>, num_heads=<span class=\"hljs-variable language_\">self</span>.c // <span class=\"hljs-number\">64</span>)<br>        <span class=\"hljs-variable language_\">self</span>.ffn = nn.Sequential(<br>            Conv(<span class=\"hljs-variable language_\">self</span>.c, <span class=\"hljs-variable language_\">self</span>.c*<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">1</span>),<br>            Conv(<span class=\"hljs-variable language_\">self</span>.c*<span class=\"hljs-number\">2</span>, <span class=\"hljs-variable language_\">self</span>.c, <span class=\"hljs-number\">1</span>, act=<span class=\"hljs-literal\">False</span>)<br>        )<br>        <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        a, b = <span class=\"hljs-variable language_\">self</span>.cv1(x).split((<span class=\"hljs-variable language_\">self</span>.c, <span class=\"hljs-variable language_\">self</span>.c), dim=<span class=\"hljs-number\">1</span>)<br>        b = b + <span class=\"hljs-variable language_\">self</span>.attn(b)<br>        b = b + <span class=\"hljs-variable language_\">self</span>.ffn(b)<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>.cv2(torch.cat((a, b), <span class=\"hljs-number\">1</span>))<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"SCDown\"><a href=\"#SCDown\" class=\"headerlink\" title=\"SCDown\"></a>SCDown</h3><p>OLOs通常利用常规的3×3标准卷积，步长为2，同时实现空间下采样（从H×W到H&#x2F;2×W&#x2F;2）和通道变换（从C到2C）。这引入了不可忽视的计算成本$O(9HWC^2)$和参数数量O$(18C^2)$。相反，我们提议将空间缩减和通道增加操作解耦，以实现更高效的下采样。具体来说，我们首先利用点对点卷积来调整通道维度，然后利用深度可分离卷积进行空间下采样。这将计算成本降低到O(2HWC^2 + 9HWC)，并将参数数量减少到O(2C^2 + 18C)。同时，它最大限度地保留了下采样过程中的信息，从而在减少延迟的同时保持了有竞争力的性能。</p>\n<p><strong>实现代码ultralytics&#x2F;nn&#x2F;modules&#x2F;block.py</strong></p>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ruby\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">SCDown</span>(nn.<span class=\"hljs-title class_\">Module</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span>, c1, c2, k, s</span>):<br>        <span class=\"hljs-variable language_\">super</span>().__init__()<br>        <span class=\"hljs-variable language_\">self</span>.cv1 = <span class=\"hljs-title class_\">Conv</span>(c1, c2, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-variable language_\">self</span>.cv2 = <span class=\"hljs-title class_\">Conv</span>(c2, c2, k=k, s=s, g=c2, act=<span class=\"hljs-title class_\">False</span>)<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span>, x</span>):<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>.cv2(<span class=\"hljs-variable language_\">self</span>.cv1(x))<br></code></pre></td></tr></table></figure>\n\n\n\n<p>参考：<a href=\"https://cloud.tencent.com/developer/article/2426044\">YOLOv10真正实时端到端目标检测（原理介绍+代码详见+结构框图）-腾讯云开发者社区-腾讯云</a></p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink\">https://github.com/chongzicbo/ReadWriteThink</a></p>\n","excerpt":"","more":"<h1 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h1><h3 id=\"背景介绍\"><a href=\"#背景介绍\" class=\"headerlink\" title=\"背景介绍\"></a>背景介绍</h3><p>实时物体检测一直是计算机视觉领域的研究热点，旨在低延迟下准确预测图像中物体的类别和位置。该技术广泛应用于自动驾驶、机器人导航和物体跟踪等实际应用中。近年来，基于卷积神经网络（CNN）的物体检测器因其高效的性能而受到广泛关注，其中YOLO系列因其出色的性能和效率平衡而脱颖而出。</p>\n<h3 id=\"研究内容\"><a href=\"#研究内容\" class=\"headerlink\" title=\"研究内容\"></a>研究内容</h3><p>本文旨在解决YOLO系列在实际部署中依赖非极大值抑制（NMS）导致的推理延迟问题，并通过优化模型架构进一步提升其性能和效率。具体来说，本文提出了以下两个主要目标：</p>\n<ol>\n<li>提出一种无需NMS训练的一致双分配策略，以实现高效的端到端检测。</li>\n<li>提出一种全面的效率-准确性驱动的模型设计策略，从后处理和模型架构两方面提升YOLO的性能和效率。</li>\n</ol>\n<h3 id=\"研究难点\"><a href=\"#研究难点\" class=\"headerlink\" title=\"研究难点\"></a>研究难点</h3><p>YOLO系列在实际应用中面临的主要挑战包括：</p>\n<ol>\n<li><strong>NMS依赖性</strong>：传统的YOLO训练过程中采用一对多标签分配策略，导致推理过程中需要依赖NMS进行后处理，这不仅增加了推理延迟，还使得模型对NMS超参数敏感，难以实现最优的端到端部署。</li>\n<li><strong>模型架构设计</strong>：尽管已有大量研究探索了不同的模型架构设计策略，但YOLO系列在各个组件的设计上仍存在计算冗余，限制了模型的性能和效率。</li>\n</ol>\n<h3 id=\"相关工作\"><a href=\"#相关工作\" class=\"headerlink\" title=\"相关工作\"></a>相关工作</h3><p>本文回顾了现有的实时物体检测器和端到端物体检测器的相关研究：</p>\n<ol>\n<li><strong>传统YOLO系列</strong>：YOLOv1、YOLOv2和YOLOv3是典型的三部分检测架构，包括主干、颈部和头部。后续的YOLOv4和YOLOv5引入了CSPNet设计，并结合数据增强策略和多种模型尺度。YOLOv6、YOLOv7和YOLOv8分别提出了BiC、E-ELAN和C2f等新的组件设计。</li>\n<li><strong>端到端物体检测器</strong>：DETR系列通过引入Transformer架构和匈牙利损失实现了一对一匹配预测，消除了手工设计的组件和后处理。其他研究如Learnable NMS和关系网络也尝试通过不同的方法实现端到端检测。</li>\n</ol>\n<h3 id=\"研究方法\"><a href=\"#研究方法\" class=\"headerlink\" title=\"研究方法\"></a>研究方法</h3><p>本文提出了一种无需NMS训练的一致双分配策略和全面的效率-准确性驱动的模型设计策略：</p>\n<ol>\n<li><strong>一致双分配策略</strong>：通过引入双标签分配和一致的匹配度量，结合一对多和一对一标签分配的优势，实现高效的端到端检测。</li>\n<li><strong>效率-准确性驱动的模型设计策略</strong>：从模型架构的各个组件入手，提出了轻量级分类头、空间-通道解耦下采样和排名引导的块设计等优化方法，减少计算冗余并提升模型性能。</li>\n</ol>\n<h3 id=\"实验设计\"><a href=\"#实验设计\" class=\"headerlink\" title=\"实验设计\"></a>实验设计</h3><p>本文在COCO数据集上对提出的YOLOv10模型进行了广泛的实验验证，具体包括：</p>\n<ol>\n<li><strong>数据集</strong>：使用COCO数据集进行训练和评估，采用标准的训练-验证-测试划分。</li>\n<li><strong>实验设置</strong>：所有模型在8块NVIDIA 3090 GPU上进行训练，采用SGD优化器，并结合Mosaic、Mixup和复制粘贴等数据增强策略。</li>\n<li><strong>评估指标</strong>：使用标准平均精度（AP）和不同IoU阈值下的AP值评估模型性能，并测量推理延迟以评估效率。</li>\n</ol>\n<h3 id=\"结果与分析\"><a href=\"#结果与分析\" class=\"headerlink\" title=\"结果与分析\"></a>结果与分析</h3><p>实验结果表明，YOLOv10在多个模型尺度上均取得了显著的性能和效率提升：</p>\n<ol>\n<li><strong>性能提升</strong>：YOLOv10-S在相似的AP下比RT-DETR-R18快1.8倍，YOLOv10-B在相同性能下比YOLOv9-C减少了46%的延迟。</li>\n<li><strong>参数和计算量减少</strong>：YOLOv10-S和YOLOv10-B分别比RT-DETR-R18和YOLOv9-C减少了2.8倍和25%的参数数量和FLOPs。</li>\n<li><strong>全面优势</strong>：YOLOv10在多个模型尺度上均优于现有先进模型，展示了其在计算-准确性权衡上的优越性。</li>\n</ol>\n<h3 id=\"总体结论\"><a href=\"#总体结论\" class=\"headerlink\" title=\"总体结论\"></a>总体结论</h3><p>本文通过提出一致双分配策略和全面的效率-准确性驱动的模型设计策略，成功提升了YOLO系列的性能和效率。实验结果验证了YOLOv10在多个模型尺度上的优越性，展示了其在实时物体检测领域的潜力。未来的工作将进一步探索减少小模型中一对多训练和无需NMS训练之间的性能差距的方法。</p>\n<h1 id=\"研究方法-1\"><a href=\"#研究方法-1\" class=\"headerlink\" title=\"研究方法\"></a>研究方法</h1><h3 id=\"无NMS训练的一致双重分配\"><a href=\"#无NMS训练的一致双重分配\" class=\"headerlink\" title=\"无NMS训练的一致双重分配\"></a>无NMS训练的一致双重分配</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/5f60bbd9bccdfacc4ce2a53bce9011dc-image.png\" alt=\"img\"></p>\n<ul>\n<li><p>双重标签分配。</p>\n<p>为了实现无需NMS的训练，论文提出了一致的双重分配策略。该策略结合一对多和多对一的标签分配策略的优点。具体来说，双重分配策略包括一个多对一的头和一个一对一的头。在训练过程中，两个头共同优化，使得主干和颈部能够享受多对一分配提供的丰富监督信号。在推理过程中，丢弃多对一头，只使用一对一头来做出预测，从而实现无需NMS的高效端到端部署。</p>\n</li>\n<li><p>一致的匹配度量。</p>\n</li>\n</ul>\n<p>为了确保两个头之间的和谐监督，论文提出了一致的匹配度量。该度量公式如下：<br>$$<br>m(\\alpha,\\beta)&#x3D;s\\cdot p^{\\alpha}\\cdot IoU(\\hat{b},b)^{\\beta}<br>$$<br>其中，<em>p</em> 是分类分数，$\\hat{b}$ 和 <em>b</em> 分别表示预测和实例的边界框，<em>s</em> 表示空间先验，指示预测的锚点是否在实例内，<em>α</em> 和 <em>β</em> 是两个重要的超参数，平衡语义预测任务和位置回归任务的影响。</p>\n<h3 id=\"全局效率-准确性驱动的模型设计\"><a href=\"#全局效率-准确性驱动的模型设计\" class=\"headerlink\" title=\"全局效率-准确性驱动的模型设计\"></a>全局效率-准确性驱动的模型设计</h3><p>除了后处理，YOLOs的模型架构也对效率-准确性权衡提出了巨大挑战[50, 8, 29]。尽管以前的工作探索了各种设计策略，但仍然缺乏对YOLOs中各个组件的全面检查。因此，模型架构展现出不可忽视的计算冗余和受限能力，这阻碍了其实现高效率和性能的潜力。在这里，我们旨在从效率和准确性角度全面执行YOLOs的模型设计。</p>\n<p>效率驱动的模型设计。YOLO中的组件包括茎(stem)、下采样层、带有基本构建块的阶段以及头部。茎的计算成本较低，因此我们对其他三个部分采用效率驱动的模型设计。</p>\n<p>（1）轻量级分类头部。在YOLO中，分类和回归头部通常共享相同的架构。然而，它们在计算开销上表现出显著的差异。例如，在YOLOv8-S中，分类头部的FLOPs和参数数量分别为回归头部的2.5倍和2.4倍。然而，在分析分类错误和回归错误的影响后（见表6），我们发现回归头部对YOLOs的性能承担了更大的重要性。因此，我们可以减少分类头部的开销，而不用担心会大幅损害性能。因此，我们简单地采用轻量级的架构用于分类头部，它由两个深度可分离的卷积[25, 9]组成，核大小为3x3，然后是一个1x1卷积。</p>\n<p>（2）空间通道解耦的下采样。YOLO通常利用常规的3x3标准卷积，步长为2，同时实现空间下采样（从H x W到$\\frac{H}{2} \\times \\frac{W}{2}$）和通道变换（从C到2C）。这引入了不可忽视的计算成本，即O(29<em>H<strong>W</strong>C</em>2)，以及参数数量，即O(18$C^2$)。相反，我们提出将空间缩减和通道增加操作解耦，以实现更高效的缩减。具体来说，我们首先利用逐点卷积来调节通道维度，然后利用深度卷积来进行空间缩减。这将计算成本降低到$O(2HWC^2+ \\frac{9}{2}HWC)$，参数数量减少到$O(2C^2+18C)$。同时，在缩减过程中最大化信息保留，从而在延迟减少的同时具有竞争力。</p>\n<p>（3）基于rank引导的模块设计：YOLOs通常在所有阶段使用相同的基本构建块，例如YOLOv8中的瓶颈块。为了彻底检查YOLOs的这种同质设计，我们利用内在秩来分析每个阶段的冗余。具体来说，我们计算每个阶段中最后一个基本块的最后一个卷积的数值秩，这计算了大于阈值的奇异值的数量。图3.(a)展示了YOLOv8的结果，表明深层阶段和大型模型更容易表现出更多的冗余。这一观察表明，简单地为所有阶段应用相同的块设计对于最佳的容量-效率权衡是次优的。为了解决这个问题，我们提出了一种基于秩的块设计方案，旨在通过紧凑的架构设计降低被证明是冗余的阶段复杂度。我们首先提出了一个紧凑的倒置块（CIB）结构，它采用廉价的深度可分离卷积进行空间混合，以及成本效益高的点对点卷积进行通道混合，如图3.(b)所示。它可以作为高效的基本构建块，例如嵌入在ELAN结构中（图3.(b)）。然后，我们提倡一种基于秩的块分配策略，以实现最佳效率，同时保持有竞争力的容量。具体来说，给定一个模型，我们根据其内在秩按升序对所有阶段进行排序。我们进一步检查用CIB替换领先阶段的基本块的性能变化。如果与给定模型相比没有性能下降，我们就继续替换下一个阶段，否则就停止该过程。因此，我们可以在不同阶段和模型规模上实现自适应的紧凑块设计，实现更高的效率而不损害性能。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/0af9b20597598897c15c90a02d5c1093-1733232140019-3.png\" alt=\"img\"></p>\n<h3 id=\"准确性驱动的模型设计。\"><a href=\"#准确性驱动的模型设计。\" class=\"headerlink\" title=\"准确性驱动的模型设计。\"></a>准确性驱动的模型设计。</h3><p>我们进一步探索大核卷积和自注意力在准确性驱动设计中的应用，旨在以最小的成本提升性能。</p>\n<p>（1）大核卷积。采用大核深度卷积是一种有效的方法来扩大感受野并增强模型的能力[10, 40, 39]。然而，简单地在所有阶段都利用它们可能会引入浅层特征中的污染，同时也会在高分辨率阶段引入显著的I&#x2F;O开销和延迟[8]。因此，我们建议在深度阶段利用CIB中的大核深度卷积。具体来说，我们增加了CIB中第二个3x3深度卷积的核大小为7x7，随后[39]。此外，我们采用结构重参数化技术[11,10,59]来引入另一个3x3深度卷积分支，以缓解优化问题而不增加推理开销。此外，随着模型规模的增加，其感受野自然扩大，使用大核卷积的好处逐渐减弱。因此，我们只在小型模型规模上采用大核卷积。</p>\n<p>(2) 部分自注意力(PSA)。自注意力[58]由于其显著的全球建模能力[38, 14, 76]而被广泛应用于各种视觉任务。然而，它表现出高计算复杂性和内存占用。为了解决这个问题，鉴于普遍存在的注意力头重用[69]，我们提出了一个高效的局部自注意力(PSA)模块设计，如图3.(c)所示。具体来说，在1x1卷积之后，我们将通道中的特征均匀划分为两部分。我们只将一部分输入到由多头自注意力模块(MHSA)和前馈网络(FFN)组成的NPSA块中。然后将两部分通过1x1卷积连接并融合。此外，我们遵循[22]的方法，将查询和键的维度分配给MHSA中的值的一半，并用BatchNorm[27]替换LayerNorm[1]以进行快速推理。此外，PSA仅在分辨率最低的第4阶段之后放置，避免了过多的开销。</p>\n<h1 id=\"实验\"><a href=\"#实验\" class=\"headerlink\" title=\"实验\"></a>实验</h1><h3 id=\"实现细节\"><a href=\"#实现细节\" class=\"headerlink\" title=\"实现细节\"></a>实现细节</h3><p>我们选择YOLOv8[21]作为我们的基线模型，因为它在延迟准确性和各种模型规模的可用性方面表现良好。我们采用了一致的NMS-free训练双重分配，并基于此进行了全体的效率-准确性驱动的模型设计，从而带来了我们的YOLOv10模型。YOLOv10具有与YOLOv8相同的变体，即N&#x2F;S&#x2F;M&#x2F;L&#x2F;X。此外，我们通过简单增加YOLOv10-M的宽度尺度因子，推导出了一个新的变体YOLOv10-B。我们在相同的全局从零开始设置[21, 65, 62]下，在COCO[35]上验证了所提出的检测器。此外，所有模型的延迟都在T4 GPU和TensorRT FP16上进行测试，遵循[78]的方法。</p>\n<h3 id=\"与最先进技术的比较\"><a href=\"#与最先进技术的比较\" class=\"headerlink\" title=\"与最先进技术的比较\"></a>与最先进技术的比较</h3><p>如表1所示，我们的YOLOv10在各种模型规模上实现了最先进的性能和端到端的延迟。我们首先将YOLOv10与我们基线模型，即YOLOv8进行比较。在N&#x2F;S&#x2F;M&#x2F;L&#x2F;X五种变体中，我们的YOLOv10实现了1.2%&#x2F;1.4%&#x2F;0.5%&#x2F;0.3%&#x2F;0.5%的AP改进，参数减少了28%&#x2F; 36%&#x2F; 41%&#x2F; 44%&#x2F; 57%，计算减少了23%&#x2F; 24%&#x2F; 25%&#x2F; 27%&#x2F; 38%，延迟减少了70%&#x2F;65%&#x2F;50%&#x2F;41%&#x2F;37%。与其他YOLO相比，</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203212603338.png\" alt=\"image-20241203212603338\"></p>\n<p>YOLOv10在准确性和计算成本之间也展现了卓越的权衡。具体来说，对于轻量级和小型的模型，YOLOv10-N&#x2F;S的性能超过了YOLOv6-3.0-N&#x2F;S，分别提高了1.5 AP和2.0 AP，参数减少了51%，计算量减少了41%。对于中等规模的模型，与YOLOv9-C&#x2F; YOLO-MS相比，YOLOv10-B&#x2F;M在相同或更好的性能下，延迟降低了46%&#x2F;62%。对于大型模型，与Gold-YOLO-L相比，我们的YOLOv10-L在参数减少了68%，延迟降低了32%，并且AP显著提高了1.4%。此外，与RT-DETR相比，YOLOv10获得了显著的性能和延迟提升。值得注意的是，在相似的性能下，YOLOv10-S&#x2F;X的推理速度比RT-DETR-R18&#x2F;R101快了1.8倍和1.3倍。这些结果充分展示了YOLOv10作为实时端到端检测器的优越性。</p>\n<p>我们还使用原始的一对多训练方法将YOLOv10与其他YOLO进行了比较。在这种情况下，我们考虑了模型前向过程（Latencyf）的性能和延迟[62, 21, 60]。如表1所示，YOLOv10在不同模型规模上也展现了最先进的表现和效率，这表明了我们架构设计的有效性。</p>\n<h3 id=\"模型分析\"><a href=\"#模型分析\" class=\"headerlink\" title=\"模型分析\"></a>模型分析</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203212826090.png\" alt=\"image-20241203212826090\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203213021438.png\" alt=\"image-20241203213021438\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203213123173.png\" alt=\"image-20241203213123173\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241203213200887.png\" alt=\"image-20241203213200887\"></p>\n<ol>\n<li><p><strong>消融研究</strong>：基于YOLOv10-S和YOLOv10-M的消融研究表明，无NMS训练结合一致的双标签分配显著降低了YOLOv10-S的端到端延迟，同时保持了44.3%的AP竞争力。此外，效率驱动的设计减少了参数数量和计算量，并显著降低了延迟。</p>\n</li>\n<li><p><strong>双标签分配</strong>：双标签分配为无NMS的YOLO提供了丰富的监督信息，并在推理时实现了高效性。一致匹配度量的引入进一步缩小了两个分支之间的监督差距，提高了性能。</p>\n</li>\n<li><p><strong>效率驱动模型设计</strong>：效率驱动模型设计通过轻量级分类头、空间-通道解耦下采样和紧凑倒置块（CIB）等组件，有效减少了参数数量、FLOPs和延迟，同时保持了竞争性的性能。</p>\n</li>\n<li><p><strong>准确性驱动模型设计</strong>：准确性驱动模型设计通过大核卷积和部分自注意力（PSA）模块，在不显著增加延迟的情况下提高了性能。</p>\n</li>\n<li><p><strong>大核卷积</strong>：大核卷积的使用扩大了感受野并增强了模型能力，但在小模型中效果更佳。</p>\n</li>\n<li><p><strong>部分自注意力模块</strong>：PSA模块通过减少自注意力头中的冗余来缓解优化问题，从而在不牺牲高效率的情况下提升了模型性能。</p>\n</li>\n</ol>\n<h1 id=\"YOLOv10代码\"><a href=\"#YOLOv10代码\" class=\"headerlink\" title=\"YOLOv10代码\"></a>YOLOv10代码</h1><h3 id=\"C2fUIB介绍\"><a href=\"#C2fUIB介绍\" class=\"headerlink\" title=\"C2fUIB介绍\"></a>C2fUIB介绍</h3><p><strong>C2fUIB只是用CIB结构替换了YOLOv8中 C2f的Bottleneck结构</strong></p>\n<p><strong>实现代码ultralytics&#x2F;nn&#x2F;modules&#x2F;block.py</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/8ed70c479c7530fe3d36f4f44fbbf2d8.png\" alt=\"img\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/a3198a08d3b755ec2e1e85cb8979c2ee.png\" alt=\"img\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">CIB</span>(nn.Module):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;Standard bottleneck.&quot;&quot;&quot;</span><br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, c1, c2, shortcut=<span class=\"hljs-literal\">True</span>, e=<span class=\"hljs-number\">0.5</span>, lk=<span class=\"hljs-literal\">False</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initializes a bottleneck module with given input/output channels, shortcut option, group, kernels, and</span><br><span class=\"hljs-string\">        expansion.</span><br><span class=\"hljs-string\">        &quot;&quot;&quot;</span><br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        c_ = <span class=\"hljs-built_in\">int</span>(c2 * e)  <span class=\"hljs-comment\"># hidden channels</span><br>        <span class=\"hljs-variable language_\">self</span>.cv1 = nn.Sequential(<br>            Conv(c1, c1, <span class=\"hljs-number\">3</span>, g=c1),<br>            Conv(c1, <span class=\"hljs-number\">2</span> * c_, <span class=\"hljs-number\">1</span>),<br>            Conv(<span class=\"hljs-number\">2</span> * c_, <span class=\"hljs-number\">2</span> * c_, <span class=\"hljs-number\">3</span>, g=<span class=\"hljs-number\">2</span> * c_) <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> lk <span class=\"hljs-keyword\">else</span> RepVGGDW(<span class=\"hljs-number\">2</span> * c_),<br>            Conv(<span class=\"hljs-number\">2</span> * c_, c2, <span class=\"hljs-number\">1</span>),<br>            Conv(c2, c2, <span class=\"hljs-number\">3</span>, g=c2),<br>        )<br><br>        <span class=\"hljs-variable language_\">self</span>.add = shortcut <span class=\"hljs-keyword\">and</span> c1 == c2<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;&#x27;forward()&#x27; applies the YOLO FPN to input data.&quot;&quot;&quot;</span><br>        <span class=\"hljs-keyword\">return</span> x + <span class=\"hljs-variable language_\">self</span>.cv1(x) <span class=\"hljs-keyword\">if</span> <span class=\"hljs-variable language_\">self</span>.add <span class=\"hljs-keyword\">else</span> <span class=\"hljs-variable language_\">self</span>.cv1(x)<br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">C2fCIB</span>(<span class=\"hljs-title class_ inherited__\">C2f</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;Faster Implementation of CSP Bottleneck with 2 convolutions.&quot;&quot;&quot;</span><br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, c1, c2, n=<span class=\"hljs-number\">1</span>, shortcut=<span class=\"hljs-literal\">False</span>, lk=<span class=\"hljs-literal\">False</span>, g=<span class=\"hljs-number\">1</span>, e=<span class=\"hljs-number\">0.5</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;Initialize CSP bottleneck layer with two convolutions with arguments ch_in, ch_out, number, shortcut, groups,</span><br><span class=\"hljs-string\">        expansion.</span><br><span class=\"hljs-string\">        &quot;&quot;&quot;</span><br>        <span class=\"hljs-built_in\">super</span>().__init__(c1, c2, n, shortcut, g, e)<br>        <span class=\"hljs-variable language_\">self</span>.m = nn.ModuleList(CIB(<span class=\"hljs-variable language_\">self</span>.c, <span class=\"hljs-variable language_\">self</span>.c, shortcut, e=<span class=\"hljs-number\">1.0</span>, lk=lk) <span class=\"hljs-keyword\">for</span> _ <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(n))<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"PSA介绍\"><a href=\"#PSA介绍\" class=\"headerlink\" title=\"PSA介绍\"></a>PSA介绍</h3><p>具体来说，我们在1×1卷积后将特征均匀地分为两部分。我们只将一部分输入到由多头自注意力模块（MHSA）和前馈网络（FFN）组成的NPSA块中。然后，两部分通过1×1卷积连接并融合。此外，遵循将查询和键的维度分配为值的一半，并用BatchNorm替换LayerNorm以实现快速推理。</p>\n<p><strong>实现代码ultralytics&#x2F;nn&#x2F;modules&#x2F;block.py</strong></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/82d0ed0834ac712354683efcb0108bc6.png\" alt=\"img\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Attention</span>(nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, dim, num_heads=<span class=\"hljs-number\">8</span>,</span><br><span class=\"hljs-params\">                 attn_ratio=<span class=\"hljs-number\">0.5</span></span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        <span class=\"hljs-variable language_\">self</span>.num_heads = num_heads<br>        <span class=\"hljs-variable language_\">self</span>.head_dim = dim // num_heads<br>        <span class=\"hljs-variable language_\">self</span>.key_dim = <span class=\"hljs-built_in\">int</span>(<span class=\"hljs-variable language_\">self</span>.head_dim * attn_ratio)<br>        <span class=\"hljs-variable language_\">self</span>.scale = <span class=\"hljs-variable language_\">self</span>.key_dim ** -<span class=\"hljs-number\">0.5</span><br>        nh_kd = nh_kd = <span class=\"hljs-variable language_\">self</span>.key_dim * num_heads<br>        h = dim + nh_kd * <span class=\"hljs-number\">2</span><br>        <span class=\"hljs-variable language_\">self</span>.qkv = Conv(dim, h, <span class=\"hljs-number\">1</span>, act=<span class=\"hljs-literal\">False</span>)<br>        <span class=\"hljs-variable language_\">self</span>.proj = Conv(dim, dim, <span class=\"hljs-number\">1</span>, act=<span class=\"hljs-literal\">False</span>)<br>        <span class=\"hljs-variable language_\">self</span>.pe = Conv(dim, dim, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">1</span>, g=dim, act=<span class=\"hljs-literal\">False</span>)<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        B, _, H, W = x.shape<br>        N = H * W<br>        qkv = <span class=\"hljs-variable language_\">self</span>.qkv(x)<br>        q, k, v = qkv.view(B, <span class=\"hljs-variable language_\">self</span>.num_heads, -<span class=\"hljs-number\">1</span>, N).split([<span class=\"hljs-variable language_\">self</span>.key_dim, <span class=\"hljs-variable language_\">self</span>.key_dim, <span class=\"hljs-variable language_\">self</span>.head_dim], dim=<span class=\"hljs-number\">2</span>)<br><br>        attn = (<br>            (q.transpose(-<span class=\"hljs-number\">2</span>, -<span class=\"hljs-number\">1</span>) @ k) * <span class=\"hljs-variable language_\">self</span>.scale<br>        )<br>        attn = attn.softmax(dim=-<span class=\"hljs-number\">1</span>)<br>        x = (v @ attn.transpose(-<span class=\"hljs-number\">2</span>, -<span class=\"hljs-number\">1</span>)).view(B, -<span class=\"hljs-number\">1</span>, H, W) + <span class=\"hljs-variable language_\">self</span>.pe(v.reshape(B, -<span class=\"hljs-number\">1</span>, H, W))<br>        x = <span class=\"hljs-variable language_\">self</span>.proj(x)<br>        <span class=\"hljs-keyword\">return</span> x<br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">PSA</span>(nn.Module):<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, c1, c2, e=<span class=\"hljs-number\">0.5</span></span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        <span class=\"hljs-keyword\">assert</span>(c1 == c2)<br>        <span class=\"hljs-variable language_\">self</span>.c = <span class=\"hljs-built_in\">int</span>(c1 * e)<br>        <span class=\"hljs-variable language_\">self</span>.cv1 = Conv(c1, <span class=\"hljs-number\">2</span> * <span class=\"hljs-variable language_\">self</span>.c, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-variable language_\">self</span>.cv2 = Conv(<span class=\"hljs-number\">2</span> * <span class=\"hljs-variable language_\">self</span>.c, c1, <span class=\"hljs-number\">1</span>)<br>        <br>        <span class=\"hljs-variable language_\">self</span>.attn = Attention(<span class=\"hljs-variable language_\">self</span>.c, attn_ratio=<span class=\"hljs-number\">0.5</span>, num_heads=<span class=\"hljs-variable language_\">self</span>.c // <span class=\"hljs-number\">64</span>)<br>        <span class=\"hljs-variable language_\">self</span>.ffn = nn.Sequential(<br>            Conv(<span class=\"hljs-variable language_\">self</span>.c, <span class=\"hljs-variable language_\">self</span>.c*<span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">1</span>),<br>            Conv(<span class=\"hljs-variable language_\">self</span>.c*<span class=\"hljs-number\">2</span>, <span class=\"hljs-variable language_\">self</span>.c, <span class=\"hljs-number\">1</span>, act=<span class=\"hljs-literal\">False</span>)<br>        )<br>        <br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        a, b = <span class=\"hljs-variable language_\">self</span>.cv1(x).split((<span class=\"hljs-variable language_\">self</span>.c, <span class=\"hljs-variable language_\">self</span>.c), dim=<span class=\"hljs-number\">1</span>)<br>        b = b + <span class=\"hljs-variable language_\">self</span>.attn(b)<br>        b = b + <span class=\"hljs-variable language_\">self</span>.ffn(b)<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>.cv2(torch.cat((a, b), <span class=\"hljs-number\">1</span>))<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"SCDown\"><a href=\"#SCDown\" class=\"headerlink\" title=\"SCDown\"></a>SCDown</h3><p>OLOs通常利用常规的3×3标准卷积，步长为2，同时实现空间下采样（从H×W到H&#x2F;2×W&#x2F;2）和通道变换（从C到2C）。这引入了不可忽视的计算成本$O(9HWC^2)$和参数数量O$(18C^2)$。相反，我们提议将空间缩减和通道增加操作解耦，以实现更高效的下采样。具体来说，我们首先利用点对点卷积来调整通道维度，然后利用深度可分离卷积进行空间下采样。这将计算成本降低到O(2HWC^2 + 9HWC)，并将参数数量减少到O(2C^2 + 18C)。同时，它最大限度地保留了下采样过程中的信息，从而在减少延迟的同时保持了有竞争力的性能。</p>\n<p><strong>实现代码ultralytics&#x2F;nn&#x2F;modules&#x2F;block.py</strong></p>\n<figure class=\"highlight ruby\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ruby\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">SCDown</span>(nn.<span class=\"hljs-title class_\">Module</span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span>, c1, c2, k, s</span>):<br>        <span class=\"hljs-variable language_\">super</span>().__init__()<br>        <span class=\"hljs-variable language_\">self</span>.cv1 = <span class=\"hljs-title class_\">Conv</span>(c1, c2, <span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-variable language_\">self</span>.cv2 = <span class=\"hljs-title class_\">Conv</span>(c2, c2, k=k, s=s, g=c2, act=<span class=\"hljs-title class_\">False</span>)<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\"><span class=\"hljs-variable language_\">self</span>, x</span>):<br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>.cv2(<span class=\"hljs-variable language_\">self</span>.cv1(x))<br></code></pre></td></tr></table></figure>\n\n\n\n<p>参考：<a href=\"https://cloud.tencent.com/developer/article/2426044\">YOLOv10真正实时端到端目标检测（原理介绍+代码详见+结构框图）-腾讯云开发者社区-腾讯云</a></p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink\">https://github.com/chongzicbo/ReadWriteThink</a></p>\n"},{"title":"深入解析 `xml.dom.minidom`：从入门到精通","date":"2024-12-13T04:00:00.000Z","_content":"\n# 深入解析 `xml.dom.minidom`：从入门到精通\n\n在 Python 中，处理 XML 文件是一个常见的需求。Python 提供了多种库来解析和操作 XML，其中 `xml.dom.minidom` 是一个轻量级的 DOM（Document Object Model）解析器，适合处理小型 XML 文件。本文将通过实际例子，详细解释 `xml.dom.minidom` 的用法，具体到每个方法的功能和使用场景。\n\n---\n\n## 1. 什么是 `xml.dom.minidom`？\n\n`xml.dom.minidom` 是 Python 标准库中的一个模块，用于解析和操作 XML 文档。它实现了 W3C 的 DOM Level 2 规范，提供了一种将 XML 文档表示为树结构的方式。通过 `xml.dom.minidom`，你可以轻松地读取、修改和生成 XML 文件。\n\n---\n\n## 2. 安装与导入\n\n`xml.dom.minidom` 是 Python 标准库的一部分，因此无需安装，直接导入即可使用：\n\n```python\nimport xml.dom.minidom\n```\n\n---\n\n## 3. 核心方法详解\n\n### 3.1 `parse(file)` - 解析 XML 文件\n\n`parse(file)` 方法用于解析一个 XML 文件，并返回一个 `Document` 对象。\n\n#### 示例：\n\n```python\n# 解析 XML 文件\ndom = xml.dom.minidom.parse(\"example.xml\")\nprint(dom.toxml())  # 输出整个 XML 文档\n```\n\n#### 解释：\n- `parse(file)`：传入一个文件路径或文件对象，返回一个 `Document` 对象。\n- `toxml()`：将 `Document` 对象转换为字符串形式的 XML。\n\n---\n\n### 3.2 `parseString(string)` - 解析 XML 字符串\n\n`parseString(string)` 方法用于解析一个 XML 字符串，并返回一个 `Document` 对象。\n\n#### 示例：\n\n```python\nfrom xml.dom import minidom\n# 解析 XML 字符串\nxml_string = \"\"\"<library>\n    <book id=\"1\">\n        <title>Python Basics</title>\n        <author>John Doe</author>\n    </book>\n    <book id=\"2\">\n        <title>Advanced Python</title>\n        <author>Jane Smith</author>\n    </book>\n</library>\n\"\"\"\ndom = minidom.parseString(xml_string)\nprint(dom.toxml())  # 输出整个 XML 文档\n```\n\n#### 解释：\n- `parseString(string)`：传入一个 XML 字符串，返回一个 `Document` 对象。\n- `toxml()`：将 `Document` 对象转换为字符串形式的 XML。\n\n---\n\n### 3.3 `getElementsByTagName(tagname)` - 获取指定标签的元素\n\n`getElementsByTagName(tagname)` 方法用于获取所有指定标签名的元素，返回一个包含 `Element` 对象的列表。\n\n#### 示例：\n\n```python\n# 获取所有 <book> 元素\nbooks = dom.getElementsByTagName(\"book\")\nfor book in books:\n    print(book.toxml())  # 输出每个 <book> 元素的 XML\n```\n\n#### 解释：\n- `getElementsByTagName(tagname)`：传入标签名，返回一个包含所有匹配元素的列表。\n- `toxml()`：将元素转换为字符串形式的 XML。\n\n---\n\n### 3.4 `getAttribute(name)` - 获取元素的属性值\n\n`getAttribute(name)` 方法用于获取元素的指定属性值。\n\n#### 示例：\n\n```python\n# 获取 <book> 元素的 \"id\" 属性\nbook = dom.getElementsByTagName(\"book\")[0]\nprint(book.getAttribute(\"id\"))  # 输出 \"1\"\n```\n\n#### 解释：\n- `getAttribute(name)`：传入属性名，返回属性值。\n\n---\n\n### 3.5 `setAttribute(name, value)` - 设置元素的属性值\n\n`setAttribute(name, value)` 方法用于设置元素的属性值。\n\n#### 示例：\n\n```python\n# 设置 <book> 元素的 \"id\" 属性\nbook = dom.getElementsByTagName(\"book\")[0]\nbook.setAttribute(\"id\", \"2\")\nprint(book.getAttribute(\"id\"))  # 输出 \"2\"\n```\n\n#### 解释：\n- `setAttribute(name, value)`：传入属性名和属性值，设置元素的属性。\n\n---\n\n### 3.6 `createElement(tagName)` - 创建新元素\n\n`createElement(tagName)` 方法用于创建一个新的元素节点。\n\n#### 示例：\n\n```python\n# 创建一个新的 <book> 元素\nnew_book = dom.createElement(\"book\")\nnew_book.setAttribute(\"id\", \"3\")\ndom.documentElement.appendChild(new_book)\nprint(dom.toxml())  # 输出更新后的 XML\n```\n\n#### 解释：\n- `createElement(tagName)`：传入标签名，创建一个新的元素节点。\n- `appendChild(node)`：将新元素添加到文档中。\n\n---\n\n### 3.7 `createTextNode(data)` - 创建文本节点\n\n`createTextNode(data)` 方法用于创建一个包含文本内容的节点。\n\n#### 示例：\n\n```python\n# 创建一个文本节点并添加到 <book> 元素中\ntext_node = dom.createTextNode(\"Python Programming\")\nnew_book = dom.createElement(\"book\")\nnew_book.appendChild(text_node)\ndom.documentElement.appendChild(new_book)\nprint(dom.toxml())  # 输出更新后的 XML\n```\n\n#### 解释：\n- `createTextNode(data)`：传入文本内容，创建一个文本节点。\n- `appendChild(node)`：将文本节点添加到元素中。\n\n---\n\n### 3.8 `removeChild(node)` - 删除子节点\n\n`removeChild(node)` 方法用于删除指定的子节点。\n\n#### 示例：\n\n```python\n# 删除第一个 <book> 元素\nbook = dom.getElementsByTagName(\"book\")[0]\ndom.documentElement.removeChild(book)\nprint(dom.toxml())  # 输出更新后的 XML\n```\n\n#### 解释：\n- `removeChild(node)`：传入要删除的节点，从父节点中移除该节点。\n\n---\n\n### 3.9 `toxml()` 和 `toprettyxml()` - 生成 XML 字符串\n\n`toxml()` 和 `toprettyxml()` 方法用于将 `Document` 对象转换为字符串形式的 XML。\n\n#### 示例：\n\n```python\n# 生成 XML 字符串\nprint(dom.toxml())  # 紧凑格式\nprint(dom.toprettyxml())  # 带缩进和换行的格式\n```\n\n#### 解释：\n- `toxml()`：生成紧凑的 XML 字符串。\n- `toprettyxml()`：生成带缩进和换行的格式化 XML 字符串。\n\n---\n\n## 4. 实际案例：图书管理系统\n\n假设我们有一个 XML 文件 `books.xml`，内容如下：\n\n```xml\n<library>\n    <book id=\"1\">\n        <title>Python Basics</title>\n        <author>John Doe</author>\n    </book>\n    <book id=\"2\">\n        <title>Advanced Python</title>\n        <author>Jane Smith</author>\n    </book>\n</library>\n```\n\n### 4.1 读取 XML 文件\n\n```python\nimport xml.dom.minidom\n\n# 解析 XML 文件\ndom = xml.dom.minidom.parse(\"books.xml\")\n\n# 获取所有 <book> 元素\nbooks = dom.getElementsByTagName(\"book\")\nfor book in books:\n    title = book.getElementsByTagName(\"title\")[0].firstChild.data\n    author = book.getElementsByTagName(\"author\")[0].firstChild.data\n    print(f\"Title: {title}, Author: {author}\")\n```\n\n#### 输出：\n```\nTitle: Python Basics, Author: John Doe\nTitle: Advanced Python, Author: Jane Smith\n```\n\n### 4.2 修改 XML 文件\n\n```python\n# 修改第一个 <book> 的标题\nbook = dom.getElementsByTagName(\"book\")[0]\ntitle = book.getElementsByTagName(\"title\")[0]\ntitle.firstChild.data = \"Python for Beginners\"\n\n# 保存修改后的 XML\nwith open(\"books_updated.xml\", \"w\") as f:\n    f.write(dom.toprettyxml())\n```\n\n#### 输出（`books_updated.xml`）：\n```xml\n<library>\n    <book id=\"1\">\n        <title>Python for Beginners</title>\n        <author>John Doe</author>\n    </book>\n    <book id=\"2\">\n        <title>Advanced Python</title>\n        <author>Jane Smith</author>\n    </book>\n</library>\n```\n\n---\n\n## 5. 总结\n\n`xml.dom.minidom` 是一个功能强大且易于使用的 XML 解析库。通过本文的详细讲解和实际案例，你应该已经掌握了如何使用 `xml.dom.minidom` 来解析、修改和生成 XML 文件。无论是读取 XML 数据，还是动态生成 XML 文档，`xml.dom.minidom` 都能满足你的需求。\n\n希望本文对你理解和使用 `xml.dom.minidom` 有所帮助！如果你有任何问题或需要进一步的帮助，请随时留言。","source":"_posts/开发/Python/Python-001：使用xml.dom.minidom解析xml文件.md","raw":"---\ntitle: '深入解析 `xml.dom.minidom`：从入门到精通'\ncategories:\n  - [开发,python]\ntags:\n  - python\ndate: 2024-12-13 12:00:00\n---\n\n# 深入解析 `xml.dom.minidom`：从入门到精通\n\n在 Python 中，处理 XML 文件是一个常见的需求。Python 提供了多种库来解析和操作 XML，其中 `xml.dom.minidom` 是一个轻量级的 DOM（Document Object Model）解析器，适合处理小型 XML 文件。本文将通过实际例子，详细解释 `xml.dom.minidom` 的用法，具体到每个方法的功能和使用场景。\n\n---\n\n## 1. 什么是 `xml.dom.minidom`？\n\n`xml.dom.minidom` 是 Python 标准库中的一个模块，用于解析和操作 XML 文档。它实现了 W3C 的 DOM Level 2 规范，提供了一种将 XML 文档表示为树结构的方式。通过 `xml.dom.minidom`，你可以轻松地读取、修改和生成 XML 文件。\n\n---\n\n## 2. 安装与导入\n\n`xml.dom.minidom` 是 Python 标准库的一部分，因此无需安装，直接导入即可使用：\n\n```python\nimport xml.dom.minidom\n```\n\n---\n\n## 3. 核心方法详解\n\n### 3.1 `parse(file)` - 解析 XML 文件\n\n`parse(file)` 方法用于解析一个 XML 文件，并返回一个 `Document` 对象。\n\n#### 示例：\n\n```python\n# 解析 XML 文件\ndom = xml.dom.minidom.parse(\"example.xml\")\nprint(dom.toxml())  # 输出整个 XML 文档\n```\n\n#### 解释：\n- `parse(file)`：传入一个文件路径或文件对象，返回一个 `Document` 对象。\n- `toxml()`：将 `Document` 对象转换为字符串形式的 XML。\n\n---\n\n### 3.2 `parseString(string)` - 解析 XML 字符串\n\n`parseString(string)` 方法用于解析一个 XML 字符串，并返回一个 `Document` 对象。\n\n#### 示例：\n\n```python\nfrom xml.dom import minidom\n# 解析 XML 字符串\nxml_string = \"\"\"<library>\n    <book id=\"1\">\n        <title>Python Basics</title>\n        <author>John Doe</author>\n    </book>\n    <book id=\"2\">\n        <title>Advanced Python</title>\n        <author>Jane Smith</author>\n    </book>\n</library>\n\"\"\"\ndom = minidom.parseString(xml_string)\nprint(dom.toxml())  # 输出整个 XML 文档\n```\n\n#### 解释：\n- `parseString(string)`：传入一个 XML 字符串，返回一个 `Document` 对象。\n- `toxml()`：将 `Document` 对象转换为字符串形式的 XML。\n\n---\n\n### 3.3 `getElementsByTagName(tagname)` - 获取指定标签的元素\n\n`getElementsByTagName(tagname)` 方法用于获取所有指定标签名的元素，返回一个包含 `Element` 对象的列表。\n\n#### 示例：\n\n```python\n# 获取所有 <book> 元素\nbooks = dom.getElementsByTagName(\"book\")\nfor book in books:\n    print(book.toxml())  # 输出每个 <book> 元素的 XML\n```\n\n#### 解释：\n- `getElementsByTagName(tagname)`：传入标签名，返回一个包含所有匹配元素的列表。\n- `toxml()`：将元素转换为字符串形式的 XML。\n\n---\n\n### 3.4 `getAttribute(name)` - 获取元素的属性值\n\n`getAttribute(name)` 方法用于获取元素的指定属性值。\n\n#### 示例：\n\n```python\n# 获取 <book> 元素的 \"id\" 属性\nbook = dom.getElementsByTagName(\"book\")[0]\nprint(book.getAttribute(\"id\"))  # 输出 \"1\"\n```\n\n#### 解释：\n- `getAttribute(name)`：传入属性名，返回属性值。\n\n---\n\n### 3.5 `setAttribute(name, value)` - 设置元素的属性值\n\n`setAttribute(name, value)` 方法用于设置元素的属性值。\n\n#### 示例：\n\n```python\n# 设置 <book> 元素的 \"id\" 属性\nbook = dom.getElementsByTagName(\"book\")[0]\nbook.setAttribute(\"id\", \"2\")\nprint(book.getAttribute(\"id\"))  # 输出 \"2\"\n```\n\n#### 解释：\n- `setAttribute(name, value)`：传入属性名和属性值，设置元素的属性。\n\n---\n\n### 3.6 `createElement(tagName)` - 创建新元素\n\n`createElement(tagName)` 方法用于创建一个新的元素节点。\n\n#### 示例：\n\n```python\n# 创建一个新的 <book> 元素\nnew_book = dom.createElement(\"book\")\nnew_book.setAttribute(\"id\", \"3\")\ndom.documentElement.appendChild(new_book)\nprint(dom.toxml())  # 输出更新后的 XML\n```\n\n#### 解释：\n- `createElement(tagName)`：传入标签名，创建一个新的元素节点。\n- `appendChild(node)`：将新元素添加到文档中。\n\n---\n\n### 3.7 `createTextNode(data)` - 创建文本节点\n\n`createTextNode(data)` 方法用于创建一个包含文本内容的节点。\n\n#### 示例：\n\n```python\n# 创建一个文本节点并添加到 <book> 元素中\ntext_node = dom.createTextNode(\"Python Programming\")\nnew_book = dom.createElement(\"book\")\nnew_book.appendChild(text_node)\ndom.documentElement.appendChild(new_book)\nprint(dom.toxml())  # 输出更新后的 XML\n```\n\n#### 解释：\n- `createTextNode(data)`：传入文本内容，创建一个文本节点。\n- `appendChild(node)`：将文本节点添加到元素中。\n\n---\n\n### 3.8 `removeChild(node)` - 删除子节点\n\n`removeChild(node)` 方法用于删除指定的子节点。\n\n#### 示例：\n\n```python\n# 删除第一个 <book> 元素\nbook = dom.getElementsByTagName(\"book\")[0]\ndom.documentElement.removeChild(book)\nprint(dom.toxml())  # 输出更新后的 XML\n```\n\n#### 解释：\n- `removeChild(node)`：传入要删除的节点，从父节点中移除该节点。\n\n---\n\n### 3.9 `toxml()` 和 `toprettyxml()` - 生成 XML 字符串\n\n`toxml()` 和 `toprettyxml()` 方法用于将 `Document` 对象转换为字符串形式的 XML。\n\n#### 示例：\n\n```python\n# 生成 XML 字符串\nprint(dom.toxml())  # 紧凑格式\nprint(dom.toprettyxml())  # 带缩进和换行的格式\n```\n\n#### 解释：\n- `toxml()`：生成紧凑的 XML 字符串。\n- `toprettyxml()`：生成带缩进和换行的格式化 XML 字符串。\n\n---\n\n## 4. 实际案例：图书管理系统\n\n假设我们有一个 XML 文件 `books.xml`，内容如下：\n\n```xml\n<library>\n    <book id=\"1\">\n        <title>Python Basics</title>\n        <author>John Doe</author>\n    </book>\n    <book id=\"2\">\n        <title>Advanced Python</title>\n        <author>Jane Smith</author>\n    </book>\n</library>\n```\n\n### 4.1 读取 XML 文件\n\n```python\nimport xml.dom.minidom\n\n# 解析 XML 文件\ndom = xml.dom.minidom.parse(\"books.xml\")\n\n# 获取所有 <book> 元素\nbooks = dom.getElementsByTagName(\"book\")\nfor book in books:\n    title = book.getElementsByTagName(\"title\")[0].firstChild.data\n    author = book.getElementsByTagName(\"author\")[0].firstChild.data\n    print(f\"Title: {title}, Author: {author}\")\n```\n\n#### 输出：\n```\nTitle: Python Basics, Author: John Doe\nTitle: Advanced Python, Author: Jane Smith\n```\n\n### 4.2 修改 XML 文件\n\n```python\n# 修改第一个 <book> 的标题\nbook = dom.getElementsByTagName(\"book\")[0]\ntitle = book.getElementsByTagName(\"title\")[0]\ntitle.firstChild.data = \"Python for Beginners\"\n\n# 保存修改后的 XML\nwith open(\"books_updated.xml\", \"w\") as f:\n    f.write(dom.toprettyxml())\n```\n\n#### 输出（`books_updated.xml`）：\n```xml\n<library>\n    <book id=\"1\">\n        <title>Python for Beginners</title>\n        <author>John Doe</author>\n    </book>\n    <book id=\"2\">\n        <title>Advanced Python</title>\n        <author>Jane Smith</author>\n    </book>\n</library>\n```\n\n---\n\n## 5. 总结\n\n`xml.dom.minidom` 是一个功能强大且易于使用的 XML 解析库。通过本文的详细讲解和实际案例，你应该已经掌握了如何使用 `xml.dom.minidom` 来解析、修改和生成 XML 文件。无论是读取 XML 数据，还是动态生成 XML 文档，`xml.dom.minidom` 都能满足你的需求。\n\n希望本文对你理解和使用 `xml.dom.minidom` 有所帮助！如果你有任何问题或需要进一步的帮助，请随时留言。","slug":"开发/Python/Python-001：使用xml.dom.minidom解析xml文件","published":1,"updated":"2024-12-26T06:20:46.929Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3c0004hghi87mpdeoz","content":"<h1 id=\"深入解析-xml-dom-minidom：从入门到精通\"><a href=\"#深入解析-xml-dom-minidom：从入门到精通\" class=\"headerlink\" title=\"深入解析 xml.dom.minidom：从入门到精通\"></a>深入解析 <code>xml.dom.minidom</code>：从入门到精通</h1><p>在 Python 中，处理 XML 文件是一个常见的需求。Python 提供了多种库来解析和操作 XML，其中 <code>xml.dom.minidom</code> 是一个轻量级的 DOM（Document Object Model）解析器，适合处理小型 XML 文件。本文将通过实际例子，详细解释 <code>xml.dom.minidom</code> 的用法，具体到每个方法的功能和使用场景。</p>\n<hr>\n<h2 id=\"1-什么是-xml-dom-minidom？\"><a href=\"#1-什么是-xml-dom-minidom？\" class=\"headerlink\" title=\"1. 什么是 xml.dom.minidom？\"></a>1. 什么是 <code>xml.dom.minidom</code>？</h2><p><code>xml.dom.minidom</code> 是 Python 标准库中的一个模块，用于解析和操作 XML 文档。它实现了 W3C 的 DOM Level 2 规范，提供了一种将 XML 文档表示为树结构的方式。通过 <code>xml.dom.minidom</code>，你可以轻松地读取、修改和生成 XML 文件。</p>\n<hr>\n<h2 id=\"2-安装与导入\"><a href=\"#2-安装与导入\" class=\"headerlink\" title=\"2. 安装与导入\"></a>2. 安装与导入</h2><p><code>xml.dom.minidom</code> 是 Python 标准库的一部分，因此无需安装，直接导入即可使用：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> xml.dom.minidom<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"3-核心方法详解\"><a href=\"#3-核心方法详解\" class=\"headerlink\" title=\"3. 核心方法详解\"></a>3. 核心方法详解</h2><h3 id=\"3-1-parse-file-解析-XML-文件\"><a href=\"#3-1-parse-file-解析-XML-文件\" class=\"headerlink\" title=\"3.1 parse(file) - 解析 XML 文件\"></a>3.1 <code>parse(file)</code> - 解析 XML 文件</h3><p><code>parse(file)</code> 方法用于解析一个 XML 文件，并返回一个 <code>Document</code> 对象。</p>\n<h4 id=\"示例：\"><a href=\"#示例：\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 解析 XML 文件</span><br>dom = xml.dom.minidom.parse(<span class=\"hljs-string\">&quot;example.xml&quot;</span>)<br><span class=\"hljs-built_in\">print</span>(dom.toxml())  <span class=\"hljs-comment\"># 输出整个 XML 文档</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：\"><a href=\"#解释：\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>parse(file)</code>：传入一个文件路径或文件对象，返回一个 <code>Document</code> 对象。</li>\n<li><code>toxml()</code>：将 <code>Document</code> 对象转换为字符串形式的 XML。</li>\n</ul>\n<hr>\n<h3 id=\"3-2-parseString-string-解析-XML-字符串\"><a href=\"#3-2-parseString-string-解析-XML-字符串\" class=\"headerlink\" title=\"3.2 parseString(string) - 解析 XML 字符串\"></a>3.2 <code>parseString(string)</code> - 解析 XML 字符串</h3><p><code>parseString(string)</code> 方法用于解析一个 XML 字符串，并返回一个 <code>Document</code> 对象。</p>\n<h4 id=\"示例：-1\"><a href=\"#示例：-1\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> xml.dom <span class=\"hljs-keyword\">import</span> minidom<br><span class=\"hljs-comment\"># 解析 XML 字符串</span><br>xml_string = <span class=\"hljs-string\">&quot;&quot;&quot;&lt;library&gt;</span><br><span class=\"hljs-string\">    &lt;book id=&quot;1&quot;&gt;</span><br><span class=\"hljs-string\">        &lt;title&gt;Python Basics&lt;/title&gt;</span><br><span class=\"hljs-string\">        &lt;author&gt;John Doe&lt;/author&gt;</span><br><span class=\"hljs-string\">    &lt;/book&gt;</span><br><span class=\"hljs-string\">    &lt;book id=&quot;2&quot;&gt;</span><br><span class=\"hljs-string\">        &lt;title&gt;Advanced Python&lt;/title&gt;</span><br><span class=\"hljs-string\">        &lt;author&gt;Jane Smith&lt;/author&gt;</span><br><span class=\"hljs-string\">    &lt;/book&gt;</span><br><span class=\"hljs-string\">&lt;/library&gt;</span><br><span class=\"hljs-string\">&quot;&quot;&quot;</span><br>dom = minidom.parseString(xml_string)<br><span class=\"hljs-built_in\">print</span>(dom.toxml())  <span class=\"hljs-comment\"># 输出整个 XML 文档</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-1\"><a href=\"#解释：-1\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>parseString(string)</code>：传入一个 XML 字符串，返回一个 <code>Document</code> 对象。</li>\n<li><code>toxml()</code>：将 <code>Document</code> 对象转换为字符串形式的 XML。</li>\n</ul>\n<hr>\n<h3 id=\"3-3-getElementsByTagName-tagname-获取指定标签的元素\"><a href=\"#3-3-getElementsByTagName-tagname-获取指定标签的元素\" class=\"headerlink\" title=\"3.3 getElementsByTagName(tagname) - 获取指定标签的元素\"></a>3.3 <code>getElementsByTagName(tagname)</code> - 获取指定标签的元素</h3><p><code>getElementsByTagName(tagname)</code> 方法用于获取所有指定标签名的元素，返回一个包含 <code>Element</code> 对象的列表。</p>\n<h4 id=\"示例：-2\"><a href=\"#示例：-2\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 获取所有 &lt;book&gt; 元素</span><br>books = dom.getElementsByTagName(<span class=\"hljs-string\">&quot;book&quot;</span>)<br><span class=\"hljs-keyword\">for</span> book <span class=\"hljs-keyword\">in</span> books:<br>    <span class=\"hljs-built_in\">print</span>(book.toxml())  <span class=\"hljs-comment\"># 输出每个 &lt;book&gt; 元素的 XML</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-2\"><a href=\"#解释：-2\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>getElementsByTagName(tagname)</code>：传入标签名，返回一个包含所有匹配元素的列表。</li>\n<li><code>toxml()</code>：将元素转换为字符串形式的 XML。</li>\n</ul>\n<hr>\n<h3 id=\"3-4-getAttribute-name-获取元素的属性值\"><a href=\"#3-4-getAttribute-name-获取元素的属性值\" class=\"headerlink\" title=\"3.4 getAttribute(name) - 获取元素的属性值\"></a>3.4 <code>getAttribute(name)</code> - 获取元素的属性值</h3><p><code>getAttribute(name)</code> 方法用于获取元素的指定属性值。</p>\n<h4 id=\"示例：-3\"><a href=\"#示例：-3\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 获取 &lt;book&gt; 元素的 &quot;id&quot; 属性</span><br>book = dom.getElementsByTagName(<span class=\"hljs-string\">&quot;book&quot;</span>)[<span class=\"hljs-number\">0</span>]<br><span class=\"hljs-built_in\">print</span>(book.getAttribute(<span class=\"hljs-string\">&quot;id&quot;</span>))  <span class=\"hljs-comment\"># 输出 &quot;1&quot;</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-3\"><a href=\"#解释：-3\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>getAttribute(name)</code>：传入属性名，返回属性值。</li>\n</ul>\n<hr>\n<h3 id=\"3-5-setAttribute-name-value-设置元素的属性值\"><a href=\"#3-5-setAttribute-name-value-设置元素的属性值\" class=\"headerlink\" title=\"3.5 setAttribute(name, value) - 设置元素的属性值\"></a>3.5 <code>setAttribute(name, value)</code> - 设置元素的属性值</h3><p><code>setAttribute(name, value)</code> 方法用于设置元素的属性值。</p>\n<h4 id=\"示例：-4\"><a href=\"#示例：-4\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 设置 &lt;book&gt; 元素的 &quot;id&quot; 属性</span><br>book = dom.getElementsByTagName(<span class=\"hljs-string\">&quot;book&quot;</span>)[<span class=\"hljs-number\">0</span>]<br>book.setAttribute(<span class=\"hljs-string\">&quot;id&quot;</span>, <span class=\"hljs-string\">&quot;2&quot;</span>)<br><span class=\"hljs-built_in\">print</span>(book.getAttribute(<span class=\"hljs-string\">&quot;id&quot;</span>))  <span class=\"hljs-comment\"># 输出 &quot;2&quot;</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-4\"><a href=\"#解释：-4\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>setAttribute(name, value)</code>：传入属性名和属性值，设置元素的属性。</li>\n</ul>\n<hr>\n<h3 id=\"3-6-createElement-tagName-创建新元素\"><a href=\"#3-6-createElement-tagName-创建新元素\" class=\"headerlink\" title=\"3.6 createElement(tagName) - 创建新元素\"></a>3.6 <code>createElement(tagName)</code> - 创建新元素</h3><p><code>createElement(tagName)</code> 方法用于创建一个新的元素节点。</p>\n<h4 id=\"示例：-5\"><a href=\"#示例：-5\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 创建一个新的 &lt;book&gt; 元素</span><br>new_book = dom.createElement(<span class=\"hljs-string\">&quot;book&quot;</span>)<br>new_book.setAttribute(<span class=\"hljs-string\">&quot;id&quot;</span>, <span class=\"hljs-string\">&quot;3&quot;</span>)<br>dom.documentElement.appendChild(new_book)<br><span class=\"hljs-built_in\">print</span>(dom.toxml())  <span class=\"hljs-comment\"># 输出更新后的 XML</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-5\"><a href=\"#解释：-5\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>createElement(tagName)</code>：传入标签名，创建一个新的元素节点。</li>\n<li><code>appendChild(node)</code>：将新元素添加到文档中。</li>\n</ul>\n<hr>\n<h3 id=\"3-7-createTextNode-data-创建文本节点\"><a href=\"#3-7-createTextNode-data-创建文本节点\" class=\"headerlink\" title=\"3.7 createTextNode(data) - 创建文本节点\"></a>3.7 <code>createTextNode(data)</code> - 创建文本节点</h3><p><code>createTextNode(data)</code> 方法用于创建一个包含文本内容的节点。</p>\n<h4 id=\"示例：-6\"><a href=\"#示例：-6\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 创建一个文本节点并添加到 &lt;book&gt; 元素中</span><br>text_node = dom.createTextNode(<span class=\"hljs-string\">&quot;Python Programming&quot;</span>)<br>new_book = dom.createElement(<span class=\"hljs-string\">&quot;book&quot;</span>)<br>new_book.appendChild(text_node)<br>dom.documentElement.appendChild(new_book)<br><span class=\"hljs-built_in\">print</span>(dom.toxml())  <span class=\"hljs-comment\"># 输出更新后的 XML</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-6\"><a href=\"#解释：-6\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>createTextNode(data)</code>：传入文本内容，创建一个文本节点。</li>\n<li><code>appendChild(node)</code>：将文本节点添加到元素中。</li>\n</ul>\n<hr>\n<h3 id=\"3-8-removeChild-node-删除子节点\"><a href=\"#3-8-removeChild-node-删除子节点\" class=\"headerlink\" title=\"3.8 removeChild(node) - 删除子节点\"></a>3.8 <code>removeChild(node)</code> - 删除子节点</h3><p><code>removeChild(node)</code> 方法用于删除指定的子节点。</p>\n<h4 id=\"示例：-7\"><a href=\"#示例：-7\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 删除第一个 &lt;book&gt; 元素</span><br>book = dom.getElementsByTagName(<span class=\"hljs-string\">&quot;book&quot;</span>)[<span class=\"hljs-number\">0</span>]<br>dom.documentElement.removeChild(book)<br><span class=\"hljs-built_in\">print</span>(dom.toxml())  <span class=\"hljs-comment\"># 输出更新后的 XML</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-7\"><a href=\"#解释：-7\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>removeChild(node)</code>：传入要删除的节点，从父节点中移除该节点。</li>\n</ul>\n<hr>\n<h3 id=\"3-9-toxml-和-toprettyxml-生成-XML-字符串\"><a href=\"#3-9-toxml-和-toprettyxml-生成-XML-字符串\" class=\"headerlink\" title=\"3.9 toxml() 和 toprettyxml() - 生成 XML 字符串\"></a>3.9 <code>toxml()</code> 和 <code>toprettyxml()</code> - 生成 XML 字符串</h3><p><code>toxml()</code> 和 <code>toprettyxml()</code> 方法用于将 <code>Document</code> 对象转换为字符串形式的 XML。</p>\n<h4 id=\"示例：-8\"><a href=\"#示例：-8\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 生成 XML 字符串</span><br><span class=\"hljs-built_in\">print</span>(dom.toxml())  <span class=\"hljs-comment\"># 紧凑格式</span><br><span class=\"hljs-built_in\">print</span>(dom.toprettyxml())  <span class=\"hljs-comment\"># 带缩进和换行的格式</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-8\"><a href=\"#解释：-8\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>toxml()</code>：生成紧凑的 XML 字符串。</li>\n<li><code>toprettyxml()</code>：生成带缩进和换行的格式化 XML 字符串。</li>\n</ul>\n<hr>\n<h2 id=\"4-实际案例：图书管理系统\"><a href=\"#4-实际案例：图书管理系统\" class=\"headerlink\" title=\"4. 实际案例：图书管理系统\"></a>4. 实际案例：图书管理系统</h2><p>假设我们有一个 XML 文件 <code>books.xml</code>，内容如下：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">library</span>&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">book</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;1&quot;</span>&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">title</span>&gt;</span>Python Basics<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">title</span>&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">author</span>&gt;</span>John Doe<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">author</span>&gt;</span><br>    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">book</span>&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">book</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;2&quot;</span>&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">title</span>&gt;</span>Advanced Python<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">title</span>&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">author</span>&gt;</span>Jane Smith<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">author</span>&gt;</span><br>    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">book</span>&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">library</span>&gt;</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"4-1-读取-XML-文件\"><a href=\"#4-1-读取-XML-文件\" class=\"headerlink\" title=\"4.1 读取 XML 文件\"></a>4.1 读取 XML 文件</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> xml.dom.minidom<br><br><span class=\"hljs-comment\"># 解析 XML 文件</span><br>dom = xml.dom.minidom.parse(<span class=\"hljs-string\">&quot;books.xml&quot;</span>)<br><br><span class=\"hljs-comment\"># 获取所有 &lt;book&gt; 元素</span><br>books = dom.getElementsByTagName(<span class=\"hljs-string\">&quot;book&quot;</span>)<br><span class=\"hljs-keyword\">for</span> book <span class=\"hljs-keyword\">in</span> books:<br>    title = book.getElementsByTagName(<span class=\"hljs-string\">&quot;title&quot;</span>)[<span class=\"hljs-number\">0</span>].firstChild.data<br>    author = book.getElementsByTagName(<span class=\"hljs-string\">&quot;author&quot;</span>)[<span class=\"hljs-number\">0</span>].firstChild.data<br>    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;Title: <span class=\"hljs-subst\">&#123;title&#125;</span>, Author: <span class=\"hljs-subst\">&#123;author&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"输出：\"><a href=\"#输出：\" class=\"headerlink\" title=\"输出：\"></a>输出：</h4><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">Title:</span> <span class=\"hljs-string\">Python</span> <span class=\"hljs-string\">Basics,</span> <span class=\"hljs-attr\">Author:</span> <span class=\"hljs-string\">John</span> <span class=\"hljs-string\">Doe</span><br><span class=\"hljs-attr\">Title:</span> <span class=\"hljs-string\">Advanced</span> <span class=\"hljs-string\">Python,</span> <span class=\"hljs-attr\">Author:</span> <span class=\"hljs-string\">Jane</span> <span class=\"hljs-string\">Smith</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"4-2-修改-XML-文件\"><a href=\"#4-2-修改-XML-文件\" class=\"headerlink\" title=\"4.2 修改 XML 文件\"></a>4.2 修改 XML 文件</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 修改第一个 &lt;book&gt; 的标题</span><br>book = dom.getElementsByTagName(<span class=\"hljs-string\">&quot;book&quot;</span>)[<span class=\"hljs-number\">0</span>]<br>title = book.getElementsByTagName(<span class=\"hljs-string\">&quot;title&quot;</span>)[<span class=\"hljs-number\">0</span>]<br>title.firstChild.data = <span class=\"hljs-string\">&quot;Python for Beginners&quot;</span><br><br><span class=\"hljs-comment\"># 保存修改后的 XML</span><br><span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">&quot;books_updated.xml&quot;</span>, <span class=\"hljs-string\">&quot;w&quot;</span>) <span class=\"hljs-keyword\">as</span> f:<br>    f.write(dom.toprettyxml())<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"输出（books-updated-xml）：\"><a href=\"#输出（books-updated-xml）：\" class=\"headerlink\" title=\"输出（books_updated.xml）：\"></a>输出（<code>books_updated.xml</code>）：</h4><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">library</span>&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">book</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;1&quot;</span>&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">title</span>&gt;</span>Python for Beginners<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">title</span>&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">author</span>&gt;</span>John Doe<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">author</span>&gt;</span><br>    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">book</span>&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">book</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;2&quot;</span>&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">title</span>&gt;</span>Advanced Python<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">title</span>&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">author</span>&gt;</span>Jane Smith<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">author</span>&gt;</span><br>    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">book</span>&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">library</span>&gt;</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"5-总结\"><a href=\"#5-总结\" class=\"headerlink\" title=\"5. 总结\"></a>5. 总结</h2><p><code>xml.dom.minidom</code> 是一个功能强大且易于使用的 XML 解析库。通过本文的详细讲解和实际案例，你应该已经掌握了如何使用 <code>xml.dom.minidom</code> 来解析、修改和生成 XML 文件。无论是读取 XML 数据，还是动态生成 XML 文档，<code>xml.dom.minidom</code> 都能满足你的需求。</p>\n<p>希望本文对你理解和使用 <code>xml.dom.minidom</code> 有所帮助！如果你有任何问题或需要进一步的帮助，请随时留言。</p>\n","excerpt":"","more":"<h1 id=\"深入解析-xml-dom-minidom：从入门到精通\"><a href=\"#深入解析-xml-dom-minidom：从入门到精通\" class=\"headerlink\" title=\"深入解析 xml.dom.minidom：从入门到精通\"></a>深入解析 <code>xml.dom.minidom</code>：从入门到精通</h1><p>在 Python 中，处理 XML 文件是一个常见的需求。Python 提供了多种库来解析和操作 XML，其中 <code>xml.dom.minidom</code> 是一个轻量级的 DOM（Document Object Model）解析器，适合处理小型 XML 文件。本文将通过实际例子，详细解释 <code>xml.dom.minidom</code> 的用法，具体到每个方法的功能和使用场景。</p>\n<hr>\n<h2 id=\"1-什么是-xml-dom-minidom？\"><a href=\"#1-什么是-xml-dom-minidom？\" class=\"headerlink\" title=\"1. 什么是 xml.dom.minidom？\"></a>1. 什么是 <code>xml.dom.minidom</code>？</h2><p><code>xml.dom.minidom</code> 是 Python 标准库中的一个模块，用于解析和操作 XML 文档。它实现了 W3C 的 DOM Level 2 规范，提供了一种将 XML 文档表示为树结构的方式。通过 <code>xml.dom.minidom</code>，你可以轻松地读取、修改和生成 XML 文件。</p>\n<hr>\n<h2 id=\"2-安装与导入\"><a href=\"#2-安装与导入\" class=\"headerlink\" title=\"2. 安装与导入\"></a>2. 安装与导入</h2><p><code>xml.dom.minidom</code> 是 Python 标准库的一部分，因此无需安装，直接导入即可使用：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> xml.dom.minidom<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"3-核心方法详解\"><a href=\"#3-核心方法详解\" class=\"headerlink\" title=\"3. 核心方法详解\"></a>3. 核心方法详解</h2><h3 id=\"3-1-parse-file-解析-XML-文件\"><a href=\"#3-1-parse-file-解析-XML-文件\" class=\"headerlink\" title=\"3.1 parse(file) - 解析 XML 文件\"></a>3.1 <code>parse(file)</code> - 解析 XML 文件</h3><p><code>parse(file)</code> 方法用于解析一个 XML 文件，并返回一个 <code>Document</code> 对象。</p>\n<h4 id=\"示例：\"><a href=\"#示例：\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 解析 XML 文件</span><br>dom = xml.dom.minidom.parse(<span class=\"hljs-string\">&quot;example.xml&quot;</span>)<br><span class=\"hljs-built_in\">print</span>(dom.toxml())  <span class=\"hljs-comment\"># 输出整个 XML 文档</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：\"><a href=\"#解释：\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>parse(file)</code>：传入一个文件路径或文件对象，返回一个 <code>Document</code> 对象。</li>\n<li><code>toxml()</code>：将 <code>Document</code> 对象转换为字符串形式的 XML。</li>\n</ul>\n<hr>\n<h3 id=\"3-2-parseString-string-解析-XML-字符串\"><a href=\"#3-2-parseString-string-解析-XML-字符串\" class=\"headerlink\" title=\"3.2 parseString(string) - 解析 XML 字符串\"></a>3.2 <code>parseString(string)</code> - 解析 XML 字符串</h3><p><code>parseString(string)</code> 方法用于解析一个 XML 字符串，并返回一个 <code>Document</code> 对象。</p>\n<h4 id=\"示例：-1\"><a href=\"#示例：-1\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> xml.dom <span class=\"hljs-keyword\">import</span> minidom<br><span class=\"hljs-comment\"># 解析 XML 字符串</span><br>xml_string = <span class=\"hljs-string\">&quot;&quot;&quot;&lt;library&gt;</span><br><span class=\"hljs-string\">    &lt;book id=&quot;1&quot;&gt;</span><br><span class=\"hljs-string\">        &lt;title&gt;Python Basics&lt;/title&gt;</span><br><span class=\"hljs-string\">        &lt;author&gt;John Doe&lt;/author&gt;</span><br><span class=\"hljs-string\">    &lt;/book&gt;</span><br><span class=\"hljs-string\">    &lt;book id=&quot;2&quot;&gt;</span><br><span class=\"hljs-string\">        &lt;title&gt;Advanced Python&lt;/title&gt;</span><br><span class=\"hljs-string\">        &lt;author&gt;Jane Smith&lt;/author&gt;</span><br><span class=\"hljs-string\">    &lt;/book&gt;</span><br><span class=\"hljs-string\">&lt;/library&gt;</span><br><span class=\"hljs-string\">&quot;&quot;&quot;</span><br>dom = minidom.parseString(xml_string)<br><span class=\"hljs-built_in\">print</span>(dom.toxml())  <span class=\"hljs-comment\"># 输出整个 XML 文档</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-1\"><a href=\"#解释：-1\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>parseString(string)</code>：传入一个 XML 字符串，返回一个 <code>Document</code> 对象。</li>\n<li><code>toxml()</code>：将 <code>Document</code> 对象转换为字符串形式的 XML。</li>\n</ul>\n<hr>\n<h3 id=\"3-3-getElementsByTagName-tagname-获取指定标签的元素\"><a href=\"#3-3-getElementsByTagName-tagname-获取指定标签的元素\" class=\"headerlink\" title=\"3.3 getElementsByTagName(tagname) - 获取指定标签的元素\"></a>3.3 <code>getElementsByTagName(tagname)</code> - 获取指定标签的元素</h3><p><code>getElementsByTagName(tagname)</code> 方法用于获取所有指定标签名的元素，返回一个包含 <code>Element</code> 对象的列表。</p>\n<h4 id=\"示例：-2\"><a href=\"#示例：-2\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 获取所有 &lt;book&gt; 元素</span><br>books = dom.getElementsByTagName(<span class=\"hljs-string\">&quot;book&quot;</span>)<br><span class=\"hljs-keyword\">for</span> book <span class=\"hljs-keyword\">in</span> books:<br>    <span class=\"hljs-built_in\">print</span>(book.toxml())  <span class=\"hljs-comment\"># 输出每个 &lt;book&gt; 元素的 XML</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-2\"><a href=\"#解释：-2\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>getElementsByTagName(tagname)</code>：传入标签名，返回一个包含所有匹配元素的列表。</li>\n<li><code>toxml()</code>：将元素转换为字符串形式的 XML。</li>\n</ul>\n<hr>\n<h3 id=\"3-4-getAttribute-name-获取元素的属性值\"><a href=\"#3-4-getAttribute-name-获取元素的属性值\" class=\"headerlink\" title=\"3.4 getAttribute(name) - 获取元素的属性值\"></a>3.4 <code>getAttribute(name)</code> - 获取元素的属性值</h3><p><code>getAttribute(name)</code> 方法用于获取元素的指定属性值。</p>\n<h4 id=\"示例：-3\"><a href=\"#示例：-3\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 获取 &lt;book&gt; 元素的 &quot;id&quot; 属性</span><br>book = dom.getElementsByTagName(<span class=\"hljs-string\">&quot;book&quot;</span>)[<span class=\"hljs-number\">0</span>]<br><span class=\"hljs-built_in\">print</span>(book.getAttribute(<span class=\"hljs-string\">&quot;id&quot;</span>))  <span class=\"hljs-comment\"># 输出 &quot;1&quot;</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-3\"><a href=\"#解释：-3\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>getAttribute(name)</code>：传入属性名，返回属性值。</li>\n</ul>\n<hr>\n<h3 id=\"3-5-setAttribute-name-value-设置元素的属性值\"><a href=\"#3-5-setAttribute-name-value-设置元素的属性值\" class=\"headerlink\" title=\"3.5 setAttribute(name, value) - 设置元素的属性值\"></a>3.5 <code>setAttribute(name, value)</code> - 设置元素的属性值</h3><p><code>setAttribute(name, value)</code> 方法用于设置元素的属性值。</p>\n<h4 id=\"示例：-4\"><a href=\"#示例：-4\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 设置 &lt;book&gt; 元素的 &quot;id&quot; 属性</span><br>book = dom.getElementsByTagName(<span class=\"hljs-string\">&quot;book&quot;</span>)[<span class=\"hljs-number\">0</span>]<br>book.setAttribute(<span class=\"hljs-string\">&quot;id&quot;</span>, <span class=\"hljs-string\">&quot;2&quot;</span>)<br><span class=\"hljs-built_in\">print</span>(book.getAttribute(<span class=\"hljs-string\">&quot;id&quot;</span>))  <span class=\"hljs-comment\"># 输出 &quot;2&quot;</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-4\"><a href=\"#解释：-4\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>setAttribute(name, value)</code>：传入属性名和属性值，设置元素的属性。</li>\n</ul>\n<hr>\n<h3 id=\"3-6-createElement-tagName-创建新元素\"><a href=\"#3-6-createElement-tagName-创建新元素\" class=\"headerlink\" title=\"3.6 createElement(tagName) - 创建新元素\"></a>3.6 <code>createElement(tagName)</code> - 创建新元素</h3><p><code>createElement(tagName)</code> 方法用于创建一个新的元素节点。</p>\n<h4 id=\"示例：-5\"><a href=\"#示例：-5\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 创建一个新的 &lt;book&gt; 元素</span><br>new_book = dom.createElement(<span class=\"hljs-string\">&quot;book&quot;</span>)<br>new_book.setAttribute(<span class=\"hljs-string\">&quot;id&quot;</span>, <span class=\"hljs-string\">&quot;3&quot;</span>)<br>dom.documentElement.appendChild(new_book)<br><span class=\"hljs-built_in\">print</span>(dom.toxml())  <span class=\"hljs-comment\"># 输出更新后的 XML</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-5\"><a href=\"#解释：-5\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>createElement(tagName)</code>：传入标签名，创建一个新的元素节点。</li>\n<li><code>appendChild(node)</code>：将新元素添加到文档中。</li>\n</ul>\n<hr>\n<h3 id=\"3-7-createTextNode-data-创建文本节点\"><a href=\"#3-7-createTextNode-data-创建文本节点\" class=\"headerlink\" title=\"3.7 createTextNode(data) - 创建文本节点\"></a>3.7 <code>createTextNode(data)</code> - 创建文本节点</h3><p><code>createTextNode(data)</code> 方法用于创建一个包含文本内容的节点。</p>\n<h4 id=\"示例：-6\"><a href=\"#示例：-6\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 创建一个文本节点并添加到 &lt;book&gt; 元素中</span><br>text_node = dom.createTextNode(<span class=\"hljs-string\">&quot;Python Programming&quot;</span>)<br>new_book = dom.createElement(<span class=\"hljs-string\">&quot;book&quot;</span>)<br>new_book.appendChild(text_node)<br>dom.documentElement.appendChild(new_book)<br><span class=\"hljs-built_in\">print</span>(dom.toxml())  <span class=\"hljs-comment\"># 输出更新后的 XML</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-6\"><a href=\"#解释：-6\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>createTextNode(data)</code>：传入文本内容，创建一个文本节点。</li>\n<li><code>appendChild(node)</code>：将文本节点添加到元素中。</li>\n</ul>\n<hr>\n<h3 id=\"3-8-removeChild-node-删除子节点\"><a href=\"#3-8-removeChild-node-删除子节点\" class=\"headerlink\" title=\"3.8 removeChild(node) - 删除子节点\"></a>3.8 <code>removeChild(node)</code> - 删除子节点</h3><p><code>removeChild(node)</code> 方法用于删除指定的子节点。</p>\n<h4 id=\"示例：-7\"><a href=\"#示例：-7\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 删除第一个 &lt;book&gt; 元素</span><br>book = dom.getElementsByTagName(<span class=\"hljs-string\">&quot;book&quot;</span>)[<span class=\"hljs-number\">0</span>]<br>dom.documentElement.removeChild(book)<br><span class=\"hljs-built_in\">print</span>(dom.toxml())  <span class=\"hljs-comment\"># 输出更新后的 XML</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-7\"><a href=\"#解释：-7\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>removeChild(node)</code>：传入要删除的节点，从父节点中移除该节点。</li>\n</ul>\n<hr>\n<h3 id=\"3-9-toxml-和-toprettyxml-生成-XML-字符串\"><a href=\"#3-9-toxml-和-toprettyxml-生成-XML-字符串\" class=\"headerlink\" title=\"3.9 toxml() 和 toprettyxml() - 生成 XML 字符串\"></a>3.9 <code>toxml()</code> 和 <code>toprettyxml()</code> - 生成 XML 字符串</h3><p><code>toxml()</code> 和 <code>toprettyxml()</code> 方法用于将 <code>Document</code> 对象转换为字符串形式的 XML。</p>\n<h4 id=\"示例：-8\"><a href=\"#示例：-8\" class=\"headerlink\" title=\"示例：\"></a>示例：</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 生成 XML 字符串</span><br><span class=\"hljs-built_in\">print</span>(dom.toxml())  <span class=\"hljs-comment\"># 紧凑格式</span><br><span class=\"hljs-built_in\">print</span>(dom.toprettyxml())  <span class=\"hljs-comment\"># 带缩进和换行的格式</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-8\"><a href=\"#解释：-8\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><code>toxml()</code>：生成紧凑的 XML 字符串。</li>\n<li><code>toprettyxml()</code>：生成带缩进和换行的格式化 XML 字符串。</li>\n</ul>\n<hr>\n<h2 id=\"4-实际案例：图书管理系统\"><a href=\"#4-实际案例：图书管理系统\" class=\"headerlink\" title=\"4. 实际案例：图书管理系统\"></a>4. 实际案例：图书管理系统</h2><p>假设我们有一个 XML 文件 <code>books.xml</code>，内容如下：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">library</span>&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">book</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;1&quot;</span>&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">title</span>&gt;</span>Python Basics<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">title</span>&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">author</span>&gt;</span>John Doe<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">author</span>&gt;</span><br>    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">book</span>&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">book</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;2&quot;</span>&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">title</span>&gt;</span>Advanced Python<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">title</span>&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">author</span>&gt;</span>Jane Smith<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">author</span>&gt;</span><br>    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">book</span>&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">library</span>&gt;</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"4-1-读取-XML-文件\"><a href=\"#4-1-读取-XML-文件\" class=\"headerlink\" title=\"4.1 读取 XML 文件\"></a>4.1 读取 XML 文件</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> xml.dom.minidom<br><br><span class=\"hljs-comment\"># 解析 XML 文件</span><br>dom = xml.dom.minidom.parse(<span class=\"hljs-string\">&quot;books.xml&quot;</span>)<br><br><span class=\"hljs-comment\"># 获取所有 &lt;book&gt; 元素</span><br>books = dom.getElementsByTagName(<span class=\"hljs-string\">&quot;book&quot;</span>)<br><span class=\"hljs-keyword\">for</span> book <span class=\"hljs-keyword\">in</span> books:<br>    title = book.getElementsByTagName(<span class=\"hljs-string\">&quot;title&quot;</span>)[<span class=\"hljs-number\">0</span>].firstChild.data<br>    author = book.getElementsByTagName(<span class=\"hljs-string\">&quot;author&quot;</span>)[<span class=\"hljs-number\">0</span>].firstChild.data<br>    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;Title: <span class=\"hljs-subst\">&#123;title&#125;</span>, Author: <span class=\"hljs-subst\">&#123;author&#125;</span>&quot;</span>)<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"输出：\"><a href=\"#输出：\" class=\"headerlink\" title=\"输出：\"></a>输出：</h4><figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs yaml\"><span class=\"hljs-attr\">Title:</span> <span class=\"hljs-string\">Python</span> <span class=\"hljs-string\">Basics,</span> <span class=\"hljs-attr\">Author:</span> <span class=\"hljs-string\">John</span> <span class=\"hljs-string\">Doe</span><br><span class=\"hljs-attr\">Title:</span> <span class=\"hljs-string\">Advanced</span> <span class=\"hljs-string\">Python,</span> <span class=\"hljs-attr\">Author:</span> <span class=\"hljs-string\">Jane</span> <span class=\"hljs-string\">Smith</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"4-2-修改-XML-文件\"><a href=\"#4-2-修改-XML-文件\" class=\"headerlink\" title=\"4.2 修改 XML 文件\"></a>4.2 修改 XML 文件</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 修改第一个 &lt;book&gt; 的标题</span><br>book = dom.getElementsByTagName(<span class=\"hljs-string\">&quot;book&quot;</span>)[<span class=\"hljs-number\">0</span>]<br>title = book.getElementsByTagName(<span class=\"hljs-string\">&quot;title&quot;</span>)[<span class=\"hljs-number\">0</span>]<br>title.firstChild.data = <span class=\"hljs-string\">&quot;Python for Beginners&quot;</span><br><br><span class=\"hljs-comment\"># 保存修改后的 XML</span><br><span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(<span class=\"hljs-string\">&quot;books_updated.xml&quot;</span>, <span class=\"hljs-string\">&quot;w&quot;</span>) <span class=\"hljs-keyword\">as</span> f:<br>    f.write(dom.toprettyxml())<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"输出（books-updated-xml）：\"><a href=\"#输出（books-updated-xml）：\" class=\"headerlink\" title=\"输出（books_updated.xml）：\"></a>输出（<code>books_updated.xml</code>）：</h4><figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">library</span>&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">book</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;1&quot;</span>&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">title</span>&gt;</span>Python for Beginners<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">title</span>&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">author</span>&gt;</span>John Doe<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">author</span>&gt;</span><br>    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">book</span>&gt;</span><br>    <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">book</span> <span class=\"hljs-attr\">id</span>=<span class=\"hljs-string\">&quot;2&quot;</span>&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">title</span>&gt;</span>Advanced Python<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">title</span>&gt;</span><br>        <span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">author</span>&gt;</span>Jane Smith<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">author</span>&gt;</span><br>    <span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">book</span>&gt;</span><br><span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">library</span>&gt;</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"5-总结\"><a href=\"#5-总结\" class=\"headerlink\" title=\"5. 总结\"></a>5. 总结</h2><p><code>xml.dom.minidom</code> 是一个功能强大且易于使用的 XML 解析库。通过本文的详细讲解和实际案例，你应该已经掌握了如何使用 <code>xml.dom.minidom</code> 来解析、修改和生成 XML 文件。无论是读取 XML 数据，还是动态生成 XML 文档，<code>xml.dom.minidom</code> 都能满足你的需求。</p>\n<p>希望本文对你理解和使用 <code>xml.dom.minidom</code> 有所帮助！如果你有任何问题或需要进一步的帮助，请随时留言。</p>\n"},{"title":"YOLO模型的全面综述","date":"2024-12-07T10:30:00.000Z","_content":"\n\n\n# 摘要\n\n本研究对YOLO （You Only Look Once） 的各个版本进行了全面的基准测试分析，从 YOLOv3 到最新的算法。它代表了首次全面评估 YOLO11 性能的研究，YOLO11 是 YOLO 系列的最新成员。它评估了它们在三个不同数据集上的性能：交通标志（具有不同的对象大小）、非洲野生动物（具有不同的纵横比，每个图像至少有一个对象实例）以及船舶和船只（具有单个类别的小型对象），确保在具有不同挑战的数据集之间进行全面评估。为了确保稳健的评估，我们采用了一套全面的指标，包括精度、召回率、平均精度均值 （mAP）、处理时间、GFLOP 计数和模型大小。我们的分析强调了每个 YOLO 版本的独特优势和局限性。例如：YOLOv9 表现出很高的准确性，但在检测小物体和效率方面表现不佳，而 YOLOv10 表现出相对较低的准确性，因为架构选择会影响其在重叠物体检测方面的性能，但在速度和效率方面表现出色。此外，YOLO11 系列在准确性、速度、计算效率和模型大小方面始终表现出卓越的性能。YOLO11m 在准确性和效率之间取得了显著的平衡，在交通标志、非洲野生动物和船舶数据集上的mAP50-95得分分别为0.795、0.81和0.325，同时保持了2.4毫秒的平均推理时间，模型大小为38.8Mb，平均约为67.6 GFLOPs。这些结果为工业界和学术界提供了重要的见解，有助于为各种应用选择最合适的 YOLO 算法，并指导未来的增强功能。\n\n# 引言\n\n![Refer to caption](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/x1.png)\n\n​                             Figure 1:Evolution of YOLO Algorithms throughout the years.\n\n主要介绍了物体检测在计算机视觉系统中的重要性及其应用，并概述了YOLO（You Only Look Once）算法的发展历程和优势。\n\n- **物体检测的重要性**：物体检测是计算机视觉系统的关键组成部分，广泛应用于自动驾驶、机器人技术、库存管理、视频监控和体育分析等领域。\n- **传统方法的局限性**：传统的物体检测方法如Viola-Jones算法和DPM模型在鲁棒性和泛化能力上存在局限，而深度学习方法已成为主流。\n- **一阶段与两阶段方法**：一阶段方法如RetinaNet和SSD在速度和准确性之间取得平衡，而两阶段方法如R-CNN提供高精度但计算密集。\n- **YOLO算法的崛起**：YOLO算法以其鲁棒性和效率脱颖而出，自2015年首次提出以来，通过不断改进框架和设计，成为实时物体检测的领先算法。\n- **YOLO算法的演进**：YOLO算法的演进包括从YOLOv1到YOLOv11的多个版本，每个版本都引入了新的架构和技术来提高性能。\n- **Ultralytics的角色**：Ultralytics在YOLO算法的发展中扮演了重要角色，通过维护和改进模型，使其更易于访问和定制。\n- **研究目的**：本研究旨在对YOLO算法的演变进行全面比较分析，特别是对最新成员YOLO11进行首次全面评估，并探讨其在不同应用场景中的优势和局限性。\n- **研究方法**：研究使用了三个多样化的数据集，并采用了一致的超参数设置，以确保公平和无偏见的比较。\n- **研究贡献**：研究的贡献在于提供了对YOLO11及其前身的全面比较，深入分析了这些算法的结构演变，并扩展了性能评估指标，为选择最适合特定用例的YOLO算法提供了宝贵的见解。\n\n# 相关工作\n\n主要回顾了YOLO算法的演变、不同版本的架构、以及与其他计算机视觉算法的基准测试。以下是对该章节的详细总结分析：\n\n### YOLO算法的演变：\n\n- 论文[14]分析了包括YOLOv8在内的七种语义分割和检测算法，用于云层分割的遥感图像。\n- 论文[22]回顾了YOLO从版本1到版本8的演变，但没有考虑YOLOv9、YOLOv10和YOLO11。\n- 论文[12]详细分析了从YOLOv1到YOLOv4的单阶段物体检测器，并比较了两阶段和单阶段物体检测器。\n- 论文[53]探讨了YOLO从版本1到10的演变，强调了其在汽车安全、医疗保健等领域的应用。\n- 论文[61]讨论了YOLO算法的发展直到第四版，并提出了新的方法和挑战。\n- 论文[27]分析了YOLO算法的发展和性能，比较了从第8版到第8版的YOLO版本。\n\n### YOLO算法的应用：\n\n- YOLO算法在自动驾驶、医疗保健、工业制造、监控和农业等领域有广泛应用。\n- YOLOv8提供了多种应用，包括实例分割、姿态估计和定向物体检测（OOB）。\n\n### YOLO算法的基准测试：\n\n- 论文[14]进行了云层分割的基准测试，评估了不同算法的架构方法和性能。\n- 论文[22]提出了结合联邦学习以提高隐私、适应性和协作训练的通用性。\n- 论文[12]提供了单阶段和两阶段物体检测器的比较。\n- 论文[53]探讨了YOLO算法对未来AI驱动应用的潜在整合。\n- 论文[61]强调了YOLO算法在物体检测方面的挑战和需要进一步研究的地方。\n\n### YOLO算法的挑战：\n\n- YOLO算法在处理小物体和不同旋转角度的物体时面临挑战。\n- YOLOv9、YOLOv10和YOLO11的最新模型在准确性和效率方面表现出色，但在某些情况下仍需改进。\n\n### YOLO算法的改进：\n\n- YOLOv9引入了信息瓶颈原理和可逆函数来保留数据，提高了模型的收敛性和性能。\n- YOLOv10通过增强的CSP-Net主干和PAN层提高了梯度流动和减少了计算冗余。\n- YOLO11引入了C2PSA模块，结合了跨阶段部分网络和自注意力机制，提高了检测精度。\n\n### YOLO算法的未来方向：\n\n- 未来的研究可以专注于优化YOLOv10以提高其准确性，同时保持其速度和效率优势。\n- 继续改进架构设计可能会带来更先进的YOLO算法。\n\n### 研究贡献：\n\n- 本研究首次全面比较了YOLO11及其前身，并在三个多样化的数据集上评估了它们的性能。\n- 研究结果为工业界和学术界提供了选择最适合特定应用场景的YOLO算法的宝贵见解。\n\n通过这些分析，可以看出YOLO算法在不断演进和改进，以适应不同的应用需求和挑战。\n\n# Benchmark 设置\n\n### 数据集\n\n介绍了三种数据集，分别是Traffic Signs Dataset、Africa Wildlife Dataset和Ships/Vessels Dataset。以下是对这三种数据集的详细介绍：\n\n#### 1. Traffic Signs Dataset（交通标志数据集）\n\n- **来源**：由Radu Oprea在Kaggle上提供的开源数据集。\n- 特点：\n  - 包含约55个类别的交通标志图像。\n  - 训练集包含3253张图像，验证集包含1128张图像。\n  - 图像大小不一，初始尺寸为640x640像素。\n  - 为了平衡不同类别的数量，采用了欠采样技术。\n- **应用领域**：自动驾驶、交通管理、道路安全和智能交通系统。\n- 挑战：\n  - 目标物体大小变化较大。\n  - 不同类别之间的模式相似，增加了检测难度。\n\n#### 2. Africa Wildlife Dataset（非洲野生动物数据集）\n\n- **来源**：由Bianca Ferreira在Kaggle上设计的开源数据集。\n- 特点：\n  - 包含四种常见的非洲动物类别：水牛、大象、犀牛和斑马。\n  - 每个类别至少有376张图像，通过Google图像搜索收集并手动标注为YOLO格式。\n  - 数据集分为训练集、验证集和测试集，比例为70%、20%和10%。\n- **应用领域**：野生动物保护、反偷猎、生物多样性监测和生态研究。\n- 挑战：\n  - 目标物体的宽高比变化较大。\n  - 每张图像至少包含一种指定的动物类别，可能还包含其他类别的多个实例或发生情况。\n  - 目标物体重叠，增加了检测难度。\n\n#### 3. Ships/Vessels Dataset（船舶数据集）\n\n- **来源**：由Siddharth Sah从多个Roboflow数据集中收集并整理的开源数据集。\n- 特点：\n  - 包含约13.5k张图像，专门用于船舶检测。\n  - 每张图像都使用YOLO格式手动标注了边界框。\n  - 数据集分为训练集、验证集和测试集，比例为70%、20%和10%。\n- **应用领域**：海事安全、渔业管理、海洋污染监测、国防、海事安全和更多实际应用。\n- 挑战：\n  - 目标物体（船舶）相对较小。\n  - 目标物体具有不同的旋转角度，增加了检测难度。\n\n这些数据集在对象检测研究中具有重要意义，因为它们涵盖了不同大小、形状和密度的对象，能够全面评估YOLO算法在不同场景下的性能。\n\n### 模型\n\n#### 比较分析：Ultralytics vs 原始YOLO模型\n\n![](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202134407205.png)\n\n在Traffic Signs数据集上，对Ultralytics提供的版本和原始模型进行比较分析，使用相同的超参数设置如表V所示。目标是为了强调突出Ultralytics提供的版本和原始模型之间的差异。由于Ultraytics缺乏对YOLO v4、YOLO v6、YOLO v7的支持，因此本文将这几个YOLO版本排除在外了。\n\n##### Ultralytics支持库中的模型和任务\n\n![image-20241202134825220](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202134825220.png)\n\n根据表I，Ultralytics库为研究人员和程序员提供了各种YOLO模型，用于推理、验证、训练和导出。我们注意到Ultralytics不支持YOLOv1、YOLOv2、YOLOv4和YOLOv7。对于YOLOv6，库只支持配置文件.yaml，而不支持预训练的.pt模型。\n\n##### Ultralytics和原始模型的性能比较\n\n通过对Ultralytics模型及其原始版本在交通标志数据集上的比较分析，我们观察到Ultralytics版本和原始版本之间存在显著差异。例如，Ultralytics版本的YOLOv5n（nano）和YOLOv3表现优越，突显了Ultralytics所做的增强和优化。相反，原始版本的YOLOv9c（compact）略微优于其Ultralytics版本，可能是由于Ultralytics对该较新模型的优化不足。这些观察结果表明，Ultralytics模型经过了大量修改，直接比较原始版本和Ultralytics版本是不公平和不准确的。因此，本文将专注于Ultralytics支持的版本，以确保基准测试的一致性和公平性。\n\n###### YOLOv3u\n\n![image-20241202135426435](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202135426435.png)\n\nYOLOv3基于其前身，旨在提高定位错误和检测效率，特别是对于较小的物体。它使用Darknet-53框架，该框架有53个卷积层，速度是ResNet-152的两倍。YOLOv3还结合了特征金字塔网络（FPN）的元素，如残差块、跳跃连接和上采样，以增强跨不同尺度的物体检测能力。该算法生成三个不同尺度的特征图，以32、16和8的因子对输入进行下采样，并使用三尺度检测机制来检测大、中、小尺寸物体，分别使用不同的特征图。尽管有所改进，YOLOv3在检测中等和大型物体时仍面临挑战，因此Ultralytics发布了YOLOv3u。YOLOv3u是YOLOv3的改进版本，使用无锚点检测方法，并提高了YOLOv3的准确性和速度，特别是对于中等和大型物体。\n\n###### YOLOv5u\n\n![image-20241202135925381](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202135925381.png)\n\nYOLOv5由Glenn Jocher提出，从Darknet框架过渡到PyTorch，保留了YOLOv4的许多改进，并使用CSPDarknet作为其骨干。CSPDarknet是原始Darknet架构的修改版本，通过将特征图分成单独的路径来实现更高效的特征提取和减少计算成本。YOLOv5采用步幅卷积层，旨在减少内存和计算成本。此外，该版本采用空间金字塔池化快速（SPPF）模块，通过在不同尺度上池化特征并提供多尺度表示来工作。YOLOv5实现了多种增强，如马赛克、复制粘贴、随机仿射、MixUp、HSV增强和随机水平翻转。Ultralytics通过YOLOv5u积极改进该模型，采用无锚点检测方法，并在复杂物体的不同尺寸上实现了更好的整体性能。\n\n###### YOLOv8\n\n![image-20241202140006851](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140006851.png)\n\nUltralytics引入了YOLOv8，这是YOLO系列的重大进化，包括五个缩放版本。除了物体检测外，YOLOv8还提供了图像分类、姿态估计、实例分割和定向物体检测（OOB）等多种应用。关键特性包括类似于YOLOv5的主干，调整后的CSPLayer（现称为C2f模块），结合了高级特征和上下文信息以提高检测精度。YOLOv8还引入了一个语义分割模型YOLOv8-Seg，结合了CSPDarknet53特征提取器和C2F模块，在物体检测和语义分割基准测试中取得了最先进的结果，同时保持了高效率。\n\n###### YOLOv9\n\n![image-20241202140048800](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140048800.png)\n\nYOLOv9由Chien-Yao Wang、I-Hau Yeh和Hong-Yuan Mark Liao开发，使用信息瓶颈原理和可逆函数来在网络深度中保留关键数据，确保可靠的梯度生成并提高模型收敛性和性能。可逆函数可以在不丢失信息的情况下反转，这是YOLOv9架构的另一个基石。这种属性允许网络保持完整的信息流，使模型参数的更新更加准确。此外，YOLOv9提供了五个缩放版本，重点是轻量级模型，这些模型通常欠参数化，并且在前向过程中容易丢失重要信息。可编程梯度信息（PGI）是YOLOv9引入的一项重大进步。PGI是一种在训练期间动态调整梯度信息的方法，通过选择性关注最具信息量的梯度来优化学习效率。通过这种方式，PGI有助于保留可能在轻量级模型中丢失的关键信息。此外，YOLOv9还包括GELAN（梯度增强轻量级架构网络），这是一种新的架构改进，旨在通过优化网络内的计算路径来提高参数利用和计算效率。\n\n###### YOLOv10\n\n![image-20241202140137372](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140137372.png)\n\nYOLOv10由清华大学的研究人员开发，基于先前模型的优势进行了关键创新。该架构具有增强的CSP-Net（跨阶段部分网络）主干，以提高梯度流动和减少计算冗余。网络结构分为三部分：主干、颈部和检测头。颈部包括PAN（路径聚合网络）层，用于有效的多尺度特征融合。PAN旨在通过聚合不同层的特征来增强信息流，使网络能够更好地捕捉和结合不同尺度的细节，这对于检测不同大小的物体至关重要。此外，该版本还提供五个缩放版本，从纳米到超大。对于推理，One-to-One Head为每个物体生成单个最佳预测，消除了对非极大值抑制（NMS）的需求。通过移除对NMS的需求，YOLOv10减少了延迟并提高了后处理速度。此外，YOLOv10还包括NMS-Free Training，使用一致的双重分配来减少推理延迟，并优化了从效率和准确性角度的各种组件，包括轻量级分类头、空间-通道解耦下采样和排名引导块设计。此外，该模型还包括大核卷积和部分自注意力模块，以在不显著增加计算成本的情况下提高性能。\n\n###### YOLO11\n\n![image-20241202140334746](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140334746.png)\n\nYOLO11是Ultralytics推出的最新创新，基于其前身的发展，特别是YOLOv8。这一迭代提供了从纳米到超大的五种缩放模型，适用于各种应用。与YOLOv8一样，YOLO11包括物体检测、实例分割、图像分类、姿态估计和定向物体检测（OBB）等多种应用。关键改进包括引入C2PSA（跨阶段部分自注意力）模块，结合了跨阶段部分网络和自注意力机制的优势。这使得模型能够在多个层次上更有效地捕获上下文信息，提高物体检测精度，特别是对于小型和重叠物体。此外，在YOLO11中，C2f块被C3k2块取代，C3k2是CSP Bottleneck的自定义实现，使用两个卷积而不是YOLOv8中使用的一个大卷积。这个块使用较小的内核，在保持精度的同时提高了效率和速度。\n\n### 硬件和软件设置\n\n- 表III：实验的软件设置\n- 表IV：6个YOLO版本的不同尺寸的模型\n\n![image-20241202140352257](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140352257.png)\n\n![image-20241202140542480](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140542480.png)\n\n总结了用于评估YOLO模型的硬件和软件环境设置。\n\n1. **软件环境**：实验使用了Python 3.12、Ubuntu 22.04、CUDA 12.5、cuDNN 8.9.7、Ultralytics 8.2.55和WandB 0.17.4等软件包。\n2. **硬件环境**：实验在两块NVIDIA RTX 4090 GPU上进行，每块GPU拥有16,384个CUDA核心。\n3. **数据集处理**：针对交通标志数据集，应用了欠采样技术以确保数据集平衡，并将图像数量从4381减少到3233张。\n4. **训练验证测试分割**：非洲野生动物数据集和船只数据集分别按照70%训练、20%验证和10%测试的比例进行分割。\n5. **模型训练**：实验中训练了23个模型，涵盖了5种不同的YOLO版本，并使用了相似的超参数以确保公平比较。\n6. **模型规模**：交通标志数据集包含24个类别，平均每个类别约100张图像；非洲野生动物数据集包含4个类别，每个类别至少有376张图像；船只数据集专注于单一类别的小型物体检测。\n\n### 评估指标\n\n评估指标包括准确性、计算效率和模型大小三个方面：\n\n#### 准确性指标\n1. **Precision（精确率）**：\n   - 定义：正确预测的观察值与总预测观察值的比率。\n   - 计算公式：$$ \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} $$\n   - 其中，TP（True Positives）为真正例，FP（False Positives）为假正例。\n\n2. **Recall（召回率）**：\n   - 定义：正确预测的观察值与所有实际观察值的比率。\n   - 计算公式：$$ \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} $$\n   - 其中，FN（False Negatives）为假反例。\n\n3. **mAP50（Mean Average Precision at an IoU threshold of 0.50）**：\n   - 定义：在IoU（Intersection over Union）阈值为0.50时的平均精度均值。\n   - 计算公式：$$ \\text{mAP50} = \\frac{1}{|C|} \\sum_{c \\in C} \\text{AP}_c $$\n   - 其中，$C$ 是类别集合，$\\text{AP}_c$ 是类别 $c$ 的平均精度。\n\n4. **mAP50-95（Mean Average Precision across IoU thresholds from 0.50 to 0.95）**：\n   - 定义：在IoU阈值从0.50到0.95范围内的平均精度均值。\n   - 计算公式：$$ \\text{mAP50-95} = \\frac{1}{15} \\sum_{r=1}^{15} \\text{AP}_{0.50 + \\frac{r-1}{14} \\times 0.05} $$\n   - 其中，$r$ 表示IoU阈值的范围。\n\n#### 计算效率指标\n1. **Preprocessing Time（预处理时间）**：\n   - 定义：准备原始数据以输入模型所需的持续时间。\n\n2. **Inference Time（推理时间）**：\n   - 定义：模型处理输入数据并生成预测所需的持续时间。\n\n3. **Postprocessing Time（后处理时间）**：\n   - 定义：将模型的原始预测转换为最终可用格式所需的时间。\n\n4. **Total Time（总时间）**：\n   - 定义：预处理时间、推理时间和后处理时间的总和。\n\n5. **GFLOPs（Giga Floating-Point Operations Per Second）**：\n   - 定义：模型训练的计算能力，反映其效率。\n\n#### 模型大小指标\n1. **Size（大小）**：\n   - 定义：模型的实际磁盘大小及其参数数量。\n\n这些指标提供了对YOLO模型性能的全面概述，有助于在不同真实世界场景中选择最优的YOLO算法。\n\n# 实验结果和讨论\n\n![image-20241202142033886](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142033886.png)\n\n### 实验结果\n\n#### 交通信号数据集\n\nYOLO模型在检测交通标志方面的有效性，展示了各种精度范围。最高的mAP50-95为0.799，而最低的精度为0.64。另一方面，最高的mAP50为0.893，而最低的为0.722。mAP50和mAP50-95之间的显著差距表明，模型在处理不同大小的交通标志时，在较高阈值下遇到了困难，这反映了其检测算法中潜在的改进领域。\n\na) 准确性：如图8所示，YOLOv5ul展示了最高的准确性，实现了mAP50为0.866和mAP50-95为0.799。紧随其后的是YOLO11m，其mAP50-95为0.795，YOLO11l的mAP50-95为0.794。相比之下，YOLOv10n展示了最低的精度，其mAP50为0.722，mAP50-95为0.64，紧随其后的是YOLOv5un，其mAP50-95为0.665，如数据点在图8中所证明的。\n\n![image-20241202142326776](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142326776.png)\n\nb) 精度和召回率：图9阐明了考虑模型大小的情况下精度和召回率之间的权衡。像YOLO11m、YOLO10l、YOLOv9m、YOLOv5ux和YOLO111这样的模型展示了高精度和召回率，特别是YOLO11m实现了0.898的精度和0.826的召回率，同时模型大小为67.9Mb，而YOLOv10l实现了0.873的精度和0.807的召回率，但模型大小显著更大（126.8 Mb）。相比之下，较小的模型如YOLOv10n（精度0.722，召回率0.602）、YOLOv8n（精度0.749，召回率0.688）和YOLO11n（精度0.768，召回率0.695）在两个指标上都表现不佳。这突显了较大模型在交通标志数据集上的优越性能。此外，YOLOv5um的高精度（0.849）和低召回率（0.701）表明了对假阴性的倾向，而YOLOv3u的高召回率（0.849）和低精度（0.75）则表明了对假阳性的倾向。\n\n![image-20241202142423060](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142423060.png)\n\nc) 计算效率：在计算效率方面，YOLOv10n是最有效的，每张图片的处理时间为2ms，GFLOPs计数为8.3，如图10和11所示。YOLO11n紧随其后，处理时间为2.2ms，GFLOPs计数为6.4，而YOLOv3u-tiny的处理时间为2.4ms，GFLOPs计数为19，与其他快速模型相比，这使得它在计算上相对低效。然而，数据显示YOLOv9e、YOLOv9m、YOLOv9c和YOLOv9s是效率最低的，推理时间分别为16.1ms、12.1ms、11.6ms和11.1ms，GFLOPs计数分别为189.4、76.7、102.6和26.8。这些发现描绘了一个明显的权衡，即在精度和计算效率之间。\n\nd) 整体性能：在评估整体性能时，包括准确性、大小和模型效率，YOLO11m作为一个一致的表现最佳的模型脱颖而出。它实现了mAP50-95为0.795，推理时间为2.4ms，模型大小为38.8Mb，GFLOPs计数为67.9，如图8、10、11和表VI中详细说明的。紧随其后的是YOLO111（mAP50-95为0.794，推理时间为4.6ms，大小为49Mb，GFLOPs计数为86.8）和YOLOv10m（mAP50-95为0.781，推理时间为2.4ms，大小为32.1Mb，63.8 GFLOPs计数）。这些结果突显了这些模型在检测各种大小的交通标志方面的稳健性，同时保持了较短的推理时间和较小的模型大小。值得注意的是，YOLO11和YOLOv10家族在准确性和计算效率方面显著优于其他YOLO家族，因为它们的模型在这些数据集上一致超越了其他家族的对应物。\n\n![image-20241202142515870](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142515870.png)\n\n#### 非洲野生动物数据集\n\n![image-20241202142815914](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142815914.png)\n\n表 VII 展示了 YOLO 模型在非洲野生动物数据集上的性能。该数据集包含大型物体尺寸，重点关注 YOLO 模型预测大型物体的能力以及由于数据集大小而导致过拟合的风险。模型在各个方面的准确性都表现出色，最高性能的模型 mAP50-95 范围从 0.832 到 0.725。这个相对较短的范围反映了模型在检测和分类大型野生动物物体时保持高准确性的有效性。\n\na) 准确性：如图 12 所示，YOLOv9s 展现了出色的性能，具有高达 0.832 的 mAP50-95 和 0.956 的 mAP50，展示了其在各种 IoU 阈值下的稳健准确性。YOLOv9c 和 YOLOv9t 紧随其后，mAP50 分数分别为 0.96 和 0.948，召回率分别为 0.896。值得注意的是，YOLOv8n 实现了 mAP50-95 得分分别为 0.83 和 0.825。这些结果突出了 YOLOv9 系列从少量图像样本中有效学习模式的能力，使其特别适合于较小型的数据集。相比之下，YOLOv5un、YOLOv10n 和 YOLOv3u-tiny 显示出较低的 mAP50-95 得分，分别为 0.791、0.786 和 0.725，表明它们在准确性方面的局限性。较大的模型如 YOLO11x、YOLOv5ux、YOLOv5ul 和 YOLOv10l 的表现不佳，可以归因于过拟合，特别是考虑到数据集规模较小。\n\n![image-20241202142853898](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142853898.png)\n\nb) 精度和召回率：图 13 表明 YOLO8l 和 YOLO111 实现了最高的精度和召回率，精度值分别为 0.942 和 0.937，召回率分别为 0.898 和 0.896。值得注意的是，YOLOv8n 实现了 0.932 的精度和 0.908 的召回率。总体而言，YOLOv8l 和 YOLO111 在精度和召回率方面表现最佳，YOLOv8n 的表现也相当出色。然而，YOLOv11 模型倾向于产生误报，这反映在其较低的精度和较高的召回率上。与此同时，YOLOv10 在精度和召回率方面的表现均不佳，尽管它是 YOLO 系列中最新的模型之一。\n\n![image-20241202142924537](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142924537.png)\n\nc) 计算效率：如图 14 和 15 所示，YOLOv10n、YOLOv8n 和 YOLOv3u-tiny 是最快的模型，处理时间分别为 2ms 和 1.8ms，GFLOPs 计数分别为 8.2 和 19.1。前两个模型具有相同的处理速度和 GFLOPs 计数，如表 VII 中所示。相比之下，YOLOv9e 展现了最慢的处理时间，为 11.2ms，GFLOPs 计数为 189.3，其次是 YOLOv5ux，处理时间为 7.5ms，GFLOPs 计数为 246.2 GFLOPs 计数。这些结果表明，较大的模型通常需要更多的处理时间和硬件资源，强调了模型大小和处理效率之间的权衡。\n\n![image-20241202143004149](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143004149.png)\n\nd) 整体性能：表 VII 和图 13、14 和 15 中的结果表明，YOLOv9t 和 YOLOv9s 在各个指标上持续表现出色，提供高准确性，同时保持较小的模型大小、低 GFLOPs 和短的处理时间，展示了 YOLOv9 较小型模型的稳健性及其在小数据集上的有效性。相比之下，YOLO5ux 和 YOLO11x 尽管具有较大的尺寸和较长的推理时间，但准确性表现不佳，可能是由于过拟合所致。大多数大型模型在这个数据集上的表现都不尽如人意，YOLOv10x 是一个例外，得益于现代架构防止过拟合，表现优异。\n\n![image-20241202143030167](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143030167.png)\n\n#### 船只和船舶数据集：\n\n![image-20241202143313627](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143313627.png)\n\n表 VIII 展示了 YOLO 模型在船只和船舶数据集上的性能，这是一个包含微小物体且旋转变化多样的大型数据集。总体而言，模型在检测船只和船舶方面表现出中等效果，mAP50-95 的范围从 0.273 到 0.327。这一表现表明 YOLO 算法在准确检测较小物体方面可能面临挑战，数据集中物体尺寸和旋转的多样性为测试模型能力提供了全面的测试。\n\na) 准确性：图 16 中 mAP50-95 和 mAP50 之间的差异凸显了 YOLO 模型在检测小物体时面临的挑战，尤其是在更高的 IoU 阈值下。此外，YOLO 模型在检测不同旋转的物体时也遇到困难。在各个模型中，YOLO11x 实现了最高的准确性，mAP50 为 0.529，mAP50-95 为 0.327，紧随其后的是 YOLO111、YOLO11m 和 YOLO11s，它们记录的 mAP50 值分别为 0.529、0.528 和 0.53，mAP50-95 值分别为 0.327、0.325 和 0.325。这些结果突出了 YOLO11 系列在检测小型和微小物体方面的稳健性。相比之下，YOLOv3u-tiny、YOLOv8n、YOLOv3u 和 YOLOv5n 展示了最低的准确性，mAP50 分数分别为 0.489、0.515、0.519 和 0.514，mAP50-95 分数分别为 0.273、0.297、0.298 和 0.298。这表明 YOLOv3u 的过时架构以及由于数据集规模较大而导致的小型模型的潜在欠拟合。\n\n![image-20241202143334789](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143334789.png)\n\nb) 精度和召回率：图 17 表明 YOLOv5ux 的表现优于其他模型，实现了 0.668 的精度和 0.555 的召回率。它紧随其后的是 YOLOv9m（精度为 0.668，召回率为 0.551）和 YOLOv8m（精度为 0.669，召回率为 0.525），两者在尺寸上显著较小（YOLOv9m 为 40.98 Mb，YOLOv8m 为 52.12 Mb）。相比之下，YOLO11n 和 YOLOv10s 表现较差，精度分别为 0.574 和 0.586，召回率分别为 0.51 和 0.511，这可能是由于欠拟合问题。总体而言，YOLO11 模型倾向于产生误报，这反映在其较低的精度和较高的召回率上。与此同时，YOLOv10 在精度和召回率方面的表现均不佳，尽管它是 YOLO 系列中最新的模型之一。\n\n![image-20241202143403226](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143403226.png)\n\nc) 计算效率：如图 18 和 19 所示，YOLOv3u-tiny 实现了最快的处理时间，为 2 毫秒，紧随其后的是 YOLOv8n 和 YOLOv5un，两者均记录了 2.3 毫秒。YOLOv10 和 YOLO11 模型也在速度上表现出色，YOLOv10n 和 YOLO11n 分别实现了 2.4 毫秒和 2.5 毫秒的快速推理时间，以及 8.2 和 6.3 的 GFLOPs 计数。相比之下，YOLOv9e 展现了最慢的速度，推理时间为 7.6 毫秒，GFLOPs 计数为 189.3，突显了 YOLOv9 系列在准确性和效率之间的权衡。\n\n![image-20241202143422503](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143422503.png)\n\nd) 整体性能：表 VIII 和图 16、17 和 18 中的结果表明，YOLO11s 和 YOLOv10s 在准确性方面表现优异，同时保持了紧凑的尺寸、低 GFLOPs 和快速的处理时间。相比之下，YOLOv3u、YOLOv8x 和 YOLOv8l 未能达到预期，尽管它们的尺寸较大且处理时间较长。这些发现突出了 YOLO11 系列的稳健性和可靠性，特别是在提高 YOLO 系列检测小型和微小物体的性能方面，同时确保高效处理。此外，结果还揭示了 YOLOv9 模型在面对大型数据集和小物体时的表现不佳，尽管它们具有现代架构。\n\n![image-20241202143442543](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143442543.png)\n\n### 讨论\n\n![image-20241202143815028](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143815028.png)\n\n基于三个数据集上模型的性能，我们按准确性、速度、GFLOps 计数和大小对它们进行了排名，如表 IX 所示，以便进行全面评估。对于准确性，由于 mAP50-95 指标能够评估模型在一系列 IoU 阈值下的表现，因此我们采用了该指标。对于速度，模型根据总处理时间进行排序，总处理时间包括预处理、推理和后处理持续时间。排名范围从第 1 名（表示最高性能）到第 28 名（表示最低性能），表中的相应排名已加粗显示。\n\n表 IX 的分析得出了几个关键观察结果：\n\n1) 准确性：YOLO11m 一致地成为顶级表现者，经常位居前列，紧随其后的是 YOLOv10x、YOLO111、YOLOv9m 和 YOLO11x。这突显了 YOLO11 系列在各种 IoU 阈值和物体大小下的稳健性能，这可以归因于它们使用 C2PSA 来保留上下文信息，从而提高了收敛性和整体性能。此外，大核卷积和部分自注意力模块的实施有助于提高算法的性能。\n\n相比之下，YOLOv3u-tiny 展现了最低的准确性，特别是在非洲野生动物和船只及船舶数据集上，YOLOv5un 和 YOLOv8n 的表现稍好但仍不理想。这表明 YOLO11 模型目前是要求高准确性的应用中最可靠的。\n\n紧随 YOLO11 系列之后，YOLOv9 模型在检测各种大小和不同 IoU 阈值的物体方面表现出色。然而，它们可能在检测小物体时遇到困难，这在船只和船舶数据集上可见。相比之下，YOLOv10 系列尽管推出较晚，但在交通标志和非洲动物数据集上的准确性相对较低，导致平均准确性下降了 2.075%，这可以归因于它们采用一对一头部方法而不是非极大值抑制（NMS）来定义边界框。这种策略在捕捉物体时可能会遇到困难，特别是在处理重叠物品时，因为它依赖于每个物体的单个预测。这一限制有助于解释第二个数据集中观察到的相对较差的结果。\n\nYOLOv3u 的过时架构也导致了其性能不佳，平均准确性比 YOLO11 模型低 6.5%。这种下降可以追溯到其对 2018 年首次引入的较旧 Darknet-53 框架的依赖，该框架可能无法充分应对当代检测挑战。\n\n2) 计算效率：YOLOv10n 在速度和 GFLOPs 计数方面始终表现优异，在所有三个数据集上均名列前茅，在速度方面排名第 1，在 GFLOPs 计数方面排名第 5。YOLOv3u-tiny、YOLOv10s 和 YOLO11n 也展示了显著的计算效率。\n\nYOLOv9e 展现了最慢的推理时间和非常高的 GFLOPs 计数，突显了准确性与效率之间的权衡。YOLO11 的速度提升可归因于它们使用的 C3k2 块，使其适用于需要快速处理的场景，超过了 YOLOv10 和 YOLOv9 模型，分别在速度上平均快了 %1.41 和 %31。\n\n虽然 YOLOv9 模型在准确性方面表现出色，但它们的推理时间却是最慢的，使它们不太适合对时间敏感的应用。相比之下，YOLOv10 模型虽然略慢于 YOLO11 变体，但仍提供了效率与速度之间的值得称赞的平衡。它们的表现非常适合时间敏感的场景，提供快速处理而不显著牺牲准确性，使它们成为实时应用的可行选择。\n\n3) 模型大小：YOLOv9t 是最小的模型，在所有三个数据集上均排名第一，其次是 YOLO11n 和 YOLOv10n。这种模型大小的效率突显了较新 YOLO 版本，特别是 YOLOv10，在高效参数利用方面的进步，实施了空间-通道解耦下采样。\n\nYOLOv3u 是最大的模型，突显了与其更现代的对应物相比，它的效率低下。\n\n4) 整体性能：考虑到准确性、速度、大小和 GFLOPs，YOLO11m、YOLOv11n、YOLO11s 和 YOLOv10s 成为最一致的表现者。它们实现了高准确性、低处理时间和功率以及高效的磁盘使用，使其适用于广泛的应用，其中速度和准确性都至关重要。\n\n相反，YOLOv9e、YOLOv5ux 和 YOLOv3u 在所有指标上的表现都较差，计算效率低下且相对于其大小表现不佳。YOLO11 模型显示出最佳的整体性能，可能是由于最近的增强功能，如 C3k2 块和 C2PSA 模块。紧随其后的是 YOLOv10 模型，尽管在准确性方面略有逊色，但由于其一对一头部用于预测的实施，在效率方面表现出色。虽然 YOLOv9 在计算效率方面表现不佳，但它在准确性方面仍然具有竞争力，这要归功于其 PGI 集成。这使 YOLOv9 成为优先考虑精度而非速度的应用的可行选择。\n\n此外，YOLOv8 和 YOLOv5u 展示了竞争性结果，超过了 YOLOv3u 的准确性，这可能是由于 YOLOv3u 的较旧架构。然而，它们的准确性仍然显著低于较新的模型，如 YOLOv9、YOLOv10 和 YOLO11。虽然 YOLOv8 和 YOLOv5u 的处理时间比 YOLOv9 快，但它们的整体表现仍然不如较新的模型。\n\n5) 物体大小和旋转检测：YOLO 算法在检测大中型物体方面效果很好，如非洲野生动物和交通标志数据集所证明的那样，准确性很高。然而，它在检测小物体方面存在困难，可能是由于将图像划分为网格，使得识别小而分辨率低的物体变得具有挑战性。此外，YOLO 在处理不同旋转的物体时也面临挑战，因为无法包围旋转物体，导致整体结果不佳。\n\n为了处理旋转物体，可以实现像 YOLO11 OBB[26] 和 YOLOv8 OBB[25]（定向边界框）这样的模型。保持与标准 YOLOv8 和 YOLO11 相同的基础架构，YOLOv8 OBB 和 YOLO11 OBB 用预测旋转矩形四个角点的头部替换了标准边界框预测头部，允许更准确的定位和表示任意方向的物体。\n\n6) YOLO11 对 YOLOv8 的崛起：尽管 YOLOv8[25] 因其在姿态估计、实例分割和定向物体检测（OBB）任务中的多功能性而成为算法的首选，但 YOLO11[26] 已经成为一个更高效和准确的替代品。通过处理相同任务的同时提供改进的上下文理解和更好的架构模块，YOLO11 设定了新的性能标准，在各种应用中的速度和准确性方面都超过了 YOLOv8。\n\n7) 数据集大小：数据集的大小显著影响 YOLO 模型的性能。例如，大型模型在小型非洲野生动物数据集上的表现不如在交通标志和船只及船舶数据集上的表现，因为它们更容易过拟合。相反，像 YOLOv9t 和 YOLOv9s 这样的小模型在非洲野生动物数据集上的表现显著更好，展示了小规模模型在处理有限数据集时的有效性。\n\n8) 训练数据集的影响：如表 VI、VII 和 VIII 所示，YOLO 模型的性能受到所使用的训练数据集的影响。不同的数据集产生不同的结果和顶尖表现者，表明数据集复杂性影响算法性能。这突显了在基准测试期间使用多样化数据集以获得每个模型优缺点全面结果的重要性。\n\n这次讨论强调了在选择 YOLO 模型进行特定应用时，需要平衡考虑准确性、速度和模型大小。YOLO11 模型在各个指标上的一致表现使它们非常适合于需要准确性和速度的多功能场景。同时，YOLOv10 模型可以在保持更快处理时间和更小模型大小的同时，类似地执行。此外，YOLOv9 可以在准确性方面提供可比的结果，但牺牲了速度，使其适用于优先考虑精度而非快速处理的应用。\n\n# 结论\n\n这项基准研究全面评估了各种 YOLO 算法的性能。它是首个对 YOLO11 及其前辈进行全面比较的研究，评估了它们在三个多样化数据集上的表现：交通标志、非洲野生动物和船只及船舶。这些数据集经过精心挑选，包含了广泛的物体属性，包括不同的物体大小、宽高比和物体密度。我们通过检查精度、召回率、平均精度均值（mAP）、处理时间、GFLOPs 计数和模型大小等一系列指标，展示了每个 YOLO 版本和家族的优势和劣势。我们的研究解决了以下关键研究问题：\n\n● 哪个 YOLO 算法在一系列综合指标上展示了卓越的性能？\n\n● 不同的 YOLO 版本在具有不同物体特征（如大小、宽高比和密度）的数据集上的表现如何？\n\n● 每个 YOLO 版本的具体优势和局限性是什么，这些见解如何指导选择最适合各种应用的算法？\n\n特别是，YOLO11 系列作为最一致的表现在各个指标上脱颖而出，YOLO11m 在准确性、效率、模型大小之间取得了最佳平衡。虽然 YOLOv10 的准确性略低于 YOLO11，但它在速度和效率方面表现出色，使其成为需要效率和快速处理的应用的强有力选择。此外，YOLOv9 总体上也表现良好，特别是在较小的数据集上表现尤为突出。这些发现为工业界和学术界提供了宝贵的见解，指导选择最适合的 YOLO 算法，并为未来的发展和改进提供信息。虽然评估的算法展示了有希望的性能，但仍有一些改进的空间。未来的研究可以专注于优化 YOLOv10，以提高其准确性，同时保持其速度和效率优势。此外，架构设计的持续进步可能为更突破性的 YOLO 算法铺平道路。我们未来的工作包括深入研究这些算法中确定的差距，并提出改进措施，以展示它们对整体效率的潜在影响。\n\n# 其它问题\n\n- **在交通标志数据集上，YOLOv5ul和YOLOv10n的性能差异是什么？原因是什么？**\n\n在交通标志数据集上，YOLOv5ul的mAP50-95达到了0.799，而YOLOv10n的mAP50-95仅为0.64，相差显著。YOLOv5ul在精度和召回率上都表现更好，具体来说，YOLOv5ul的Precision为0.866，Recall为0.849，而YOLOv10n的Precision为0.722，Recall为0.602。这种差异的原因可能包括：\n\n1. **模型架构改进**：YOLOv5ul采用了更先进的CSPDarknet53作为主干网络，并引入了Spatial Pyramid Pooling Fast（SPPF）模块，这些改进提高了模型的特征提取能力和多尺度适应性。\n2. **数据增强**：YOLOv5ul使用了多种数据增强技术，如Mosaic、Copy-Paste、Random Affine等，这些技术有助于提高模型的泛化能力和鲁棒性。\n3. **优化策略**：YOLOv5ul在训练过程中使用了更有效的优化策略，如AdamW优化器和学习率调度，这些策略有助于模型更快地收敛和提高性能。\n\n- **在船舶与船只数据集上，YOLOv11x为什么表现最好？与其他模型相比有哪些优势？**\n\n​\t在船舶与船只数据集上，YOLOv11x的mAP50-95达到了0.327，表现最好。与其他模型相比，YOLOv11x有以下优势：\n\n1. **小对象检测**：YOLOv11x特别适用于检测小对象，能够在复杂的图像环境中准确识别和定位小尺寸的船只。\n2. **架构改进**：YOLOv11x引入了C3k2块和C2PSA（Cross-Stage Partial with Self-Attention）模块，这些改进提高了模型的空间注意力和特征提取能力，特别是在处理重叠和小的对象时表现优异。\n3. **计算效率**：尽管YOLOv11x在精度上有所提升，但其推理时间仍然保持在2.4ms左右，保持了较高的计算效率，适合实时应用。\n\n- **在非洲野生动物数据集上，YOLOv9s的表现优于其他模型的原因是什么？**\n\n  在非洲野生动物数据集上，YOLOv9s的mAP50-95达到了0.832，表现优于其他模型。YOLOv9s之所以表现优异，主要原因包括：\n\n  1. **小型数据集适应性**：YOLOv9s在小型数据集上表现出色，能够有效学习对象的模式。其小型模型（如YOLOv9t）在非洲野生动物数据集上表现尤为突出，mAP50-95为0.832，mAP50为0.956。\n  2. **特征提取能力**：YOLOv9s采用了CSPNet（Cross-Stage Partial Network），这种结构通过分割特征图来提高特征提取效率，减少了计算复杂度。\n  3. **正则化技术**：YOLOv9s使用了GelAN（Gradient Enhanced Lightweight Architecture Network），这种技术通过优化网络内的计算路径，提高了参数利用率和计算效率。\n\n[Evaluating the Evolution of YOLO (You Only Look Once) Models: A Comprehensive Benchmark Study of YOLO11 and Its Predecessors](https://arxiv.org/html/2411.00201v1)\n\n![二维码](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","source":"_posts/人工智能/computer-vision/CV008-评估 YOLO （You Only Look Once） 模型的演变：YOLO11 及其前身的全面基准研究.md","raw":"---\ntitle: 'YOLO模型的全面综述'\ndate: 2024-12-7 18:30:00\ncategories:\n  - [人工智能,computer-vision]\ntags:\n  - 人工智能\n  - yolo\n  - 目标检测\n---\n\n\n\n# 摘要\n\n本研究对YOLO （You Only Look Once） 的各个版本进行了全面的基准测试分析，从 YOLOv3 到最新的算法。它代表了首次全面评估 YOLO11 性能的研究，YOLO11 是 YOLO 系列的最新成员。它评估了它们在三个不同数据集上的性能：交通标志（具有不同的对象大小）、非洲野生动物（具有不同的纵横比，每个图像至少有一个对象实例）以及船舶和船只（具有单个类别的小型对象），确保在具有不同挑战的数据集之间进行全面评估。为了确保稳健的评估，我们采用了一套全面的指标，包括精度、召回率、平均精度均值 （mAP）、处理时间、GFLOP 计数和模型大小。我们的分析强调了每个 YOLO 版本的独特优势和局限性。例如：YOLOv9 表现出很高的准确性，但在检测小物体和效率方面表现不佳，而 YOLOv10 表现出相对较低的准确性，因为架构选择会影响其在重叠物体检测方面的性能，但在速度和效率方面表现出色。此外，YOLO11 系列在准确性、速度、计算效率和模型大小方面始终表现出卓越的性能。YOLO11m 在准确性和效率之间取得了显著的平衡，在交通标志、非洲野生动物和船舶数据集上的mAP50-95得分分别为0.795、0.81和0.325，同时保持了2.4毫秒的平均推理时间，模型大小为38.8Mb，平均约为67.6 GFLOPs。这些结果为工业界和学术界提供了重要的见解，有助于为各种应用选择最合适的 YOLO 算法，并指导未来的增强功能。\n\n# 引言\n\n![Refer to caption](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/x1.png)\n\n​                             Figure 1:Evolution of YOLO Algorithms throughout the years.\n\n主要介绍了物体检测在计算机视觉系统中的重要性及其应用，并概述了YOLO（You Only Look Once）算法的发展历程和优势。\n\n- **物体检测的重要性**：物体检测是计算机视觉系统的关键组成部分，广泛应用于自动驾驶、机器人技术、库存管理、视频监控和体育分析等领域。\n- **传统方法的局限性**：传统的物体检测方法如Viola-Jones算法和DPM模型在鲁棒性和泛化能力上存在局限，而深度学习方法已成为主流。\n- **一阶段与两阶段方法**：一阶段方法如RetinaNet和SSD在速度和准确性之间取得平衡，而两阶段方法如R-CNN提供高精度但计算密集。\n- **YOLO算法的崛起**：YOLO算法以其鲁棒性和效率脱颖而出，自2015年首次提出以来，通过不断改进框架和设计，成为实时物体检测的领先算法。\n- **YOLO算法的演进**：YOLO算法的演进包括从YOLOv1到YOLOv11的多个版本，每个版本都引入了新的架构和技术来提高性能。\n- **Ultralytics的角色**：Ultralytics在YOLO算法的发展中扮演了重要角色，通过维护和改进模型，使其更易于访问和定制。\n- **研究目的**：本研究旨在对YOLO算法的演变进行全面比较分析，特别是对最新成员YOLO11进行首次全面评估，并探讨其在不同应用场景中的优势和局限性。\n- **研究方法**：研究使用了三个多样化的数据集，并采用了一致的超参数设置，以确保公平和无偏见的比较。\n- **研究贡献**：研究的贡献在于提供了对YOLO11及其前身的全面比较，深入分析了这些算法的结构演变，并扩展了性能评估指标，为选择最适合特定用例的YOLO算法提供了宝贵的见解。\n\n# 相关工作\n\n主要回顾了YOLO算法的演变、不同版本的架构、以及与其他计算机视觉算法的基准测试。以下是对该章节的详细总结分析：\n\n### YOLO算法的演变：\n\n- 论文[14]分析了包括YOLOv8在内的七种语义分割和检测算法，用于云层分割的遥感图像。\n- 论文[22]回顾了YOLO从版本1到版本8的演变，但没有考虑YOLOv9、YOLOv10和YOLO11。\n- 论文[12]详细分析了从YOLOv1到YOLOv4的单阶段物体检测器，并比较了两阶段和单阶段物体检测器。\n- 论文[53]探讨了YOLO从版本1到10的演变，强调了其在汽车安全、医疗保健等领域的应用。\n- 论文[61]讨论了YOLO算法的发展直到第四版，并提出了新的方法和挑战。\n- 论文[27]分析了YOLO算法的发展和性能，比较了从第8版到第8版的YOLO版本。\n\n### YOLO算法的应用：\n\n- YOLO算法在自动驾驶、医疗保健、工业制造、监控和农业等领域有广泛应用。\n- YOLOv8提供了多种应用，包括实例分割、姿态估计和定向物体检测（OOB）。\n\n### YOLO算法的基准测试：\n\n- 论文[14]进行了云层分割的基准测试，评估了不同算法的架构方法和性能。\n- 论文[22]提出了结合联邦学习以提高隐私、适应性和协作训练的通用性。\n- 论文[12]提供了单阶段和两阶段物体检测器的比较。\n- 论文[53]探讨了YOLO算法对未来AI驱动应用的潜在整合。\n- 论文[61]强调了YOLO算法在物体检测方面的挑战和需要进一步研究的地方。\n\n### YOLO算法的挑战：\n\n- YOLO算法在处理小物体和不同旋转角度的物体时面临挑战。\n- YOLOv9、YOLOv10和YOLO11的最新模型在准确性和效率方面表现出色，但在某些情况下仍需改进。\n\n### YOLO算法的改进：\n\n- YOLOv9引入了信息瓶颈原理和可逆函数来保留数据，提高了模型的收敛性和性能。\n- YOLOv10通过增强的CSP-Net主干和PAN层提高了梯度流动和减少了计算冗余。\n- YOLO11引入了C2PSA模块，结合了跨阶段部分网络和自注意力机制，提高了检测精度。\n\n### YOLO算法的未来方向：\n\n- 未来的研究可以专注于优化YOLOv10以提高其准确性，同时保持其速度和效率优势。\n- 继续改进架构设计可能会带来更先进的YOLO算法。\n\n### 研究贡献：\n\n- 本研究首次全面比较了YOLO11及其前身，并在三个多样化的数据集上评估了它们的性能。\n- 研究结果为工业界和学术界提供了选择最适合特定应用场景的YOLO算法的宝贵见解。\n\n通过这些分析，可以看出YOLO算法在不断演进和改进，以适应不同的应用需求和挑战。\n\n# Benchmark 设置\n\n### 数据集\n\n介绍了三种数据集，分别是Traffic Signs Dataset、Africa Wildlife Dataset和Ships/Vessels Dataset。以下是对这三种数据集的详细介绍：\n\n#### 1. Traffic Signs Dataset（交通标志数据集）\n\n- **来源**：由Radu Oprea在Kaggle上提供的开源数据集。\n- 特点：\n  - 包含约55个类别的交通标志图像。\n  - 训练集包含3253张图像，验证集包含1128张图像。\n  - 图像大小不一，初始尺寸为640x640像素。\n  - 为了平衡不同类别的数量，采用了欠采样技术。\n- **应用领域**：自动驾驶、交通管理、道路安全和智能交通系统。\n- 挑战：\n  - 目标物体大小变化较大。\n  - 不同类别之间的模式相似，增加了检测难度。\n\n#### 2. Africa Wildlife Dataset（非洲野生动物数据集）\n\n- **来源**：由Bianca Ferreira在Kaggle上设计的开源数据集。\n- 特点：\n  - 包含四种常见的非洲动物类别：水牛、大象、犀牛和斑马。\n  - 每个类别至少有376张图像，通过Google图像搜索收集并手动标注为YOLO格式。\n  - 数据集分为训练集、验证集和测试集，比例为70%、20%和10%。\n- **应用领域**：野生动物保护、反偷猎、生物多样性监测和生态研究。\n- 挑战：\n  - 目标物体的宽高比变化较大。\n  - 每张图像至少包含一种指定的动物类别，可能还包含其他类别的多个实例或发生情况。\n  - 目标物体重叠，增加了检测难度。\n\n#### 3. Ships/Vessels Dataset（船舶数据集）\n\n- **来源**：由Siddharth Sah从多个Roboflow数据集中收集并整理的开源数据集。\n- 特点：\n  - 包含约13.5k张图像，专门用于船舶检测。\n  - 每张图像都使用YOLO格式手动标注了边界框。\n  - 数据集分为训练集、验证集和测试集，比例为70%、20%和10%。\n- **应用领域**：海事安全、渔业管理、海洋污染监测、国防、海事安全和更多实际应用。\n- 挑战：\n  - 目标物体（船舶）相对较小。\n  - 目标物体具有不同的旋转角度，增加了检测难度。\n\n这些数据集在对象检测研究中具有重要意义，因为它们涵盖了不同大小、形状和密度的对象，能够全面评估YOLO算法在不同场景下的性能。\n\n### 模型\n\n#### 比较分析：Ultralytics vs 原始YOLO模型\n\n![](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202134407205.png)\n\n在Traffic Signs数据集上，对Ultralytics提供的版本和原始模型进行比较分析，使用相同的超参数设置如表V所示。目标是为了强调突出Ultralytics提供的版本和原始模型之间的差异。由于Ultraytics缺乏对YOLO v4、YOLO v6、YOLO v7的支持，因此本文将这几个YOLO版本排除在外了。\n\n##### Ultralytics支持库中的模型和任务\n\n![image-20241202134825220](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202134825220.png)\n\n根据表I，Ultralytics库为研究人员和程序员提供了各种YOLO模型，用于推理、验证、训练和导出。我们注意到Ultralytics不支持YOLOv1、YOLOv2、YOLOv4和YOLOv7。对于YOLOv6，库只支持配置文件.yaml，而不支持预训练的.pt模型。\n\n##### Ultralytics和原始模型的性能比较\n\n通过对Ultralytics模型及其原始版本在交通标志数据集上的比较分析，我们观察到Ultralytics版本和原始版本之间存在显著差异。例如，Ultralytics版本的YOLOv5n（nano）和YOLOv3表现优越，突显了Ultralytics所做的增强和优化。相反，原始版本的YOLOv9c（compact）略微优于其Ultralytics版本，可能是由于Ultralytics对该较新模型的优化不足。这些观察结果表明，Ultralytics模型经过了大量修改，直接比较原始版本和Ultralytics版本是不公平和不准确的。因此，本文将专注于Ultralytics支持的版本，以确保基准测试的一致性和公平性。\n\n###### YOLOv3u\n\n![image-20241202135426435](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202135426435.png)\n\nYOLOv3基于其前身，旨在提高定位错误和检测效率，特别是对于较小的物体。它使用Darknet-53框架，该框架有53个卷积层，速度是ResNet-152的两倍。YOLOv3还结合了特征金字塔网络（FPN）的元素，如残差块、跳跃连接和上采样，以增强跨不同尺度的物体检测能力。该算法生成三个不同尺度的特征图，以32、16和8的因子对输入进行下采样，并使用三尺度检测机制来检测大、中、小尺寸物体，分别使用不同的特征图。尽管有所改进，YOLOv3在检测中等和大型物体时仍面临挑战，因此Ultralytics发布了YOLOv3u。YOLOv3u是YOLOv3的改进版本，使用无锚点检测方法，并提高了YOLOv3的准确性和速度，特别是对于中等和大型物体。\n\n###### YOLOv5u\n\n![image-20241202135925381](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202135925381.png)\n\nYOLOv5由Glenn Jocher提出，从Darknet框架过渡到PyTorch，保留了YOLOv4的许多改进，并使用CSPDarknet作为其骨干。CSPDarknet是原始Darknet架构的修改版本，通过将特征图分成单独的路径来实现更高效的特征提取和减少计算成本。YOLOv5采用步幅卷积层，旨在减少内存和计算成本。此外，该版本采用空间金字塔池化快速（SPPF）模块，通过在不同尺度上池化特征并提供多尺度表示来工作。YOLOv5实现了多种增强，如马赛克、复制粘贴、随机仿射、MixUp、HSV增强和随机水平翻转。Ultralytics通过YOLOv5u积极改进该模型，采用无锚点检测方法，并在复杂物体的不同尺寸上实现了更好的整体性能。\n\n###### YOLOv8\n\n![image-20241202140006851](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140006851.png)\n\nUltralytics引入了YOLOv8，这是YOLO系列的重大进化，包括五个缩放版本。除了物体检测外，YOLOv8还提供了图像分类、姿态估计、实例分割和定向物体检测（OOB）等多种应用。关键特性包括类似于YOLOv5的主干，调整后的CSPLayer（现称为C2f模块），结合了高级特征和上下文信息以提高检测精度。YOLOv8还引入了一个语义分割模型YOLOv8-Seg，结合了CSPDarknet53特征提取器和C2F模块，在物体检测和语义分割基准测试中取得了最先进的结果，同时保持了高效率。\n\n###### YOLOv9\n\n![image-20241202140048800](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140048800.png)\n\nYOLOv9由Chien-Yao Wang、I-Hau Yeh和Hong-Yuan Mark Liao开发，使用信息瓶颈原理和可逆函数来在网络深度中保留关键数据，确保可靠的梯度生成并提高模型收敛性和性能。可逆函数可以在不丢失信息的情况下反转，这是YOLOv9架构的另一个基石。这种属性允许网络保持完整的信息流，使模型参数的更新更加准确。此外，YOLOv9提供了五个缩放版本，重点是轻量级模型，这些模型通常欠参数化，并且在前向过程中容易丢失重要信息。可编程梯度信息（PGI）是YOLOv9引入的一项重大进步。PGI是一种在训练期间动态调整梯度信息的方法，通过选择性关注最具信息量的梯度来优化学习效率。通过这种方式，PGI有助于保留可能在轻量级模型中丢失的关键信息。此外，YOLOv9还包括GELAN（梯度增强轻量级架构网络），这是一种新的架构改进，旨在通过优化网络内的计算路径来提高参数利用和计算效率。\n\n###### YOLOv10\n\n![image-20241202140137372](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140137372.png)\n\nYOLOv10由清华大学的研究人员开发，基于先前模型的优势进行了关键创新。该架构具有增强的CSP-Net（跨阶段部分网络）主干，以提高梯度流动和减少计算冗余。网络结构分为三部分：主干、颈部和检测头。颈部包括PAN（路径聚合网络）层，用于有效的多尺度特征融合。PAN旨在通过聚合不同层的特征来增强信息流，使网络能够更好地捕捉和结合不同尺度的细节，这对于检测不同大小的物体至关重要。此外，该版本还提供五个缩放版本，从纳米到超大。对于推理，One-to-One Head为每个物体生成单个最佳预测，消除了对非极大值抑制（NMS）的需求。通过移除对NMS的需求，YOLOv10减少了延迟并提高了后处理速度。此外，YOLOv10还包括NMS-Free Training，使用一致的双重分配来减少推理延迟，并优化了从效率和准确性角度的各种组件，包括轻量级分类头、空间-通道解耦下采样和排名引导块设计。此外，该模型还包括大核卷积和部分自注意力模块，以在不显著增加计算成本的情况下提高性能。\n\n###### YOLO11\n\n![image-20241202140334746](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140334746.png)\n\nYOLO11是Ultralytics推出的最新创新，基于其前身的发展，特别是YOLOv8。这一迭代提供了从纳米到超大的五种缩放模型，适用于各种应用。与YOLOv8一样，YOLO11包括物体检测、实例分割、图像分类、姿态估计和定向物体检测（OBB）等多种应用。关键改进包括引入C2PSA（跨阶段部分自注意力）模块，结合了跨阶段部分网络和自注意力机制的优势。这使得模型能够在多个层次上更有效地捕获上下文信息，提高物体检测精度，特别是对于小型和重叠物体。此外，在YOLO11中，C2f块被C3k2块取代，C3k2是CSP Bottleneck的自定义实现，使用两个卷积而不是YOLOv8中使用的一个大卷积。这个块使用较小的内核，在保持精度的同时提高了效率和速度。\n\n### 硬件和软件设置\n\n- 表III：实验的软件设置\n- 表IV：6个YOLO版本的不同尺寸的模型\n\n![image-20241202140352257](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140352257.png)\n\n![image-20241202140542480](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140542480.png)\n\n总结了用于评估YOLO模型的硬件和软件环境设置。\n\n1. **软件环境**：实验使用了Python 3.12、Ubuntu 22.04、CUDA 12.5、cuDNN 8.9.7、Ultralytics 8.2.55和WandB 0.17.4等软件包。\n2. **硬件环境**：实验在两块NVIDIA RTX 4090 GPU上进行，每块GPU拥有16,384个CUDA核心。\n3. **数据集处理**：针对交通标志数据集，应用了欠采样技术以确保数据集平衡，并将图像数量从4381减少到3233张。\n4. **训练验证测试分割**：非洲野生动物数据集和船只数据集分别按照70%训练、20%验证和10%测试的比例进行分割。\n5. **模型训练**：实验中训练了23个模型，涵盖了5种不同的YOLO版本，并使用了相似的超参数以确保公平比较。\n6. **模型规模**：交通标志数据集包含24个类别，平均每个类别约100张图像；非洲野生动物数据集包含4个类别，每个类别至少有376张图像；船只数据集专注于单一类别的小型物体检测。\n\n### 评估指标\n\n评估指标包括准确性、计算效率和模型大小三个方面：\n\n#### 准确性指标\n1. **Precision（精确率）**：\n   - 定义：正确预测的观察值与总预测观察值的比率。\n   - 计算公式：$$ \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} $$\n   - 其中，TP（True Positives）为真正例，FP（False Positives）为假正例。\n\n2. **Recall（召回率）**：\n   - 定义：正确预测的观察值与所有实际观察值的比率。\n   - 计算公式：$$ \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} $$\n   - 其中，FN（False Negatives）为假反例。\n\n3. **mAP50（Mean Average Precision at an IoU threshold of 0.50）**：\n   - 定义：在IoU（Intersection over Union）阈值为0.50时的平均精度均值。\n   - 计算公式：$$ \\text{mAP50} = \\frac{1}{|C|} \\sum_{c \\in C} \\text{AP}_c $$\n   - 其中，$C$ 是类别集合，$\\text{AP}_c$ 是类别 $c$ 的平均精度。\n\n4. **mAP50-95（Mean Average Precision across IoU thresholds from 0.50 to 0.95）**：\n   - 定义：在IoU阈值从0.50到0.95范围内的平均精度均值。\n   - 计算公式：$$ \\text{mAP50-95} = \\frac{1}{15} \\sum_{r=1}^{15} \\text{AP}_{0.50 + \\frac{r-1}{14} \\times 0.05} $$\n   - 其中，$r$ 表示IoU阈值的范围。\n\n#### 计算效率指标\n1. **Preprocessing Time（预处理时间）**：\n   - 定义：准备原始数据以输入模型所需的持续时间。\n\n2. **Inference Time（推理时间）**：\n   - 定义：模型处理输入数据并生成预测所需的持续时间。\n\n3. **Postprocessing Time（后处理时间）**：\n   - 定义：将模型的原始预测转换为最终可用格式所需的时间。\n\n4. **Total Time（总时间）**：\n   - 定义：预处理时间、推理时间和后处理时间的总和。\n\n5. **GFLOPs（Giga Floating-Point Operations Per Second）**：\n   - 定义：模型训练的计算能力，反映其效率。\n\n#### 模型大小指标\n1. **Size（大小）**：\n   - 定义：模型的实际磁盘大小及其参数数量。\n\n这些指标提供了对YOLO模型性能的全面概述，有助于在不同真实世界场景中选择最优的YOLO算法。\n\n# 实验结果和讨论\n\n![image-20241202142033886](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142033886.png)\n\n### 实验结果\n\n#### 交通信号数据集\n\nYOLO模型在检测交通标志方面的有效性，展示了各种精度范围。最高的mAP50-95为0.799，而最低的精度为0.64。另一方面，最高的mAP50为0.893，而最低的为0.722。mAP50和mAP50-95之间的显著差距表明，模型在处理不同大小的交通标志时，在较高阈值下遇到了困难，这反映了其检测算法中潜在的改进领域。\n\na) 准确性：如图8所示，YOLOv5ul展示了最高的准确性，实现了mAP50为0.866和mAP50-95为0.799。紧随其后的是YOLO11m，其mAP50-95为0.795，YOLO11l的mAP50-95为0.794。相比之下，YOLOv10n展示了最低的精度，其mAP50为0.722，mAP50-95为0.64，紧随其后的是YOLOv5un，其mAP50-95为0.665，如数据点在图8中所证明的。\n\n![image-20241202142326776](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142326776.png)\n\nb) 精度和召回率：图9阐明了考虑模型大小的情况下精度和召回率之间的权衡。像YOLO11m、YOLO10l、YOLOv9m、YOLOv5ux和YOLO111这样的模型展示了高精度和召回率，特别是YOLO11m实现了0.898的精度和0.826的召回率，同时模型大小为67.9Mb，而YOLOv10l实现了0.873的精度和0.807的召回率，但模型大小显著更大（126.8 Mb）。相比之下，较小的模型如YOLOv10n（精度0.722，召回率0.602）、YOLOv8n（精度0.749，召回率0.688）和YOLO11n（精度0.768，召回率0.695）在两个指标上都表现不佳。这突显了较大模型在交通标志数据集上的优越性能。此外，YOLOv5um的高精度（0.849）和低召回率（0.701）表明了对假阴性的倾向，而YOLOv3u的高召回率（0.849）和低精度（0.75）则表明了对假阳性的倾向。\n\n![image-20241202142423060](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142423060.png)\n\nc) 计算效率：在计算效率方面，YOLOv10n是最有效的，每张图片的处理时间为2ms，GFLOPs计数为8.3，如图10和11所示。YOLO11n紧随其后，处理时间为2.2ms，GFLOPs计数为6.4，而YOLOv3u-tiny的处理时间为2.4ms，GFLOPs计数为19，与其他快速模型相比，这使得它在计算上相对低效。然而，数据显示YOLOv9e、YOLOv9m、YOLOv9c和YOLOv9s是效率最低的，推理时间分别为16.1ms、12.1ms、11.6ms和11.1ms，GFLOPs计数分别为189.4、76.7、102.6和26.8。这些发现描绘了一个明显的权衡，即在精度和计算效率之间。\n\nd) 整体性能：在评估整体性能时，包括准确性、大小和模型效率，YOLO11m作为一个一致的表现最佳的模型脱颖而出。它实现了mAP50-95为0.795，推理时间为2.4ms，模型大小为38.8Mb，GFLOPs计数为67.9，如图8、10、11和表VI中详细说明的。紧随其后的是YOLO111（mAP50-95为0.794，推理时间为4.6ms，大小为49Mb，GFLOPs计数为86.8）和YOLOv10m（mAP50-95为0.781，推理时间为2.4ms，大小为32.1Mb，63.8 GFLOPs计数）。这些结果突显了这些模型在检测各种大小的交通标志方面的稳健性，同时保持了较短的推理时间和较小的模型大小。值得注意的是，YOLO11和YOLOv10家族在准确性和计算效率方面显著优于其他YOLO家族，因为它们的模型在这些数据集上一致超越了其他家族的对应物。\n\n![image-20241202142515870](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142515870.png)\n\n#### 非洲野生动物数据集\n\n![image-20241202142815914](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142815914.png)\n\n表 VII 展示了 YOLO 模型在非洲野生动物数据集上的性能。该数据集包含大型物体尺寸，重点关注 YOLO 模型预测大型物体的能力以及由于数据集大小而导致过拟合的风险。模型在各个方面的准确性都表现出色，最高性能的模型 mAP50-95 范围从 0.832 到 0.725。这个相对较短的范围反映了模型在检测和分类大型野生动物物体时保持高准确性的有效性。\n\na) 准确性：如图 12 所示，YOLOv9s 展现了出色的性能，具有高达 0.832 的 mAP50-95 和 0.956 的 mAP50，展示了其在各种 IoU 阈值下的稳健准确性。YOLOv9c 和 YOLOv9t 紧随其后，mAP50 分数分别为 0.96 和 0.948，召回率分别为 0.896。值得注意的是，YOLOv8n 实现了 mAP50-95 得分分别为 0.83 和 0.825。这些结果突出了 YOLOv9 系列从少量图像样本中有效学习模式的能力，使其特别适合于较小型的数据集。相比之下，YOLOv5un、YOLOv10n 和 YOLOv3u-tiny 显示出较低的 mAP50-95 得分，分别为 0.791、0.786 和 0.725，表明它们在准确性方面的局限性。较大的模型如 YOLO11x、YOLOv5ux、YOLOv5ul 和 YOLOv10l 的表现不佳，可以归因于过拟合，特别是考虑到数据集规模较小。\n\n![image-20241202142853898](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142853898.png)\n\nb) 精度和召回率：图 13 表明 YOLO8l 和 YOLO111 实现了最高的精度和召回率，精度值分别为 0.942 和 0.937，召回率分别为 0.898 和 0.896。值得注意的是，YOLOv8n 实现了 0.932 的精度和 0.908 的召回率。总体而言，YOLOv8l 和 YOLO111 在精度和召回率方面表现最佳，YOLOv8n 的表现也相当出色。然而，YOLOv11 模型倾向于产生误报，这反映在其较低的精度和较高的召回率上。与此同时，YOLOv10 在精度和召回率方面的表现均不佳，尽管它是 YOLO 系列中最新的模型之一。\n\n![image-20241202142924537](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142924537.png)\n\nc) 计算效率：如图 14 和 15 所示，YOLOv10n、YOLOv8n 和 YOLOv3u-tiny 是最快的模型，处理时间分别为 2ms 和 1.8ms，GFLOPs 计数分别为 8.2 和 19.1。前两个模型具有相同的处理速度和 GFLOPs 计数，如表 VII 中所示。相比之下，YOLOv9e 展现了最慢的处理时间，为 11.2ms，GFLOPs 计数为 189.3，其次是 YOLOv5ux，处理时间为 7.5ms，GFLOPs 计数为 246.2 GFLOPs 计数。这些结果表明，较大的模型通常需要更多的处理时间和硬件资源，强调了模型大小和处理效率之间的权衡。\n\n![image-20241202143004149](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143004149.png)\n\nd) 整体性能：表 VII 和图 13、14 和 15 中的结果表明，YOLOv9t 和 YOLOv9s 在各个指标上持续表现出色，提供高准确性，同时保持较小的模型大小、低 GFLOPs 和短的处理时间，展示了 YOLOv9 较小型模型的稳健性及其在小数据集上的有效性。相比之下，YOLO5ux 和 YOLO11x 尽管具有较大的尺寸和较长的推理时间，但准确性表现不佳，可能是由于过拟合所致。大多数大型模型在这个数据集上的表现都不尽如人意，YOLOv10x 是一个例外，得益于现代架构防止过拟合，表现优异。\n\n![image-20241202143030167](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143030167.png)\n\n#### 船只和船舶数据集：\n\n![image-20241202143313627](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143313627.png)\n\n表 VIII 展示了 YOLO 模型在船只和船舶数据集上的性能，这是一个包含微小物体且旋转变化多样的大型数据集。总体而言，模型在检测船只和船舶方面表现出中等效果，mAP50-95 的范围从 0.273 到 0.327。这一表现表明 YOLO 算法在准确检测较小物体方面可能面临挑战，数据集中物体尺寸和旋转的多样性为测试模型能力提供了全面的测试。\n\na) 准确性：图 16 中 mAP50-95 和 mAP50 之间的差异凸显了 YOLO 模型在检测小物体时面临的挑战，尤其是在更高的 IoU 阈值下。此外，YOLO 模型在检测不同旋转的物体时也遇到困难。在各个模型中，YOLO11x 实现了最高的准确性，mAP50 为 0.529，mAP50-95 为 0.327，紧随其后的是 YOLO111、YOLO11m 和 YOLO11s，它们记录的 mAP50 值分别为 0.529、0.528 和 0.53，mAP50-95 值分别为 0.327、0.325 和 0.325。这些结果突出了 YOLO11 系列在检测小型和微小物体方面的稳健性。相比之下，YOLOv3u-tiny、YOLOv8n、YOLOv3u 和 YOLOv5n 展示了最低的准确性，mAP50 分数分别为 0.489、0.515、0.519 和 0.514，mAP50-95 分数分别为 0.273、0.297、0.298 和 0.298。这表明 YOLOv3u 的过时架构以及由于数据集规模较大而导致的小型模型的潜在欠拟合。\n\n![image-20241202143334789](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143334789.png)\n\nb) 精度和召回率：图 17 表明 YOLOv5ux 的表现优于其他模型，实现了 0.668 的精度和 0.555 的召回率。它紧随其后的是 YOLOv9m（精度为 0.668，召回率为 0.551）和 YOLOv8m（精度为 0.669，召回率为 0.525），两者在尺寸上显著较小（YOLOv9m 为 40.98 Mb，YOLOv8m 为 52.12 Mb）。相比之下，YOLO11n 和 YOLOv10s 表现较差，精度分别为 0.574 和 0.586，召回率分别为 0.51 和 0.511，这可能是由于欠拟合问题。总体而言，YOLO11 模型倾向于产生误报，这反映在其较低的精度和较高的召回率上。与此同时，YOLOv10 在精度和召回率方面的表现均不佳，尽管它是 YOLO 系列中最新的模型之一。\n\n![image-20241202143403226](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143403226.png)\n\nc) 计算效率：如图 18 和 19 所示，YOLOv3u-tiny 实现了最快的处理时间，为 2 毫秒，紧随其后的是 YOLOv8n 和 YOLOv5un，两者均记录了 2.3 毫秒。YOLOv10 和 YOLO11 模型也在速度上表现出色，YOLOv10n 和 YOLO11n 分别实现了 2.4 毫秒和 2.5 毫秒的快速推理时间，以及 8.2 和 6.3 的 GFLOPs 计数。相比之下，YOLOv9e 展现了最慢的速度，推理时间为 7.6 毫秒，GFLOPs 计数为 189.3，突显了 YOLOv9 系列在准确性和效率之间的权衡。\n\n![image-20241202143422503](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143422503.png)\n\nd) 整体性能：表 VIII 和图 16、17 和 18 中的结果表明，YOLO11s 和 YOLOv10s 在准确性方面表现优异，同时保持了紧凑的尺寸、低 GFLOPs 和快速的处理时间。相比之下，YOLOv3u、YOLOv8x 和 YOLOv8l 未能达到预期，尽管它们的尺寸较大且处理时间较长。这些发现突出了 YOLO11 系列的稳健性和可靠性，特别是在提高 YOLO 系列检测小型和微小物体的性能方面，同时确保高效处理。此外，结果还揭示了 YOLOv9 模型在面对大型数据集和小物体时的表现不佳，尽管它们具有现代架构。\n\n![image-20241202143442543](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143442543.png)\n\n### 讨论\n\n![image-20241202143815028](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143815028.png)\n\n基于三个数据集上模型的性能，我们按准确性、速度、GFLOps 计数和大小对它们进行了排名，如表 IX 所示，以便进行全面评估。对于准确性，由于 mAP50-95 指标能够评估模型在一系列 IoU 阈值下的表现，因此我们采用了该指标。对于速度，模型根据总处理时间进行排序，总处理时间包括预处理、推理和后处理持续时间。排名范围从第 1 名（表示最高性能）到第 28 名（表示最低性能），表中的相应排名已加粗显示。\n\n表 IX 的分析得出了几个关键观察结果：\n\n1) 准确性：YOLO11m 一致地成为顶级表现者，经常位居前列，紧随其后的是 YOLOv10x、YOLO111、YOLOv9m 和 YOLO11x。这突显了 YOLO11 系列在各种 IoU 阈值和物体大小下的稳健性能，这可以归因于它们使用 C2PSA 来保留上下文信息，从而提高了收敛性和整体性能。此外，大核卷积和部分自注意力模块的实施有助于提高算法的性能。\n\n相比之下，YOLOv3u-tiny 展现了最低的准确性，特别是在非洲野生动物和船只及船舶数据集上，YOLOv5un 和 YOLOv8n 的表现稍好但仍不理想。这表明 YOLO11 模型目前是要求高准确性的应用中最可靠的。\n\n紧随 YOLO11 系列之后，YOLOv9 模型在检测各种大小和不同 IoU 阈值的物体方面表现出色。然而，它们可能在检测小物体时遇到困难，这在船只和船舶数据集上可见。相比之下，YOLOv10 系列尽管推出较晚，但在交通标志和非洲动物数据集上的准确性相对较低，导致平均准确性下降了 2.075%，这可以归因于它们采用一对一头部方法而不是非极大值抑制（NMS）来定义边界框。这种策略在捕捉物体时可能会遇到困难，特别是在处理重叠物品时，因为它依赖于每个物体的单个预测。这一限制有助于解释第二个数据集中观察到的相对较差的结果。\n\nYOLOv3u 的过时架构也导致了其性能不佳，平均准确性比 YOLO11 模型低 6.5%。这种下降可以追溯到其对 2018 年首次引入的较旧 Darknet-53 框架的依赖，该框架可能无法充分应对当代检测挑战。\n\n2) 计算效率：YOLOv10n 在速度和 GFLOPs 计数方面始终表现优异，在所有三个数据集上均名列前茅，在速度方面排名第 1，在 GFLOPs 计数方面排名第 5。YOLOv3u-tiny、YOLOv10s 和 YOLO11n 也展示了显著的计算效率。\n\nYOLOv9e 展现了最慢的推理时间和非常高的 GFLOPs 计数，突显了准确性与效率之间的权衡。YOLO11 的速度提升可归因于它们使用的 C3k2 块，使其适用于需要快速处理的场景，超过了 YOLOv10 和 YOLOv9 模型，分别在速度上平均快了 %1.41 和 %31。\n\n虽然 YOLOv9 模型在准确性方面表现出色，但它们的推理时间却是最慢的，使它们不太适合对时间敏感的应用。相比之下，YOLOv10 模型虽然略慢于 YOLO11 变体，但仍提供了效率与速度之间的值得称赞的平衡。它们的表现非常适合时间敏感的场景，提供快速处理而不显著牺牲准确性，使它们成为实时应用的可行选择。\n\n3) 模型大小：YOLOv9t 是最小的模型，在所有三个数据集上均排名第一，其次是 YOLO11n 和 YOLOv10n。这种模型大小的效率突显了较新 YOLO 版本，特别是 YOLOv10，在高效参数利用方面的进步，实施了空间-通道解耦下采样。\n\nYOLOv3u 是最大的模型，突显了与其更现代的对应物相比，它的效率低下。\n\n4) 整体性能：考虑到准确性、速度、大小和 GFLOPs，YOLO11m、YOLOv11n、YOLO11s 和 YOLOv10s 成为最一致的表现者。它们实现了高准确性、低处理时间和功率以及高效的磁盘使用，使其适用于广泛的应用，其中速度和准确性都至关重要。\n\n相反，YOLOv9e、YOLOv5ux 和 YOLOv3u 在所有指标上的表现都较差，计算效率低下且相对于其大小表现不佳。YOLO11 模型显示出最佳的整体性能，可能是由于最近的增强功能，如 C3k2 块和 C2PSA 模块。紧随其后的是 YOLOv10 模型，尽管在准确性方面略有逊色，但由于其一对一头部用于预测的实施，在效率方面表现出色。虽然 YOLOv9 在计算效率方面表现不佳，但它在准确性方面仍然具有竞争力，这要归功于其 PGI 集成。这使 YOLOv9 成为优先考虑精度而非速度的应用的可行选择。\n\n此外，YOLOv8 和 YOLOv5u 展示了竞争性结果，超过了 YOLOv3u 的准确性，这可能是由于 YOLOv3u 的较旧架构。然而，它们的准确性仍然显著低于较新的模型，如 YOLOv9、YOLOv10 和 YOLO11。虽然 YOLOv8 和 YOLOv5u 的处理时间比 YOLOv9 快，但它们的整体表现仍然不如较新的模型。\n\n5) 物体大小和旋转检测：YOLO 算法在检测大中型物体方面效果很好，如非洲野生动物和交通标志数据集所证明的那样，准确性很高。然而，它在检测小物体方面存在困难，可能是由于将图像划分为网格，使得识别小而分辨率低的物体变得具有挑战性。此外，YOLO 在处理不同旋转的物体时也面临挑战，因为无法包围旋转物体，导致整体结果不佳。\n\n为了处理旋转物体，可以实现像 YOLO11 OBB[26] 和 YOLOv8 OBB[25]（定向边界框）这样的模型。保持与标准 YOLOv8 和 YOLO11 相同的基础架构，YOLOv8 OBB 和 YOLO11 OBB 用预测旋转矩形四个角点的头部替换了标准边界框预测头部，允许更准确的定位和表示任意方向的物体。\n\n6) YOLO11 对 YOLOv8 的崛起：尽管 YOLOv8[25] 因其在姿态估计、实例分割和定向物体检测（OBB）任务中的多功能性而成为算法的首选，但 YOLO11[26] 已经成为一个更高效和准确的替代品。通过处理相同任务的同时提供改进的上下文理解和更好的架构模块，YOLO11 设定了新的性能标准，在各种应用中的速度和准确性方面都超过了 YOLOv8。\n\n7) 数据集大小：数据集的大小显著影响 YOLO 模型的性能。例如，大型模型在小型非洲野生动物数据集上的表现不如在交通标志和船只及船舶数据集上的表现，因为它们更容易过拟合。相反，像 YOLOv9t 和 YOLOv9s 这样的小模型在非洲野生动物数据集上的表现显著更好，展示了小规模模型在处理有限数据集时的有效性。\n\n8) 训练数据集的影响：如表 VI、VII 和 VIII 所示，YOLO 模型的性能受到所使用的训练数据集的影响。不同的数据集产生不同的结果和顶尖表现者，表明数据集复杂性影响算法性能。这突显了在基准测试期间使用多样化数据集以获得每个模型优缺点全面结果的重要性。\n\n这次讨论强调了在选择 YOLO 模型进行特定应用时，需要平衡考虑准确性、速度和模型大小。YOLO11 模型在各个指标上的一致表现使它们非常适合于需要准确性和速度的多功能场景。同时，YOLOv10 模型可以在保持更快处理时间和更小模型大小的同时，类似地执行。此外，YOLOv9 可以在准确性方面提供可比的结果，但牺牲了速度，使其适用于优先考虑精度而非快速处理的应用。\n\n# 结论\n\n这项基准研究全面评估了各种 YOLO 算法的性能。它是首个对 YOLO11 及其前辈进行全面比较的研究，评估了它们在三个多样化数据集上的表现：交通标志、非洲野生动物和船只及船舶。这些数据集经过精心挑选，包含了广泛的物体属性，包括不同的物体大小、宽高比和物体密度。我们通过检查精度、召回率、平均精度均值（mAP）、处理时间、GFLOPs 计数和模型大小等一系列指标，展示了每个 YOLO 版本和家族的优势和劣势。我们的研究解决了以下关键研究问题：\n\n● 哪个 YOLO 算法在一系列综合指标上展示了卓越的性能？\n\n● 不同的 YOLO 版本在具有不同物体特征（如大小、宽高比和密度）的数据集上的表现如何？\n\n● 每个 YOLO 版本的具体优势和局限性是什么，这些见解如何指导选择最适合各种应用的算法？\n\n特别是，YOLO11 系列作为最一致的表现在各个指标上脱颖而出，YOLO11m 在准确性、效率、模型大小之间取得了最佳平衡。虽然 YOLOv10 的准确性略低于 YOLO11，但它在速度和效率方面表现出色，使其成为需要效率和快速处理的应用的强有力选择。此外，YOLOv9 总体上也表现良好，特别是在较小的数据集上表现尤为突出。这些发现为工业界和学术界提供了宝贵的见解，指导选择最适合的 YOLO 算法，并为未来的发展和改进提供信息。虽然评估的算法展示了有希望的性能，但仍有一些改进的空间。未来的研究可以专注于优化 YOLOv10，以提高其准确性，同时保持其速度和效率优势。此外，架构设计的持续进步可能为更突破性的 YOLO 算法铺平道路。我们未来的工作包括深入研究这些算法中确定的差距，并提出改进措施，以展示它们对整体效率的潜在影响。\n\n# 其它问题\n\n- **在交通标志数据集上，YOLOv5ul和YOLOv10n的性能差异是什么？原因是什么？**\n\n在交通标志数据集上，YOLOv5ul的mAP50-95达到了0.799，而YOLOv10n的mAP50-95仅为0.64，相差显著。YOLOv5ul在精度和召回率上都表现更好，具体来说，YOLOv5ul的Precision为0.866，Recall为0.849，而YOLOv10n的Precision为0.722，Recall为0.602。这种差异的原因可能包括：\n\n1. **模型架构改进**：YOLOv5ul采用了更先进的CSPDarknet53作为主干网络，并引入了Spatial Pyramid Pooling Fast（SPPF）模块，这些改进提高了模型的特征提取能力和多尺度适应性。\n2. **数据增强**：YOLOv5ul使用了多种数据增强技术，如Mosaic、Copy-Paste、Random Affine等，这些技术有助于提高模型的泛化能力和鲁棒性。\n3. **优化策略**：YOLOv5ul在训练过程中使用了更有效的优化策略，如AdamW优化器和学习率调度，这些策略有助于模型更快地收敛和提高性能。\n\n- **在船舶与船只数据集上，YOLOv11x为什么表现最好？与其他模型相比有哪些优势？**\n\n​\t在船舶与船只数据集上，YOLOv11x的mAP50-95达到了0.327，表现最好。与其他模型相比，YOLOv11x有以下优势：\n\n1. **小对象检测**：YOLOv11x特别适用于检测小对象，能够在复杂的图像环境中准确识别和定位小尺寸的船只。\n2. **架构改进**：YOLOv11x引入了C3k2块和C2PSA（Cross-Stage Partial with Self-Attention）模块，这些改进提高了模型的空间注意力和特征提取能力，特别是在处理重叠和小的对象时表现优异。\n3. **计算效率**：尽管YOLOv11x在精度上有所提升，但其推理时间仍然保持在2.4ms左右，保持了较高的计算效率，适合实时应用。\n\n- **在非洲野生动物数据集上，YOLOv9s的表现优于其他模型的原因是什么？**\n\n  在非洲野生动物数据集上，YOLOv9s的mAP50-95达到了0.832，表现优于其他模型。YOLOv9s之所以表现优异，主要原因包括：\n\n  1. **小型数据集适应性**：YOLOv9s在小型数据集上表现出色，能够有效学习对象的模式。其小型模型（如YOLOv9t）在非洲野生动物数据集上表现尤为突出，mAP50-95为0.832，mAP50为0.956。\n  2. **特征提取能力**：YOLOv9s采用了CSPNet（Cross-Stage Partial Network），这种结构通过分割特征图来提高特征提取效率，减少了计算复杂度。\n  3. **正则化技术**：YOLOv9s使用了GelAN（Gradient Enhanced Lightweight Architecture Network），这种技术通过优化网络内的计算路径，提高了参数利用率和计算效率。\n\n[Evaluating the Evolution of YOLO (You Only Look Once) Models: A Comprehensive Benchmark Study of YOLO11 and Its Predecessors](https://arxiv.org/html/2411.00201v1)\n\n![二维码](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","slug":"人工智能/computer-vision/CV008-评估 YOLO （You Only Look Once） 模型的演变：YOLO11 及其前身的全面基准研究","published":1,"updated":"2024-12-26T04:24:42.759Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3d0006hghie6d8fkog","content":"<h1 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h1><p>本研究对YOLO （You Only Look Once） 的各个版本进行了全面的基准测试分析，从 YOLOv3 到最新的算法。它代表了首次全面评估 YOLO11 性能的研究，YOLO11 是 YOLO 系列的最新成员。它评估了它们在三个不同数据集上的性能：交通标志（具有不同的对象大小）、非洲野生动物（具有不同的纵横比，每个图像至少有一个对象实例）以及船舶和船只（具有单个类别的小型对象），确保在具有不同挑战的数据集之间进行全面评估。为了确保稳健的评估，我们采用了一套全面的指标，包括精度、召回率、平均精度均值 （mAP）、处理时间、GFLOP 计数和模型大小。我们的分析强调了每个 YOLO 版本的独特优势和局限性。例如：YOLOv9 表现出很高的准确性，但在检测小物体和效率方面表现不佳，而 YOLOv10 表现出相对较低的准确性，因为架构选择会影响其在重叠物体检测方面的性能，但在速度和效率方面表现出色。此外，YOLO11 系列在准确性、速度、计算效率和模型大小方面始终表现出卓越的性能。YOLO11m 在准确性和效率之间取得了显著的平衡，在交通标志、非洲野生动物和船舶数据集上的mAP50-95得分分别为0.795、0.81和0.325，同时保持了2.4毫秒的平均推理时间，模型大小为38.8Mb，平均约为67.6 GFLOPs。这些结果为工业界和学术界提供了重要的见解，有助于为各种应用选择最合适的 YOLO 算法，并指导未来的增强功能。</p>\n<h1 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h1><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/x1.png\" alt=\"Refer to caption\"></p>\n<p>​                             Figure 1:Evolution of YOLO Algorithms throughout the years.</p>\n<p>主要介绍了物体检测在计算机视觉系统中的重要性及其应用，并概述了YOLO（You Only Look Once）算法的发展历程和优势。</p>\n<ul>\n<li><strong>物体检测的重要性</strong>：物体检测是计算机视觉系统的关键组成部分，广泛应用于自动驾驶、机器人技术、库存管理、视频监控和体育分析等领域。</li>\n<li><strong>传统方法的局限性</strong>：传统的物体检测方法如Viola-Jones算法和DPM模型在鲁棒性和泛化能力上存在局限，而深度学习方法已成为主流。</li>\n<li><strong>一阶段与两阶段方法</strong>：一阶段方法如RetinaNet和SSD在速度和准确性之间取得平衡，而两阶段方法如R-CNN提供高精度但计算密集。</li>\n<li><strong>YOLO算法的崛起</strong>：YOLO算法以其鲁棒性和效率脱颖而出，自2015年首次提出以来，通过不断改进框架和设计，成为实时物体检测的领先算法。</li>\n<li><strong>YOLO算法的演进</strong>：YOLO算法的演进包括从YOLOv1到YOLOv11的多个版本，每个版本都引入了新的架构和技术来提高性能。</li>\n<li><strong>Ultralytics的角色</strong>：Ultralytics在YOLO算法的发展中扮演了重要角色，通过维护和改进模型，使其更易于访问和定制。</li>\n<li><strong>研究目的</strong>：本研究旨在对YOLO算法的演变进行全面比较分析，特别是对最新成员YOLO11进行首次全面评估，并探讨其在不同应用场景中的优势和局限性。</li>\n<li><strong>研究方法</strong>：研究使用了三个多样化的数据集，并采用了一致的超参数设置，以确保公平和无偏见的比较。</li>\n<li><strong>研究贡献</strong>：研究的贡献在于提供了对YOLO11及其前身的全面比较，深入分析了这些算法的结构演变，并扩展了性能评估指标，为选择最适合特定用例的YOLO算法提供了宝贵的见解。</li>\n</ul>\n<h1 id=\"相关工作\"><a href=\"#相关工作\" class=\"headerlink\" title=\"相关工作\"></a>相关工作</h1><p>主要回顾了YOLO算法的演变、不同版本的架构、以及与其他计算机视觉算法的基准测试。以下是对该章节的详细总结分析：</p>\n<h3 id=\"YOLO算法的演变：\"><a href=\"#YOLO算法的演变：\" class=\"headerlink\" title=\"YOLO算法的演变：\"></a>YOLO算法的演变：</h3><ul>\n<li>论文[14]分析了包括YOLOv8在内的七种语义分割和检测算法，用于云层分割的遥感图像。</li>\n<li>论文[22]回顾了YOLO从版本1到版本8的演变，但没有考虑YOLOv9、YOLOv10和YOLO11。</li>\n<li>论文[12]详细分析了从YOLOv1到YOLOv4的单阶段物体检测器，并比较了两阶段和单阶段物体检测器。</li>\n<li>论文[53]探讨了YOLO从版本1到10的演变，强调了其在汽车安全、医疗保健等领域的应用。</li>\n<li>论文[61]讨论了YOLO算法的发展直到第四版，并提出了新的方法和挑战。</li>\n<li>论文[27]分析了YOLO算法的发展和性能，比较了从第8版到第8版的YOLO版本。</li>\n</ul>\n<h3 id=\"YOLO算法的应用：\"><a href=\"#YOLO算法的应用：\" class=\"headerlink\" title=\"YOLO算法的应用：\"></a>YOLO算法的应用：</h3><ul>\n<li>YOLO算法在自动驾驶、医疗保健、工业制造、监控和农业等领域有广泛应用。</li>\n<li>YOLOv8提供了多种应用，包括实例分割、姿态估计和定向物体检测（OOB）。</li>\n</ul>\n<h3 id=\"YOLO算法的基准测试：\"><a href=\"#YOLO算法的基准测试：\" class=\"headerlink\" title=\"YOLO算法的基准测试：\"></a>YOLO算法的基准测试：</h3><ul>\n<li>论文[14]进行了云层分割的基准测试，评估了不同算法的架构方法和性能。</li>\n<li>论文[22]提出了结合联邦学习以提高隐私、适应性和协作训练的通用性。</li>\n<li>论文[12]提供了单阶段和两阶段物体检测器的比较。</li>\n<li>论文[53]探讨了YOLO算法对未来AI驱动应用的潜在整合。</li>\n<li>论文[61]强调了YOLO算法在物体检测方面的挑战和需要进一步研究的地方。</li>\n</ul>\n<h3 id=\"YOLO算法的挑战：\"><a href=\"#YOLO算法的挑战：\" class=\"headerlink\" title=\"YOLO算法的挑战：\"></a>YOLO算法的挑战：</h3><ul>\n<li>YOLO算法在处理小物体和不同旋转角度的物体时面临挑战。</li>\n<li>YOLOv9、YOLOv10和YOLO11的最新模型在准确性和效率方面表现出色，但在某些情况下仍需改进。</li>\n</ul>\n<h3 id=\"YOLO算法的改进：\"><a href=\"#YOLO算法的改进：\" class=\"headerlink\" title=\"YOLO算法的改进：\"></a>YOLO算法的改进：</h3><ul>\n<li>YOLOv9引入了信息瓶颈原理和可逆函数来保留数据，提高了模型的收敛性和性能。</li>\n<li>YOLOv10通过增强的CSP-Net主干和PAN层提高了梯度流动和减少了计算冗余。</li>\n<li>YOLO11引入了C2PSA模块，结合了跨阶段部分网络和自注意力机制，提高了检测精度。</li>\n</ul>\n<h3 id=\"YOLO算法的未来方向：\"><a href=\"#YOLO算法的未来方向：\" class=\"headerlink\" title=\"YOLO算法的未来方向：\"></a>YOLO算法的未来方向：</h3><ul>\n<li>未来的研究可以专注于优化YOLOv10以提高其准确性，同时保持其速度和效率优势。</li>\n<li>继续改进架构设计可能会带来更先进的YOLO算法。</li>\n</ul>\n<h3 id=\"研究贡献：\"><a href=\"#研究贡献：\" class=\"headerlink\" title=\"研究贡献：\"></a>研究贡献：</h3><ul>\n<li>本研究首次全面比较了YOLO11及其前身，并在三个多样化的数据集上评估了它们的性能。</li>\n<li>研究结果为工业界和学术界提供了选择最适合特定应用场景的YOLO算法的宝贵见解。</li>\n</ul>\n<p>通过这些分析，可以看出YOLO算法在不断演进和改进，以适应不同的应用需求和挑战。</p>\n<h1 id=\"Benchmark-设置\"><a href=\"#Benchmark-设置\" class=\"headerlink\" title=\"Benchmark 设置\"></a>Benchmark 设置</h1><h3 id=\"数据集\"><a href=\"#数据集\" class=\"headerlink\" title=\"数据集\"></a>数据集</h3><p>介绍了三种数据集，分别是Traffic Signs Dataset、Africa Wildlife Dataset和Ships&#x2F;Vessels Dataset。以下是对这三种数据集的详细介绍：</p>\n<h4 id=\"1-Traffic-Signs-Dataset（交通标志数据集）\"><a href=\"#1-Traffic-Signs-Dataset（交通标志数据集）\" class=\"headerlink\" title=\"1. Traffic Signs Dataset（交通标志数据集）\"></a>1. Traffic Signs Dataset（交通标志数据集）</h4><ul>\n<li><strong>来源</strong>：由Radu Oprea在Kaggle上提供的开源数据集。</li>\n<li>特点：<ul>\n<li>包含约55个类别的交通标志图像。</li>\n<li>训练集包含3253张图像，验证集包含1128张图像。</li>\n<li>图像大小不一，初始尺寸为640x640像素。</li>\n<li>为了平衡不同类别的数量，采用了欠采样技术。</li>\n</ul>\n</li>\n<li><strong>应用领域</strong>：自动驾驶、交通管理、道路安全和智能交通系统。</li>\n<li>挑战：<ul>\n<li>目标物体大小变化较大。</li>\n<li>不同类别之间的模式相似，增加了检测难度。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"2-Africa-Wildlife-Dataset（非洲野生动物数据集）\"><a href=\"#2-Africa-Wildlife-Dataset（非洲野生动物数据集）\" class=\"headerlink\" title=\"2. Africa Wildlife Dataset（非洲野生动物数据集）\"></a>2. Africa Wildlife Dataset（非洲野生动物数据集）</h4><ul>\n<li><strong>来源</strong>：由Bianca Ferreira在Kaggle上设计的开源数据集。</li>\n<li>特点：<ul>\n<li>包含四种常见的非洲动物类别：水牛、大象、犀牛和斑马。</li>\n<li>每个类别至少有376张图像，通过Google图像搜索收集并手动标注为YOLO格式。</li>\n<li>数据集分为训练集、验证集和测试集，比例为70%、20%和10%。</li>\n</ul>\n</li>\n<li><strong>应用领域</strong>：野生动物保护、反偷猎、生物多样性监测和生态研究。</li>\n<li>挑战：<ul>\n<li>目标物体的宽高比变化较大。</li>\n<li>每张图像至少包含一种指定的动物类别，可能还包含其他类别的多个实例或发生情况。</li>\n<li>目标物体重叠，增加了检测难度。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"3-Ships-Vessels-Dataset（船舶数据集）\"><a href=\"#3-Ships-Vessels-Dataset（船舶数据集）\" class=\"headerlink\" title=\"3. Ships&#x2F;Vessels Dataset（船舶数据集）\"></a>3. Ships&#x2F;Vessels Dataset（船舶数据集）</h4><ul>\n<li><strong>来源</strong>：由Siddharth Sah从多个Roboflow数据集中收集并整理的开源数据集。</li>\n<li>特点：<ul>\n<li>包含约13.5k张图像，专门用于船舶检测。</li>\n<li>每张图像都使用YOLO格式手动标注了边界框。</li>\n<li>数据集分为训练集、验证集和测试集，比例为70%、20%和10%。</li>\n</ul>\n</li>\n<li><strong>应用领域</strong>：海事安全、渔业管理、海洋污染监测、国防、海事安全和更多实际应用。</li>\n<li>挑战：<ul>\n<li>目标物体（船舶）相对较小。</li>\n<li>目标物体具有不同的旋转角度，增加了检测难度。</li>\n</ul>\n</li>\n</ul>\n<p>这些数据集在对象检测研究中具有重要意义，因为它们涵盖了不同大小、形状和密度的对象，能够全面评估YOLO算法在不同场景下的性能。</p>\n<h3 id=\"模型\"><a href=\"#模型\" class=\"headerlink\" title=\"模型\"></a>模型</h3><h4 id=\"比较分析：Ultralytics-vs-原始YOLO模型\"><a href=\"#比较分析：Ultralytics-vs-原始YOLO模型\" class=\"headerlink\" title=\"比较分析：Ultralytics vs 原始YOLO模型\"></a>比较分析：Ultralytics vs 原始YOLO模型</h4><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202134407205.png\"></p>\n<p>在Traffic Signs数据集上，对Ultralytics提供的版本和原始模型进行比较分析，使用相同的超参数设置如表V所示。目标是为了强调突出Ultralytics提供的版本和原始模型之间的差异。由于Ultraytics缺乏对YOLO v4、YOLO v6、YOLO v7的支持，因此本文将这几个YOLO版本排除在外了。</p>\n<h5 id=\"Ultralytics支持库中的模型和任务\"><a href=\"#Ultralytics支持库中的模型和任务\" class=\"headerlink\" title=\"Ultralytics支持库中的模型和任务\"></a>Ultralytics支持库中的模型和任务</h5><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202134825220.png\" alt=\"image-20241202134825220\"></p>\n<p>根据表I，Ultralytics库为研究人员和程序员提供了各种YOLO模型，用于推理、验证、训练和导出。我们注意到Ultralytics不支持YOLOv1、YOLOv2、YOLOv4和YOLOv7。对于YOLOv6，库只支持配置文件.yaml，而不支持预训练的.pt模型。</p>\n<h5 id=\"Ultralytics和原始模型的性能比较\"><a href=\"#Ultralytics和原始模型的性能比较\" class=\"headerlink\" title=\"Ultralytics和原始模型的性能比较\"></a>Ultralytics和原始模型的性能比较</h5><p>通过对Ultralytics模型及其原始版本在交通标志数据集上的比较分析，我们观察到Ultralytics版本和原始版本之间存在显著差异。例如，Ultralytics版本的YOLOv5n（nano）和YOLOv3表现优越，突显了Ultralytics所做的增强和优化。相反，原始版本的YOLOv9c（compact）略微优于其Ultralytics版本，可能是由于Ultralytics对该较新模型的优化不足。这些观察结果表明，Ultralytics模型经过了大量修改，直接比较原始版本和Ultralytics版本是不公平和不准确的。因此，本文将专注于Ultralytics支持的版本，以确保基准测试的一致性和公平性。</p>\n<h6 id=\"YOLOv3u\"><a href=\"#YOLOv3u\" class=\"headerlink\" title=\"YOLOv3u\"></a>YOLOv3u</h6><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202135426435.png\" alt=\"image-20241202135426435\"></p>\n<p>YOLOv3基于其前身，旨在提高定位错误和检测效率，特别是对于较小的物体。它使用Darknet-53框架，该框架有53个卷积层，速度是ResNet-152的两倍。YOLOv3还结合了特征金字塔网络（FPN）的元素，如残差块、跳跃连接和上采样，以增强跨不同尺度的物体检测能力。该算法生成三个不同尺度的特征图，以32、16和8的因子对输入进行下采样，并使用三尺度检测机制来检测大、中、小尺寸物体，分别使用不同的特征图。尽管有所改进，YOLOv3在检测中等和大型物体时仍面临挑战，因此Ultralytics发布了YOLOv3u。YOLOv3u是YOLOv3的改进版本，使用无锚点检测方法，并提高了YOLOv3的准确性和速度，特别是对于中等和大型物体。</p>\n<h6 id=\"YOLOv5u\"><a href=\"#YOLOv5u\" class=\"headerlink\" title=\"YOLOv5u\"></a>YOLOv5u</h6><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202135925381.png\" alt=\"image-20241202135925381\"></p>\n<p>YOLOv5由Glenn Jocher提出，从Darknet框架过渡到PyTorch，保留了YOLOv4的许多改进，并使用CSPDarknet作为其骨干。CSPDarknet是原始Darknet架构的修改版本，通过将特征图分成单独的路径来实现更高效的特征提取和减少计算成本。YOLOv5采用步幅卷积层，旨在减少内存和计算成本。此外，该版本采用空间金字塔池化快速（SPPF）模块，通过在不同尺度上池化特征并提供多尺度表示来工作。YOLOv5实现了多种增强，如马赛克、复制粘贴、随机仿射、MixUp、HSV增强和随机水平翻转。Ultralytics通过YOLOv5u积极改进该模型，采用无锚点检测方法，并在复杂物体的不同尺寸上实现了更好的整体性能。</p>\n<h6 id=\"YOLOv8\"><a href=\"#YOLOv8\" class=\"headerlink\" title=\"YOLOv8\"></a>YOLOv8</h6><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140006851.png\" alt=\"image-20241202140006851\"></p>\n<p>Ultralytics引入了YOLOv8，这是YOLO系列的重大进化，包括五个缩放版本。除了物体检测外，YOLOv8还提供了图像分类、姿态估计、实例分割和定向物体检测（OOB）等多种应用。关键特性包括类似于YOLOv5的主干，调整后的CSPLayer（现称为C2f模块），结合了高级特征和上下文信息以提高检测精度。YOLOv8还引入了一个语义分割模型YOLOv8-Seg，结合了CSPDarknet53特征提取器和C2F模块，在物体检测和语义分割基准测试中取得了最先进的结果，同时保持了高效率。</p>\n<h6 id=\"YOLOv9\"><a href=\"#YOLOv9\" class=\"headerlink\" title=\"YOLOv9\"></a>YOLOv9</h6><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140048800.png\" alt=\"image-20241202140048800\"></p>\n<p>YOLOv9由Chien-Yao Wang、I-Hau Yeh和Hong-Yuan Mark Liao开发，使用信息瓶颈原理和可逆函数来在网络深度中保留关键数据，确保可靠的梯度生成并提高模型收敛性和性能。可逆函数可以在不丢失信息的情况下反转，这是YOLOv9架构的另一个基石。这种属性允许网络保持完整的信息流，使模型参数的更新更加准确。此外，YOLOv9提供了五个缩放版本，重点是轻量级模型，这些模型通常欠参数化，并且在前向过程中容易丢失重要信息。可编程梯度信息（PGI）是YOLOv9引入的一项重大进步。PGI是一种在训练期间动态调整梯度信息的方法，通过选择性关注最具信息量的梯度来优化学习效率。通过这种方式，PGI有助于保留可能在轻量级模型中丢失的关键信息。此外，YOLOv9还包括GELAN（梯度增强轻量级架构网络），这是一种新的架构改进，旨在通过优化网络内的计算路径来提高参数利用和计算效率。</p>\n<h6 id=\"YOLOv10\"><a href=\"#YOLOv10\" class=\"headerlink\" title=\"YOLOv10\"></a>YOLOv10</h6><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140137372.png\" alt=\"image-20241202140137372\"></p>\n<p>YOLOv10由清华大学的研究人员开发，基于先前模型的优势进行了关键创新。该架构具有增强的CSP-Net（跨阶段部分网络）主干，以提高梯度流动和减少计算冗余。网络结构分为三部分：主干、颈部和检测头。颈部包括PAN（路径聚合网络）层，用于有效的多尺度特征融合。PAN旨在通过聚合不同层的特征来增强信息流，使网络能够更好地捕捉和结合不同尺度的细节，这对于检测不同大小的物体至关重要。此外，该版本还提供五个缩放版本，从纳米到超大。对于推理，One-to-One Head为每个物体生成单个最佳预测，消除了对非极大值抑制（NMS）的需求。通过移除对NMS的需求，YOLOv10减少了延迟并提高了后处理速度。此外，YOLOv10还包括NMS-Free Training，使用一致的双重分配来减少推理延迟，并优化了从效率和准确性角度的各种组件，包括轻量级分类头、空间-通道解耦下采样和排名引导块设计。此外，该模型还包括大核卷积和部分自注意力模块，以在不显著增加计算成本的情况下提高性能。</p>\n<h6 id=\"YOLO11\"><a href=\"#YOLO11\" class=\"headerlink\" title=\"YOLO11\"></a>YOLO11</h6><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140334746.png\" alt=\"image-20241202140334746\"></p>\n<p>YOLO11是Ultralytics推出的最新创新，基于其前身的发展，特别是YOLOv8。这一迭代提供了从纳米到超大的五种缩放模型，适用于各种应用。与YOLOv8一样，YOLO11包括物体检测、实例分割、图像分类、姿态估计和定向物体检测（OBB）等多种应用。关键改进包括引入C2PSA（跨阶段部分自注意力）模块，结合了跨阶段部分网络和自注意力机制的优势。这使得模型能够在多个层次上更有效地捕获上下文信息，提高物体检测精度，特别是对于小型和重叠物体。此外，在YOLO11中，C2f块被C3k2块取代，C3k2是CSP Bottleneck的自定义实现，使用两个卷积而不是YOLOv8中使用的一个大卷积。这个块使用较小的内核，在保持精度的同时提高了效率和速度。</p>\n<h3 id=\"硬件和软件设置\"><a href=\"#硬件和软件设置\" class=\"headerlink\" title=\"硬件和软件设置\"></a>硬件和软件设置</h3><ul>\n<li>表III：实验的软件设置</li>\n<li>表IV：6个YOLO版本的不同尺寸的模型</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140352257.png\" alt=\"image-20241202140352257\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140542480.png\" alt=\"image-20241202140542480\"></p>\n<p>总结了用于评估YOLO模型的硬件和软件环境设置。</p>\n<ol>\n<li><strong>软件环境</strong>：实验使用了Python 3.12、Ubuntu 22.04、CUDA 12.5、cuDNN 8.9.7、Ultralytics 8.2.55和WandB 0.17.4等软件包。</li>\n<li><strong>硬件环境</strong>：实验在两块NVIDIA RTX 4090 GPU上进行，每块GPU拥有16,384个CUDA核心。</li>\n<li><strong>数据集处理</strong>：针对交通标志数据集，应用了欠采样技术以确保数据集平衡，并将图像数量从4381减少到3233张。</li>\n<li><strong>训练验证测试分割</strong>：非洲野生动物数据集和船只数据集分别按照70%训练、20%验证和10%测试的比例进行分割。</li>\n<li><strong>模型训练</strong>：实验中训练了23个模型，涵盖了5种不同的YOLO版本，并使用了相似的超参数以确保公平比较。</li>\n<li><strong>模型规模</strong>：交通标志数据集包含24个类别，平均每个类别约100张图像；非洲野生动物数据集包含4个类别，每个类别至少有376张图像；船只数据集专注于单一类别的小型物体检测。</li>\n</ol>\n<h3 id=\"评估指标\"><a href=\"#评估指标\" class=\"headerlink\" title=\"评估指标\"></a>评估指标</h3><p>评估指标包括准确性、计算效率和模型大小三个方面：</p>\n<h4 id=\"准确性指标\"><a href=\"#准确性指标\" class=\"headerlink\" title=\"准确性指标\"></a>准确性指标</h4><ol>\n<li><p><strong>Precision（精确率）</strong>：</p>\n<ul>\n<li>定义：正确预测的观察值与总预测观察值的比率。</li>\n<li>计算公式：$$ \\text{Precision} &#x3D; \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} $$</li>\n<li>其中，TP（True Positives）为真正例，FP（False Positives）为假正例。</li>\n</ul>\n</li>\n<li><p><strong>Recall（召回率）</strong>：</p>\n<ul>\n<li>定义：正确预测的观察值与所有实际观察值的比率。</li>\n<li>计算公式：$$ \\text{Recall} &#x3D; \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} $$</li>\n<li>其中，FN（False Negatives）为假反例。</li>\n</ul>\n</li>\n<li><p><strong>mAP50（Mean Average Precision at an IoU threshold of 0.50）</strong>：</p>\n<ul>\n<li>定义：在IoU（Intersection over Union）阈值为0.50时的平均精度均值。</li>\n<li>计算公式：$$ \\text{mAP50} &#x3D; \\frac{1}{|C|} \\sum_{c \\in C} \\text{AP}_c $$</li>\n<li>其中，$C$ 是类别集合，$\\text{AP}_c$ 是类别 $c$ 的平均精度。</li>\n</ul>\n</li>\n<li><p><strong>mAP50-95（Mean Average Precision across IoU thresholds from 0.50 to 0.95）</strong>：</p>\n<ul>\n<li>定义：在IoU阈值从0.50到0.95范围内的平均精度均值。</li>\n<li>计算公式：$$ \\text{mAP50-95} &#x3D; \\frac{1}{15} \\sum_{r&#x3D;1}^{15} \\text{AP}_{0.50 + \\frac{r-1}{14} \\times 0.05} $$</li>\n<li>其中，$r$ 表示IoU阈值的范围。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"计算效率指标\"><a href=\"#计算效率指标\" class=\"headerlink\" title=\"计算效率指标\"></a>计算效率指标</h4><ol>\n<li><p><strong>Preprocessing Time（预处理时间）</strong>：</p>\n<ul>\n<li>定义：准备原始数据以输入模型所需的持续时间。</li>\n</ul>\n</li>\n<li><p><strong>Inference Time（推理时间）</strong>：</p>\n<ul>\n<li>定义：模型处理输入数据并生成预测所需的持续时间。</li>\n</ul>\n</li>\n<li><p><strong>Postprocessing Time（后处理时间）</strong>：</p>\n<ul>\n<li>定义：将模型的原始预测转换为最终可用格式所需的时间。</li>\n</ul>\n</li>\n<li><p><strong>Total Time（总时间）</strong>：</p>\n<ul>\n<li>定义：预处理时间、推理时间和后处理时间的总和。</li>\n</ul>\n</li>\n<li><p><strong>GFLOPs（Giga Floating-Point Operations Per Second）</strong>：</p>\n<ul>\n<li>定义：模型训练的计算能力，反映其效率。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"模型大小指标\"><a href=\"#模型大小指标\" class=\"headerlink\" title=\"模型大小指标\"></a>模型大小指标</h4><ol>\n<li><strong>Size（大小）</strong>：<ul>\n<li>定义：模型的实际磁盘大小及其参数数量。</li>\n</ul>\n</li>\n</ol>\n<p>这些指标提供了对YOLO模型性能的全面概述，有助于在不同真实世界场景中选择最优的YOLO算法。</p>\n<h1 id=\"实验结果和讨论\"><a href=\"#实验结果和讨论\" class=\"headerlink\" title=\"实验结果和讨论\"></a>实验结果和讨论</h1><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142033886.png\" alt=\"image-20241202142033886\"></p>\n<h3 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h3><h4 id=\"交通信号数据集\"><a href=\"#交通信号数据集\" class=\"headerlink\" title=\"交通信号数据集\"></a>交通信号数据集</h4><p>YOLO模型在检测交通标志方面的有效性，展示了各种精度范围。最高的mAP50-95为0.799，而最低的精度为0.64。另一方面，最高的mAP50为0.893，而最低的为0.722。mAP50和mAP50-95之间的显著差距表明，模型在处理不同大小的交通标志时，在较高阈值下遇到了困难，这反映了其检测算法中潜在的改进领域。</p>\n<p>a) 准确性：如图8所示，YOLOv5ul展示了最高的准确性，实现了mAP50为0.866和mAP50-95为0.799。紧随其后的是YOLO11m，其mAP50-95为0.795，YOLO11l的mAP50-95为0.794。相比之下，YOLOv10n展示了最低的精度，其mAP50为0.722，mAP50-95为0.64，紧随其后的是YOLOv5un，其mAP50-95为0.665，如数据点在图8中所证明的。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142326776.png\" alt=\"image-20241202142326776\"></p>\n<p>b) 精度和召回率：图9阐明了考虑模型大小的情况下精度和召回率之间的权衡。像YOLO11m、YOLO10l、YOLOv9m、YOLOv5ux和YOLO111这样的模型展示了高精度和召回率，特别是YOLO11m实现了0.898的精度和0.826的召回率，同时模型大小为67.9Mb，而YOLOv10l实现了0.873的精度和0.807的召回率，但模型大小显著更大（126.8 Mb）。相比之下，较小的模型如YOLOv10n（精度0.722，召回率0.602）、YOLOv8n（精度0.749，召回率0.688）和YOLO11n（精度0.768，召回率0.695）在两个指标上都表现不佳。这突显了较大模型在交通标志数据集上的优越性能。此外，YOLOv5um的高精度（0.849）和低召回率（0.701）表明了对假阴性的倾向，而YOLOv3u的高召回率（0.849）和低精度（0.75）则表明了对假阳性的倾向。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142423060.png\" alt=\"image-20241202142423060\"></p>\n<p>c) 计算效率：在计算效率方面，YOLOv10n是最有效的，每张图片的处理时间为2ms，GFLOPs计数为8.3，如图10和11所示。YOLO11n紧随其后，处理时间为2.2ms，GFLOPs计数为6.4，而YOLOv3u-tiny的处理时间为2.4ms，GFLOPs计数为19，与其他快速模型相比，这使得它在计算上相对低效。然而，数据显示YOLOv9e、YOLOv9m、YOLOv9c和YOLOv9s是效率最低的，推理时间分别为16.1ms、12.1ms、11.6ms和11.1ms，GFLOPs计数分别为189.4、76.7、102.6和26.8。这些发现描绘了一个明显的权衡，即在精度和计算效率之间。</p>\n<p>d) 整体性能：在评估整体性能时，包括准确性、大小和模型效率，YOLO11m作为一个一致的表现最佳的模型脱颖而出。它实现了mAP50-95为0.795，推理时间为2.4ms，模型大小为38.8Mb，GFLOPs计数为67.9，如图8、10、11和表VI中详细说明的。紧随其后的是YOLO111（mAP50-95为0.794，推理时间为4.6ms，大小为49Mb，GFLOPs计数为86.8）和YOLOv10m（mAP50-95为0.781，推理时间为2.4ms，大小为32.1Mb，63.8 GFLOPs计数）。这些结果突显了这些模型在检测各种大小的交通标志方面的稳健性，同时保持了较短的推理时间和较小的模型大小。值得注意的是，YOLO11和YOLOv10家族在准确性和计算效率方面显著优于其他YOLO家族，因为它们的模型在这些数据集上一致超越了其他家族的对应物。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142515870.png\" alt=\"image-20241202142515870\"></p>\n<h4 id=\"非洲野生动物数据集\"><a href=\"#非洲野生动物数据集\" class=\"headerlink\" title=\"非洲野生动物数据集\"></a>非洲野生动物数据集</h4><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142815914.png\" alt=\"image-20241202142815914\"></p>\n<p>表 VII 展示了 YOLO 模型在非洲野生动物数据集上的性能。该数据集包含大型物体尺寸，重点关注 YOLO 模型预测大型物体的能力以及由于数据集大小而导致过拟合的风险。模型在各个方面的准确性都表现出色，最高性能的模型 mAP50-95 范围从 0.832 到 0.725。这个相对较短的范围反映了模型在检测和分类大型野生动物物体时保持高准确性的有效性。</p>\n<p>a) 准确性：如图 12 所示，YOLOv9s 展现了出色的性能，具有高达 0.832 的 mAP50-95 和 0.956 的 mAP50，展示了其在各种 IoU 阈值下的稳健准确性。YOLOv9c 和 YOLOv9t 紧随其后，mAP50 分数分别为 0.96 和 0.948，召回率分别为 0.896。值得注意的是，YOLOv8n 实现了 mAP50-95 得分分别为 0.83 和 0.825。这些结果突出了 YOLOv9 系列从少量图像样本中有效学习模式的能力，使其特别适合于较小型的数据集。相比之下，YOLOv5un、YOLOv10n 和 YOLOv3u-tiny 显示出较低的 mAP50-95 得分，分别为 0.791、0.786 和 0.725，表明它们在准确性方面的局限性。较大的模型如 YOLO11x、YOLOv5ux、YOLOv5ul 和 YOLOv10l 的表现不佳，可以归因于过拟合，特别是考虑到数据集规模较小。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142853898.png\" alt=\"image-20241202142853898\"></p>\n<p>b) 精度和召回率：图 13 表明 YOLO8l 和 YOLO111 实现了最高的精度和召回率，精度值分别为 0.942 和 0.937，召回率分别为 0.898 和 0.896。值得注意的是，YOLOv8n 实现了 0.932 的精度和 0.908 的召回率。总体而言，YOLOv8l 和 YOLO111 在精度和召回率方面表现最佳，YOLOv8n 的表现也相当出色。然而，YOLOv11 模型倾向于产生误报，这反映在其较低的精度和较高的召回率上。与此同时，YOLOv10 在精度和召回率方面的表现均不佳，尽管它是 YOLO 系列中最新的模型之一。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142924537.png\" alt=\"image-20241202142924537\"></p>\n<p>c) 计算效率：如图 14 和 15 所示，YOLOv10n、YOLOv8n 和 YOLOv3u-tiny 是最快的模型，处理时间分别为 2ms 和 1.8ms，GFLOPs 计数分别为 8.2 和 19.1。前两个模型具有相同的处理速度和 GFLOPs 计数，如表 VII 中所示。相比之下，YOLOv9e 展现了最慢的处理时间，为 11.2ms，GFLOPs 计数为 189.3，其次是 YOLOv5ux，处理时间为 7.5ms，GFLOPs 计数为 246.2 GFLOPs 计数。这些结果表明，较大的模型通常需要更多的处理时间和硬件资源，强调了模型大小和处理效率之间的权衡。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143004149.png\" alt=\"image-20241202143004149\"></p>\n<p>d) 整体性能：表 VII 和图 13、14 和 15 中的结果表明，YOLOv9t 和 YOLOv9s 在各个指标上持续表现出色，提供高准确性，同时保持较小的模型大小、低 GFLOPs 和短的处理时间，展示了 YOLOv9 较小型模型的稳健性及其在小数据集上的有效性。相比之下，YOLO5ux 和 YOLO11x 尽管具有较大的尺寸和较长的推理时间，但准确性表现不佳，可能是由于过拟合所致。大多数大型模型在这个数据集上的表现都不尽如人意，YOLOv10x 是一个例外，得益于现代架构防止过拟合，表现优异。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143030167.png\" alt=\"image-20241202143030167\"></p>\n<h4 id=\"船只和船舶数据集：\"><a href=\"#船只和船舶数据集：\" class=\"headerlink\" title=\"船只和船舶数据集：\"></a>船只和船舶数据集：</h4><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143313627.png\" alt=\"image-20241202143313627\"></p>\n<p>表 VIII 展示了 YOLO 模型在船只和船舶数据集上的性能，这是一个包含微小物体且旋转变化多样的大型数据集。总体而言，模型在检测船只和船舶方面表现出中等效果，mAP50-95 的范围从 0.273 到 0.327。这一表现表明 YOLO 算法在准确检测较小物体方面可能面临挑战，数据集中物体尺寸和旋转的多样性为测试模型能力提供了全面的测试。</p>\n<p>a) 准确性：图 16 中 mAP50-95 和 mAP50 之间的差异凸显了 YOLO 模型在检测小物体时面临的挑战，尤其是在更高的 IoU 阈值下。此外，YOLO 模型在检测不同旋转的物体时也遇到困难。在各个模型中，YOLO11x 实现了最高的准确性，mAP50 为 0.529，mAP50-95 为 0.327，紧随其后的是 YOLO111、YOLO11m 和 YOLO11s，它们记录的 mAP50 值分别为 0.529、0.528 和 0.53，mAP50-95 值分别为 0.327、0.325 和 0.325。这些结果突出了 YOLO11 系列在检测小型和微小物体方面的稳健性。相比之下，YOLOv3u-tiny、YOLOv8n、YOLOv3u 和 YOLOv5n 展示了最低的准确性，mAP50 分数分别为 0.489、0.515、0.519 和 0.514，mAP50-95 分数分别为 0.273、0.297、0.298 和 0.298。这表明 YOLOv3u 的过时架构以及由于数据集规模较大而导致的小型模型的潜在欠拟合。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143334789.png\" alt=\"image-20241202143334789\"></p>\n<p>b) 精度和召回率：图 17 表明 YOLOv5ux 的表现优于其他模型，实现了 0.668 的精度和 0.555 的召回率。它紧随其后的是 YOLOv9m（精度为 0.668，召回率为 0.551）和 YOLOv8m（精度为 0.669，召回率为 0.525），两者在尺寸上显著较小（YOLOv9m 为 40.98 Mb，YOLOv8m 为 52.12 Mb）。相比之下，YOLO11n 和 YOLOv10s 表现较差，精度分别为 0.574 和 0.586，召回率分别为 0.51 和 0.511，这可能是由于欠拟合问题。总体而言，YOLO11 模型倾向于产生误报，这反映在其较低的精度和较高的召回率上。与此同时，YOLOv10 在精度和召回率方面的表现均不佳，尽管它是 YOLO 系列中最新的模型之一。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143403226.png\" alt=\"image-20241202143403226\"></p>\n<p>c) 计算效率：如图 18 和 19 所示，YOLOv3u-tiny 实现了最快的处理时间，为 2 毫秒，紧随其后的是 YOLOv8n 和 YOLOv5un，两者均记录了 2.3 毫秒。YOLOv10 和 YOLO11 模型也在速度上表现出色，YOLOv10n 和 YOLO11n 分别实现了 2.4 毫秒和 2.5 毫秒的快速推理时间，以及 8.2 和 6.3 的 GFLOPs 计数。相比之下，YOLOv9e 展现了最慢的速度，推理时间为 7.6 毫秒，GFLOPs 计数为 189.3，突显了 YOLOv9 系列在准确性和效率之间的权衡。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143422503.png\" alt=\"image-20241202143422503\"></p>\n<p>d) 整体性能：表 VIII 和图 16、17 和 18 中的结果表明，YOLO11s 和 YOLOv10s 在准确性方面表现优异，同时保持了紧凑的尺寸、低 GFLOPs 和快速的处理时间。相比之下，YOLOv3u、YOLOv8x 和 YOLOv8l 未能达到预期，尽管它们的尺寸较大且处理时间较长。这些发现突出了 YOLO11 系列的稳健性和可靠性，特别是在提高 YOLO 系列检测小型和微小物体的性能方面，同时确保高效处理。此外，结果还揭示了 YOLOv9 模型在面对大型数据集和小物体时的表现不佳，尽管它们具有现代架构。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143442543.png\" alt=\"image-20241202143442543\"></p>\n<h3 id=\"讨论\"><a href=\"#讨论\" class=\"headerlink\" title=\"讨论\"></a>讨论</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143815028.png\" alt=\"image-20241202143815028\"></p>\n<p>基于三个数据集上模型的性能，我们按准确性、速度、GFLOps 计数和大小对它们进行了排名，如表 IX 所示，以便进行全面评估。对于准确性，由于 mAP50-95 指标能够评估模型在一系列 IoU 阈值下的表现，因此我们采用了该指标。对于速度，模型根据总处理时间进行排序，总处理时间包括预处理、推理和后处理持续时间。排名范围从第 1 名（表示最高性能）到第 28 名（表示最低性能），表中的相应排名已加粗显示。</p>\n<p>表 IX 的分析得出了几个关键观察结果：</p>\n<ol>\n<li>准确性：YOLO11m 一致地成为顶级表现者，经常位居前列，紧随其后的是 YOLOv10x、YOLO111、YOLOv9m 和 YOLO11x。这突显了 YOLO11 系列在各种 IoU 阈值和物体大小下的稳健性能，这可以归因于它们使用 C2PSA 来保留上下文信息，从而提高了收敛性和整体性能。此外，大核卷积和部分自注意力模块的实施有助于提高算法的性能。</li>\n</ol>\n<p>相比之下，YOLOv3u-tiny 展现了最低的准确性，特别是在非洲野生动物和船只及船舶数据集上，YOLOv5un 和 YOLOv8n 的表现稍好但仍不理想。这表明 YOLO11 模型目前是要求高准确性的应用中最可靠的。</p>\n<p>紧随 YOLO11 系列之后，YOLOv9 模型在检测各种大小和不同 IoU 阈值的物体方面表现出色。然而，它们可能在检测小物体时遇到困难，这在船只和船舶数据集上可见。相比之下，YOLOv10 系列尽管推出较晚，但在交通标志和非洲动物数据集上的准确性相对较低，导致平均准确性下降了 2.075%，这可以归因于它们采用一对一头部方法而不是非极大值抑制（NMS）来定义边界框。这种策略在捕捉物体时可能会遇到困难，特别是在处理重叠物品时，因为它依赖于每个物体的单个预测。这一限制有助于解释第二个数据集中观察到的相对较差的结果。</p>\n<p>YOLOv3u 的过时架构也导致了其性能不佳，平均准确性比 YOLO11 模型低 6.5%。这种下降可以追溯到其对 2018 年首次引入的较旧 Darknet-53 框架的依赖，该框架可能无法充分应对当代检测挑战。</p>\n<ol start=\"2\">\n<li>计算效率：YOLOv10n 在速度和 GFLOPs 计数方面始终表现优异，在所有三个数据集上均名列前茅，在速度方面排名第 1，在 GFLOPs 计数方面排名第 5。YOLOv3u-tiny、YOLOv10s 和 YOLO11n 也展示了显著的计算效率。</li>\n</ol>\n<p>YOLOv9e 展现了最慢的推理时间和非常高的 GFLOPs 计数，突显了准确性与效率之间的权衡。YOLO11 的速度提升可归因于它们使用的 C3k2 块，使其适用于需要快速处理的场景，超过了 YOLOv10 和 YOLOv9 模型，分别在速度上平均快了 %1.41 和 %31。</p>\n<p>虽然 YOLOv9 模型在准确性方面表现出色，但它们的推理时间却是最慢的，使它们不太适合对时间敏感的应用。相比之下，YOLOv10 模型虽然略慢于 YOLO11 变体，但仍提供了效率与速度之间的值得称赞的平衡。它们的表现非常适合时间敏感的场景，提供快速处理而不显著牺牲准确性，使它们成为实时应用的可行选择。</p>\n<ol start=\"3\">\n<li>模型大小：YOLOv9t 是最小的模型，在所有三个数据集上均排名第一，其次是 YOLO11n 和 YOLOv10n。这种模型大小的效率突显了较新 YOLO 版本，特别是 YOLOv10，在高效参数利用方面的进步，实施了空间-通道解耦下采样。</li>\n</ol>\n<p>YOLOv3u 是最大的模型，突显了与其更现代的对应物相比，它的效率低下。</p>\n<ol start=\"4\">\n<li>整体性能：考虑到准确性、速度、大小和 GFLOPs，YOLO11m、YOLOv11n、YOLO11s 和 YOLOv10s 成为最一致的表现者。它们实现了高准确性、低处理时间和功率以及高效的磁盘使用，使其适用于广泛的应用，其中速度和准确性都至关重要。</li>\n</ol>\n<p>相反，YOLOv9e、YOLOv5ux 和 YOLOv3u 在所有指标上的表现都较差，计算效率低下且相对于其大小表现不佳。YOLO11 模型显示出最佳的整体性能，可能是由于最近的增强功能，如 C3k2 块和 C2PSA 模块。紧随其后的是 YOLOv10 模型，尽管在准确性方面略有逊色，但由于其一对一头部用于预测的实施，在效率方面表现出色。虽然 YOLOv9 在计算效率方面表现不佳，但它在准确性方面仍然具有竞争力，这要归功于其 PGI 集成。这使 YOLOv9 成为优先考虑精度而非速度的应用的可行选择。</p>\n<p>此外，YOLOv8 和 YOLOv5u 展示了竞争性结果，超过了 YOLOv3u 的准确性，这可能是由于 YOLOv3u 的较旧架构。然而，它们的准确性仍然显著低于较新的模型，如 YOLOv9、YOLOv10 和 YOLO11。虽然 YOLOv8 和 YOLOv5u 的处理时间比 YOLOv9 快，但它们的整体表现仍然不如较新的模型。</p>\n<ol start=\"5\">\n<li>物体大小和旋转检测：YOLO 算法在检测大中型物体方面效果很好，如非洲野生动物和交通标志数据集所证明的那样，准确性很高。然而，它在检测小物体方面存在困难，可能是由于将图像划分为网格，使得识别小而分辨率低的物体变得具有挑战性。此外，YOLO 在处理不同旋转的物体时也面临挑战，因为无法包围旋转物体，导致整体结果不佳。</li>\n</ol>\n<p>为了处理旋转物体，可以实现像 YOLO11 OBB[26] 和 YOLOv8 OBB[25]（定向边界框）这样的模型。保持与标准 YOLOv8 和 YOLO11 相同的基础架构，YOLOv8 OBB 和 YOLO11 OBB 用预测旋转矩形四个角点的头部替换了标准边界框预测头部，允许更准确的定位和表示任意方向的物体。</p>\n<ol start=\"6\">\n<li><p>YOLO11 对 YOLOv8 的崛起：尽管 YOLOv8[25] 因其在姿态估计、实例分割和定向物体检测（OBB）任务中的多功能性而成为算法的首选，但 YOLO11[26] 已经成为一个更高效和准确的替代品。通过处理相同任务的同时提供改进的上下文理解和更好的架构模块，YOLO11 设定了新的性能标准，在各种应用中的速度和准确性方面都超过了 YOLOv8。</p>\n</li>\n<li><p>数据集大小：数据集的大小显著影响 YOLO 模型的性能。例如，大型模型在小型非洲野生动物数据集上的表现不如在交通标志和船只及船舶数据集上的表现，因为它们更容易过拟合。相反，像 YOLOv9t 和 YOLOv9s 这样的小模型在非洲野生动物数据集上的表现显著更好，展示了小规模模型在处理有限数据集时的有效性。</p>\n</li>\n<li><p>训练数据集的影响：如表 VI、VII 和 VIII 所示，YOLO 模型的性能受到所使用的训练数据集的影响。不同的数据集产生不同的结果和顶尖表现者，表明数据集复杂性影响算法性能。这突显了在基准测试期间使用多样化数据集以获得每个模型优缺点全面结果的重要性。</p>\n</li>\n</ol>\n<p>这次讨论强调了在选择 YOLO 模型进行特定应用时，需要平衡考虑准确性、速度和模型大小。YOLO11 模型在各个指标上的一致表现使它们非常适合于需要准确性和速度的多功能场景。同时，YOLOv10 模型可以在保持更快处理时间和更小模型大小的同时，类似地执行。此外，YOLOv9 可以在准确性方面提供可比的结果，但牺牲了速度，使其适用于优先考虑精度而非快速处理的应用。</p>\n<h1 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h1><p>这项基准研究全面评估了各种 YOLO 算法的性能。它是首个对 YOLO11 及其前辈进行全面比较的研究，评估了它们在三个多样化数据集上的表现：交通标志、非洲野生动物和船只及船舶。这些数据集经过精心挑选，包含了广泛的物体属性，包括不同的物体大小、宽高比和物体密度。我们通过检查精度、召回率、平均精度均值（mAP）、处理时间、GFLOPs 计数和模型大小等一系列指标，展示了每个 YOLO 版本和家族的优势和劣势。我们的研究解决了以下关键研究问题：</p>\n<p>● 哪个 YOLO 算法在一系列综合指标上展示了卓越的性能？</p>\n<p>● 不同的 YOLO 版本在具有不同物体特征（如大小、宽高比和密度）的数据集上的表现如何？</p>\n<p>● 每个 YOLO 版本的具体优势和局限性是什么，这些见解如何指导选择最适合各种应用的算法？</p>\n<p>特别是，YOLO11 系列作为最一致的表现在各个指标上脱颖而出，YOLO11m 在准确性、效率、模型大小之间取得了最佳平衡。虽然 YOLOv10 的准确性略低于 YOLO11，但它在速度和效率方面表现出色，使其成为需要效率和快速处理的应用的强有力选择。此外，YOLOv9 总体上也表现良好，特别是在较小的数据集上表现尤为突出。这些发现为工业界和学术界提供了宝贵的见解，指导选择最适合的 YOLO 算法，并为未来的发展和改进提供信息。虽然评估的算法展示了有希望的性能，但仍有一些改进的空间。未来的研究可以专注于优化 YOLOv10，以提高其准确性，同时保持其速度和效率优势。此外，架构设计的持续进步可能为更突破性的 YOLO 算法铺平道路。我们未来的工作包括深入研究这些算法中确定的差距，并提出改进措施，以展示它们对整体效率的潜在影响。</p>\n<h1 id=\"其它问题\"><a href=\"#其它问题\" class=\"headerlink\" title=\"其它问题\"></a>其它问题</h1><ul>\n<li><strong>在交通标志数据集上，YOLOv5ul和YOLOv10n的性能差异是什么？原因是什么？</strong></li>\n</ul>\n<p>在交通标志数据集上，YOLOv5ul的mAP50-95达到了0.799，而YOLOv10n的mAP50-95仅为0.64，相差显著。YOLOv5ul在精度和召回率上都表现更好，具体来说，YOLOv5ul的Precision为0.866，Recall为0.849，而YOLOv10n的Precision为0.722，Recall为0.602。这种差异的原因可能包括：</p>\n<ol>\n<li><strong>模型架构改进</strong>：YOLOv5ul采用了更先进的CSPDarknet53作为主干网络，并引入了Spatial Pyramid Pooling Fast（SPPF）模块，这些改进提高了模型的特征提取能力和多尺度适应性。</li>\n<li><strong>数据增强</strong>：YOLOv5ul使用了多种数据增强技术，如Mosaic、Copy-Paste、Random Affine等，这些技术有助于提高模型的泛化能力和鲁棒性。</li>\n<li><strong>优化策略</strong>：YOLOv5ul在训练过程中使用了更有效的优化策略，如AdamW优化器和学习率调度，这些策略有助于模型更快地收敛和提高性能。</li>\n</ol>\n<ul>\n<li><strong>在船舶与船只数据集上，YOLOv11x为什么表现最好？与其他模型相比有哪些优势？</strong></li>\n</ul>\n<p>​\t在船舶与船只数据集上，YOLOv11x的mAP50-95达到了0.327，表现最好。与其他模型相比，YOLOv11x有以下优势：</p>\n<ol>\n<li><strong>小对象检测</strong>：YOLOv11x特别适用于检测小对象，能够在复杂的图像环境中准确识别和定位小尺寸的船只。</li>\n<li><strong>架构改进</strong>：YOLOv11x引入了C3k2块和C2PSA（Cross-Stage Partial with Self-Attention）模块，这些改进提高了模型的空间注意力和特征提取能力，特别是在处理重叠和小的对象时表现优异。</li>\n<li><strong>计算效率</strong>：尽管YOLOv11x在精度上有所提升，但其推理时间仍然保持在2.4ms左右，保持了较高的计算效率，适合实时应用。</li>\n</ol>\n<ul>\n<li><p><strong>在非洲野生动物数据集上，YOLOv9s的表现优于其他模型的原因是什么？</strong></p>\n<p>在非洲野生动物数据集上，YOLOv9s的mAP50-95达到了0.832，表现优于其他模型。YOLOv9s之所以表现优异，主要原因包括：</p>\n<ol>\n<li><strong>小型数据集适应性</strong>：YOLOv9s在小型数据集上表现出色，能够有效学习对象的模式。其小型模型（如YOLOv9t）在非洲野生动物数据集上表现尤为突出，mAP50-95为0.832，mAP50为0.956。</li>\n<li><strong>特征提取能力</strong>：YOLOv9s采用了CSPNet（Cross-Stage Partial Network），这种结构通过分割特征图来提高特征提取效率，减少了计算复杂度。</li>\n<li><strong>正则化技术</strong>：YOLOv9s使用了GelAN（Gradient Enhanced Lightweight Architecture Network），这种技术通过优化网络内的计算路径，提高了参数利用率和计算效率。</li>\n</ol>\n</li>\n</ul>\n<p><a href=\"https://arxiv.org/html/2411.00201v1\">Evaluating the Evolution of YOLO (You Only Look Once) Models: A Comprehensive Benchmark Study of YOLO11 and Its Predecessors</a></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"二维码\"></p>\n","excerpt":"","more":"<h1 id=\"摘要\"><a href=\"#摘要\" class=\"headerlink\" title=\"摘要\"></a>摘要</h1><p>本研究对YOLO （You Only Look Once） 的各个版本进行了全面的基准测试分析，从 YOLOv3 到最新的算法。它代表了首次全面评估 YOLO11 性能的研究，YOLO11 是 YOLO 系列的最新成员。它评估了它们在三个不同数据集上的性能：交通标志（具有不同的对象大小）、非洲野生动物（具有不同的纵横比，每个图像至少有一个对象实例）以及船舶和船只（具有单个类别的小型对象），确保在具有不同挑战的数据集之间进行全面评估。为了确保稳健的评估，我们采用了一套全面的指标，包括精度、召回率、平均精度均值 （mAP）、处理时间、GFLOP 计数和模型大小。我们的分析强调了每个 YOLO 版本的独特优势和局限性。例如：YOLOv9 表现出很高的准确性，但在检测小物体和效率方面表现不佳，而 YOLOv10 表现出相对较低的准确性，因为架构选择会影响其在重叠物体检测方面的性能，但在速度和效率方面表现出色。此外，YOLO11 系列在准确性、速度、计算效率和模型大小方面始终表现出卓越的性能。YOLO11m 在准确性和效率之间取得了显著的平衡，在交通标志、非洲野生动物和船舶数据集上的mAP50-95得分分别为0.795、0.81和0.325，同时保持了2.4毫秒的平均推理时间，模型大小为38.8Mb，平均约为67.6 GFLOPs。这些结果为工业界和学术界提供了重要的见解，有助于为各种应用选择最合适的 YOLO 算法，并指导未来的增强功能。</p>\n<h1 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h1><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/x1.png\" alt=\"Refer to caption\"></p>\n<p>​                             Figure 1:Evolution of YOLO Algorithms throughout the years.</p>\n<p>主要介绍了物体检测在计算机视觉系统中的重要性及其应用，并概述了YOLO（You Only Look Once）算法的发展历程和优势。</p>\n<ul>\n<li><strong>物体检测的重要性</strong>：物体检测是计算机视觉系统的关键组成部分，广泛应用于自动驾驶、机器人技术、库存管理、视频监控和体育分析等领域。</li>\n<li><strong>传统方法的局限性</strong>：传统的物体检测方法如Viola-Jones算法和DPM模型在鲁棒性和泛化能力上存在局限，而深度学习方法已成为主流。</li>\n<li><strong>一阶段与两阶段方法</strong>：一阶段方法如RetinaNet和SSD在速度和准确性之间取得平衡，而两阶段方法如R-CNN提供高精度但计算密集。</li>\n<li><strong>YOLO算法的崛起</strong>：YOLO算法以其鲁棒性和效率脱颖而出，自2015年首次提出以来，通过不断改进框架和设计，成为实时物体检测的领先算法。</li>\n<li><strong>YOLO算法的演进</strong>：YOLO算法的演进包括从YOLOv1到YOLOv11的多个版本，每个版本都引入了新的架构和技术来提高性能。</li>\n<li><strong>Ultralytics的角色</strong>：Ultralytics在YOLO算法的发展中扮演了重要角色，通过维护和改进模型，使其更易于访问和定制。</li>\n<li><strong>研究目的</strong>：本研究旨在对YOLO算法的演变进行全面比较分析，特别是对最新成员YOLO11进行首次全面评估，并探讨其在不同应用场景中的优势和局限性。</li>\n<li><strong>研究方法</strong>：研究使用了三个多样化的数据集，并采用了一致的超参数设置，以确保公平和无偏见的比较。</li>\n<li><strong>研究贡献</strong>：研究的贡献在于提供了对YOLO11及其前身的全面比较，深入分析了这些算法的结构演变，并扩展了性能评估指标，为选择最适合特定用例的YOLO算法提供了宝贵的见解。</li>\n</ul>\n<h1 id=\"相关工作\"><a href=\"#相关工作\" class=\"headerlink\" title=\"相关工作\"></a>相关工作</h1><p>主要回顾了YOLO算法的演变、不同版本的架构、以及与其他计算机视觉算法的基准测试。以下是对该章节的详细总结分析：</p>\n<h3 id=\"YOLO算法的演变：\"><a href=\"#YOLO算法的演变：\" class=\"headerlink\" title=\"YOLO算法的演变：\"></a>YOLO算法的演变：</h3><ul>\n<li>论文[14]分析了包括YOLOv8在内的七种语义分割和检测算法，用于云层分割的遥感图像。</li>\n<li>论文[22]回顾了YOLO从版本1到版本8的演变，但没有考虑YOLOv9、YOLOv10和YOLO11。</li>\n<li>论文[12]详细分析了从YOLOv1到YOLOv4的单阶段物体检测器，并比较了两阶段和单阶段物体检测器。</li>\n<li>论文[53]探讨了YOLO从版本1到10的演变，强调了其在汽车安全、医疗保健等领域的应用。</li>\n<li>论文[61]讨论了YOLO算法的发展直到第四版，并提出了新的方法和挑战。</li>\n<li>论文[27]分析了YOLO算法的发展和性能，比较了从第8版到第8版的YOLO版本。</li>\n</ul>\n<h3 id=\"YOLO算法的应用：\"><a href=\"#YOLO算法的应用：\" class=\"headerlink\" title=\"YOLO算法的应用：\"></a>YOLO算法的应用：</h3><ul>\n<li>YOLO算法在自动驾驶、医疗保健、工业制造、监控和农业等领域有广泛应用。</li>\n<li>YOLOv8提供了多种应用，包括实例分割、姿态估计和定向物体检测（OOB）。</li>\n</ul>\n<h3 id=\"YOLO算法的基准测试：\"><a href=\"#YOLO算法的基准测试：\" class=\"headerlink\" title=\"YOLO算法的基准测试：\"></a>YOLO算法的基准测试：</h3><ul>\n<li>论文[14]进行了云层分割的基准测试，评估了不同算法的架构方法和性能。</li>\n<li>论文[22]提出了结合联邦学习以提高隐私、适应性和协作训练的通用性。</li>\n<li>论文[12]提供了单阶段和两阶段物体检测器的比较。</li>\n<li>论文[53]探讨了YOLO算法对未来AI驱动应用的潜在整合。</li>\n<li>论文[61]强调了YOLO算法在物体检测方面的挑战和需要进一步研究的地方。</li>\n</ul>\n<h3 id=\"YOLO算法的挑战：\"><a href=\"#YOLO算法的挑战：\" class=\"headerlink\" title=\"YOLO算法的挑战：\"></a>YOLO算法的挑战：</h3><ul>\n<li>YOLO算法在处理小物体和不同旋转角度的物体时面临挑战。</li>\n<li>YOLOv9、YOLOv10和YOLO11的最新模型在准确性和效率方面表现出色，但在某些情况下仍需改进。</li>\n</ul>\n<h3 id=\"YOLO算法的改进：\"><a href=\"#YOLO算法的改进：\" class=\"headerlink\" title=\"YOLO算法的改进：\"></a>YOLO算法的改进：</h3><ul>\n<li>YOLOv9引入了信息瓶颈原理和可逆函数来保留数据，提高了模型的收敛性和性能。</li>\n<li>YOLOv10通过增强的CSP-Net主干和PAN层提高了梯度流动和减少了计算冗余。</li>\n<li>YOLO11引入了C2PSA模块，结合了跨阶段部分网络和自注意力机制，提高了检测精度。</li>\n</ul>\n<h3 id=\"YOLO算法的未来方向：\"><a href=\"#YOLO算法的未来方向：\" class=\"headerlink\" title=\"YOLO算法的未来方向：\"></a>YOLO算法的未来方向：</h3><ul>\n<li>未来的研究可以专注于优化YOLOv10以提高其准确性，同时保持其速度和效率优势。</li>\n<li>继续改进架构设计可能会带来更先进的YOLO算法。</li>\n</ul>\n<h3 id=\"研究贡献：\"><a href=\"#研究贡献：\" class=\"headerlink\" title=\"研究贡献：\"></a>研究贡献：</h3><ul>\n<li>本研究首次全面比较了YOLO11及其前身，并在三个多样化的数据集上评估了它们的性能。</li>\n<li>研究结果为工业界和学术界提供了选择最适合特定应用场景的YOLO算法的宝贵见解。</li>\n</ul>\n<p>通过这些分析，可以看出YOLO算法在不断演进和改进，以适应不同的应用需求和挑战。</p>\n<h1 id=\"Benchmark-设置\"><a href=\"#Benchmark-设置\" class=\"headerlink\" title=\"Benchmark 设置\"></a>Benchmark 设置</h1><h3 id=\"数据集\"><a href=\"#数据集\" class=\"headerlink\" title=\"数据集\"></a>数据集</h3><p>介绍了三种数据集，分别是Traffic Signs Dataset、Africa Wildlife Dataset和Ships&#x2F;Vessels Dataset。以下是对这三种数据集的详细介绍：</p>\n<h4 id=\"1-Traffic-Signs-Dataset（交通标志数据集）\"><a href=\"#1-Traffic-Signs-Dataset（交通标志数据集）\" class=\"headerlink\" title=\"1. Traffic Signs Dataset（交通标志数据集）\"></a>1. Traffic Signs Dataset（交通标志数据集）</h4><ul>\n<li><strong>来源</strong>：由Radu Oprea在Kaggle上提供的开源数据集。</li>\n<li>特点：<ul>\n<li>包含约55个类别的交通标志图像。</li>\n<li>训练集包含3253张图像，验证集包含1128张图像。</li>\n<li>图像大小不一，初始尺寸为640x640像素。</li>\n<li>为了平衡不同类别的数量，采用了欠采样技术。</li>\n</ul>\n</li>\n<li><strong>应用领域</strong>：自动驾驶、交通管理、道路安全和智能交通系统。</li>\n<li>挑战：<ul>\n<li>目标物体大小变化较大。</li>\n<li>不同类别之间的模式相似，增加了检测难度。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"2-Africa-Wildlife-Dataset（非洲野生动物数据集）\"><a href=\"#2-Africa-Wildlife-Dataset（非洲野生动物数据集）\" class=\"headerlink\" title=\"2. Africa Wildlife Dataset（非洲野生动物数据集）\"></a>2. Africa Wildlife Dataset（非洲野生动物数据集）</h4><ul>\n<li><strong>来源</strong>：由Bianca Ferreira在Kaggle上设计的开源数据集。</li>\n<li>特点：<ul>\n<li>包含四种常见的非洲动物类别：水牛、大象、犀牛和斑马。</li>\n<li>每个类别至少有376张图像，通过Google图像搜索收集并手动标注为YOLO格式。</li>\n<li>数据集分为训练集、验证集和测试集，比例为70%、20%和10%。</li>\n</ul>\n</li>\n<li><strong>应用领域</strong>：野生动物保护、反偷猎、生物多样性监测和生态研究。</li>\n<li>挑战：<ul>\n<li>目标物体的宽高比变化较大。</li>\n<li>每张图像至少包含一种指定的动物类别，可能还包含其他类别的多个实例或发生情况。</li>\n<li>目标物体重叠，增加了检测难度。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"3-Ships-Vessels-Dataset（船舶数据集）\"><a href=\"#3-Ships-Vessels-Dataset（船舶数据集）\" class=\"headerlink\" title=\"3. Ships&#x2F;Vessels Dataset（船舶数据集）\"></a>3. Ships&#x2F;Vessels Dataset（船舶数据集）</h4><ul>\n<li><strong>来源</strong>：由Siddharth Sah从多个Roboflow数据集中收集并整理的开源数据集。</li>\n<li>特点：<ul>\n<li>包含约13.5k张图像，专门用于船舶检测。</li>\n<li>每张图像都使用YOLO格式手动标注了边界框。</li>\n<li>数据集分为训练集、验证集和测试集，比例为70%、20%和10%。</li>\n</ul>\n</li>\n<li><strong>应用领域</strong>：海事安全、渔业管理、海洋污染监测、国防、海事安全和更多实际应用。</li>\n<li>挑战：<ul>\n<li>目标物体（船舶）相对较小。</li>\n<li>目标物体具有不同的旋转角度，增加了检测难度。</li>\n</ul>\n</li>\n</ul>\n<p>这些数据集在对象检测研究中具有重要意义，因为它们涵盖了不同大小、形状和密度的对象，能够全面评估YOLO算法在不同场景下的性能。</p>\n<h3 id=\"模型\"><a href=\"#模型\" class=\"headerlink\" title=\"模型\"></a>模型</h3><h4 id=\"比较分析：Ultralytics-vs-原始YOLO模型\"><a href=\"#比较分析：Ultralytics-vs-原始YOLO模型\" class=\"headerlink\" title=\"比较分析：Ultralytics vs 原始YOLO模型\"></a>比较分析：Ultralytics vs 原始YOLO模型</h4><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202134407205.png\"></p>\n<p>在Traffic Signs数据集上，对Ultralytics提供的版本和原始模型进行比较分析，使用相同的超参数设置如表V所示。目标是为了强调突出Ultralytics提供的版本和原始模型之间的差异。由于Ultraytics缺乏对YOLO v4、YOLO v6、YOLO v7的支持，因此本文将这几个YOLO版本排除在外了。</p>\n<h5 id=\"Ultralytics支持库中的模型和任务\"><a href=\"#Ultralytics支持库中的模型和任务\" class=\"headerlink\" title=\"Ultralytics支持库中的模型和任务\"></a>Ultralytics支持库中的模型和任务</h5><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202134825220.png\" alt=\"image-20241202134825220\"></p>\n<p>根据表I，Ultralytics库为研究人员和程序员提供了各种YOLO模型，用于推理、验证、训练和导出。我们注意到Ultralytics不支持YOLOv1、YOLOv2、YOLOv4和YOLOv7。对于YOLOv6，库只支持配置文件.yaml，而不支持预训练的.pt模型。</p>\n<h5 id=\"Ultralytics和原始模型的性能比较\"><a href=\"#Ultralytics和原始模型的性能比较\" class=\"headerlink\" title=\"Ultralytics和原始模型的性能比较\"></a>Ultralytics和原始模型的性能比较</h5><p>通过对Ultralytics模型及其原始版本在交通标志数据集上的比较分析，我们观察到Ultralytics版本和原始版本之间存在显著差异。例如，Ultralytics版本的YOLOv5n（nano）和YOLOv3表现优越，突显了Ultralytics所做的增强和优化。相反，原始版本的YOLOv9c（compact）略微优于其Ultralytics版本，可能是由于Ultralytics对该较新模型的优化不足。这些观察结果表明，Ultralytics模型经过了大量修改，直接比较原始版本和Ultralytics版本是不公平和不准确的。因此，本文将专注于Ultralytics支持的版本，以确保基准测试的一致性和公平性。</p>\n<h6 id=\"YOLOv3u\"><a href=\"#YOLOv3u\" class=\"headerlink\" title=\"YOLOv3u\"></a>YOLOv3u</h6><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202135426435.png\" alt=\"image-20241202135426435\"></p>\n<p>YOLOv3基于其前身，旨在提高定位错误和检测效率，特别是对于较小的物体。它使用Darknet-53框架，该框架有53个卷积层，速度是ResNet-152的两倍。YOLOv3还结合了特征金字塔网络（FPN）的元素，如残差块、跳跃连接和上采样，以增强跨不同尺度的物体检测能力。该算法生成三个不同尺度的特征图，以32、16和8的因子对输入进行下采样，并使用三尺度检测机制来检测大、中、小尺寸物体，分别使用不同的特征图。尽管有所改进，YOLOv3在检测中等和大型物体时仍面临挑战，因此Ultralytics发布了YOLOv3u。YOLOv3u是YOLOv3的改进版本，使用无锚点检测方法，并提高了YOLOv3的准确性和速度，特别是对于中等和大型物体。</p>\n<h6 id=\"YOLOv5u\"><a href=\"#YOLOv5u\" class=\"headerlink\" title=\"YOLOv5u\"></a>YOLOv5u</h6><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202135925381.png\" alt=\"image-20241202135925381\"></p>\n<p>YOLOv5由Glenn Jocher提出，从Darknet框架过渡到PyTorch，保留了YOLOv4的许多改进，并使用CSPDarknet作为其骨干。CSPDarknet是原始Darknet架构的修改版本，通过将特征图分成单独的路径来实现更高效的特征提取和减少计算成本。YOLOv5采用步幅卷积层，旨在减少内存和计算成本。此外，该版本采用空间金字塔池化快速（SPPF）模块，通过在不同尺度上池化特征并提供多尺度表示来工作。YOLOv5实现了多种增强，如马赛克、复制粘贴、随机仿射、MixUp、HSV增强和随机水平翻转。Ultralytics通过YOLOv5u积极改进该模型，采用无锚点检测方法，并在复杂物体的不同尺寸上实现了更好的整体性能。</p>\n<h6 id=\"YOLOv8\"><a href=\"#YOLOv8\" class=\"headerlink\" title=\"YOLOv8\"></a>YOLOv8</h6><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140006851.png\" alt=\"image-20241202140006851\"></p>\n<p>Ultralytics引入了YOLOv8，这是YOLO系列的重大进化，包括五个缩放版本。除了物体检测外，YOLOv8还提供了图像分类、姿态估计、实例分割和定向物体检测（OOB）等多种应用。关键特性包括类似于YOLOv5的主干，调整后的CSPLayer（现称为C2f模块），结合了高级特征和上下文信息以提高检测精度。YOLOv8还引入了一个语义分割模型YOLOv8-Seg，结合了CSPDarknet53特征提取器和C2F模块，在物体检测和语义分割基准测试中取得了最先进的结果，同时保持了高效率。</p>\n<h6 id=\"YOLOv9\"><a href=\"#YOLOv9\" class=\"headerlink\" title=\"YOLOv9\"></a>YOLOv9</h6><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140048800.png\" alt=\"image-20241202140048800\"></p>\n<p>YOLOv9由Chien-Yao Wang、I-Hau Yeh和Hong-Yuan Mark Liao开发，使用信息瓶颈原理和可逆函数来在网络深度中保留关键数据，确保可靠的梯度生成并提高模型收敛性和性能。可逆函数可以在不丢失信息的情况下反转，这是YOLOv9架构的另一个基石。这种属性允许网络保持完整的信息流，使模型参数的更新更加准确。此外，YOLOv9提供了五个缩放版本，重点是轻量级模型，这些模型通常欠参数化，并且在前向过程中容易丢失重要信息。可编程梯度信息（PGI）是YOLOv9引入的一项重大进步。PGI是一种在训练期间动态调整梯度信息的方法，通过选择性关注最具信息量的梯度来优化学习效率。通过这种方式，PGI有助于保留可能在轻量级模型中丢失的关键信息。此外，YOLOv9还包括GELAN（梯度增强轻量级架构网络），这是一种新的架构改进，旨在通过优化网络内的计算路径来提高参数利用和计算效率。</p>\n<h6 id=\"YOLOv10\"><a href=\"#YOLOv10\" class=\"headerlink\" title=\"YOLOv10\"></a>YOLOv10</h6><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140137372.png\" alt=\"image-20241202140137372\"></p>\n<p>YOLOv10由清华大学的研究人员开发，基于先前模型的优势进行了关键创新。该架构具有增强的CSP-Net（跨阶段部分网络）主干，以提高梯度流动和减少计算冗余。网络结构分为三部分：主干、颈部和检测头。颈部包括PAN（路径聚合网络）层，用于有效的多尺度特征融合。PAN旨在通过聚合不同层的特征来增强信息流，使网络能够更好地捕捉和结合不同尺度的细节，这对于检测不同大小的物体至关重要。此外，该版本还提供五个缩放版本，从纳米到超大。对于推理，One-to-One Head为每个物体生成单个最佳预测，消除了对非极大值抑制（NMS）的需求。通过移除对NMS的需求，YOLOv10减少了延迟并提高了后处理速度。此外，YOLOv10还包括NMS-Free Training，使用一致的双重分配来减少推理延迟，并优化了从效率和准确性角度的各种组件，包括轻量级分类头、空间-通道解耦下采样和排名引导块设计。此外，该模型还包括大核卷积和部分自注意力模块，以在不显著增加计算成本的情况下提高性能。</p>\n<h6 id=\"YOLO11\"><a href=\"#YOLO11\" class=\"headerlink\" title=\"YOLO11\"></a>YOLO11</h6><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140334746.png\" alt=\"image-20241202140334746\"></p>\n<p>YOLO11是Ultralytics推出的最新创新，基于其前身的发展，特别是YOLOv8。这一迭代提供了从纳米到超大的五种缩放模型，适用于各种应用。与YOLOv8一样，YOLO11包括物体检测、实例分割、图像分类、姿态估计和定向物体检测（OBB）等多种应用。关键改进包括引入C2PSA（跨阶段部分自注意力）模块，结合了跨阶段部分网络和自注意力机制的优势。这使得模型能够在多个层次上更有效地捕获上下文信息，提高物体检测精度，特别是对于小型和重叠物体。此外，在YOLO11中，C2f块被C3k2块取代，C3k2是CSP Bottleneck的自定义实现，使用两个卷积而不是YOLOv8中使用的一个大卷积。这个块使用较小的内核，在保持精度的同时提高了效率和速度。</p>\n<h3 id=\"硬件和软件设置\"><a href=\"#硬件和软件设置\" class=\"headerlink\" title=\"硬件和软件设置\"></a>硬件和软件设置</h3><ul>\n<li>表III：实验的软件设置</li>\n<li>表IV：6个YOLO版本的不同尺寸的模型</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140352257.png\" alt=\"image-20241202140352257\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202140542480.png\" alt=\"image-20241202140542480\"></p>\n<p>总结了用于评估YOLO模型的硬件和软件环境设置。</p>\n<ol>\n<li><strong>软件环境</strong>：实验使用了Python 3.12、Ubuntu 22.04、CUDA 12.5、cuDNN 8.9.7、Ultralytics 8.2.55和WandB 0.17.4等软件包。</li>\n<li><strong>硬件环境</strong>：实验在两块NVIDIA RTX 4090 GPU上进行，每块GPU拥有16,384个CUDA核心。</li>\n<li><strong>数据集处理</strong>：针对交通标志数据集，应用了欠采样技术以确保数据集平衡，并将图像数量从4381减少到3233张。</li>\n<li><strong>训练验证测试分割</strong>：非洲野生动物数据集和船只数据集分别按照70%训练、20%验证和10%测试的比例进行分割。</li>\n<li><strong>模型训练</strong>：实验中训练了23个模型，涵盖了5种不同的YOLO版本，并使用了相似的超参数以确保公平比较。</li>\n<li><strong>模型规模</strong>：交通标志数据集包含24个类别，平均每个类别约100张图像；非洲野生动物数据集包含4个类别，每个类别至少有376张图像；船只数据集专注于单一类别的小型物体检测。</li>\n</ol>\n<h3 id=\"评估指标\"><a href=\"#评估指标\" class=\"headerlink\" title=\"评估指标\"></a>评估指标</h3><p>评估指标包括准确性、计算效率和模型大小三个方面：</p>\n<h4 id=\"准确性指标\"><a href=\"#准确性指标\" class=\"headerlink\" title=\"准确性指标\"></a>准确性指标</h4><ol>\n<li><p><strong>Precision（精确率）</strong>：</p>\n<ul>\n<li>定义：正确预测的观察值与总预测观察值的比率。</li>\n<li>计算公式：$$ \\text{Precision} &#x3D; \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} $$</li>\n<li>其中，TP（True Positives）为真正例，FP（False Positives）为假正例。</li>\n</ul>\n</li>\n<li><p><strong>Recall（召回率）</strong>：</p>\n<ul>\n<li>定义：正确预测的观察值与所有实际观察值的比率。</li>\n<li>计算公式：$$ \\text{Recall} &#x3D; \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} $$</li>\n<li>其中，FN（False Negatives）为假反例。</li>\n</ul>\n</li>\n<li><p><strong>mAP50（Mean Average Precision at an IoU threshold of 0.50）</strong>：</p>\n<ul>\n<li>定义：在IoU（Intersection over Union）阈值为0.50时的平均精度均值。</li>\n<li>计算公式：$$ \\text{mAP50} &#x3D; \\frac{1}{|C|} \\sum_{c \\in C} \\text{AP}_c $$</li>\n<li>其中，$C$ 是类别集合，$\\text{AP}_c$ 是类别 $c$ 的平均精度。</li>\n</ul>\n</li>\n<li><p><strong>mAP50-95（Mean Average Precision across IoU thresholds from 0.50 to 0.95）</strong>：</p>\n<ul>\n<li>定义：在IoU阈值从0.50到0.95范围内的平均精度均值。</li>\n<li>计算公式：$$ \\text{mAP50-95} &#x3D; \\frac{1}{15} \\sum_{r&#x3D;1}^{15} \\text{AP}_{0.50 + \\frac{r-1}{14} \\times 0.05} $$</li>\n<li>其中，$r$ 表示IoU阈值的范围。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"计算效率指标\"><a href=\"#计算效率指标\" class=\"headerlink\" title=\"计算效率指标\"></a>计算效率指标</h4><ol>\n<li><p><strong>Preprocessing Time（预处理时间）</strong>：</p>\n<ul>\n<li>定义：准备原始数据以输入模型所需的持续时间。</li>\n</ul>\n</li>\n<li><p><strong>Inference Time（推理时间）</strong>：</p>\n<ul>\n<li>定义：模型处理输入数据并生成预测所需的持续时间。</li>\n</ul>\n</li>\n<li><p><strong>Postprocessing Time（后处理时间）</strong>：</p>\n<ul>\n<li>定义：将模型的原始预测转换为最终可用格式所需的时间。</li>\n</ul>\n</li>\n<li><p><strong>Total Time（总时间）</strong>：</p>\n<ul>\n<li>定义：预处理时间、推理时间和后处理时间的总和。</li>\n</ul>\n</li>\n<li><p><strong>GFLOPs（Giga Floating-Point Operations Per Second）</strong>：</p>\n<ul>\n<li>定义：模型训练的计算能力，反映其效率。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"模型大小指标\"><a href=\"#模型大小指标\" class=\"headerlink\" title=\"模型大小指标\"></a>模型大小指标</h4><ol>\n<li><strong>Size（大小）</strong>：<ul>\n<li>定义：模型的实际磁盘大小及其参数数量。</li>\n</ul>\n</li>\n</ol>\n<p>这些指标提供了对YOLO模型性能的全面概述，有助于在不同真实世界场景中选择最优的YOLO算法。</p>\n<h1 id=\"实验结果和讨论\"><a href=\"#实验结果和讨论\" class=\"headerlink\" title=\"实验结果和讨论\"></a>实验结果和讨论</h1><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142033886.png\" alt=\"image-20241202142033886\"></p>\n<h3 id=\"实验结果\"><a href=\"#实验结果\" class=\"headerlink\" title=\"实验结果\"></a>实验结果</h3><h4 id=\"交通信号数据集\"><a href=\"#交通信号数据集\" class=\"headerlink\" title=\"交通信号数据集\"></a>交通信号数据集</h4><p>YOLO模型在检测交通标志方面的有效性，展示了各种精度范围。最高的mAP50-95为0.799，而最低的精度为0.64。另一方面，最高的mAP50为0.893，而最低的为0.722。mAP50和mAP50-95之间的显著差距表明，模型在处理不同大小的交通标志时，在较高阈值下遇到了困难，这反映了其检测算法中潜在的改进领域。</p>\n<p>a) 准确性：如图8所示，YOLOv5ul展示了最高的准确性，实现了mAP50为0.866和mAP50-95为0.799。紧随其后的是YOLO11m，其mAP50-95为0.795，YOLO11l的mAP50-95为0.794。相比之下，YOLOv10n展示了最低的精度，其mAP50为0.722，mAP50-95为0.64，紧随其后的是YOLOv5un，其mAP50-95为0.665，如数据点在图8中所证明的。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142326776.png\" alt=\"image-20241202142326776\"></p>\n<p>b) 精度和召回率：图9阐明了考虑模型大小的情况下精度和召回率之间的权衡。像YOLO11m、YOLO10l、YOLOv9m、YOLOv5ux和YOLO111这样的模型展示了高精度和召回率，特别是YOLO11m实现了0.898的精度和0.826的召回率，同时模型大小为67.9Mb，而YOLOv10l实现了0.873的精度和0.807的召回率，但模型大小显著更大（126.8 Mb）。相比之下，较小的模型如YOLOv10n（精度0.722，召回率0.602）、YOLOv8n（精度0.749，召回率0.688）和YOLO11n（精度0.768，召回率0.695）在两个指标上都表现不佳。这突显了较大模型在交通标志数据集上的优越性能。此外，YOLOv5um的高精度（0.849）和低召回率（0.701）表明了对假阴性的倾向，而YOLOv3u的高召回率（0.849）和低精度（0.75）则表明了对假阳性的倾向。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142423060.png\" alt=\"image-20241202142423060\"></p>\n<p>c) 计算效率：在计算效率方面，YOLOv10n是最有效的，每张图片的处理时间为2ms，GFLOPs计数为8.3，如图10和11所示。YOLO11n紧随其后，处理时间为2.2ms，GFLOPs计数为6.4，而YOLOv3u-tiny的处理时间为2.4ms，GFLOPs计数为19，与其他快速模型相比，这使得它在计算上相对低效。然而，数据显示YOLOv9e、YOLOv9m、YOLOv9c和YOLOv9s是效率最低的，推理时间分别为16.1ms、12.1ms、11.6ms和11.1ms，GFLOPs计数分别为189.4、76.7、102.6和26.8。这些发现描绘了一个明显的权衡，即在精度和计算效率之间。</p>\n<p>d) 整体性能：在评估整体性能时，包括准确性、大小和模型效率，YOLO11m作为一个一致的表现最佳的模型脱颖而出。它实现了mAP50-95为0.795，推理时间为2.4ms，模型大小为38.8Mb，GFLOPs计数为67.9，如图8、10、11和表VI中详细说明的。紧随其后的是YOLO111（mAP50-95为0.794，推理时间为4.6ms，大小为49Mb，GFLOPs计数为86.8）和YOLOv10m（mAP50-95为0.781，推理时间为2.4ms，大小为32.1Mb，63.8 GFLOPs计数）。这些结果突显了这些模型在检测各种大小的交通标志方面的稳健性，同时保持了较短的推理时间和较小的模型大小。值得注意的是，YOLO11和YOLOv10家族在准确性和计算效率方面显著优于其他YOLO家族，因为它们的模型在这些数据集上一致超越了其他家族的对应物。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142515870.png\" alt=\"image-20241202142515870\"></p>\n<h4 id=\"非洲野生动物数据集\"><a href=\"#非洲野生动物数据集\" class=\"headerlink\" title=\"非洲野生动物数据集\"></a>非洲野生动物数据集</h4><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142815914.png\" alt=\"image-20241202142815914\"></p>\n<p>表 VII 展示了 YOLO 模型在非洲野生动物数据集上的性能。该数据集包含大型物体尺寸，重点关注 YOLO 模型预测大型物体的能力以及由于数据集大小而导致过拟合的风险。模型在各个方面的准确性都表现出色，最高性能的模型 mAP50-95 范围从 0.832 到 0.725。这个相对较短的范围反映了模型在检测和分类大型野生动物物体时保持高准确性的有效性。</p>\n<p>a) 准确性：如图 12 所示，YOLOv9s 展现了出色的性能，具有高达 0.832 的 mAP50-95 和 0.956 的 mAP50，展示了其在各种 IoU 阈值下的稳健准确性。YOLOv9c 和 YOLOv9t 紧随其后，mAP50 分数分别为 0.96 和 0.948，召回率分别为 0.896。值得注意的是，YOLOv8n 实现了 mAP50-95 得分分别为 0.83 和 0.825。这些结果突出了 YOLOv9 系列从少量图像样本中有效学习模式的能力，使其特别适合于较小型的数据集。相比之下，YOLOv5un、YOLOv10n 和 YOLOv3u-tiny 显示出较低的 mAP50-95 得分，分别为 0.791、0.786 和 0.725，表明它们在准确性方面的局限性。较大的模型如 YOLO11x、YOLOv5ux、YOLOv5ul 和 YOLOv10l 的表现不佳，可以归因于过拟合，特别是考虑到数据集规模较小。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142853898.png\" alt=\"image-20241202142853898\"></p>\n<p>b) 精度和召回率：图 13 表明 YOLO8l 和 YOLO111 实现了最高的精度和召回率，精度值分别为 0.942 和 0.937，召回率分别为 0.898 和 0.896。值得注意的是，YOLOv8n 实现了 0.932 的精度和 0.908 的召回率。总体而言，YOLOv8l 和 YOLO111 在精度和召回率方面表现最佳，YOLOv8n 的表现也相当出色。然而，YOLOv11 模型倾向于产生误报，这反映在其较低的精度和较高的召回率上。与此同时，YOLOv10 在精度和召回率方面的表现均不佳，尽管它是 YOLO 系列中最新的模型之一。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202142924537.png\" alt=\"image-20241202142924537\"></p>\n<p>c) 计算效率：如图 14 和 15 所示，YOLOv10n、YOLOv8n 和 YOLOv3u-tiny 是最快的模型，处理时间分别为 2ms 和 1.8ms，GFLOPs 计数分别为 8.2 和 19.1。前两个模型具有相同的处理速度和 GFLOPs 计数，如表 VII 中所示。相比之下，YOLOv9e 展现了最慢的处理时间，为 11.2ms，GFLOPs 计数为 189.3，其次是 YOLOv5ux，处理时间为 7.5ms，GFLOPs 计数为 246.2 GFLOPs 计数。这些结果表明，较大的模型通常需要更多的处理时间和硬件资源，强调了模型大小和处理效率之间的权衡。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143004149.png\" alt=\"image-20241202143004149\"></p>\n<p>d) 整体性能：表 VII 和图 13、14 和 15 中的结果表明，YOLOv9t 和 YOLOv9s 在各个指标上持续表现出色，提供高准确性，同时保持较小的模型大小、低 GFLOPs 和短的处理时间，展示了 YOLOv9 较小型模型的稳健性及其在小数据集上的有效性。相比之下，YOLO5ux 和 YOLO11x 尽管具有较大的尺寸和较长的推理时间，但准确性表现不佳，可能是由于过拟合所致。大多数大型模型在这个数据集上的表现都不尽如人意，YOLOv10x 是一个例外，得益于现代架构防止过拟合，表现优异。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143030167.png\" alt=\"image-20241202143030167\"></p>\n<h4 id=\"船只和船舶数据集：\"><a href=\"#船只和船舶数据集：\" class=\"headerlink\" title=\"船只和船舶数据集：\"></a>船只和船舶数据集：</h4><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143313627.png\" alt=\"image-20241202143313627\"></p>\n<p>表 VIII 展示了 YOLO 模型在船只和船舶数据集上的性能，这是一个包含微小物体且旋转变化多样的大型数据集。总体而言，模型在检测船只和船舶方面表现出中等效果，mAP50-95 的范围从 0.273 到 0.327。这一表现表明 YOLO 算法在准确检测较小物体方面可能面临挑战，数据集中物体尺寸和旋转的多样性为测试模型能力提供了全面的测试。</p>\n<p>a) 准确性：图 16 中 mAP50-95 和 mAP50 之间的差异凸显了 YOLO 模型在检测小物体时面临的挑战，尤其是在更高的 IoU 阈值下。此外，YOLO 模型在检测不同旋转的物体时也遇到困难。在各个模型中，YOLO11x 实现了最高的准确性，mAP50 为 0.529，mAP50-95 为 0.327，紧随其后的是 YOLO111、YOLO11m 和 YOLO11s，它们记录的 mAP50 值分别为 0.529、0.528 和 0.53，mAP50-95 值分别为 0.327、0.325 和 0.325。这些结果突出了 YOLO11 系列在检测小型和微小物体方面的稳健性。相比之下，YOLOv3u-tiny、YOLOv8n、YOLOv3u 和 YOLOv5n 展示了最低的准确性，mAP50 分数分别为 0.489、0.515、0.519 和 0.514，mAP50-95 分数分别为 0.273、0.297、0.298 和 0.298。这表明 YOLOv3u 的过时架构以及由于数据集规模较大而导致的小型模型的潜在欠拟合。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143334789.png\" alt=\"image-20241202143334789\"></p>\n<p>b) 精度和召回率：图 17 表明 YOLOv5ux 的表现优于其他模型，实现了 0.668 的精度和 0.555 的召回率。它紧随其后的是 YOLOv9m（精度为 0.668，召回率为 0.551）和 YOLOv8m（精度为 0.669，召回率为 0.525），两者在尺寸上显著较小（YOLOv9m 为 40.98 Mb，YOLOv8m 为 52.12 Mb）。相比之下，YOLO11n 和 YOLOv10s 表现较差，精度分别为 0.574 和 0.586，召回率分别为 0.51 和 0.511，这可能是由于欠拟合问题。总体而言，YOLO11 模型倾向于产生误报，这反映在其较低的精度和较高的召回率上。与此同时，YOLOv10 在精度和召回率方面的表现均不佳，尽管它是 YOLO 系列中最新的模型之一。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143403226.png\" alt=\"image-20241202143403226\"></p>\n<p>c) 计算效率：如图 18 和 19 所示，YOLOv3u-tiny 实现了最快的处理时间，为 2 毫秒，紧随其后的是 YOLOv8n 和 YOLOv5un，两者均记录了 2.3 毫秒。YOLOv10 和 YOLO11 模型也在速度上表现出色，YOLOv10n 和 YOLO11n 分别实现了 2.4 毫秒和 2.5 毫秒的快速推理时间，以及 8.2 和 6.3 的 GFLOPs 计数。相比之下，YOLOv9e 展现了最慢的速度，推理时间为 7.6 毫秒，GFLOPs 计数为 189.3，突显了 YOLOv9 系列在准确性和效率之间的权衡。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143422503.png\" alt=\"image-20241202143422503\"></p>\n<p>d) 整体性能：表 VIII 和图 16、17 和 18 中的结果表明，YOLO11s 和 YOLOv10s 在准确性方面表现优异，同时保持了紧凑的尺寸、低 GFLOPs 和快速的处理时间。相比之下，YOLOv3u、YOLOv8x 和 YOLOv8l 未能达到预期，尽管它们的尺寸较大且处理时间较长。这些发现突出了 YOLO11 系列的稳健性和可靠性，特别是在提高 YOLO 系列检测小型和微小物体的性能方面，同时确保高效处理。此外，结果还揭示了 YOLOv9 模型在面对大型数据集和小物体时的表现不佳，尽管它们具有现代架构。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143442543.png\" alt=\"image-20241202143442543\"></p>\n<h3 id=\"讨论\"><a href=\"#讨论\" class=\"headerlink\" title=\"讨论\"></a>讨论</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241202143815028.png\" alt=\"image-20241202143815028\"></p>\n<p>基于三个数据集上模型的性能，我们按准确性、速度、GFLOps 计数和大小对它们进行了排名，如表 IX 所示，以便进行全面评估。对于准确性，由于 mAP50-95 指标能够评估模型在一系列 IoU 阈值下的表现，因此我们采用了该指标。对于速度，模型根据总处理时间进行排序，总处理时间包括预处理、推理和后处理持续时间。排名范围从第 1 名（表示最高性能）到第 28 名（表示最低性能），表中的相应排名已加粗显示。</p>\n<p>表 IX 的分析得出了几个关键观察结果：</p>\n<ol>\n<li>准确性：YOLO11m 一致地成为顶级表现者，经常位居前列，紧随其后的是 YOLOv10x、YOLO111、YOLOv9m 和 YOLO11x。这突显了 YOLO11 系列在各种 IoU 阈值和物体大小下的稳健性能，这可以归因于它们使用 C2PSA 来保留上下文信息，从而提高了收敛性和整体性能。此外，大核卷积和部分自注意力模块的实施有助于提高算法的性能。</li>\n</ol>\n<p>相比之下，YOLOv3u-tiny 展现了最低的准确性，特别是在非洲野生动物和船只及船舶数据集上，YOLOv5un 和 YOLOv8n 的表现稍好但仍不理想。这表明 YOLO11 模型目前是要求高准确性的应用中最可靠的。</p>\n<p>紧随 YOLO11 系列之后，YOLOv9 模型在检测各种大小和不同 IoU 阈值的物体方面表现出色。然而，它们可能在检测小物体时遇到困难，这在船只和船舶数据集上可见。相比之下，YOLOv10 系列尽管推出较晚，但在交通标志和非洲动物数据集上的准确性相对较低，导致平均准确性下降了 2.075%，这可以归因于它们采用一对一头部方法而不是非极大值抑制（NMS）来定义边界框。这种策略在捕捉物体时可能会遇到困难，特别是在处理重叠物品时，因为它依赖于每个物体的单个预测。这一限制有助于解释第二个数据集中观察到的相对较差的结果。</p>\n<p>YOLOv3u 的过时架构也导致了其性能不佳，平均准确性比 YOLO11 模型低 6.5%。这种下降可以追溯到其对 2018 年首次引入的较旧 Darknet-53 框架的依赖，该框架可能无法充分应对当代检测挑战。</p>\n<ol start=\"2\">\n<li>计算效率：YOLOv10n 在速度和 GFLOPs 计数方面始终表现优异，在所有三个数据集上均名列前茅，在速度方面排名第 1，在 GFLOPs 计数方面排名第 5。YOLOv3u-tiny、YOLOv10s 和 YOLO11n 也展示了显著的计算效率。</li>\n</ol>\n<p>YOLOv9e 展现了最慢的推理时间和非常高的 GFLOPs 计数，突显了准确性与效率之间的权衡。YOLO11 的速度提升可归因于它们使用的 C3k2 块，使其适用于需要快速处理的场景，超过了 YOLOv10 和 YOLOv9 模型，分别在速度上平均快了 %1.41 和 %31。</p>\n<p>虽然 YOLOv9 模型在准确性方面表现出色，但它们的推理时间却是最慢的，使它们不太适合对时间敏感的应用。相比之下，YOLOv10 模型虽然略慢于 YOLO11 变体，但仍提供了效率与速度之间的值得称赞的平衡。它们的表现非常适合时间敏感的场景，提供快速处理而不显著牺牲准确性，使它们成为实时应用的可行选择。</p>\n<ol start=\"3\">\n<li>模型大小：YOLOv9t 是最小的模型，在所有三个数据集上均排名第一，其次是 YOLO11n 和 YOLOv10n。这种模型大小的效率突显了较新 YOLO 版本，特别是 YOLOv10，在高效参数利用方面的进步，实施了空间-通道解耦下采样。</li>\n</ol>\n<p>YOLOv3u 是最大的模型，突显了与其更现代的对应物相比，它的效率低下。</p>\n<ol start=\"4\">\n<li>整体性能：考虑到准确性、速度、大小和 GFLOPs，YOLO11m、YOLOv11n、YOLO11s 和 YOLOv10s 成为最一致的表现者。它们实现了高准确性、低处理时间和功率以及高效的磁盘使用，使其适用于广泛的应用，其中速度和准确性都至关重要。</li>\n</ol>\n<p>相反，YOLOv9e、YOLOv5ux 和 YOLOv3u 在所有指标上的表现都较差，计算效率低下且相对于其大小表现不佳。YOLO11 模型显示出最佳的整体性能，可能是由于最近的增强功能，如 C3k2 块和 C2PSA 模块。紧随其后的是 YOLOv10 模型，尽管在准确性方面略有逊色，但由于其一对一头部用于预测的实施，在效率方面表现出色。虽然 YOLOv9 在计算效率方面表现不佳，但它在准确性方面仍然具有竞争力，这要归功于其 PGI 集成。这使 YOLOv9 成为优先考虑精度而非速度的应用的可行选择。</p>\n<p>此外，YOLOv8 和 YOLOv5u 展示了竞争性结果，超过了 YOLOv3u 的准确性，这可能是由于 YOLOv3u 的较旧架构。然而，它们的准确性仍然显著低于较新的模型，如 YOLOv9、YOLOv10 和 YOLO11。虽然 YOLOv8 和 YOLOv5u 的处理时间比 YOLOv9 快，但它们的整体表现仍然不如较新的模型。</p>\n<ol start=\"5\">\n<li>物体大小和旋转检测：YOLO 算法在检测大中型物体方面效果很好，如非洲野生动物和交通标志数据集所证明的那样，准确性很高。然而，它在检测小物体方面存在困难，可能是由于将图像划分为网格，使得识别小而分辨率低的物体变得具有挑战性。此外，YOLO 在处理不同旋转的物体时也面临挑战，因为无法包围旋转物体，导致整体结果不佳。</li>\n</ol>\n<p>为了处理旋转物体，可以实现像 YOLO11 OBB[26] 和 YOLOv8 OBB[25]（定向边界框）这样的模型。保持与标准 YOLOv8 和 YOLO11 相同的基础架构，YOLOv8 OBB 和 YOLO11 OBB 用预测旋转矩形四个角点的头部替换了标准边界框预测头部，允许更准确的定位和表示任意方向的物体。</p>\n<ol start=\"6\">\n<li><p>YOLO11 对 YOLOv8 的崛起：尽管 YOLOv8[25] 因其在姿态估计、实例分割和定向物体检测（OBB）任务中的多功能性而成为算法的首选，但 YOLO11[26] 已经成为一个更高效和准确的替代品。通过处理相同任务的同时提供改进的上下文理解和更好的架构模块，YOLO11 设定了新的性能标准，在各种应用中的速度和准确性方面都超过了 YOLOv8。</p>\n</li>\n<li><p>数据集大小：数据集的大小显著影响 YOLO 模型的性能。例如，大型模型在小型非洲野生动物数据集上的表现不如在交通标志和船只及船舶数据集上的表现，因为它们更容易过拟合。相反，像 YOLOv9t 和 YOLOv9s 这样的小模型在非洲野生动物数据集上的表现显著更好，展示了小规模模型在处理有限数据集时的有效性。</p>\n</li>\n<li><p>训练数据集的影响：如表 VI、VII 和 VIII 所示，YOLO 模型的性能受到所使用的训练数据集的影响。不同的数据集产生不同的结果和顶尖表现者，表明数据集复杂性影响算法性能。这突显了在基准测试期间使用多样化数据集以获得每个模型优缺点全面结果的重要性。</p>\n</li>\n</ol>\n<p>这次讨论强调了在选择 YOLO 模型进行特定应用时，需要平衡考虑准确性、速度和模型大小。YOLO11 模型在各个指标上的一致表现使它们非常适合于需要准确性和速度的多功能场景。同时，YOLOv10 模型可以在保持更快处理时间和更小模型大小的同时，类似地执行。此外，YOLOv9 可以在准确性方面提供可比的结果，但牺牲了速度，使其适用于优先考虑精度而非快速处理的应用。</p>\n<h1 id=\"结论\"><a href=\"#结论\" class=\"headerlink\" title=\"结论\"></a>结论</h1><p>这项基准研究全面评估了各种 YOLO 算法的性能。它是首个对 YOLO11 及其前辈进行全面比较的研究，评估了它们在三个多样化数据集上的表现：交通标志、非洲野生动物和船只及船舶。这些数据集经过精心挑选，包含了广泛的物体属性，包括不同的物体大小、宽高比和物体密度。我们通过检查精度、召回率、平均精度均值（mAP）、处理时间、GFLOPs 计数和模型大小等一系列指标，展示了每个 YOLO 版本和家族的优势和劣势。我们的研究解决了以下关键研究问题：</p>\n<p>● 哪个 YOLO 算法在一系列综合指标上展示了卓越的性能？</p>\n<p>● 不同的 YOLO 版本在具有不同物体特征（如大小、宽高比和密度）的数据集上的表现如何？</p>\n<p>● 每个 YOLO 版本的具体优势和局限性是什么，这些见解如何指导选择最适合各种应用的算法？</p>\n<p>特别是，YOLO11 系列作为最一致的表现在各个指标上脱颖而出，YOLO11m 在准确性、效率、模型大小之间取得了最佳平衡。虽然 YOLOv10 的准确性略低于 YOLO11，但它在速度和效率方面表现出色，使其成为需要效率和快速处理的应用的强有力选择。此外，YOLOv9 总体上也表现良好，特别是在较小的数据集上表现尤为突出。这些发现为工业界和学术界提供了宝贵的见解，指导选择最适合的 YOLO 算法，并为未来的发展和改进提供信息。虽然评估的算法展示了有希望的性能，但仍有一些改进的空间。未来的研究可以专注于优化 YOLOv10，以提高其准确性，同时保持其速度和效率优势。此外，架构设计的持续进步可能为更突破性的 YOLO 算法铺平道路。我们未来的工作包括深入研究这些算法中确定的差距，并提出改进措施，以展示它们对整体效率的潜在影响。</p>\n<h1 id=\"其它问题\"><a href=\"#其它问题\" class=\"headerlink\" title=\"其它问题\"></a>其它问题</h1><ul>\n<li><strong>在交通标志数据集上，YOLOv5ul和YOLOv10n的性能差异是什么？原因是什么？</strong></li>\n</ul>\n<p>在交通标志数据集上，YOLOv5ul的mAP50-95达到了0.799，而YOLOv10n的mAP50-95仅为0.64，相差显著。YOLOv5ul在精度和召回率上都表现更好，具体来说，YOLOv5ul的Precision为0.866，Recall为0.849，而YOLOv10n的Precision为0.722，Recall为0.602。这种差异的原因可能包括：</p>\n<ol>\n<li><strong>模型架构改进</strong>：YOLOv5ul采用了更先进的CSPDarknet53作为主干网络，并引入了Spatial Pyramid Pooling Fast（SPPF）模块，这些改进提高了模型的特征提取能力和多尺度适应性。</li>\n<li><strong>数据增强</strong>：YOLOv5ul使用了多种数据增强技术，如Mosaic、Copy-Paste、Random Affine等，这些技术有助于提高模型的泛化能力和鲁棒性。</li>\n<li><strong>优化策略</strong>：YOLOv5ul在训练过程中使用了更有效的优化策略，如AdamW优化器和学习率调度，这些策略有助于模型更快地收敛和提高性能。</li>\n</ol>\n<ul>\n<li><strong>在船舶与船只数据集上，YOLOv11x为什么表现最好？与其他模型相比有哪些优势？</strong></li>\n</ul>\n<p>​\t在船舶与船只数据集上，YOLOv11x的mAP50-95达到了0.327，表现最好。与其他模型相比，YOLOv11x有以下优势：</p>\n<ol>\n<li><strong>小对象检测</strong>：YOLOv11x特别适用于检测小对象，能够在复杂的图像环境中准确识别和定位小尺寸的船只。</li>\n<li><strong>架构改进</strong>：YOLOv11x引入了C3k2块和C2PSA（Cross-Stage Partial with Self-Attention）模块，这些改进提高了模型的空间注意力和特征提取能力，特别是在处理重叠和小的对象时表现优异。</li>\n<li><strong>计算效率</strong>：尽管YOLOv11x在精度上有所提升，但其推理时间仍然保持在2.4ms左右，保持了较高的计算效率，适合实时应用。</li>\n</ol>\n<ul>\n<li><p><strong>在非洲野生动物数据集上，YOLOv9s的表现优于其他模型的原因是什么？</strong></p>\n<p>在非洲野生动物数据集上，YOLOv9s的mAP50-95达到了0.832，表现优于其他模型。YOLOv9s之所以表现优异，主要原因包括：</p>\n<ol>\n<li><strong>小型数据集适应性</strong>：YOLOv9s在小型数据集上表现出色，能够有效学习对象的模式。其小型模型（如YOLOv9t）在非洲野生动物数据集上表现尤为突出，mAP50-95为0.832，mAP50为0.956。</li>\n<li><strong>特征提取能力</strong>：YOLOv9s采用了CSPNet（Cross-Stage Partial Network），这种结构通过分割特征图来提高特征提取效率，减少了计算复杂度。</li>\n<li><strong>正则化技术</strong>：YOLOv9s使用了GelAN（Gradient Enhanced Lightweight Architecture Network），这种技术通过优化网络内的计算路径，提高了参数利用率和计算效率。</li>\n</ol>\n</li>\n</ul>\n<p><a href=\"https://arxiv.org/html/2411.00201v1\">Evaluating the Evolution of YOLO (You Only Look Once) Models: A Comprehensive Benchmark Study of YOLO11 and Its Predecessors</a></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"二维码\"></p>\n"},{"title":"MiniCPM详解","date":"2024-12-19T16:00:00.000Z","_content":"\n\n\n“MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies” 由清华大学和 Modelbest Inc. 的众多研究人员共同撰写，介绍了 MiniCPM 系列小型语言模型，包括模型架构、训练方法、实验结果等，展现了其在模型和数据维度的可扩展性，以及在小型语言模型中的优势。\n\n## 1. 研究背景\n\n### 1.1 之前研究存在的问题\n\n近年来，大型语言模型（LLMs）如GPT-3、PaLM等在自然语言处理领域取得了显著的进展。这些模型通常拥有数十亿甚至上万亿的参数，能够处理复杂的任务并展现出强大的泛化能力。然而，训练和部署这些大型模型面临着巨大的资源消耗和成本问题。例如，训练一个万亿参数的模型需要大量的计算资源和能源，且在实际应用中，这些模型的部署也面临着效率和可行性的挑战。\n\n### 1.2 研究难点\n\n尽管大型模型的性能令人印象深刻，但其高昂的训练成本和资源消耗使得许多研究者和企业难以负担。此外，这些模型在实际应用中的部署也面临着诸多限制，尤其是在资源受限的设备上，如个人电脑或智能手机。因此，如何在不牺牲性能的前提下，开发出资源效率更高的小型语言模型（SLMs）成为了当前研究的一个重要方向。\n\n### 1.3 相关工作总结\n\n近年来，小型语言模型（SLMs）的研究逐渐受到关注。一些研究者提出了通过数据优化、模型剪枝和架构重构等方法来提升SLMs的性能。例如，Phi系列、TinyLlama、MobileLLM等模型通过高质量数据和结构优化，展示了SLMs在特定任务上的潜力。然而，这些模型在综合能力上仍然难以与大型模型相媲美，且缺乏透明和可扩展的训练方法。\n\n## 2. 研究方法\n\n### 2.1 模型风洞实验\n\n#### Scaling Hyper-parameters Invariant LM\n\nScaling Hyper-parameters Invariant LM（缩放超参数不变的语言模型）是一种旨在通过调整模型的超参数来实现不同规模模型的性能稳定的方法。这种方法的核心思想是利用Tensor Program框架中的宽度缩放和深度缩放技术，以预测大型语言模型（LLMs）的损失，并确保在不同规模的模型上获得最佳的学习率。\n\n在MiniCPM中，作者采用了Tensor Program的这两种缩放技术：\n\n1. **宽度缩放（Width Scaling）**：这种技术通过调整模型的隐藏层维度来改变模型的宽度。在MiniCPM中，宽度缩放被应用于所有模型，包括MiniCPM-1.2B和MiniCPM-2.4B。\n\n2. **深度缩放（Depth Scaling）**：这种技术通过增加模型的层数来改变模型的深度。尽管Yang等人在2023年的研究中观察到，当网络块深度大于2时，深度缩放的效果不理想，但作者在实践中发现，对于MiniCPM模型，深度缩放仍然能够带来稳定的学习率。\n\n此外，作者没有采用注意力softmax缩放技术，因为他们在实践中发现，即使不使用这种技术，模型的学习率仍然是稳定的。\n\n通过这些缩放技术，MiniCPM能够在不同规模的模型上实现超参数的稳定性和一致性，从而提高模型的训练效率和性能。\n\n![image-20241223141035777](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223141035777.png)\n\n![image-20241223141106997](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223141106997.png)\n\n#### 最优批量大小\n\n在\"3.2 Optimal Batch Size\"部分，论文探讨了批量大小（batch size）对模型训练的影响以及如何确定最佳的批量大小。批量大小决定了模型在每次迭代中处理的数据量，它直接影响模型的收敛速度和计算资源的消耗。以下是该部分的几个主要观点：\n\n1. **批量大小与收敛速度和资源消耗的平衡**：\n   - 如果批量大小过大，会导致大量的数据和计算成本。\n   - 如果批量大小过小，则需要更多的训练步骤，可能导致损失函数下降有限。\n\n2. **实验设置**：\n   - 论文在三个不同大小的模型上进行了实验：0.009B、0.03B 和 0.17B。\n   - 每个模型在六个不同的批量大小上进行训练，全局学习率为0.01，使用余弦学习率调度器。\n\n3. **观察到的趋势**：\n   - 批量大小与损失之间的关系显示，随着损失的减少，最佳批量大小会增大。\n   - 通过拟合等损失点，发现批量大小与损失之间存在线性关系。\n\n4. **公式推导**：\n   - 论文提出了一个公式来描述批量大小（bs）与C4数据集上的损失（L）之间的关系：\n     $$\n     bs=\\frac{1.21\\times10^{9}}{L^{6.24}}\n     $$\n\n总的来说，论文通过实验和分析，展示了如何根据预期的损失来确定最佳批量大小，并提出了一个基于损失预测的批量大小估计方法。\n\n![image-20241223141919897](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223141919897.png)\n\n#### 最优学习率\n\n由于我们使用了张量程序（Yang等人，2022年；2023年），我们预计学习率在模型扩展期间不会发生显著变化。为了验证这一点，我们在0.04B、0.1B、0.3B和0.5B的六个学习率实验中进行测试。在图3中，我们发现尽管模型大小增加了十倍，最优基础学习率2并没有明显变化，保持在大约0.01左右。我们进一步在2.1B的规模上进行简单验证，确认0.01的学习率确实实现了最低损失。\n\n\n\n![图3：损失与学习率的关系。在应用张量程序后，学习率的变动变得非常小。](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/ffd302f2750f29d6e75e666fa43c51a3-image.png)\n\n\n\n### 2.2 WSD 学习率调度器（LRS）\n\n#### 分析 Cosine LRS\n\n![图4：具有不同周期的余弦学习率调度器。Y轴是C4语料库上的损失。](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/96d5f382f6d650b0f98f618576276f19-image.png)\n\n在\"4.1 Analysing Cosine LRS\"小节中，论文分析了余弦学习率调度器（Cosine LRS）的关键特性和其对模型性能的影响。以下是该小节的主要内容：\n\n1. **余弦学习率调度器的基本原理**：\n   - 余弦学习率调度器（Cosine LRS）是一种常用的学习率调整策略，它在训练过程中逐渐降低学习率，遵循余弦曲线的变化。具体来说，学习率在预热阶段达到最大值后，按照余弦函数的形状逐渐下降。\n\n2. **关键超参数**：\n   - 余弦学习率调度器的一个关键超参数是步长 $T$，即余弦函数首次降到最小值的时间点。通常，$T$ 被设置为总训练步数 $S$。\n\n3. **实验验证**：\n   - 论文通过在0.036B模型上进行实验，验证了不同 $T$ 值对学习率调度器性能的影响。实验结果表明，当 $T=S$ 时，模型的损失最低。这表明在整个训练过程中保持较高的学习率有助于模型找到更好的全局最优解。\n   - 当 $T<S$ 或 $T>S$ 时，模型的性能不如 $T=S$ 时的表现。特别是，$T>S$ 会导致性能下降。\n\n4. **假设分析**：\n   - 论文提出了两个假设来解释为什么 $T=S$ 时余弦学习率调度器表现优异：\n     1. 当 $T=S$ 时，高学习率训练的持续时间更长，这有助于模型找到更好的全局最优解。\n     2. 当 $T=S$ 时，学习率衰减阶段更为彻底，这可能涉及独特的训练动态，使模型能够找到更好的局部最优解。\n\n5. **实验结果**：\n   - 实验结果显示，在 $T=S$ 时，余弦学习率调度器的性能最佳。具体来说，当训练步数为 $S=20N, 40N, 60N, 80N$ 时，损失总是由 $\\operatorname{Cosine}(T)$ 达到最低，而不是 $\\operatorname{Cosine}(T)$ 或 $\\operatorname{CosineLoop}(T)$。\n\n通过这些分析，论文强调了余弦学习率调度器在特定条件下（即 $T=S$）的优越性，并为后续提出的WSD（Warmup-Stable-Decay）学习率调度器奠定了基础。\n\n#### 提出 WSD LRS\n\n在\"4.2 WSD LRS\"小节中，论文提出了一种新的学习率调度器，称为Warmup-Stable-Decay (WSD) 学习率调度器。以下是该小节的主要内容：\n\n\n\n##### 引言\n- **背景**：现有的学习率调度器（如Cosine LRS）在训练过程中逐渐降低学习率，但在某些情况下，可能需要更灵活的调度策略来优化模型性能。\n- **目标**：提出一种新的学习率调度器，能够在训练的不同阶段有效地调整学习率，以提高模型的训练效率和性能。\n\n##### WSD LRS的定义\n- **定义**：WSD LRS将训练过程分为三个阶段：预热阶段（Warmup）、稳定阶段（Stable）和衰减阶段（Decay）。\n- **公式**：\n  $$\n  WSD(T; s)=\\left\\{\\begin{array}{l}\n  \\frac{s}{W}\\eta,\\quad s<W\\\\\n  \\eta,\\quad W<s<T\\\\\n  f(s-T)\\eta,\\quad T<s<S\n  \\end{array}\\right.\n  $$\n  其中，$0<f(s-T)\\leq 1$ 是一个关于 $s$ 的递减函数，$\\eta$ 是最大学习率。\n\n##### 实验验证\n- **损失下降**：在0.036B模型上使用WSD LRS进行实验，结果显示在衰减阶段，随着学习率的降低，损失显著下降，并且很快达到或低于Cosine LRS在步长 $T=S$ 时的表现。\n\n![image-20241223143810882](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223143810882.png)\n\n- **快速测试**：缩短衰减阶段可以加快不同模型检查点的快速测试。实验表明，使用10%的总标记数进行衰减足以达到最佳效果。\n\n##### 数据扩展的有效性\n- **连续训练**：使用WSD LRS可以持续训练固定大小的模型到极端收敛。实验比较了连续训练0.036B模型和使用40N数据的0.17B模型的性能，结果显示0.036B模型在增加约4倍的训练计算量的情况下，可以达到与0.17B模型相当的性能，同时节省了约5倍的推理计算量。\n\n#### 衰减阶段的分析\n\n![image-20241223144222463](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223144222463.png)\n\n![image-20241223144246606](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223144246606.png)\n\n在\"4.4 Analysis of the Decay Stage\"部分，论文对MiniCPM-2.4B模型在衰减阶段的训练过程进行了详细分析。以下是该部分的几个主要分析点：\n\n1. **权重更新与损失的关系**：\n   - 研究者计算了MiniCPM-2.4B模型中所有权重矩阵的最大权重元素更新。结果显示，权重更新与学习率的幅度之间存在强相关性。具体来说，在学习率衰减之前，模型检查点经历了显著的权重更新，但损失几乎没有减少。相反，在衰减阶段，尽管权重更新的幅度较小，损失却迅速下降。\n\n2. **梯度信息的分析**：\n   - 研究者记录了0.2B模型的每一步梯度信息，并评估了连续步骤之间的差异，以近似二阶梯度信息。结果显示，梯度范数在衰减阶段减小，梯度之间的角度余弦值主要为正值，表明在衰减阶段，模型参数在每一步都是一致变化的。\n   - 一阶梯度在每一步显著减小，与学习率的变化密切相关。二阶梯度的幅度略有增加，表明损失函数的曲率增大，接近局部最优解。\n\n3. **优化过程的几何解释**：\n   - 研究者将优化过程视为在高维流形上的轨迹，并计算了一阶和二阶梯向导数。结果显示，一阶梯向导数与学习率成指数衰减，而二阶梯向导数的幅度略有增加。这表明在衰减阶段，模型参数的变化更加一致，损失函数的曲率增大，接近局部最优解。\n\n4. **实验结果的可视化**：\n   - 图7展示了权重更新的最大差异，图8展示了梯度统计信息。这些图表直观地展示了在衰减阶段，尽管权重更新的幅度较小，但损失迅速下降的现象。\n\n通过这些分析，研究者揭示了在衰减阶段，MiniCPM-2.4B模型的训练动态具有独特的特征，这些特征有助于模型更快地收敛到局部最优解。这些发现为进一步优化模型训练过程提供了重要的见解。\n\n#### 缩放定律的测量\n\n![image-20241223144614364](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223144614364.png)\n\n![image-20241223144647906](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223144647906.png)\n\n在\"4.5 Measuring the Scaling Law with WSD LRS\"部分，论文介绍了如何利用WSD（Warmup-Stable-Decay）学习率调度器来高效地研究大规模语言模型（LLMs）的规模定律。以下是该部分的详细介绍和分析：\n\n##### 1. 规模定律的重要性\n规模定律是指导LLMs发展的重要原则，它描述了模型规模和数据规模之间的关系。Kaplan等人（2020）和Hoffmann等人（2022）分别提出了不同的规模定律模型，前者认为模型规模增加十倍应对应数据规模增加一倍，而后者则认为两者应同比例增加。\n\n##### 2. 传统规模实验的挑战\n传统的规模实验需要在不同模型规模和数据规模上进行多次训练，计算成本高昂，时间复杂度为$O(m^2 C)$，其中$m$是模型数量，$C$是每次训练的成本。\n\n##### 3. WSD调度器的优势\nWSD调度器允许在稳定阶段的任意检查点开始衰减，从而在不需要从头开始训练的情况下，精确测量规模定律。这使得规模定律的测量在数据轴上具有线性成本$O(m C)$，大大提高了效率。\n\n##### 4. 实验设计\n- **模型和数据规模**：研究者在6个不同规模的模型（从0.04B到2B）上进行了实验，每个模型在稳定阶段的6个不同检查点（从10N到60N数据）开始衰减。\n- **训练和评估**：每个模型在五个独立的评估数据集上进行最终损失评估。为了公平比较，损失按字节数而非标记数平均。\n\n##### 5. 规模定律的拟合\n- **拟合公式**：研究者使用Hoffmann等人（2022）提出的公式来拟合损失与模型规模和数据规模的关系：\n  $$\n  L(N, D) = C_N N^{-\\alpha} + C_D D^{-\\beta} + L_0\n  $$\n  其中，$N$和$D$分别是模型规模和数据规模，$C_N$和$C_D$是常数，$\\alpha$和$\\beta$是指数，$L_0$是常数项。\n- **最优模型和数据规模**：通过拟合，研究者得到了每个数据集和检查点的最优模型规模$N_{\\text{opt}}$和数据规模$D_{\\text{opt}}$，并计算了数据-模型比例$\\frac{D_{\\text{opt}}}{N_{\\text{opt}}}$。\n\n##### 6. 结果分析\n- **数据-模型比例**：研究结果表明，数据-模型比例比Hoffmann等人（2022）的结果高得多，平均约为192倍，而不是20倍。这表明较小的模型可以吸收更多的数据，从而提高推理和部署的效率。\n- **与Chinchilla Optimal的比较**：尽管与Chinchilla Optimal的结果存在较大差异，但通过与Llama2的比较，研究者认为WSD调度器在更现代的配置下可能具有更高的数据-模型比例。\n\n##### 7. 未来方向\n- **进一步研究**：研究者计划深入分析衰减阶段的损失下降原因，并通过扩大模型和数据规模来增强MiniCPM的能力。\n\n##### 总结\n通过引入WSD调度器，论文提出了一种高效的方法来研究LLMs的规模定律，显著降低了计算成本。研究结果表明，较小的模型可以吸收更多的数据，从而提高推理和部署的效率。未来的研究将进一步探索WSD调度器在其他模型上的应用及其对规模定律的影响。\n\n## 3. 两阶段预训练策略\n\n论文提出了一种两阶段的预训练策略，旨在提高小型语言模型（SLMs）的性能。以下是对该章节的详细总结和分析：\n\n### 3.1 背景与动机\n\n- **背景**：大型语言模型（LLMs）的训练成本高昂，且在个人电脑或智能手机等终端设备上部署效率低下。\n- **动机**：探索小型语言模型（SLMs）作为资源高效的替代方案，并通过可扩展的训练策略，使其具备与大型模型相似的能力。\n\n### 3.2 两阶段预训练策略\n- **阶段划分**：\n  - **第一阶段**：仅使用大规模、低质量的预训练数据进行训练。\n  - **第二阶段**：在衰减阶段引入高质量、知识导向的监督微调（SFT）数据，混合到预训练数据中。\n\n- **优势**：\n  - **全面学习**：在衰减阶段引入高质量数据，促进模型在更接近实际用户场景的数据分布上进行更显著的损失减少。\n  - **持续训练**：避免在整个预训练过程中均匀分布高质量数据，集中资源和持续预训练。\n\n### 3.3 实验验证\n\n![image-20241223145718563](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223145718563.png)\n\n- **实验设置**：\n  - **模型选择**：使用MiniCPM-2.4B和MiniCPM-1.2B模型。\n  - **对比实验**：\n    - A-1：2.4B模型，仅使用预训练数据进行衰减，随后进行4B标记的SFT。\n    - A-2：2.4B模型，在衰减阶段混合高质量数据和SFT数据，随后进行4B标记的SFT。\n    - B-1：1.2B模型，仅使用预训练数据进行衰减，随后进行6B标记的SFT。\n    - B-2：1.2B模型，仅使用预训练数据进行衰减，随后进行12B标记的SFT。\n    - B-3：1.2B模型，在衰减阶段混合高质量数据和SFT数据，随后进行6B标记的SFT。\n\n- **结果分析**：\n  - **A-2 vs A-1**：尽管A-2和A-1在SFT阶段使用相同的数据分布，但A-2在衰减阶段引入高质量数据，显著提升了模型性能。\n  - **B-3 vs B-2**：B-3在衰减阶段引入高质量数据，表现优于仅在SFT阶段引入高质量数据的B-2。\n\n### 3.4 结论\n- **策略有效性**：引入高质量数据到衰减阶段比仅在SFT阶段引入数据更能提升模型性能。\n- **推荐**：建议从衰减阶段开始，专门化和增强模型能力。\n\n\n\n### 总结\n论文提出的两阶段预训练策略通过在不同阶段引入不同类型的数据，显著提升了小型语言模型的性能。该策略不仅提高了模型的学习效率，还为未来的大型语言模型开发提供了有价值的参考。\n\n## 4. MiniCPM 模型\n\n第6章节“6 Model”详细介绍了MiniCPM模型的各个方面，包括模型细节、训练阶段、训练数据分布、训练损失和模型评估。以下是各部分的详细介绍：\n\n### 4.1 Model Details\n\n![image-20241223153902417](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223153902417.png)\n\n#### 词汇\n- **MiniCPM-2.4B**：使用122,753词汇大小的tokenizer。\n- **MiniCPM-1.2B**：使用73,440词汇大小的tokenizer，较小的词汇表有利于效率而不显著影响性能。\n\n#### 共享输入输出层\n- 为了减少参数空间，MiniCPM-2.4B和MiniCPM-1.2B都使用了嵌入共享技术。\n\n#### 深而薄的网络\n- **MiniCPM-2.4B**：在训练MiniCPM-1.2B之前，采用了更深更薄的网络架构。\n- **MiniCPM-1.2B**：进一步加深和变薄，以适应长上下文任务。\n\n#### 组查询注意力\n- **MiniCPM-2.4B**：未修改注意力层。\n- **MiniCPM-1.2B**：应用了组查询注意力（Group Query Attention）以减少参数数量。\n\n### 4.2 Training Stages\n\n#### 稳定训练阶段\n- 使用约1T的数据，主要来自开放数据集。\n- 使用WSD学习率调度器，批量大小为3.93百万，最大学习率为0.01。\n\n#### 衰减阶段\n- 使用预训练数据和高质量的SFT数据混合。\n- 采用指数衰减形式，T设为5000步（20B标记）。\n\n#### SFT阶段\n- 使用类似衰减阶段的数据，但不包括预训练数据，训练约60亿标记。\n- 学习率与衰减阶段末尾相同，使用WSD调度器。\n\n### 4.3 Training Data Distribution\n\n![image-20241223153949999](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223153949999.png)\n\n- **稳定阶段**：主要使用开放数据集，如CommonCrawl、Dolma、C4、Pile、Code Pre-train等。\n- **衰减阶段**：数据混合包含更多样化和专有的数据，如UltraChat、SlimOrca、OssInstruct、EvolInstruct等。\n\n### 4.4 Training Loss\n\n![image-20241223154011909](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154011909.png)\n\n- 在C4数据集上的整体训练损失显示，衰减阶段的损失显著下降。\n- 由于使用指数衰减，学习率降至最大值的10%以下后，损失仍继续下降，但最终检查点未用于微调。\n\n### 4.5 Evaluation\n\n![image-20241223154036251](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154036251.png)\n\n- 使用开源工具UltraEval进行评估，支持多种主流大型模型的性能评估。\n- 评估数据集包括MMLU、CMMLU、C-Eval、MBPP、GSM8K、MATH、HumanEval、BBH等。\n- 评估方法包括标准化输入提示和调整输入输出模板，确保公平比较。\n\n#### 评估结果\n- **MiniCPM-2.4B**：在多个基准测试中表现优异，特别是在中文任务中表现优于Mistral-7B。\n- **MiniCPM-1.2B**：在多个基准测试中也表现出色，特别是在直接生成任务中表现优于PPL测试。\n\n通过这些详细的介绍，可以看出MiniCPM模型在设计、训练和评估方面都经过了精心考虑和优化，取得了显著的性能提升。\n\n## 5. MiniCPM 家族模型\n\n论文介绍了基于MiniCPM基础模型的几种扩展模型，包括MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE。这些模型在各自的应用领域中展示了卓越的性能。以下是该章节的详细介绍：\n\n### 5.1 MiniCPM-DPO\n\n![image-20241223154302859](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154302859.png)\n\n![image-20241223154345626](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154345626.png)\n\n- **背景**：在微调阶段之后，使用DPO（Direct Preference Optimization）进行人类偏好对齐。\n- **训练**：使用UltraFeedback作为主要对齐数据集，并构建了一个专有的偏好数据集以增强模型的代码和数学能力。\n- **结果**：在MTBench上的得分从SFT后的6.89提高到7.25，超过了像Llama2-70B-Chat这样的大型模型。然而，基准测试结果略有下降，这是对齐税（alignment tax）的表现。\n\n### 5.2 MiniCPM-128K\n\n![image-20241223154425567](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154425567.png)\n\n- **背景**：处理长上下文任务需要模型能够隐含地理解长文本中的信息。\n- **初始化**：禁用输入和输出之间的嵌入共享，以适应长上下文训练所需的词汇并行性。\n- **训练**：使用WSD学习率调度器，训练数据分为“短数据”和“长数据”，长数据占44%，短数据占56%。使用Adjusted Base Frequency (ABF)和NTK-Aware RoPE Scaling进行扩展。\n- **评估**：在∞Bench基准测试中表现优异，特别是在长上下文推理任务中，超越了ChatGLM3-6B-128K。\n\n### 5.3 MiniCPM-MoE\n\n![image-20241223154445784](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154445784.png)\n\n- **背景**：通过混合专家（MoE）技术扩展MiniCPM的能力。\n- **初始化**：使用Sparse Upcycling进行初始化，将密集模型的每个MLP层替换为MoE层，路由参数随机初始化。\n- **训练**：使用WSD学习率调度器，训练批量大小在稳定和衰减阶段为4M，在SFT阶段减少到2M。\n- **结果**：在多个基准测试中表现优异，特别是在C-Eval、CMMLU、MMLU、HumanEval、MBPP、GSM8K和MATH等任务上。\n\nMiniCPM家族的扩展模型在各自的领域中展示了卓越的性能，证明了MiniCPM在多样化的SLM应用中的潜力。未来的研究方向包括深入分析衰减阶段的损失下降，并通过扩展模型规模和数据规模来增强MiniCPM的能力。\n\n## 6. 研究结论\n\n- MiniCPM 系列模型展示了小型语言模型在资源效率和性能上的巨大潜力。通过创新的训练方法和架构设计，MiniCPM 不仅在小型模型中表现出色，还能够与大型模型相媲美。WSD 学习率调度器的引入为模型的持续训练和数据-模型缩放规律的研究提供了新的思路。此外，MiniCPM 家族的多样化模型进一步巩固了其在不同应用场景中的基础地位。\n\n  \n\n## 7. 论文研究的不足\n\n尽管 MiniCPM 在小型语言模型的研究中取得了显著进展，但仍存在一些不足之处：\n\n1. **未验证在大型模型上的应用**：论文主要集中在小型模型的研究上，尚未验证 WSD 调度器在大型模型上的应用效果。\n2. **缺乏对损失下降机制的深入分析**：尽管 WSD 调度器在 Decay 阶段表现出色，但其背后的机制尚未得到深入分析，未来需要进一步研究。\n3. **未考虑实际部署中的优化**：虽然 MiniCPM 在资源效率上表现出色，但在实际部署中，仍需进一步优化以适应不同的硬件环境。\n\n## 8.论文评价\n\n### 优点与创新\n\n1. **MiniCPM模型系列**：论文介绍了MiniCPM系列小型语言模型，包括1.2B和2.4B非嵌入参数变体，这些模型在各自的小规模类别中表现卓越，并且与7B-13B大型语言模型的能力相当。\n2. **可扩展性**：研究展示了在模型和数据维度上的可扩展性，为未来的大型语言模型（LLM）研究提供了潜力。\n3. **模型风洞实验**：通过广泛的模型风洞实验，确保了稳定和最优的模型扩展。\n4. **温暖的稳定衰减（WSD）学习率调度器（LRS）**：引入了WSD LRS，有利于连续训练和领域适应，并能够高效地研究数据-模型扩展规律。\n5. **训练动态分析**：对WSD LRS的训练动态进行了深入分析，揭示了模型预训练的有趣损失景观。\n6. **更高的计算最优数据-模型比率**：通过WSD LRS，能够在模型轴上线性努力，在数据轴上忽略不计的努力，从而得出比Chinchilla Optimal更高的计算最优数据-模型比率。\n7. **MiniCPM家族**：介绍了MiniCPM家族，包括MiniCPM-DPO、MiniCPM-MoE和MiniCPM-128K，进一步巩固了MiniCPM在多样化小型语言模型应用中的基础。\n8. **公开可用**：MiniCPM模型系列公开发布，便于其他研究人员使用和改进。\n\n### 不足与反思\n\n1. **未扩展到大型语言模型**：尽管研究了小型语言模型的扩展规律，但论文并未扩展到训练大型语言模型以验证扩展规律。\n2. **WSD LRS在大型语言模型上的应用未完全探索**：尽管对WSD LRS在大型语言模型上的潜在优势保持乐观，但目前尚未完全探索其在大型语言模型上的应用。\n\n## 9. 关键问题及回答\n\n### **问题1：MiniCPM模型在模型风洞实验中是如何进行超参数优化的？**\n\nMiniCPM模型在模型风洞实验中进行了广泛的超参数优化，主要包括以下几个方面：\n\n1. **宽度缩放**：使用Tensor Program技术进行宽度缩放，支持CerebrasGPT等模型在不同模型规模下的超参数一致性。\n2. **深度缩放**：同样使用Tensor Program技术进行深度缩放，尽管对于深度大于2的网络，深度缩放的效果不如预期，但实验结果显示最优学习率是稳定的。\n3. **学习率调度器**：引入了Warmup-Stable-Decay（WSD）学习率调度器，适用于连续训练和领域适应。WSD调度器将训练阶段明确分为高学习率阶段和衰减阶段。\n\n通过这些超参数优化技术，MiniCPM模型能够在不同模型规模下实现稳定的训练和优化。\n\n### **问题2：Warmup-Stable-Decay（WSD）学习率调度器在MiniCPM模型中的具体实现和效果如何？**\n\nWarmup-Stable-Decay（WSD）学习率调度器在MiniCPM模型中的具体实现如下：\n\n1. **高学习率阶段**：模型在初始阶段采用较高的学习率进行训练，以便快速找到全局最优解。\n2. **衰减阶段**：当学习率达到一定值后，学习率逐渐减小，直至达到最小值。这一阶段的学习率衰减是线性的，并且在衰减结束后保持恒定。\n3. **连续训练**：WSD调度器允许模型在衰减阶段之后继续进行训练，从而实现连续训练。\n\n效果方面，WSD调度器在MiniCPM模型中表现出显著的优势：\n\n1. **损失降低**：在衰减阶段，学习率的突然减小导致损失显著下降，并且损失迅速降至与Cosine LRS相当的水平。\n2. **连续训练**：通过WSD调度器，模型可以在衰减阶段之后继续训练，达到与较大模型相似的性能，同时节省了大量的计算资源。\n3. **数据-模型缩放定律**：WSD调度器使得研究数据-模型缩放定律变得更加高效，能够在模型轴和数据轴上以线性努力进行研究。\n\n### **问题3：MiniCPM家族中的其他成员（如MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE）有哪些具体功能和表现？**\n\nMiniCPM家族中的其他成员包括MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE，它们各自具有不同的功能和表现：\n\n1. **MiniCPM-DPO**：在SFT阶段之后，MiniCPM-DPO通过DPO（Direct Preference Optimization）进行人类偏好对齐。使用UltraFeedback作为主要对齐数据集，并构建了一个专有的偏好数据集以增强模型的代码和数学能力。在MTBench基准测试中，MiniCPM-DPO的性能从SFT后的6.89提高到7.25，超过了多个较大的模型。\n2. **MiniCPM-128K**：将MiniCPM-2.4B的上下文长度从4096扩展到128,000 tokens，展示了小型语言模型在处理长上下文任务中的能力。通过调整基础频率和使用NTK-Aware RoPE Scaling等技术，MiniCPM-128K在∞Bench基准测试中取得了与Mistral-7B-Instruct-v0.2相当的结果，尽管其模型规模较小。\n3. **MiniCPM-MoE**：通过引入Mixture-of-Expert（MoE），MiniCPM-MoE进一步扩展了MiniCPM的能力。MoE模型在每个token上激活两个专家，并使用Router参数进行路由。在MBPP基准测试中，MiniCPM-MoE的性能与Llama2-34B相当，表明其在多任务语言理解方面的强大能力。\n\n\n\n文章合集：https://github.com/chongzicbo/ReadWriteThink\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","source":"_posts/人工智能/multi-modal/论文阅读14：MiniCPM深入解析.md","raw":"---\ntitle: 'MiniCPM详解'\ncategories:\n  - [人工智能,multi-modal]\ntags:\n  - 人工智能\n  - 多模态\n  - 论文阅读\ndate: 2024-12-20\n\n---\n\n\n\n“MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies” 由清华大学和 Modelbest Inc. 的众多研究人员共同撰写，介绍了 MiniCPM 系列小型语言模型，包括模型架构、训练方法、实验结果等，展现了其在模型和数据维度的可扩展性，以及在小型语言模型中的优势。\n\n## 1. 研究背景\n\n### 1.1 之前研究存在的问题\n\n近年来，大型语言模型（LLMs）如GPT-3、PaLM等在自然语言处理领域取得了显著的进展。这些模型通常拥有数十亿甚至上万亿的参数，能够处理复杂的任务并展现出强大的泛化能力。然而，训练和部署这些大型模型面临着巨大的资源消耗和成本问题。例如，训练一个万亿参数的模型需要大量的计算资源和能源，且在实际应用中，这些模型的部署也面临着效率和可行性的挑战。\n\n### 1.2 研究难点\n\n尽管大型模型的性能令人印象深刻，但其高昂的训练成本和资源消耗使得许多研究者和企业难以负担。此外，这些模型在实际应用中的部署也面临着诸多限制，尤其是在资源受限的设备上，如个人电脑或智能手机。因此，如何在不牺牲性能的前提下，开发出资源效率更高的小型语言模型（SLMs）成为了当前研究的一个重要方向。\n\n### 1.3 相关工作总结\n\n近年来，小型语言模型（SLMs）的研究逐渐受到关注。一些研究者提出了通过数据优化、模型剪枝和架构重构等方法来提升SLMs的性能。例如，Phi系列、TinyLlama、MobileLLM等模型通过高质量数据和结构优化，展示了SLMs在特定任务上的潜力。然而，这些模型在综合能力上仍然难以与大型模型相媲美，且缺乏透明和可扩展的训练方法。\n\n## 2. 研究方法\n\n### 2.1 模型风洞实验\n\n#### Scaling Hyper-parameters Invariant LM\n\nScaling Hyper-parameters Invariant LM（缩放超参数不变的语言模型）是一种旨在通过调整模型的超参数来实现不同规模模型的性能稳定的方法。这种方法的核心思想是利用Tensor Program框架中的宽度缩放和深度缩放技术，以预测大型语言模型（LLMs）的损失，并确保在不同规模的模型上获得最佳的学习率。\n\n在MiniCPM中，作者采用了Tensor Program的这两种缩放技术：\n\n1. **宽度缩放（Width Scaling）**：这种技术通过调整模型的隐藏层维度来改变模型的宽度。在MiniCPM中，宽度缩放被应用于所有模型，包括MiniCPM-1.2B和MiniCPM-2.4B。\n\n2. **深度缩放（Depth Scaling）**：这种技术通过增加模型的层数来改变模型的深度。尽管Yang等人在2023年的研究中观察到，当网络块深度大于2时，深度缩放的效果不理想，但作者在实践中发现，对于MiniCPM模型，深度缩放仍然能够带来稳定的学习率。\n\n此外，作者没有采用注意力softmax缩放技术，因为他们在实践中发现，即使不使用这种技术，模型的学习率仍然是稳定的。\n\n通过这些缩放技术，MiniCPM能够在不同规模的模型上实现超参数的稳定性和一致性，从而提高模型的训练效率和性能。\n\n![image-20241223141035777](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223141035777.png)\n\n![image-20241223141106997](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223141106997.png)\n\n#### 最优批量大小\n\n在\"3.2 Optimal Batch Size\"部分，论文探讨了批量大小（batch size）对模型训练的影响以及如何确定最佳的批量大小。批量大小决定了模型在每次迭代中处理的数据量，它直接影响模型的收敛速度和计算资源的消耗。以下是该部分的几个主要观点：\n\n1. **批量大小与收敛速度和资源消耗的平衡**：\n   - 如果批量大小过大，会导致大量的数据和计算成本。\n   - 如果批量大小过小，则需要更多的训练步骤，可能导致损失函数下降有限。\n\n2. **实验设置**：\n   - 论文在三个不同大小的模型上进行了实验：0.009B、0.03B 和 0.17B。\n   - 每个模型在六个不同的批量大小上进行训练，全局学习率为0.01，使用余弦学习率调度器。\n\n3. **观察到的趋势**：\n   - 批量大小与损失之间的关系显示，随着损失的减少，最佳批量大小会增大。\n   - 通过拟合等损失点，发现批量大小与损失之间存在线性关系。\n\n4. **公式推导**：\n   - 论文提出了一个公式来描述批量大小（bs）与C4数据集上的损失（L）之间的关系：\n     $$\n     bs=\\frac{1.21\\times10^{9}}{L^{6.24}}\n     $$\n\n总的来说，论文通过实验和分析，展示了如何根据预期的损失来确定最佳批量大小，并提出了一个基于损失预测的批量大小估计方法。\n\n![image-20241223141919897](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223141919897.png)\n\n#### 最优学习率\n\n由于我们使用了张量程序（Yang等人，2022年；2023年），我们预计学习率在模型扩展期间不会发生显著变化。为了验证这一点，我们在0.04B、0.1B、0.3B和0.5B的六个学习率实验中进行测试。在图3中，我们发现尽管模型大小增加了十倍，最优基础学习率2并没有明显变化，保持在大约0.01左右。我们进一步在2.1B的规模上进行简单验证，确认0.01的学习率确实实现了最低损失。\n\n\n\n![图3：损失与学习率的关系。在应用张量程序后，学习率的变动变得非常小。](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/ffd302f2750f29d6e75e666fa43c51a3-image.png)\n\n\n\n### 2.2 WSD 学习率调度器（LRS）\n\n#### 分析 Cosine LRS\n\n![图4：具有不同周期的余弦学习率调度器。Y轴是C4语料库上的损失。](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/96d5f382f6d650b0f98f618576276f19-image.png)\n\n在\"4.1 Analysing Cosine LRS\"小节中，论文分析了余弦学习率调度器（Cosine LRS）的关键特性和其对模型性能的影响。以下是该小节的主要内容：\n\n1. **余弦学习率调度器的基本原理**：\n   - 余弦学习率调度器（Cosine LRS）是一种常用的学习率调整策略，它在训练过程中逐渐降低学习率，遵循余弦曲线的变化。具体来说，学习率在预热阶段达到最大值后，按照余弦函数的形状逐渐下降。\n\n2. **关键超参数**：\n   - 余弦学习率调度器的一个关键超参数是步长 $T$，即余弦函数首次降到最小值的时间点。通常，$T$ 被设置为总训练步数 $S$。\n\n3. **实验验证**：\n   - 论文通过在0.036B模型上进行实验，验证了不同 $T$ 值对学习率调度器性能的影响。实验结果表明，当 $T=S$ 时，模型的损失最低。这表明在整个训练过程中保持较高的学习率有助于模型找到更好的全局最优解。\n   - 当 $T<S$ 或 $T>S$ 时，模型的性能不如 $T=S$ 时的表现。特别是，$T>S$ 会导致性能下降。\n\n4. **假设分析**：\n   - 论文提出了两个假设来解释为什么 $T=S$ 时余弦学习率调度器表现优异：\n     1. 当 $T=S$ 时，高学习率训练的持续时间更长，这有助于模型找到更好的全局最优解。\n     2. 当 $T=S$ 时，学习率衰减阶段更为彻底，这可能涉及独特的训练动态，使模型能够找到更好的局部最优解。\n\n5. **实验结果**：\n   - 实验结果显示，在 $T=S$ 时，余弦学习率调度器的性能最佳。具体来说，当训练步数为 $S=20N, 40N, 60N, 80N$ 时，损失总是由 $\\operatorname{Cosine}(T)$ 达到最低，而不是 $\\operatorname{Cosine}(T)$ 或 $\\operatorname{CosineLoop}(T)$。\n\n通过这些分析，论文强调了余弦学习率调度器在特定条件下（即 $T=S$）的优越性，并为后续提出的WSD（Warmup-Stable-Decay）学习率调度器奠定了基础。\n\n#### 提出 WSD LRS\n\n在\"4.2 WSD LRS\"小节中，论文提出了一种新的学习率调度器，称为Warmup-Stable-Decay (WSD) 学习率调度器。以下是该小节的主要内容：\n\n\n\n##### 引言\n- **背景**：现有的学习率调度器（如Cosine LRS）在训练过程中逐渐降低学习率，但在某些情况下，可能需要更灵活的调度策略来优化模型性能。\n- **目标**：提出一种新的学习率调度器，能够在训练的不同阶段有效地调整学习率，以提高模型的训练效率和性能。\n\n##### WSD LRS的定义\n- **定义**：WSD LRS将训练过程分为三个阶段：预热阶段（Warmup）、稳定阶段（Stable）和衰减阶段（Decay）。\n- **公式**：\n  $$\n  WSD(T; s)=\\left\\{\\begin{array}{l}\n  \\frac{s}{W}\\eta,\\quad s<W\\\\\n  \\eta,\\quad W<s<T\\\\\n  f(s-T)\\eta,\\quad T<s<S\n  \\end{array}\\right.\n  $$\n  其中，$0<f(s-T)\\leq 1$ 是一个关于 $s$ 的递减函数，$\\eta$ 是最大学习率。\n\n##### 实验验证\n- **损失下降**：在0.036B模型上使用WSD LRS进行实验，结果显示在衰减阶段，随着学习率的降低，损失显著下降，并且很快达到或低于Cosine LRS在步长 $T=S$ 时的表现。\n\n![image-20241223143810882](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223143810882.png)\n\n- **快速测试**：缩短衰减阶段可以加快不同模型检查点的快速测试。实验表明，使用10%的总标记数进行衰减足以达到最佳效果。\n\n##### 数据扩展的有效性\n- **连续训练**：使用WSD LRS可以持续训练固定大小的模型到极端收敛。实验比较了连续训练0.036B模型和使用40N数据的0.17B模型的性能，结果显示0.036B模型在增加约4倍的训练计算量的情况下，可以达到与0.17B模型相当的性能，同时节省了约5倍的推理计算量。\n\n#### 衰减阶段的分析\n\n![image-20241223144222463](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223144222463.png)\n\n![image-20241223144246606](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223144246606.png)\n\n在\"4.4 Analysis of the Decay Stage\"部分，论文对MiniCPM-2.4B模型在衰减阶段的训练过程进行了详细分析。以下是该部分的几个主要分析点：\n\n1. **权重更新与损失的关系**：\n   - 研究者计算了MiniCPM-2.4B模型中所有权重矩阵的最大权重元素更新。结果显示，权重更新与学习率的幅度之间存在强相关性。具体来说，在学习率衰减之前，模型检查点经历了显著的权重更新，但损失几乎没有减少。相反，在衰减阶段，尽管权重更新的幅度较小，损失却迅速下降。\n\n2. **梯度信息的分析**：\n   - 研究者记录了0.2B模型的每一步梯度信息，并评估了连续步骤之间的差异，以近似二阶梯度信息。结果显示，梯度范数在衰减阶段减小，梯度之间的角度余弦值主要为正值，表明在衰减阶段，模型参数在每一步都是一致变化的。\n   - 一阶梯度在每一步显著减小，与学习率的变化密切相关。二阶梯度的幅度略有增加，表明损失函数的曲率增大，接近局部最优解。\n\n3. **优化过程的几何解释**：\n   - 研究者将优化过程视为在高维流形上的轨迹，并计算了一阶和二阶梯向导数。结果显示，一阶梯向导数与学习率成指数衰减，而二阶梯向导数的幅度略有增加。这表明在衰减阶段，模型参数的变化更加一致，损失函数的曲率增大，接近局部最优解。\n\n4. **实验结果的可视化**：\n   - 图7展示了权重更新的最大差异，图8展示了梯度统计信息。这些图表直观地展示了在衰减阶段，尽管权重更新的幅度较小，但损失迅速下降的现象。\n\n通过这些分析，研究者揭示了在衰减阶段，MiniCPM-2.4B模型的训练动态具有独特的特征，这些特征有助于模型更快地收敛到局部最优解。这些发现为进一步优化模型训练过程提供了重要的见解。\n\n#### 缩放定律的测量\n\n![image-20241223144614364](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223144614364.png)\n\n![image-20241223144647906](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223144647906.png)\n\n在\"4.5 Measuring the Scaling Law with WSD LRS\"部分，论文介绍了如何利用WSD（Warmup-Stable-Decay）学习率调度器来高效地研究大规模语言模型（LLMs）的规模定律。以下是该部分的详细介绍和分析：\n\n##### 1. 规模定律的重要性\n规模定律是指导LLMs发展的重要原则，它描述了模型规模和数据规模之间的关系。Kaplan等人（2020）和Hoffmann等人（2022）分别提出了不同的规模定律模型，前者认为模型规模增加十倍应对应数据规模增加一倍，而后者则认为两者应同比例增加。\n\n##### 2. 传统规模实验的挑战\n传统的规模实验需要在不同模型规模和数据规模上进行多次训练，计算成本高昂，时间复杂度为$O(m^2 C)$，其中$m$是模型数量，$C$是每次训练的成本。\n\n##### 3. WSD调度器的优势\nWSD调度器允许在稳定阶段的任意检查点开始衰减，从而在不需要从头开始训练的情况下，精确测量规模定律。这使得规模定律的测量在数据轴上具有线性成本$O(m C)$，大大提高了效率。\n\n##### 4. 实验设计\n- **模型和数据规模**：研究者在6个不同规模的模型（从0.04B到2B）上进行了实验，每个模型在稳定阶段的6个不同检查点（从10N到60N数据）开始衰减。\n- **训练和评估**：每个模型在五个独立的评估数据集上进行最终损失评估。为了公平比较，损失按字节数而非标记数平均。\n\n##### 5. 规模定律的拟合\n- **拟合公式**：研究者使用Hoffmann等人（2022）提出的公式来拟合损失与模型规模和数据规模的关系：\n  $$\n  L(N, D) = C_N N^{-\\alpha} + C_D D^{-\\beta} + L_0\n  $$\n  其中，$N$和$D$分别是模型规模和数据规模，$C_N$和$C_D$是常数，$\\alpha$和$\\beta$是指数，$L_0$是常数项。\n- **最优模型和数据规模**：通过拟合，研究者得到了每个数据集和检查点的最优模型规模$N_{\\text{opt}}$和数据规模$D_{\\text{opt}}$，并计算了数据-模型比例$\\frac{D_{\\text{opt}}}{N_{\\text{opt}}}$。\n\n##### 6. 结果分析\n- **数据-模型比例**：研究结果表明，数据-模型比例比Hoffmann等人（2022）的结果高得多，平均约为192倍，而不是20倍。这表明较小的模型可以吸收更多的数据，从而提高推理和部署的效率。\n- **与Chinchilla Optimal的比较**：尽管与Chinchilla Optimal的结果存在较大差异，但通过与Llama2的比较，研究者认为WSD调度器在更现代的配置下可能具有更高的数据-模型比例。\n\n##### 7. 未来方向\n- **进一步研究**：研究者计划深入分析衰减阶段的损失下降原因，并通过扩大模型和数据规模来增强MiniCPM的能力。\n\n##### 总结\n通过引入WSD调度器，论文提出了一种高效的方法来研究LLMs的规模定律，显著降低了计算成本。研究结果表明，较小的模型可以吸收更多的数据，从而提高推理和部署的效率。未来的研究将进一步探索WSD调度器在其他模型上的应用及其对规模定律的影响。\n\n## 3. 两阶段预训练策略\n\n论文提出了一种两阶段的预训练策略，旨在提高小型语言模型（SLMs）的性能。以下是对该章节的详细总结和分析：\n\n### 3.1 背景与动机\n\n- **背景**：大型语言模型（LLMs）的训练成本高昂，且在个人电脑或智能手机等终端设备上部署效率低下。\n- **动机**：探索小型语言模型（SLMs）作为资源高效的替代方案，并通过可扩展的训练策略，使其具备与大型模型相似的能力。\n\n### 3.2 两阶段预训练策略\n- **阶段划分**：\n  - **第一阶段**：仅使用大规模、低质量的预训练数据进行训练。\n  - **第二阶段**：在衰减阶段引入高质量、知识导向的监督微调（SFT）数据，混合到预训练数据中。\n\n- **优势**：\n  - **全面学习**：在衰减阶段引入高质量数据，促进模型在更接近实际用户场景的数据分布上进行更显著的损失减少。\n  - **持续训练**：避免在整个预训练过程中均匀分布高质量数据，集中资源和持续预训练。\n\n### 3.3 实验验证\n\n![image-20241223145718563](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223145718563.png)\n\n- **实验设置**：\n  - **模型选择**：使用MiniCPM-2.4B和MiniCPM-1.2B模型。\n  - **对比实验**：\n    - A-1：2.4B模型，仅使用预训练数据进行衰减，随后进行4B标记的SFT。\n    - A-2：2.4B模型，在衰减阶段混合高质量数据和SFT数据，随后进行4B标记的SFT。\n    - B-1：1.2B模型，仅使用预训练数据进行衰减，随后进行6B标记的SFT。\n    - B-2：1.2B模型，仅使用预训练数据进行衰减，随后进行12B标记的SFT。\n    - B-3：1.2B模型，在衰减阶段混合高质量数据和SFT数据，随后进行6B标记的SFT。\n\n- **结果分析**：\n  - **A-2 vs A-1**：尽管A-2和A-1在SFT阶段使用相同的数据分布，但A-2在衰减阶段引入高质量数据，显著提升了模型性能。\n  - **B-3 vs B-2**：B-3在衰减阶段引入高质量数据，表现优于仅在SFT阶段引入高质量数据的B-2。\n\n### 3.4 结论\n- **策略有效性**：引入高质量数据到衰减阶段比仅在SFT阶段引入数据更能提升模型性能。\n- **推荐**：建议从衰减阶段开始，专门化和增强模型能力。\n\n\n\n### 总结\n论文提出的两阶段预训练策略通过在不同阶段引入不同类型的数据，显著提升了小型语言模型的性能。该策略不仅提高了模型的学习效率，还为未来的大型语言模型开发提供了有价值的参考。\n\n## 4. MiniCPM 模型\n\n第6章节“6 Model”详细介绍了MiniCPM模型的各个方面，包括模型细节、训练阶段、训练数据分布、训练损失和模型评估。以下是各部分的详细介绍：\n\n### 4.1 Model Details\n\n![image-20241223153902417](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223153902417.png)\n\n#### 词汇\n- **MiniCPM-2.4B**：使用122,753词汇大小的tokenizer。\n- **MiniCPM-1.2B**：使用73,440词汇大小的tokenizer，较小的词汇表有利于效率而不显著影响性能。\n\n#### 共享输入输出层\n- 为了减少参数空间，MiniCPM-2.4B和MiniCPM-1.2B都使用了嵌入共享技术。\n\n#### 深而薄的网络\n- **MiniCPM-2.4B**：在训练MiniCPM-1.2B之前，采用了更深更薄的网络架构。\n- **MiniCPM-1.2B**：进一步加深和变薄，以适应长上下文任务。\n\n#### 组查询注意力\n- **MiniCPM-2.4B**：未修改注意力层。\n- **MiniCPM-1.2B**：应用了组查询注意力（Group Query Attention）以减少参数数量。\n\n### 4.2 Training Stages\n\n#### 稳定训练阶段\n- 使用约1T的数据，主要来自开放数据集。\n- 使用WSD学习率调度器，批量大小为3.93百万，最大学习率为0.01。\n\n#### 衰减阶段\n- 使用预训练数据和高质量的SFT数据混合。\n- 采用指数衰减形式，T设为5000步（20B标记）。\n\n#### SFT阶段\n- 使用类似衰减阶段的数据，但不包括预训练数据，训练约60亿标记。\n- 学习率与衰减阶段末尾相同，使用WSD调度器。\n\n### 4.3 Training Data Distribution\n\n![image-20241223153949999](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223153949999.png)\n\n- **稳定阶段**：主要使用开放数据集，如CommonCrawl、Dolma、C4、Pile、Code Pre-train等。\n- **衰减阶段**：数据混合包含更多样化和专有的数据，如UltraChat、SlimOrca、OssInstruct、EvolInstruct等。\n\n### 4.4 Training Loss\n\n![image-20241223154011909](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154011909.png)\n\n- 在C4数据集上的整体训练损失显示，衰减阶段的损失显著下降。\n- 由于使用指数衰减，学习率降至最大值的10%以下后，损失仍继续下降，但最终检查点未用于微调。\n\n### 4.5 Evaluation\n\n![image-20241223154036251](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154036251.png)\n\n- 使用开源工具UltraEval进行评估，支持多种主流大型模型的性能评估。\n- 评估数据集包括MMLU、CMMLU、C-Eval、MBPP、GSM8K、MATH、HumanEval、BBH等。\n- 评估方法包括标准化输入提示和调整输入输出模板，确保公平比较。\n\n#### 评估结果\n- **MiniCPM-2.4B**：在多个基准测试中表现优异，特别是在中文任务中表现优于Mistral-7B。\n- **MiniCPM-1.2B**：在多个基准测试中也表现出色，特别是在直接生成任务中表现优于PPL测试。\n\n通过这些详细的介绍，可以看出MiniCPM模型在设计、训练和评估方面都经过了精心考虑和优化，取得了显著的性能提升。\n\n## 5. MiniCPM 家族模型\n\n论文介绍了基于MiniCPM基础模型的几种扩展模型，包括MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE。这些模型在各自的应用领域中展示了卓越的性能。以下是该章节的详细介绍：\n\n### 5.1 MiniCPM-DPO\n\n![image-20241223154302859](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154302859.png)\n\n![image-20241223154345626](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154345626.png)\n\n- **背景**：在微调阶段之后，使用DPO（Direct Preference Optimization）进行人类偏好对齐。\n- **训练**：使用UltraFeedback作为主要对齐数据集，并构建了一个专有的偏好数据集以增强模型的代码和数学能力。\n- **结果**：在MTBench上的得分从SFT后的6.89提高到7.25，超过了像Llama2-70B-Chat这样的大型模型。然而，基准测试结果略有下降，这是对齐税（alignment tax）的表现。\n\n### 5.2 MiniCPM-128K\n\n![image-20241223154425567](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154425567.png)\n\n- **背景**：处理长上下文任务需要模型能够隐含地理解长文本中的信息。\n- **初始化**：禁用输入和输出之间的嵌入共享，以适应长上下文训练所需的词汇并行性。\n- **训练**：使用WSD学习率调度器，训练数据分为“短数据”和“长数据”，长数据占44%，短数据占56%。使用Adjusted Base Frequency (ABF)和NTK-Aware RoPE Scaling进行扩展。\n- **评估**：在∞Bench基准测试中表现优异，特别是在长上下文推理任务中，超越了ChatGLM3-6B-128K。\n\n### 5.3 MiniCPM-MoE\n\n![image-20241223154445784](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154445784.png)\n\n- **背景**：通过混合专家（MoE）技术扩展MiniCPM的能力。\n- **初始化**：使用Sparse Upcycling进行初始化，将密集模型的每个MLP层替换为MoE层，路由参数随机初始化。\n- **训练**：使用WSD学习率调度器，训练批量大小在稳定和衰减阶段为4M，在SFT阶段减少到2M。\n- **结果**：在多个基准测试中表现优异，特别是在C-Eval、CMMLU、MMLU、HumanEval、MBPP、GSM8K和MATH等任务上。\n\nMiniCPM家族的扩展模型在各自的领域中展示了卓越的性能，证明了MiniCPM在多样化的SLM应用中的潜力。未来的研究方向包括深入分析衰减阶段的损失下降，并通过扩展模型规模和数据规模来增强MiniCPM的能力。\n\n## 6. 研究结论\n\n- MiniCPM 系列模型展示了小型语言模型在资源效率和性能上的巨大潜力。通过创新的训练方法和架构设计，MiniCPM 不仅在小型模型中表现出色，还能够与大型模型相媲美。WSD 学习率调度器的引入为模型的持续训练和数据-模型缩放规律的研究提供了新的思路。此外，MiniCPM 家族的多样化模型进一步巩固了其在不同应用场景中的基础地位。\n\n  \n\n## 7. 论文研究的不足\n\n尽管 MiniCPM 在小型语言模型的研究中取得了显著进展，但仍存在一些不足之处：\n\n1. **未验证在大型模型上的应用**：论文主要集中在小型模型的研究上，尚未验证 WSD 调度器在大型模型上的应用效果。\n2. **缺乏对损失下降机制的深入分析**：尽管 WSD 调度器在 Decay 阶段表现出色，但其背后的机制尚未得到深入分析，未来需要进一步研究。\n3. **未考虑实际部署中的优化**：虽然 MiniCPM 在资源效率上表现出色，但在实际部署中，仍需进一步优化以适应不同的硬件环境。\n\n## 8.论文评价\n\n### 优点与创新\n\n1. **MiniCPM模型系列**：论文介绍了MiniCPM系列小型语言模型，包括1.2B和2.4B非嵌入参数变体，这些模型在各自的小规模类别中表现卓越，并且与7B-13B大型语言模型的能力相当。\n2. **可扩展性**：研究展示了在模型和数据维度上的可扩展性，为未来的大型语言模型（LLM）研究提供了潜力。\n3. **模型风洞实验**：通过广泛的模型风洞实验，确保了稳定和最优的模型扩展。\n4. **温暖的稳定衰减（WSD）学习率调度器（LRS）**：引入了WSD LRS，有利于连续训练和领域适应，并能够高效地研究数据-模型扩展规律。\n5. **训练动态分析**：对WSD LRS的训练动态进行了深入分析，揭示了模型预训练的有趣损失景观。\n6. **更高的计算最优数据-模型比率**：通过WSD LRS，能够在模型轴上线性努力，在数据轴上忽略不计的努力，从而得出比Chinchilla Optimal更高的计算最优数据-模型比率。\n7. **MiniCPM家族**：介绍了MiniCPM家族，包括MiniCPM-DPO、MiniCPM-MoE和MiniCPM-128K，进一步巩固了MiniCPM在多样化小型语言模型应用中的基础。\n8. **公开可用**：MiniCPM模型系列公开发布，便于其他研究人员使用和改进。\n\n### 不足与反思\n\n1. **未扩展到大型语言模型**：尽管研究了小型语言模型的扩展规律，但论文并未扩展到训练大型语言模型以验证扩展规律。\n2. **WSD LRS在大型语言模型上的应用未完全探索**：尽管对WSD LRS在大型语言模型上的潜在优势保持乐观，但目前尚未完全探索其在大型语言模型上的应用。\n\n## 9. 关键问题及回答\n\n### **问题1：MiniCPM模型在模型风洞实验中是如何进行超参数优化的？**\n\nMiniCPM模型在模型风洞实验中进行了广泛的超参数优化，主要包括以下几个方面：\n\n1. **宽度缩放**：使用Tensor Program技术进行宽度缩放，支持CerebrasGPT等模型在不同模型规模下的超参数一致性。\n2. **深度缩放**：同样使用Tensor Program技术进行深度缩放，尽管对于深度大于2的网络，深度缩放的效果不如预期，但实验结果显示最优学习率是稳定的。\n3. **学习率调度器**：引入了Warmup-Stable-Decay（WSD）学习率调度器，适用于连续训练和领域适应。WSD调度器将训练阶段明确分为高学习率阶段和衰减阶段。\n\n通过这些超参数优化技术，MiniCPM模型能够在不同模型规模下实现稳定的训练和优化。\n\n### **问题2：Warmup-Stable-Decay（WSD）学习率调度器在MiniCPM模型中的具体实现和效果如何？**\n\nWarmup-Stable-Decay（WSD）学习率调度器在MiniCPM模型中的具体实现如下：\n\n1. **高学习率阶段**：模型在初始阶段采用较高的学习率进行训练，以便快速找到全局最优解。\n2. **衰减阶段**：当学习率达到一定值后，学习率逐渐减小，直至达到最小值。这一阶段的学习率衰减是线性的，并且在衰减结束后保持恒定。\n3. **连续训练**：WSD调度器允许模型在衰减阶段之后继续进行训练，从而实现连续训练。\n\n效果方面，WSD调度器在MiniCPM模型中表现出显著的优势：\n\n1. **损失降低**：在衰减阶段，学习率的突然减小导致损失显著下降，并且损失迅速降至与Cosine LRS相当的水平。\n2. **连续训练**：通过WSD调度器，模型可以在衰减阶段之后继续训练，达到与较大模型相似的性能，同时节省了大量的计算资源。\n3. **数据-模型缩放定律**：WSD调度器使得研究数据-模型缩放定律变得更加高效，能够在模型轴和数据轴上以线性努力进行研究。\n\n### **问题3：MiniCPM家族中的其他成员（如MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE）有哪些具体功能和表现？**\n\nMiniCPM家族中的其他成员包括MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE，它们各自具有不同的功能和表现：\n\n1. **MiniCPM-DPO**：在SFT阶段之后，MiniCPM-DPO通过DPO（Direct Preference Optimization）进行人类偏好对齐。使用UltraFeedback作为主要对齐数据集，并构建了一个专有的偏好数据集以增强模型的代码和数学能力。在MTBench基准测试中，MiniCPM-DPO的性能从SFT后的6.89提高到7.25，超过了多个较大的模型。\n2. **MiniCPM-128K**：将MiniCPM-2.4B的上下文长度从4096扩展到128,000 tokens，展示了小型语言模型在处理长上下文任务中的能力。通过调整基础频率和使用NTK-Aware RoPE Scaling等技术，MiniCPM-128K在∞Bench基准测试中取得了与Mistral-7B-Instruct-v0.2相当的结果，尽管其模型规模较小。\n3. **MiniCPM-MoE**：通过引入Mixture-of-Expert（MoE），MiniCPM-MoE进一步扩展了MiniCPM的能力。MoE模型在每个token上激活两个专家，并使用Router参数进行路由。在MBPP基准测试中，MiniCPM-MoE的性能与Llama2-34B相当，表明其在多任务语言理解方面的强大能力。\n\n\n\n文章合集：https://github.com/chongzicbo/ReadWriteThink\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","slug":"人工智能/multi-modal/论文阅读14：MiniCPM深入解析","published":1,"updated":"2024-12-26T06:19:07.140Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3d0007hghifwlr0ami","content":"<p>“MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies” 由清华大学和 Modelbest Inc. 的众多研究人员共同撰写，介绍了 MiniCPM 系列小型语言模型，包括模型架构、训练方法、实验结果等，展现了其在模型和数据维度的可扩展性，以及在小型语言模型中的优势。</p>\n<h2 id=\"1-研究背景\"><a href=\"#1-研究背景\" class=\"headerlink\" title=\"1. 研究背景\"></a>1. 研究背景</h2><h3 id=\"1-1-之前研究存在的问题\"><a href=\"#1-1-之前研究存在的问题\" class=\"headerlink\" title=\"1.1 之前研究存在的问题\"></a>1.1 之前研究存在的问题</h3><p>近年来，大型语言模型（LLMs）如GPT-3、PaLM等在自然语言处理领域取得了显著的进展。这些模型通常拥有数十亿甚至上万亿的参数，能够处理复杂的任务并展现出强大的泛化能力。然而，训练和部署这些大型模型面临着巨大的资源消耗和成本问题。例如，训练一个万亿参数的模型需要大量的计算资源和能源，且在实际应用中，这些模型的部署也面临着效率和可行性的挑战。</p>\n<h3 id=\"1-2-研究难点\"><a href=\"#1-2-研究难点\" class=\"headerlink\" title=\"1.2 研究难点\"></a>1.2 研究难点</h3><p>尽管大型模型的性能令人印象深刻，但其高昂的训练成本和资源消耗使得许多研究者和企业难以负担。此外，这些模型在实际应用中的部署也面临着诸多限制，尤其是在资源受限的设备上，如个人电脑或智能手机。因此，如何在不牺牲性能的前提下，开发出资源效率更高的小型语言模型（SLMs）成为了当前研究的一个重要方向。</p>\n<h3 id=\"1-3-相关工作总结\"><a href=\"#1-3-相关工作总结\" class=\"headerlink\" title=\"1.3 相关工作总结\"></a>1.3 相关工作总结</h3><p>近年来，小型语言模型（SLMs）的研究逐渐受到关注。一些研究者提出了通过数据优化、模型剪枝和架构重构等方法来提升SLMs的性能。例如，Phi系列、TinyLlama、MobileLLM等模型通过高质量数据和结构优化，展示了SLMs在特定任务上的潜力。然而，这些模型在综合能力上仍然难以与大型模型相媲美，且缺乏透明和可扩展的训练方法。</p>\n<h2 id=\"2-研究方法\"><a href=\"#2-研究方法\" class=\"headerlink\" title=\"2. 研究方法\"></a>2. 研究方法</h2><h3 id=\"2-1-模型风洞实验\"><a href=\"#2-1-模型风洞实验\" class=\"headerlink\" title=\"2.1 模型风洞实验\"></a>2.1 模型风洞实验</h3><h4 id=\"Scaling-Hyper-parameters-Invariant-LM\"><a href=\"#Scaling-Hyper-parameters-Invariant-LM\" class=\"headerlink\" title=\"Scaling Hyper-parameters Invariant LM\"></a>Scaling Hyper-parameters Invariant LM</h4><p>Scaling Hyper-parameters Invariant LM（缩放超参数不变的语言模型）是一种旨在通过调整模型的超参数来实现不同规模模型的性能稳定的方法。这种方法的核心思想是利用Tensor Program框架中的宽度缩放和深度缩放技术，以预测大型语言模型（LLMs）的损失，并确保在不同规模的模型上获得最佳的学习率。</p>\n<p>在MiniCPM中，作者采用了Tensor Program的这两种缩放技术：</p>\n<ol>\n<li><p><strong>宽度缩放（Width Scaling）</strong>：这种技术通过调整模型的隐藏层维度来改变模型的宽度。在MiniCPM中，宽度缩放被应用于所有模型，包括MiniCPM-1.2B和MiniCPM-2.4B。</p>\n</li>\n<li><p><strong>深度缩放（Depth Scaling）</strong>：这种技术通过增加模型的层数来改变模型的深度。尽管Yang等人在2023年的研究中观察到，当网络块深度大于2时，深度缩放的效果不理想，但作者在实践中发现，对于MiniCPM模型，深度缩放仍然能够带来稳定的学习率。</p>\n</li>\n</ol>\n<p>此外，作者没有采用注意力softmax缩放技术，因为他们在实践中发现，即使不使用这种技术，模型的学习率仍然是稳定的。</p>\n<p>通过这些缩放技术，MiniCPM能够在不同规模的模型上实现超参数的稳定性和一致性，从而提高模型的训练效率和性能。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223141035777.png\" alt=\"image-20241223141035777\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223141106997.png\" alt=\"image-20241223141106997\"></p>\n<h4 id=\"最优批量大小\"><a href=\"#最优批量大小\" class=\"headerlink\" title=\"最优批量大小\"></a>最优批量大小</h4><p>在”3.2 Optimal Batch Size”部分，论文探讨了批量大小（batch size）对模型训练的影响以及如何确定最佳的批量大小。批量大小决定了模型在每次迭代中处理的数据量，它直接影响模型的收敛速度和计算资源的消耗。以下是该部分的几个主要观点：</p>\n<ol>\n<li><p><strong>批量大小与收敛速度和资源消耗的平衡</strong>：</p>\n<ul>\n<li>如果批量大小过大，会导致大量的数据和计算成本。</li>\n<li>如果批量大小过小，则需要更多的训练步骤，可能导致损失函数下降有限。</li>\n</ul>\n</li>\n<li><p><strong>实验设置</strong>：</p>\n<ul>\n<li>论文在三个不同大小的模型上进行了实验：0.009B、0.03B 和 0.17B。</li>\n<li>每个模型在六个不同的批量大小上进行训练，全局学习率为0.01，使用余弦学习率调度器。</li>\n</ul>\n</li>\n<li><p><strong>观察到的趋势</strong>：</p>\n<ul>\n<li>批量大小与损失之间的关系显示，随着损失的减少，最佳批量大小会增大。</li>\n<li>通过拟合等损失点，发现批量大小与损失之间存在线性关系。</li>\n</ul>\n</li>\n<li><p><strong>公式推导</strong>：</p>\n<ul>\n<li>论文提出了一个公式来描述批量大小（bs）与C4数据集上的损失（L）之间的关系：<br>$$<br>bs&#x3D;\\frac{1.21\\times10^{9}}{L^{6.24}}<br>$$</li>\n</ul>\n</li>\n</ol>\n<p>总的来说，论文通过实验和分析，展示了如何根据预期的损失来确定最佳批量大小，并提出了一个基于损失预测的批量大小估计方法。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223141919897.png\" alt=\"image-20241223141919897\"></p>\n<h4 id=\"最优学习率\"><a href=\"#最优学习率\" class=\"headerlink\" title=\"最优学习率\"></a>最优学习率</h4><p>由于我们使用了张量程序（Yang等人，2022年；2023年），我们预计学习率在模型扩展期间不会发生显著变化。为了验证这一点，我们在0.04B、0.1B、0.3B和0.5B的六个学习率实验中进行测试。在图3中，我们发现尽管模型大小增加了十倍，最优基础学习率2并没有明显变化，保持在大约0.01左右。我们进一步在2.1B的规模上进行简单验证，确认0.01的学习率确实实现了最低损失。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/ffd302f2750f29d6e75e666fa43c51a3-image.png\" alt=\"图3：损失与学习率的关系。在应用张量程序后，学习率的变动变得非常小。\"></p>\n<h3 id=\"2-2-WSD-学习率调度器（LRS）\"><a href=\"#2-2-WSD-学习率调度器（LRS）\" class=\"headerlink\" title=\"2.2 WSD 学习率调度器（LRS）\"></a>2.2 WSD 学习率调度器（LRS）</h3><h4 id=\"分析-Cosine-LRS\"><a href=\"#分析-Cosine-LRS\" class=\"headerlink\" title=\"分析 Cosine LRS\"></a>分析 Cosine LRS</h4><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/96d5f382f6d650b0f98f618576276f19-image.png\" alt=\"图4：具有不同周期的余弦学习率调度器。Y轴是C4语料库上的损失。\"></p>\n<p>在”4.1 Analysing Cosine LRS”小节中，论文分析了余弦学习率调度器（Cosine LRS）的关键特性和其对模型性能的影响。以下是该小节的主要内容：</p>\n<ol>\n<li><p><strong>余弦学习率调度器的基本原理</strong>：</p>\n<ul>\n<li>余弦学习率调度器（Cosine LRS）是一种常用的学习率调整策略，它在训练过程中逐渐降低学习率，遵循余弦曲线的变化。具体来说，学习率在预热阶段达到最大值后，按照余弦函数的形状逐渐下降。</li>\n</ul>\n</li>\n<li><p><strong>关键超参数</strong>：</p>\n<ul>\n<li>余弦学习率调度器的一个关键超参数是步长 $T$，即余弦函数首次降到最小值的时间点。通常，$T$ 被设置为总训练步数 $S$。</li>\n</ul>\n</li>\n<li><p><strong>实验验证</strong>：</p>\n<ul>\n<li>论文通过在0.036B模型上进行实验，验证了不同 $T$ 值对学习率调度器性能的影响。实验结果表明，当 $T&#x3D;S$ 时，模型的损失最低。这表明在整个训练过程中保持较高的学习率有助于模型找到更好的全局最优解。</li>\n<li>当 $T&lt;S$ 或 $T&gt;S$ 时，模型的性能不如 $T&#x3D;S$ 时的表现。特别是，$T&gt;S$ 会导致性能下降。</li>\n</ul>\n</li>\n<li><p><strong>假设分析</strong>：</p>\n<ul>\n<li>论文提出了两个假设来解释为什么 $T&#x3D;S$ 时余弦学习率调度器表现优异：<ol>\n<li>当 $T&#x3D;S$ 时，高学习率训练的持续时间更长，这有助于模型找到更好的全局最优解。</li>\n<li>当 $T&#x3D;S$ 时，学习率衰减阶段更为彻底，这可能涉及独特的训练动态，使模型能够找到更好的局部最优解。</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><p><strong>实验结果</strong>：</p>\n<ul>\n<li>实验结果显示，在 $T&#x3D;S$ 时，余弦学习率调度器的性能最佳。具体来说，当训练步数为 $S&#x3D;20N, 40N, 60N, 80N$ 时，损失总是由 $\\operatorname{Cosine}(T)$ 达到最低，而不是 $\\operatorname{Cosine}(T)$ 或 $\\operatorname{CosineLoop}(T)$。</li>\n</ul>\n</li>\n</ol>\n<p>通过这些分析，论文强调了余弦学习率调度器在特定条件下（即 $T&#x3D;S$）的优越性，并为后续提出的WSD（Warmup-Stable-Decay）学习率调度器奠定了基础。</p>\n<h4 id=\"提出-WSD-LRS\"><a href=\"#提出-WSD-LRS\" class=\"headerlink\" title=\"提出 WSD LRS\"></a>提出 WSD LRS</h4><p>在”4.2 WSD LRS”小节中，论文提出了一种新的学习率调度器，称为Warmup-Stable-Decay (WSD) 学习率调度器。以下是该小节的主要内容：</p>\n<h5 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h5><ul>\n<li><strong>背景</strong>：现有的学习率调度器（如Cosine LRS）在训练过程中逐渐降低学习率，但在某些情况下，可能需要更灵活的调度策略来优化模型性能。</li>\n<li><strong>目标</strong>：提出一种新的学习率调度器，能够在训练的不同阶段有效地调整学习率，以提高模型的训练效率和性能。</li>\n</ul>\n<h5 id=\"WSD-LRS的定义\"><a href=\"#WSD-LRS的定义\" class=\"headerlink\" title=\"WSD LRS的定义\"></a>WSD LRS的定义</h5><ul>\n<li><strong>定义</strong>：WSD LRS将训练过程分为三个阶段：预热阶段（Warmup）、稳定阶段（Stable）和衰减阶段（Decay）。</li>\n<li><strong>公式</strong>：<br>$$<br>WSD(T; s)&#x3D;\\left{\\begin{array}{l}<br>\\frac{s}{W}\\eta,\\quad s&lt;W\\<br>\\eta,\\quad W&lt;s&lt;T\\<br>f(s-T)\\eta,\\quad T&lt;s&lt;S<br>\\end{array}\\right.<br>$$<br>其中，$0&lt;f(s-T)\\leq 1$ 是一个关于 $s$ 的递减函数，$\\eta$ 是最大学习率。</li>\n</ul>\n<h5 id=\"实验验证\"><a href=\"#实验验证\" class=\"headerlink\" title=\"实验验证\"></a>实验验证</h5><ul>\n<li><strong>损失下降</strong>：在0.036B模型上使用WSD LRS进行实验，结果显示在衰减阶段，随着学习率的降低，损失显著下降，并且很快达到或低于Cosine LRS在步长 $T&#x3D;S$ 时的表现。</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223143810882.png\" alt=\"image-20241223143810882\"></p>\n<ul>\n<li><strong>快速测试</strong>：缩短衰减阶段可以加快不同模型检查点的快速测试。实验表明，使用10%的总标记数进行衰减足以达到最佳效果。</li>\n</ul>\n<h5 id=\"数据扩展的有效性\"><a href=\"#数据扩展的有效性\" class=\"headerlink\" title=\"数据扩展的有效性\"></a>数据扩展的有效性</h5><ul>\n<li><strong>连续训练</strong>：使用WSD LRS可以持续训练固定大小的模型到极端收敛。实验比较了连续训练0.036B模型和使用40N数据的0.17B模型的性能，结果显示0.036B模型在增加约4倍的训练计算量的情况下，可以达到与0.17B模型相当的性能，同时节省了约5倍的推理计算量。</li>\n</ul>\n<h4 id=\"衰减阶段的分析\"><a href=\"#衰减阶段的分析\" class=\"headerlink\" title=\"衰减阶段的分析\"></a>衰减阶段的分析</h4><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223144222463.png\" alt=\"image-20241223144222463\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223144246606.png\" alt=\"image-20241223144246606\"></p>\n<p>在”4.4 Analysis of the Decay Stage”部分，论文对MiniCPM-2.4B模型在衰减阶段的训练过程进行了详细分析。以下是该部分的几个主要分析点：</p>\n<ol>\n<li><p><strong>权重更新与损失的关系</strong>：</p>\n<ul>\n<li>研究者计算了MiniCPM-2.4B模型中所有权重矩阵的最大权重元素更新。结果显示，权重更新与学习率的幅度之间存在强相关性。具体来说，在学习率衰减之前，模型检查点经历了显著的权重更新，但损失几乎没有减少。相反，在衰减阶段，尽管权重更新的幅度较小，损失却迅速下降。</li>\n</ul>\n</li>\n<li><p><strong>梯度信息的分析</strong>：</p>\n<ul>\n<li>研究者记录了0.2B模型的每一步梯度信息，并评估了连续步骤之间的差异，以近似二阶梯度信息。结果显示，梯度范数在衰减阶段减小，梯度之间的角度余弦值主要为正值，表明在衰减阶段，模型参数在每一步都是一致变化的。</li>\n<li>一阶梯度在每一步显著减小，与学习率的变化密切相关。二阶梯度的幅度略有增加，表明损失函数的曲率增大，接近局部最优解。</li>\n</ul>\n</li>\n<li><p><strong>优化过程的几何解释</strong>：</p>\n<ul>\n<li>研究者将优化过程视为在高维流形上的轨迹，并计算了一阶和二阶梯向导数。结果显示，一阶梯向导数与学习率成指数衰减，而二阶梯向导数的幅度略有增加。这表明在衰减阶段，模型参数的变化更加一致，损失函数的曲率增大，接近局部最优解。</li>\n</ul>\n</li>\n<li><p><strong>实验结果的可视化</strong>：</p>\n<ul>\n<li>图7展示了权重更新的最大差异，图8展示了梯度统计信息。这些图表直观地展示了在衰减阶段，尽管权重更新的幅度较小，但损失迅速下降的现象。</li>\n</ul>\n</li>\n</ol>\n<p>通过这些分析，研究者揭示了在衰减阶段，MiniCPM-2.4B模型的训练动态具有独特的特征，这些特征有助于模型更快地收敛到局部最优解。这些发现为进一步优化模型训练过程提供了重要的见解。</p>\n<h4 id=\"缩放定律的测量\"><a href=\"#缩放定律的测量\" class=\"headerlink\" title=\"缩放定律的测量\"></a>缩放定律的测量</h4><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223144614364.png\" alt=\"image-20241223144614364\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223144647906.png\" alt=\"image-20241223144647906\"></p>\n<p>在”4.5 Measuring the Scaling Law with WSD LRS”部分，论文介绍了如何利用WSD（Warmup-Stable-Decay）学习率调度器来高效地研究大规模语言模型（LLMs）的规模定律。以下是该部分的详细介绍和分析：</p>\n<h5 id=\"1-规模定律的重要性\"><a href=\"#1-规模定律的重要性\" class=\"headerlink\" title=\"1. 规模定律的重要性\"></a>1. 规模定律的重要性</h5><p>规模定律是指导LLMs发展的重要原则，它描述了模型规模和数据规模之间的关系。Kaplan等人（2020）和Hoffmann等人（2022）分别提出了不同的规模定律模型，前者认为模型规模增加十倍应对应数据规模增加一倍，而后者则认为两者应同比例增加。</p>\n<h5 id=\"2-传统规模实验的挑战\"><a href=\"#2-传统规模实验的挑战\" class=\"headerlink\" title=\"2. 传统规模实验的挑战\"></a>2. 传统规模实验的挑战</h5><p>传统的规模实验需要在不同模型规模和数据规模上进行多次训练，计算成本高昂，时间复杂度为$O(m^2 C)$，其中$m$是模型数量，$C$是每次训练的成本。</p>\n<h5 id=\"3-WSD调度器的优势\"><a href=\"#3-WSD调度器的优势\" class=\"headerlink\" title=\"3. WSD调度器的优势\"></a>3. WSD调度器的优势</h5><p>WSD调度器允许在稳定阶段的任意检查点开始衰减，从而在不需要从头开始训练的情况下，精确测量规模定律。这使得规模定律的测量在数据轴上具有线性成本$O(m C)$，大大提高了效率。</p>\n<h5 id=\"4-实验设计\"><a href=\"#4-实验设计\" class=\"headerlink\" title=\"4. 实验设计\"></a>4. 实验设计</h5><ul>\n<li><strong>模型和数据规模</strong>：研究者在6个不同规模的模型（从0.04B到2B）上进行了实验，每个模型在稳定阶段的6个不同检查点（从10N到60N数据）开始衰减。</li>\n<li><strong>训练和评估</strong>：每个模型在五个独立的评估数据集上进行最终损失评估。为了公平比较，损失按字节数而非标记数平均。</li>\n</ul>\n<h5 id=\"5-规模定律的拟合\"><a href=\"#5-规模定律的拟合\" class=\"headerlink\" title=\"5. 规模定律的拟合\"></a>5. 规模定律的拟合</h5><ul>\n<li><strong>拟合公式</strong>：研究者使用Hoffmann等人（2022）提出的公式来拟合损失与模型规模和数据规模的关系：<br>$$<br>L(N, D) &#x3D; C_N N^{-\\alpha} + C_D D^{-\\beta} + L_0<br>$$<br>其中，$N$和$D$分别是模型规模和数据规模，$C_N$和$C_D$是常数，$\\alpha$和$\\beta$是指数，$L_0$是常数项。</li>\n<li><strong>最优模型和数据规模</strong>：通过拟合，研究者得到了每个数据集和检查点的最优模型规模$N_{\\text{opt}}$和数据规模$D_{\\text{opt}}$，并计算了数据-模型比例$\\frac{D_{\\text{opt}}}{N_{\\text{opt}}}$。</li>\n</ul>\n<h5 id=\"6-结果分析\"><a href=\"#6-结果分析\" class=\"headerlink\" title=\"6. 结果分析\"></a>6. 结果分析</h5><ul>\n<li><strong>数据-模型比例</strong>：研究结果表明，数据-模型比例比Hoffmann等人（2022）的结果高得多，平均约为192倍，而不是20倍。这表明较小的模型可以吸收更多的数据，从而提高推理和部署的效率。</li>\n<li><strong>与Chinchilla Optimal的比较</strong>：尽管与Chinchilla Optimal的结果存在较大差异，但通过与Llama2的比较，研究者认为WSD调度器在更现代的配置下可能具有更高的数据-模型比例。</li>\n</ul>\n<h5 id=\"7-未来方向\"><a href=\"#7-未来方向\" class=\"headerlink\" title=\"7. 未来方向\"></a>7. 未来方向</h5><ul>\n<li><strong>进一步研究</strong>：研究者计划深入分析衰减阶段的损失下降原因，并通过扩大模型和数据规模来增强MiniCPM的能力。</li>\n</ul>\n<h5 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h5><p>通过引入WSD调度器，论文提出了一种高效的方法来研究LLMs的规模定律，显著降低了计算成本。研究结果表明，较小的模型可以吸收更多的数据，从而提高推理和部署的效率。未来的研究将进一步探索WSD调度器在其他模型上的应用及其对规模定律的影响。</p>\n<h2 id=\"3-两阶段预训练策略\"><a href=\"#3-两阶段预训练策略\" class=\"headerlink\" title=\"3. 两阶段预训练策略\"></a>3. 两阶段预训练策略</h2><p>论文提出了一种两阶段的预训练策略，旨在提高小型语言模型（SLMs）的性能。以下是对该章节的详细总结和分析：</p>\n<h3 id=\"3-1-背景与动机\"><a href=\"#3-1-背景与动机\" class=\"headerlink\" title=\"3.1 背景与动机\"></a>3.1 背景与动机</h3><ul>\n<li><strong>背景</strong>：大型语言模型（LLMs）的训练成本高昂，且在个人电脑或智能手机等终端设备上部署效率低下。</li>\n<li><strong>动机</strong>：探索小型语言模型（SLMs）作为资源高效的替代方案，并通过可扩展的训练策略，使其具备与大型模型相似的能力。</li>\n</ul>\n<h3 id=\"3-2-两阶段预训练策略\"><a href=\"#3-2-两阶段预训练策略\" class=\"headerlink\" title=\"3.2 两阶段预训练策略\"></a>3.2 两阶段预训练策略</h3><ul>\n<li><p><strong>阶段划分</strong>：</p>\n<ul>\n<li><strong>第一阶段</strong>：仅使用大规模、低质量的预训练数据进行训练。</li>\n<li><strong>第二阶段</strong>：在衰减阶段引入高质量、知识导向的监督微调（SFT）数据，混合到预训练数据中。</li>\n</ul>\n</li>\n<li><p><strong>优势</strong>：</p>\n<ul>\n<li><strong>全面学习</strong>：在衰减阶段引入高质量数据，促进模型在更接近实际用户场景的数据分布上进行更显著的损失减少。</li>\n<li><strong>持续训练</strong>：避免在整个预训练过程中均匀分布高质量数据，集中资源和持续预训练。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"3-3-实验验证\"><a href=\"#3-3-实验验证\" class=\"headerlink\" title=\"3.3 实验验证\"></a>3.3 实验验证</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223145718563.png\" alt=\"image-20241223145718563\"></p>\n<ul>\n<li><p><strong>实验设置</strong>：</p>\n<ul>\n<li><strong>模型选择</strong>：使用MiniCPM-2.4B和MiniCPM-1.2B模型。</li>\n<li><strong>对比实验</strong>：<ul>\n<li>A-1：2.4B模型，仅使用预训练数据进行衰减，随后进行4B标记的SFT。</li>\n<li>A-2：2.4B模型，在衰减阶段混合高质量数据和SFT数据，随后进行4B标记的SFT。</li>\n<li>B-1：1.2B模型，仅使用预训练数据进行衰减，随后进行6B标记的SFT。</li>\n<li>B-2：1.2B模型，仅使用预训练数据进行衰减，随后进行12B标记的SFT。</li>\n<li>B-3：1.2B模型，在衰减阶段混合高质量数据和SFT数据，随后进行6B标记的SFT。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p><strong>结果分析</strong>：</p>\n<ul>\n<li><strong>A-2 vs A-1</strong>：尽管A-2和A-1在SFT阶段使用相同的数据分布，但A-2在衰减阶段引入高质量数据，显著提升了模型性能。</li>\n<li><strong>B-3 vs B-2</strong>：B-3在衰减阶段引入高质量数据，表现优于仅在SFT阶段引入高质量数据的B-2。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"3-4-结论\"><a href=\"#3-4-结论\" class=\"headerlink\" title=\"3.4 结论\"></a>3.4 结论</h3><ul>\n<li><strong>策略有效性</strong>：引入高质量数据到衰减阶段比仅在SFT阶段引入数据更能提升模型性能。</li>\n<li><strong>推荐</strong>：建议从衰减阶段开始，专门化和增强模型能力。</li>\n</ul>\n<h3 id=\"总结-1\"><a href=\"#总结-1\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>论文提出的两阶段预训练策略通过在不同阶段引入不同类型的数据，显著提升了小型语言模型的性能。该策略不仅提高了模型的学习效率，还为未来的大型语言模型开发提供了有价值的参考。</p>\n<h2 id=\"4-MiniCPM-模型\"><a href=\"#4-MiniCPM-模型\" class=\"headerlink\" title=\"4. MiniCPM 模型\"></a>4. MiniCPM 模型</h2><p>第6章节“6 Model”详细介绍了MiniCPM模型的各个方面，包括模型细节、训练阶段、训练数据分布、训练损失和模型评估。以下是各部分的详细介绍：</p>\n<h3 id=\"4-1-Model-Details\"><a href=\"#4-1-Model-Details\" class=\"headerlink\" title=\"4.1 Model Details\"></a>4.1 Model Details</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223153902417.png\" alt=\"image-20241223153902417\"></p>\n<h4 id=\"词汇\"><a href=\"#词汇\" class=\"headerlink\" title=\"词汇\"></a>词汇</h4><ul>\n<li><strong>MiniCPM-2.4B</strong>：使用122,753词汇大小的tokenizer。</li>\n<li><strong>MiniCPM-1.2B</strong>：使用73,440词汇大小的tokenizer，较小的词汇表有利于效率而不显著影响性能。</li>\n</ul>\n<h4 id=\"共享输入输出层\"><a href=\"#共享输入输出层\" class=\"headerlink\" title=\"共享输入输出层\"></a>共享输入输出层</h4><ul>\n<li>为了减少参数空间，MiniCPM-2.4B和MiniCPM-1.2B都使用了嵌入共享技术。</li>\n</ul>\n<h4 id=\"深而薄的网络\"><a href=\"#深而薄的网络\" class=\"headerlink\" title=\"深而薄的网络\"></a>深而薄的网络</h4><ul>\n<li><strong>MiniCPM-2.4B</strong>：在训练MiniCPM-1.2B之前，采用了更深更薄的网络架构。</li>\n<li><strong>MiniCPM-1.2B</strong>：进一步加深和变薄，以适应长上下文任务。</li>\n</ul>\n<h4 id=\"组查询注意力\"><a href=\"#组查询注意力\" class=\"headerlink\" title=\"组查询注意力\"></a>组查询注意力</h4><ul>\n<li><strong>MiniCPM-2.4B</strong>：未修改注意力层。</li>\n<li><strong>MiniCPM-1.2B</strong>：应用了组查询注意力（Group Query Attention）以减少参数数量。</li>\n</ul>\n<h3 id=\"4-2-Training-Stages\"><a href=\"#4-2-Training-Stages\" class=\"headerlink\" title=\"4.2 Training Stages\"></a>4.2 Training Stages</h3><h4 id=\"稳定训练阶段\"><a href=\"#稳定训练阶段\" class=\"headerlink\" title=\"稳定训练阶段\"></a>稳定训练阶段</h4><ul>\n<li>使用约1T的数据，主要来自开放数据集。</li>\n<li>使用WSD学习率调度器，批量大小为3.93百万，最大学习率为0.01。</li>\n</ul>\n<h4 id=\"衰减阶段\"><a href=\"#衰减阶段\" class=\"headerlink\" title=\"衰减阶段\"></a>衰减阶段</h4><ul>\n<li>使用预训练数据和高质量的SFT数据混合。</li>\n<li>采用指数衰减形式，T设为5000步（20B标记）。</li>\n</ul>\n<h4 id=\"SFT阶段\"><a href=\"#SFT阶段\" class=\"headerlink\" title=\"SFT阶段\"></a>SFT阶段</h4><ul>\n<li>使用类似衰减阶段的数据，但不包括预训练数据，训练约60亿标记。</li>\n<li>学习率与衰减阶段末尾相同，使用WSD调度器。</li>\n</ul>\n<h3 id=\"4-3-Training-Data-Distribution\"><a href=\"#4-3-Training-Data-Distribution\" class=\"headerlink\" title=\"4.3 Training Data Distribution\"></a>4.3 Training Data Distribution</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223153949999.png\" alt=\"image-20241223153949999\"></p>\n<ul>\n<li><strong>稳定阶段</strong>：主要使用开放数据集，如CommonCrawl、Dolma、C4、Pile、Code Pre-train等。</li>\n<li><strong>衰减阶段</strong>：数据混合包含更多样化和专有的数据，如UltraChat、SlimOrca、OssInstruct、EvolInstruct等。</li>\n</ul>\n<h3 id=\"4-4-Training-Loss\"><a href=\"#4-4-Training-Loss\" class=\"headerlink\" title=\"4.4 Training Loss\"></a>4.4 Training Loss</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154011909.png\" alt=\"image-20241223154011909\"></p>\n<ul>\n<li>在C4数据集上的整体训练损失显示，衰减阶段的损失显著下降。</li>\n<li>由于使用指数衰减，学习率降至最大值的10%以下后，损失仍继续下降，但最终检查点未用于微调。</li>\n</ul>\n<h3 id=\"4-5-Evaluation\"><a href=\"#4-5-Evaluation\" class=\"headerlink\" title=\"4.5 Evaluation\"></a>4.5 Evaluation</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154036251.png\" alt=\"image-20241223154036251\"></p>\n<ul>\n<li>使用开源工具UltraEval进行评估，支持多种主流大型模型的性能评估。</li>\n<li>评估数据集包括MMLU、CMMLU、C-Eval、MBPP、GSM8K、MATH、HumanEval、BBH等。</li>\n<li>评估方法包括标准化输入提示和调整输入输出模板，确保公平比较。</li>\n</ul>\n<h4 id=\"评估结果\"><a href=\"#评估结果\" class=\"headerlink\" title=\"评估结果\"></a>评估结果</h4><ul>\n<li><strong>MiniCPM-2.4B</strong>：在多个基准测试中表现优异，特别是在中文任务中表现优于Mistral-7B。</li>\n<li><strong>MiniCPM-1.2B</strong>：在多个基准测试中也表现出色，特别是在直接生成任务中表现优于PPL测试。</li>\n</ul>\n<p>通过这些详细的介绍，可以看出MiniCPM模型在设计、训练和评估方面都经过了精心考虑和优化，取得了显著的性能提升。</p>\n<h2 id=\"5-MiniCPM-家族模型\"><a href=\"#5-MiniCPM-家族模型\" class=\"headerlink\" title=\"5. MiniCPM 家族模型\"></a>5. MiniCPM 家族模型</h2><p>论文介绍了基于MiniCPM基础模型的几种扩展模型，包括MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE。这些模型在各自的应用领域中展示了卓越的性能。以下是该章节的详细介绍：</p>\n<h3 id=\"5-1-MiniCPM-DPO\"><a href=\"#5-1-MiniCPM-DPO\" class=\"headerlink\" title=\"5.1 MiniCPM-DPO\"></a>5.1 MiniCPM-DPO</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154302859.png\" alt=\"image-20241223154302859\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154345626.png\" alt=\"image-20241223154345626\"></p>\n<ul>\n<li><strong>背景</strong>：在微调阶段之后，使用DPO（Direct Preference Optimization）进行人类偏好对齐。</li>\n<li><strong>训练</strong>：使用UltraFeedback作为主要对齐数据集，并构建了一个专有的偏好数据集以增强模型的代码和数学能力。</li>\n<li><strong>结果</strong>：在MTBench上的得分从SFT后的6.89提高到7.25，超过了像Llama2-70B-Chat这样的大型模型。然而，基准测试结果略有下降，这是对齐税（alignment tax）的表现。</li>\n</ul>\n<h3 id=\"5-2-MiniCPM-128K\"><a href=\"#5-2-MiniCPM-128K\" class=\"headerlink\" title=\"5.2 MiniCPM-128K\"></a>5.2 MiniCPM-128K</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154425567.png\" alt=\"image-20241223154425567\"></p>\n<ul>\n<li><strong>背景</strong>：处理长上下文任务需要模型能够隐含地理解长文本中的信息。</li>\n<li><strong>初始化</strong>：禁用输入和输出之间的嵌入共享，以适应长上下文训练所需的词汇并行性。</li>\n<li><strong>训练</strong>：使用WSD学习率调度器，训练数据分为“短数据”和“长数据”，长数据占44%，短数据占56%。使用Adjusted Base Frequency (ABF)和NTK-Aware RoPE Scaling进行扩展。</li>\n<li><strong>评估</strong>：在∞Bench基准测试中表现优异，特别是在长上下文推理任务中，超越了ChatGLM3-6B-128K。</li>\n</ul>\n<h3 id=\"5-3-MiniCPM-MoE\"><a href=\"#5-3-MiniCPM-MoE\" class=\"headerlink\" title=\"5.3 MiniCPM-MoE\"></a>5.3 MiniCPM-MoE</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154445784.png\" alt=\"image-20241223154445784\"></p>\n<ul>\n<li><strong>背景</strong>：通过混合专家（MoE）技术扩展MiniCPM的能力。</li>\n<li><strong>初始化</strong>：使用Sparse Upcycling进行初始化，将密集模型的每个MLP层替换为MoE层，路由参数随机初始化。</li>\n<li><strong>训练</strong>：使用WSD学习率调度器，训练批量大小在稳定和衰减阶段为4M，在SFT阶段减少到2M。</li>\n<li><strong>结果</strong>：在多个基准测试中表现优异，特别是在C-Eval、CMMLU、MMLU、HumanEval、MBPP、GSM8K和MATH等任务上。</li>\n</ul>\n<p>MiniCPM家族的扩展模型在各自的领域中展示了卓越的性能，证明了MiniCPM在多样化的SLM应用中的潜力。未来的研究方向包括深入分析衰减阶段的损失下降，并通过扩展模型规模和数据规模来增强MiniCPM的能力。</p>\n<h2 id=\"6-研究结论\"><a href=\"#6-研究结论\" class=\"headerlink\" title=\"6. 研究结论\"></a>6. 研究结论</h2><ul>\n<li>MiniCPM 系列模型展示了小型语言模型在资源效率和性能上的巨大潜力。通过创新的训练方法和架构设计，MiniCPM 不仅在小型模型中表现出色，还能够与大型模型相媲美。WSD 学习率调度器的引入为模型的持续训练和数据-模型缩放规律的研究提供了新的思路。此外，MiniCPM 家族的多样化模型进一步巩固了其在不同应用场景中的基础地位。</li>\n</ul>\n<h2 id=\"7-论文研究的不足\"><a href=\"#7-论文研究的不足\" class=\"headerlink\" title=\"7. 论文研究的不足\"></a>7. 论文研究的不足</h2><p>尽管 MiniCPM 在小型语言模型的研究中取得了显著进展，但仍存在一些不足之处：</p>\n<ol>\n<li><strong>未验证在大型模型上的应用</strong>：论文主要集中在小型模型的研究上，尚未验证 WSD 调度器在大型模型上的应用效果。</li>\n<li><strong>缺乏对损失下降机制的深入分析</strong>：尽管 WSD 调度器在 Decay 阶段表现出色，但其背后的机制尚未得到深入分析，未来需要进一步研究。</li>\n<li><strong>未考虑实际部署中的优化</strong>：虽然 MiniCPM 在资源效率上表现出色，但在实际部署中，仍需进一步优化以适应不同的硬件环境。</li>\n</ol>\n<h2 id=\"8-论文评价\"><a href=\"#8-论文评价\" class=\"headerlink\" title=\"8.论文评价\"></a>8.论文评价</h2><h3 id=\"优点与创新\"><a href=\"#优点与创新\" class=\"headerlink\" title=\"优点与创新\"></a>优点与创新</h3><ol>\n<li><strong>MiniCPM模型系列</strong>：论文介绍了MiniCPM系列小型语言模型，包括1.2B和2.4B非嵌入参数变体，这些模型在各自的小规模类别中表现卓越，并且与7B-13B大型语言模型的能力相当。</li>\n<li><strong>可扩展性</strong>：研究展示了在模型和数据维度上的可扩展性，为未来的大型语言模型（LLM）研究提供了潜力。</li>\n<li><strong>模型风洞实验</strong>：通过广泛的模型风洞实验，确保了稳定和最优的模型扩展。</li>\n<li><strong>温暖的稳定衰减（WSD）学习率调度器（LRS）</strong>：引入了WSD LRS，有利于连续训练和领域适应，并能够高效地研究数据-模型扩展规律。</li>\n<li><strong>训练动态分析</strong>：对WSD LRS的训练动态进行了深入分析，揭示了模型预训练的有趣损失景观。</li>\n<li><strong>更高的计算最优数据-模型比率</strong>：通过WSD LRS，能够在模型轴上线性努力，在数据轴上忽略不计的努力，从而得出比Chinchilla Optimal更高的计算最优数据-模型比率。</li>\n<li><strong>MiniCPM家族</strong>：介绍了MiniCPM家族，包括MiniCPM-DPO、MiniCPM-MoE和MiniCPM-128K，进一步巩固了MiniCPM在多样化小型语言模型应用中的基础。</li>\n<li><strong>公开可用</strong>：MiniCPM模型系列公开发布，便于其他研究人员使用和改进。</li>\n</ol>\n<h3 id=\"不足与反思\"><a href=\"#不足与反思\" class=\"headerlink\" title=\"不足与反思\"></a>不足与反思</h3><ol>\n<li><strong>未扩展到大型语言模型</strong>：尽管研究了小型语言模型的扩展规律，但论文并未扩展到训练大型语言模型以验证扩展规律。</li>\n<li><strong>WSD LRS在大型语言模型上的应用未完全探索</strong>：尽管对WSD LRS在大型语言模型上的潜在优势保持乐观，但目前尚未完全探索其在大型语言模型上的应用。</li>\n</ol>\n<h2 id=\"9-关键问题及回答\"><a href=\"#9-关键问题及回答\" class=\"headerlink\" title=\"9. 关键问题及回答\"></a>9. 关键问题及回答</h2><h3 id=\"问题1：MiniCPM模型在模型风洞实验中是如何进行超参数优化的？\"><a href=\"#问题1：MiniCPM模型在模型风洞实验中是如何进行超参数优化的？\" class=\"headerlink\" title=\"问题1：MiniCPM模型在模型风洞实验中是如何进行超参数优化的？\"></a><strong>问题1：MiniCPM模型在模型风洞实验中是如何进行超参数优化的？</strong></h3><p>MiniCPM模型在模型风洞实验中进行了广泛的超参数优化，主要包括以下几个方面：</p>\n<ol>\n<li><strong>宽度缩放</strong>：使用Tensor Program技术进行宽度缩放，支持CerebrasGPT等模型在不同模型规模下的超参数一致性。</li>\n<li><strong>深度缩放</strong>：同样使用Tensor Program技术进行深度缩放，尽管对于深度大于2的网络，深度缩放的效果不如预期，但实验结果显示最优学习率是稳定的。</li>\n<li><strong>学习率调度器</strong>：引入了Warmup-Stable-Decay（WSD）学习率调度器，适用于连续训练和领域适应。WSD调度器将训练阶段明确分为高学习率阶段和衰减阶段。</li>\n</ol>\n<p>通过这些超参数优化技术，MiniCPM模型能够在不同模型规模下实现稳定的训练和优化。</p>\n<h3 id=\"问题2：Warmup-Stable-Decay（WSD）学习率调度器在MiniCPM模型中的具体实现和效果如何？\"><a href=\"#问题2：Warmup-Stable-Decay（WSD）学习率调度器在MiniCPM模型中的具体实现和效果如何？\" class=\"headerlink\" title=\"问题2：Warmup-Stable-Decay（WSD）学习率调度器在MiniCPM模型中的具体实现和效果如何？\"></a><strong>问题2：Warmup-Stable-Decay（WSD）学习率调度器在MiniCPM模型中的具体实现和效果如何？</strong></h3><p>Warmup-Stable-Decay（WSD）学习率调度器在MiniCPM模型中的具体实现如下：</p>\n<ol>\n<li><strong>高学习率阶段</strong>：模型在初始阶段采用较高的学习率进行训练，以便快速找到全局最优解。</li>\n<li><strong>衰减阶段</strong>：当学习率达到一定值后，学习率逐渐减小，直至达到最小值。这一阶段的学习率衰减是线性的，并且在衰减结束后保持恒定。</li>\n<li><strong>连续训练</strong>：WSD调度器允许模型在衰减阶段之后继续进行训练，从而实现连续训练。</li>\n</ol>\n<p>效果方面，WSD调度器在MiniCPM模型中表现出显著的优势：</p>\n<ol>\n<li><strong>损失降低</strong>：在衰减阶段，学习率的突然减小导致损失显著下降，并且损失迅速降至与Cosine LRS相当的水平。</li>\n<li><strong>连续训练</strong>：通过WSD调度器，模型可以在衰减阶段之后继续训练，达到与较大模型相似的性能，同时节省了大量的计算资源。</li>\n<li><strong>数据-模型缩放定律</strong>：WSD调度器使得研究数据-模型缩放定律变得更加高效，能够在模型轴和数据轴上以线性努力进行研究。</li>\n</ol>\n<h3 id=\"问题3：MiniCPM家族中的其他成员（如MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE）有哪些具体功能和表现？\"><a href=\"#问题3：MiniCPM家族中的其他成员（如MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE）有哪些具体功能和表现？\" class=\"headerlink\" title=\"问题3：MiniCPM家族中的其他成员（如MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE）有哪些具体功能和表现？\"></a><strong>问题3：MiniCPM家族中的其他成员（如MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE）有哪些具体功能和表现？</strong></h3><p>MiniCPM家族中的其他成员包括MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE，它们各自具有不同的功能和表现：</p>\n<ol>\n<li><strong>MiniCPM-DPO</strong>：在SFT阶段之后，MiniCPM-DPO通过DPO（Direct Preference Optimization）进行人类偏好对齐。使用UltraFeedback作为主要对齐数据集，并构建了一个专有的偏好数据集以增强模型的代码和数学能力。在MTBench基准测试中，MiniCPM-DPO的性能从SFT后的6.89提高到7.25，超过了多个较大的模型。</li>\n<li><strong>MiniCPM-128K</strong>：将MiniCPM-2.4B的上下文长度从4096扩展到128,000 tokens，展示了小型语言模型在处理长上下文任务中的能力。通过调整基础频率和使用NTK-Aware RoPE Scaling等技术，MiniCPM-128K在∞Bench基准测试中取得了与Mistral-7B-Instruct-v0.2相当的结果，尽管其模型规模较小。</li>\n<li><strong>MiniCPM-MoE</strong>：通过引入Mixture-of-Expert（MoE），MiniCPM-MoE进一步扩展了MiniCPM的能力。MoE模型在每个token上激活两个专家，并使用Router参数进行路由。在MBPP基准测试中，MiniCPM-MoE的性能与Llama2-34B相当，表明其在多任务语言理解方面的强大能力。</li>\n</ol>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink\">https://github.com/chongzicbo/ReadWriteThink</a></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n","excerpt":"","more":"<p>“MiniCPM: Unveiling the Potential of Small Language Models with Scalable Training Strategies” 由清华大学和 Modelbest Inc. 的众多研究人员共同撰写，介绍了 MiniCPM 系列小型语言模型，包括模型架构、训练方法、实验结果等，展现了其在模型和数据维度的可扩展性，以及在小型语言模型中的优势。</p>\n<h2 id=\"1-研究背景\"><a href=\"#1-研究背景\" class=\"headerlink\" title=\"1. 研究背景\"></a>1. 研究背景</h2><h3 id=\"1-1-之前研究存在的问题\"><a href=\"#1-1-之前研究存在的问题\" class=\"headerlink\" title=\"1.1 之前研究存在的问题\"></a>1.1 之前研究存在的问题</h3><p>近年来，大型语言模型（LLMs）如GPT-3、PaLM等在自然语言处理领域取得了显著的进展。这些模型通常拥有数十亿甚至上万亿的参数，能够处理复杂的任务并展现出强大的泛化能力。然而，训练和部署这些大型模型面临着巨大的资源消耗和成本问题。例如，训练一个万亿参数的模型需要大量的计算资源和能源，且在实际应用中，这些模型的部署也面临着效率和可行性的挑战。</p>\n<h3 id=\"1-2-研究难点\"><a href=\"#1-2-研究难点\" class=\"headerlink\" title=\"1.2 研究难点\"></a>1.2 研究难点</h3><p>尽管大型模型的性能令人印象深刻，但其高昂的训练成本和资源消耗使得许多研究者和企业难以负担。此外，这些模型在实际应用中的部署也面临着诸多限制，尤其是在资源受限的设备上，如个人电脑或智能手机。因此，如何在不牺牲性能的前提下，开发出资源效率更高的小型语言模型（SLMs）成为了当前研究的一个重要方向。</p>\n<h3 id=\"1-3-相关工作总结\"><a href=\"#1-3-相关工作总结\" class=\"headerlink\" title=\"1.3 相关工作总结\"></a>1.3 相关工作总结</h3><p>近年来，小型语言模型（SLMs）的研究逐渐受到关注。一些研究者提出了通过数据优化、模型剪枝和架构重构等方法来提升SLMs的性能。例如，Phi系列、TinyLlama、MobileLLM等模型通过高质量数据和结构优化，展示了SLMs在特定任务上的潜力。然而，这些模型在综合能力上仍然难以与大型模型相媲美，且缺乏透明和可扩展的训练方法。</p>\n<h2 id=\"2-研究方法\"><a href=\"#2-研究方法\" class=\"headerlink\" title=\"2. 研究方法\"></a>2. 研究方法</h2><h3 id=\"2-1-模型风洞实验\"><a href=\"#2-1-模型风洞实验\" class=\"headerlink\" title=\"2.1 模型风洞实验\"></a>2.1 模型风洞实验</h3><h4 id=\"Scaling-Hyper-parameters-Invariant-LM\"><a href=\"#Scaling-Hyper-parameters-Invariant-LM\" class=\"headerlink\" title=\"Scaling Hyper-parameters Invariant LM\"></a>Scaling Hyper-parameters Invariant LM</h4><p>Scaling Hyper-parameters Invariant LM（缩放超参数不变的语言模型）是一种旨在通过调整模型的超参数来实现不同规模模型的性能稳定的方法。这种方法的核心思想是利用Tensor Program框架中的宽度缩放和深度缩放技术，以预测大型语言模型（LLMs）的损失，并确保在不同规模的模型上获得最佳的学习率。</p>\n<p>在MiniCPM中，作者采用了Tensor Program的这两种缩放技术：</p>\n<ol>\n<li><p><strong>宽度缩放（Width Scaling）</strong>：这种技术通过调整模型的隐藏层维度来改变模型的宽度。在MiniCPM中，宽度缩放被应用于所有模型，包括MiniCPM-1.2B和MiniCPM-2.4B。</p>\n</li>\n<li><p><strong>深度缩放（Depth Scaling）</strong>：这种技术通过增加模型的层数来改变模型的深度。尽管Yang等人在2023年的研究中观察到，当网络块深度大于2时，深度缩放的效果不理想，但作者在实践中发现，对于MiniCPM模型，深度缩放仍然能够带来稳定的学习率。</p>\n</li>\n</ol>\n<p>此外，作者没有采用注意力softmax缩放技术，因为他们在实践中发现，即使不使用这种技术，模型的学习率仍然是稳定的。</p>\n<p>通过这些缩放技术，MiniCPM能够在不同规模的模型上实现超参数的稳定性和一致性，从而提高模型的训练效率和性能。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223141035777.png\" alt=\"image-20241223141035777\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223141106997.png\" alt=\"image-20241223141106997\"></p>\n<h4 id=\"最优批量大小\"><a href=\"#最优批量大小\" class=\"headerlink\" title=\"最优批量大小\"></a>最优批量大小</h4><p>在”3.2 Optimal Batch Size”部分，论文探讨了批量大小（batch size）对模型训练的影响以及如何确定最佳的批量大小。批量大小决定了模型在每次迭代中处理的数据量，它直接影响模型的收敛速度和计算资源的消耗。以下是该部分的几个主要观点：</p>\n<ol>\n<li><p><strong>批量大小与收敛速度和资源消耗的平衡</strong>：</p>\n<ul>\n<li>如果批量大小过大，会导致大量的数据和计算成本。</li>\n<li>如果批量大小过小，则需要更多的训练步骤，可能导致损失函数下降有限。</li>\n</ul>\n</li>\n<li><p><strong>实验设置</strong>：</p>\n<ul>\n<li>论文在三个不同大小的模型上进行了实验：0.009B、0.03B 和 0.17B。</li>\n<li>每个模型在六个不同的批量大小上进行训练，全局学习率为0.01，使用余弦学习率调度器。</li>\n</ul>\n</li>\n<li><p><strong>观察到的趋势</strong>：</p>\n<ul>\n<li>批量大小与损失之间的关系显示，随着损失的减少，最佳批量大小会增大。</li>\n<li>通过拟合等损失点，发现批量大小与损失之间存在线性关系。</li>\n</ul>\n</li>\n<li><p><strong>公式推导</strong>：</p>\n<ul>\n<li>论文提出了一个公式来描述批量大小（bs）与C4数据集上的损失（L）之间的关系：<br>$$<br>bs&#x3D;\\frac{1.21\\times10^{9}}{L^{6.24}}<br>$$</li>\n</ul>\n</li>\n</ol>\n<p>总的来说，论文通过实验和分析，展示了如何根据预期的损失来确定最佳批量大小，并提出了一个基于损失预测的批量大小估计方法。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223141919897.png\" alt=\"image-20241223141919897\"></p>\n<h4 id=\"最优学习率\"><a href=\"#最优学习率\" class=\"headerlink\" title=\"最优学习率\"></a>最优学习率</h4><p>由于我们使用了张量程序（Yang等人，2022年；2023年），我们预计学习率在模型扩展期间不会发生显著变化。为了验证这一点，我们在0.04B、0.1B、0.3B和0.5B的六个学习率实验中进行测试。在图3中，我们发现尽管模型大小增加了十倍，最优基础学习率2并没有明显变化，保持在大约0.01左右。我们进一步在2.1B的规模上进行简单验证，确认0.01的学习率确实实现了最低损失。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/ffd302f2750f29d6e75e666fa43c51a3-image.png\" alt=\"图3：损失与学习率的关系。在应用张量程序后，学习率的变动变得非常小。\"></p>\n<h3 id=\"2-2-WSD-学习率调度器（LRS）\"><a href=\"#2-2-WSD-学习率调度器（LRS）\" class=\"headerlink\" title=\"2.2 WSD 学习率调度器（LRS）\"></a>2.2 WSD 学习率调度器（LRS）</h3><h4 id=\"分析-Cosine-LRS\"><a href=\"#分析-Cosine-LRS\" class=\"headerlink\" title=\"分析 Cosine LRS\"></a>分析 Cosine LRS</h4><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/96d5f382f6d650b0f98f618576276f19-image.png\" alt=\"图4：具有不同周期的余弦学习率调度器。Y轴是C4语料库上的损失。\"></p>\n<p>在”4.1 Analysing Cosine LRS”小节中，论文分析了余弦学习率调度器（Cosine LRS）的关键特性和其对模型性能的影响。以下是该小节的主要内容：</p>\n<ol>\n<li><p><strong>余弦学习率调度器的基本原理</strong>：</p>\n<ul>\n<li>余弦学习率调度器（Cosine LRS）是一种常用的学习率调整策略，它在训练过程中逐渐降低学习率，遵循余弦曲线的变化。具体来说，学习率在预热阶段达到最大值后，按照余弦函数的形状逐渐下降。</li>\n</ul>\n</li>\n<li><p><strong>关键超参数</strong>：</p>\n<ul>\n<li>余弦学习率调度器的一个关键超参数是步长 $T$，即余弦函数首次降到最小值的时间点。通常，$T$ 被设置为总训练步数 $S$。</li>\n</ul>\n</li>\n<li><p><strong>实验验证</strong>：</p>\n<ul>\n<li>论文通过在0.036B模型上进行实验，验证了不同 $T$ 值对学习率调度器性能的影响。实验结果表明，当 $T&#x3D;S$ 时，模型的损失最低。这表明在整个训练过程中保持较高的学习率有助于模型找到更好的全局最优解。</li>\n<li>当 $T&lt;S$ 或 $T&gt;S$ 时，模型的性能不如 $T&#x3D;S$ 时的表现。特别是，$T&gt;S$ 会导致性能下降。</li>\n</ul>\n</li>\n<li><p><strong>假设分析</strong>：</p>\n<ul>\n<li>论文提出了两个假设来解释为什么 $T&#x3D;S$ 时余弦学习率调度器表现优异：<ol>\n<li>当 $T&#x3D;S$ 时，高学习率训练的持续时间更长，这有助于模型找到更好的全局最优解。</li>\n<li>当 $T&#x3D;S$ 时，学习率衰减阶段更为彻底，这可能涉及独特的训练动态，使模型能够找到更好的局部最优解。</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><p><strong>实验结果</strong>：</p>\n<ul>\n<li>实验结果显示，在 $T&#x3D;S$ 时，余弦学习率调度器的性能最佳。具体来说，当训练步数为 $S&#x3D;20N, 40N, 60N, 80N$ 时，损失总是由 $\\operatorname{Cosine}(T)$ 达到最低，而不是 $\\operatorname{Cosine}(T)$ 或 $\\operatorname{CosineLoop}(T)$。</li>\n</ul>\n</li>\n</ol>\n<p>通过这些分析，论文强调了余弦学习率调度器在特定条件下（即 $T&#x3D;S$）的优越性，并为后续提出的WSD（Warmup-Stable-Decay）学习率调度器奠定了基础。</p>\n<h4 id=\"提出-WSD-LRS\"><a href=\"#提出-WSD-LRS\" class=\"headerlink\" title=\"提出 WSD LRS\"></a>提出 WSD LRS</h4><p>在”4.2 WSD LRS”小节中，论文提出了一种新的学习率调度器，称为Warmup-Stable-Decay (WSD) 学习率调度器。以下是该小节的主要内容：</p>\n<h5 id=\"引言\"><a href=\"#引言\" class=\"headerlink\" title=\"引言\"></a>引言</h5><ul>\n<li><strong>背景</strong>：现有的学习率调度器（如Cosine LRS）在训练过程中逐渐降低学习率，但在某些情况下，可能需要更灵活的调度策略来优化模型性能。</li>\n<li><strong>目标</strong>：提出一种新的学习率调度器，能够在训练的不同阶段有效地调整学习率，以提高模型的训练效率和性能。</li>\n</ul>\n<h5 id=\"WSD-LRS的定义\"><a href=\"#WSD-LRS的定义\" class=\"headerlink\" title=\"WSD LRS的定义\"></a>WSD LRS的定义</h5><ul>\n<li><strong>定义</strong>：WSD LRS将训练过程分为三个阶段：预热阶段（Warmup）、稳定阶段（Stable）和衰减阶段（Decay）。</li>\n<li><strong>公式</strong>：<br>$$<br>WSD(T; s)&#x3D;\\left{\\begin{array}{l}<br>\\frac{s}{W}\\eta,\\quad s&lt;W\\<br>\\eta,\\quad W&lt;s&lt;T\\<br>f(s-T)\\eta,\\quad T&lt;s&lt;S<br>\\end{array}\\right.<br>$$<br>其中，$0&lt;f(s-T)\\leq 1$ 是一个关于 $s$ 的递减函数，$\\eta$ 是最大学习率。</li>\n</ul>\n<h5 id=\"实验验证\"><a href=\"#实验验证\" class=\"headerlink\" title=\"实验验证\"></a>实验验证</h5><ul>\n<li><strong>损失下降</strong>：在0.036B模型上使用WSD LRS进行实验，结果显示在衰减阶段，随着学习率的降低，损失显著下降，并且很快达到或低于Cosine LRS在步长 $T&#x3D;S$ 时的表现。</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223143810882.png\" alt=\"image-20241223143810882\"></p>\n<ul>\n<li><strong>快速测试</strong>：缩短衰减阶段可以加快不同模型检查点的快速测试。实验表明，使用10%的总标记数进行衰减足以达到最佳效果。</li>\n</ul>\n<h5 id=\"数据扩展的有效性\"><a href=\"#数据扩展的有效性\" class=\"headerlink\" title=\"数据扩展的有效性\"></a>数据扩展的有效性</h5><ul>\n<li><strong>连续训练</strong>：使用WSD LRS可以持续训练固定大小的模型到极端收敛。实验比较了连续训练0.036B模型和使用40N数据的0.17B模型的性能，结果显示0.036B模型在增加约4倍的训练计算量的情况下，可以达到与0.17B模型相当的性能，同时节省了约5倍的推理计算量。</li>\n</ul>\n<h4 id=\"衰减阶段的分析\"><a href=\"#衰减阶段的分析\" class=\"headerlink\" title=\"衰减阶段的分析\"></a>衰减阶段的分析</h4><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223144222463.png\" alt=\"image-20241223144222463\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223144246606.png\" alt=\"image-20241223144246606\"></p>\n<p>在”4.4 Analysis of the Decay Stage”部分，论文对MiniCPM-2.4B模型在衰减阶段的训练过程进行了详细分析。以下是该部分的几个主要分析点：</p>\n<ol>\n<li><p><strong>权重更新与损失的关系</strong>：</p>\n<ul>\n<li>研究者计算了MiniCPM-2.4B模型中所有权重矩阵的最大权重元素更新。结果显示，权重更新与学习率的幅度之间存在强相关性。具体来说，在学习率衰减之前，模型检查点经历了显著的权重更新，但损失几乎没有减少。相反，在衰减阶段，尽管权重更新的幅度较小，损失却迅速下降。</li>\n</ul>\n</li>\n<li><p><strong>梯度信息的分析</strong>：</p>\n<ul>\n<li>研究者记录了0.2B模型的每一步梯度信息，并评估了连续步骤之间的差异，以近似二阶梯度信息。结果显示，梯度范数在衰减阶段减小，梯度之间的角度余弦值主要为正值，表明在衰减阶段，模型参数在每一步都是一致变化的。</li>\n<li>一阶梯度在每一步显著减小，与学习率的变化密切相关。二阶梯度的幅度略有增加，表明损失函数的曲率增大，接近局部最优解。</li>\n</ul>\n</li>\n<li><p><strong>优化过程的几何解释</strong>：</p>\n<ul>\n<li>研究者将优化过程视为在高维流形上的轨迹，并计算了一阶和二阶梯向导数。结果显示，一阶梯向导数与学习率成指数衰减，而二阶梯向导数的幅度略有增加。这表明在衰减阶段，模型参数的变化更加一致，损失函数的曲率增大，接近局部最优解。</li>\n</ul>\n</li>\n<li><p><strong>实验结果的可视化</strong>：</p>\n<ul>\n<li>图7展示了权重更新的最大差异，图8展示了梯度统计信息。这些图表直观地展示了在衰减阶段，尽管权重更新的幅度较小，但损失迅速下降的现象。</li>\n</ul>\n</li>\n</ol>\n<p>通过这些分析，研究者揭示了在衰减阶段，MiniCPM-2.4B模型的训练动态具有独特的特征，这些特征有助于模型更快地收敛到局部最优解。这些发现为进一步优化模型训练过程提供了重要的见解。</p>\n<h4 id=\"缩放定律的测量\"><a href=\"#缩放定律的测量\" class=\"headerlink\" title=\"缩放定律的测量\"></a>缩放定律的测量</h4><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223144614364.png\" alt=\"image-20241223144614364\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223144647906.png\" alt=\"image-20241223144647906\"></p>\n<p>在”4.5 Measuring the Scaling Law with WSD LRS”部分，论文介绍了如何利用WSD（Warmup-Stable-Decay）学习率调度器来高效地研究大规模语言模型（LLMs）的规模定律。以下是该部分的详细介绍和分析：</p>\n<h5 id=\"1-规模定律的重要性\"><a href=\"#1-规模定律的重要性\" class=\"headerlink\" title=\"1. 规模定律的重要性\"></a>1. 规模定律的重要性</h5><p>规模定律是指导LLMs发展的重要原则，它描述了模型规模和数据规模之间的关系。Kaplan等人（2020）和Hoffmann等人（2022）分别提出了不同的规模定律模型，前者认为模型规模增加十倍应对应数据规模增加一倍，而后者则认为两者应同比例增加。</p>\n<h5 id=\"2-传统规模实验的挑战\"><a href=\"#2-传统规模实验的挑战\" class=\"headerlink\" title=\"2. 传统规模实验的挑战\"></a>2. 传统规模实验的挑战</h5><p>传统的规模实验需要在不同模型规模和数据规模上进行多次训练，计算成本高昂，时间复杂度为$O(m^2 C)$，其中$m$是模型数量，$C$是每次训练的成本。</p>\n<h5 id=\"3-WSD调度器的优势\"><a href=\"#3-WSD调度器的优势\" class=\"headerlink\" title=\"3. WSD调度器的优势\"></a>3. WSD调度器的优势</h5><p>WSD调度器允许在稳定阶段的任意检查点开始衰减，从而在不需要从头开始训练的情况下，精确测量规模定律。这使得规模定律的测量在数据轴上具有线性成本$O(m C)$，大大提高了效率。</p>\n<h5 id=\"4-实验设计\"><a href=\"#4-实验设计\" class=\"headerlink\" title=\"4. 实验设计\"></a>4. 实验设计</h5><ul>\n<li><strong>模型和数据规模</strong>：研究者在6个不同规模的模型（从0.04B到2B）上进行了实验，每个模型在稳定阶段的6个不同检查点（从10N到60N数据）开始衰减。</li>\n<li><strong>训练和评估</strong>：每个模型在五个独立的评估数据集上进行最终损失评估。为了公平比较，损失按字节数而非标记数平均。</li>\n</ul>\n<h5 id=\"5-规模定律的拟合\"><a href=\"#5-规模定律的拟合\" class=\"headerlink\" title=\"5. 规模定律的拟合\"></a>5. 规模定律的拟合</h5><ul>\n<li><strong>拟合公式</strong>：研究者使用Hoffmann等人（2022）提出的公式来拟合损失与模型规模和数据规模的关系：<br>$$<br>L(N, D) &#x3D; C_N N^{-\\alpha} + C_D D^{-\\beta} + L_0<br>$$<br>其中，$N$和$D$分别是模型规模和数据规模，$C_N$和$C_D$是常数，$\\alpha$和$\\beta$是指数，$L_0$是常数项。</li>\n<li><strong>最优模型和数据规模</strong>：通过拟合，研究者得到了每个数据集和检查点的最优模型规模$N_{\\text{opt}}$和数据规模$D_{\\text{opt}}$，并计算了数据-模型比例$\\frac{D_{\\text{opt}}}{N_{\\text{opt}}}$。</li>\n</ul>\n<h5 id=\"6-结果分析\"><a href=\"#6-结果分析\" class=\"headerlink\" title=\"6. 结果分析\"></a>6. 结果分析</h5><ul>\n<li><strong>数据-模型比例</strong>：研究结果表明，数据-模型比例比Hoffmann等人（2022）的结果高得多，平均约为192倍，而不是20倍。这表明较小的模型可以吸收更多的数据，从而提高推理和部署的效率。</li>\n<li><strong>与Chinchilla Optimal的比较</strong>：尽管与Chinchilla Optimal的结果存在较大差异，但通过与Llama2的比较，研究者认为WSD调度器在更现代的配置下可能具有更高的数据-模型比例。</li>\n</ul>\n<h5 id=\"7-未来方向\"><a href=\"#7-未来方向\" class=\"headerlink\" title=\"7. 未来方向\"></a>7. 未来方向</h5><ul>\n<li><strong>进一步研究</strong>：研究者计划深入分析衰减阶段的损失下降原因，并通过扩大模型和数据规模来增强MiniCPM的能力。</li>\n</ul>\n<h5 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h5><p>通过引入WSD调度器，论文提出了一种高效的方法来研究LLMs的规模定律，显著降低了计算成本。研究结果表明，较小的模型可以吸收更多的数据，从而提高推理和部署的效率。未来的研究将进一步探索WSD调度器在其他模型上的应用及其对规模定律的影响。</p>\n<h2 id=\"3-两阶段预训练策略\"><a href=\"#3-两阶段预训练策略\" class=\"headerlink\" title=\"3. 两阶段预训练策略\"></a>3. 两阶段预训练策略</h2><p>论文提出了一种两阶段的预训练策略，旨在提高小型语言模型（SLMs）的性能。以下是对该章节的详细总结和分析：</p>\n<h3 id=\"3-1-背景与动机\"><a href=\"#3-1-背景与动机\" class=\"headerlink\" title=\"3.1 背景与动机\"></a>3.1 背景与动机</h3><ul>\n<li><strong>背景</strong>：大型语言模型（LLMs）的训练成本高昂，且在个人电脑或智能手机等终端设备上部署效率低下。</li>\n<li><strong>动机</strong>：探索小型语言模型（SLMs）作为资源高效的替代方案，并通过可扩展的训练策略，使其具备与大型模型相似的能力。</li>\n</ul>\n<h3 id=\"3-2-两阶段预训练策略\"><a href=\"#3-2-两阶段预训练策略\" class=\"headerlink\" title=\"3.2 两阶段预训练策略\"></a>3.2 两阶段预训练策略</h3><ul>\n<li><p><strong>阶段划分</strong>：</p>\n<ul>\n<li><strong>第一阶段</strong>：仅使用大规模、低质量的预训练数据进行训练。</li>\n<li><strong>第二阶段</strong>：在衰减阶段引入高质量、知识导向的监督微调（SFT）数据，混合到预训练数据中。</li>\n</ul>\n</li>\n<li><p><strong>优势</strong>：</p>\n<ul>\n<li><strong>全面学习</strong>：在衰减阶段引入高质量数据，促进模型在更接近实际用户场景的数据分布上进行更显著的损失减少。</li>\n<li><strong>持续训练</strong>：避免在整个预训练过程中均匀分布高质量数据，集中资源和持续预训练。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"3-3-实验验证\"><a href=\"#3-3-实验验证\" class=\"headerlink\" title=\"3.3 实验验证\"></a>3.3 实验验证</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223145718563.png\" alt=\"image-20241223145718563\"></p>\n<ul>\n<li><p><strong>实验设置</strong>：</p>\n<ul>\n<li><strong>模型选择</strong>：使用MiniCPM-2.4B和MiniCPM-1.2B模型。</li>\n<li><strong>对比实验</strong>：<ul>\n<li>A-1：2.4B模型，仅使用预训练数据进行衰减，随后进行4B标记的SFT。</li>\n<li>A-2：2.4B模型，在衰减阶段混合高质量数据和SFT数据，随后进行4B标记的SFT。</li>\n<li>B-1：1.2B模型，仅使用预训练数据进行衰减，随后进行6B标记的SFT。</li>\n<li>B-2：1.2B模型，仅使用预训练数据进行衰减，随后进行12B标记的SFT。</li>\n<li>B-3：1.2B模型，在衰减阶段混合高质量数据和SFT数据，随后进行6B标记的SFT。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p><strong>结果分析</strong>：</p>\n<ul>\n<li><strong>A-2 vs A-1</strong>：尽管A-2和A-1在SFT阶段使用相同的数据分布，但A-2在衰减阶段引入高质量数据，显著提升了模型性能。</li>\n<li><strong>B-3 vs B-2</strong>：B-3在衰减阶段引入高质量数据，表现优于仅在SFT阶段引入高质量数据的B-2。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"3-4-结论\"><a href=\"#3-4-结论\" class=\"headerlink\" title=\"3.4 结论\"></a>3.4 结论</h3><ul>\n<li><strong>策略有效性</strong>：引入高质量数据到衰减阶段比仅在SFT阶段引入数据更能提升模型性能。</li>\n<li><strong>推荐</strong>：建议从衰减阶段开始，专门化和增强模型能力。</li>\n</ul>\n<h3 id=\"总结-1\"><a href=\"#总结-1\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p>论文提出的两阶段预训练策略通过在不同阶段引入不同类型的数据，显著提升了小型语言模型的性能。该策略不仅提高了模型的学习效率，还为未来的大型语言模型开发提供了有价值的参考。</p>\n<h2 id=\"4-MiniCPM-模型\"><a href=\"#4-MiniCPM-模型\" class=\"headerlink\" title=\"4. MiniCPM 模型\"></a>4. MiniCPM 模型</h2><p>第6章节“6 Model”详细介绍了MiniCPM模型的各个方面，包括模型细节、训练阶段、训练数据分布、训练损失和模型评估。以下是各部分的详细介绍：</p>\n<h3 id=\"4-1-Model-Details\"><a href=\"#4-1-Model-Details\" class=\"headerlink\" title=\"4.1 Model Details\"></a>4.1 Model Details</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223153902417.png\" alt=\"image-20241223153902417\"></p>\n<h4 id=\"词汇\"><a href=\"#词汇\" class=\"headerlink\" title=\"词汇\"></a>词汇</h4><ul>\n<li><strong>MiniCPM-2.4B</strong>：使用122,753词汇大小的tokenizer。</li>\n<li><strong>MiniCPM-1.2B</strong>：使用73,440词汇大小的tokenizer，较小的词汇表有利于效率而不显著影响性能。</li>\n</ul>\n<h4 id=\"共享输入输出层\"><a href=\"#共享输入输出层\" class=\"headerlink\" title=\"共享输入输出层\"></a>共享输入输出层</h4><ul>\n<li>为了减少参数空间，MiniCPM-2.4B和MiniCPM-1.2B都使用了嵌入共享技术。</li>\n</ul>\n<h4 id=\"深而薄的网络\"><a href=\"#深而薄的网络\" class=\"headerlink\" title=\"深而薄的网络\"></a>深而薄的网络</h4><ul>\n<li><strong>MiniCPM-2.4B</strong>：在训练MiniCPM-1.2B之前，采用了更深更薄的网络架构。</li>\n<li><strong>MiniCPM-1.2B</strong>：进一步加深和变薄，以适应长上下文任务。</li>\n</ul>\n<h4 id=\"组查询注意力\"><a href=\"#组查询注意力\" class=\"headerlink\" title=\"组查询注意力\"></a>组查询注意力</h4><ul>\n<li><strong>MiniCPM-2.4B</strong>：未修改注意力层。</li>\n<li><strong>MiniCPM-1.2B</strong>：应用了组查询注意力（Group Query Attention）以减少参数数量。</li>\n</ul>\n<h3 id=\"4-2-Training-Stages\"><a href=\"#4-2-Training-Stages\" class=\"headerlink\" title=\"4.2 Training Stages\"></a>4.2 Training Stages</h3><h4 id=\"稳定训练阶段\"><a href=\"#稳定训练阶段\" class=\"headerlink\" title=\"稳定训练阶段\"></a>稳定训练阶段</h4><ul>\n<li>使用约1T的数据，主要来自开放数据集。</li>\n<li>使用WSD学习率调度器，批量大小为3.93百万，最大学习率为0.01。</li>\n</ul>\n<h4 id=\"衰减阶段\"><a href=\"#衰减阶段\" class=\"headerlink\" title=\"衰减阶段\"></a>衰减阶段</h4><ul>\n<li>使用预训练数据和高质量的SFT数据混合。</li>\n<li>采用指数衰减形式，T设为5000步（20B标记）。</li>\n</ul>\n<h4 id=\"SFT阶段\"><a href=\"#SFT阶段\" class=\"headerlink\" title=\"SFT阶段\"></a>SFT阶段</h4><ul>\n<li>使用类似衰减阶段的数据，但不包括预训练数据，训练约60亿标记。</li>\n<li>学习率与衰减阶段末尾相同，使用WSD调度器。</li>\n</ul>\n<h3 id=\"4-3-Training-Data-Distribution\"><a href=\"#4-3-Training-Data-Distribution\" class=\"headerlink\" title=\"4.3 Training Data Distribution\"></a>4.3 Training Data Distribution</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223153949999.png\" alt=\"image-20241223153949999\"></p>\n<ul>\n<li><strong>稳定阶段</strong>：主要使用开放数据集，如CommonCrawl、Dolma、C4、Pile、Code Pre-train等。</li>\n<li><strong>衰减阶段</strong>：数据混合包含更多样化和专有的数据，如UltraChat、SlimOrca、OssInstruct、EvolInstruct等。</li>\n</ul>\n<h3 id=\"4-4-Training-Loss\"><a href=\"#4-4-Training-Loss\" class=\"headerlink\" title=\"4.4 Training Loss\"></a>4.4 Training Loss</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154011909.png\" alt=\"image-20241223154011909\"></p>\n<ul>\n<li>在C4数据集上的整体训练损失显示，衰减阶段的损失显著下降。</li>\n<li>由于使用指数衰减，学习率降至最大值的10%以下后，损失仍继续下降，但最终检查点未用于微调。</li>\n</ul>\n<h3 id=\"4-5-Evaluation\"><a href=\"#4-5-Evaluation\" class=\"headerlink\" title=\"4.5 Evaluation\"></a>4.5 Evaluation</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154036251.png\" alt=\"image-20241223154036251\"></p>\n<ul>\n<li>使用开源工具UltraEval进行评估，支持多种主流大型模型的性能评估。</li>\n<li>评估数据集包括MMLU、CMMLU、C-Eval、MBPP、GSM8K、MATH、HumanEval、BBH等。</li>\n<li>评估方法包括标准化输入提示和调整输入输出模板，确保公平比较。</li>\n</ul>\n<h4 id=\"评估结果\"><a href=\"#评估结果\" class=\"headerlink\" title=\"评估结果\"></a>评估结果</h4><ul>\n<li><strong>MiniCPM-2.4B</strong>：在多个基准测试中表现优异，特别是在中文任务中表现优于Mistral-7B。</li>\n<li><strong>MiniCPM-1.2B</strong>：在多个基准测试中也表现出色，特别是在直接生成任务中表现优于PPL测试。</li>\n</ul>\n<p>通过这些详细的介绍，可以看出MiniCPM模型在设计、训练和评估方面都经过了精心考虑和优化，取得了显著的性能提升。</p>\n<h2 id=\"5-MiniCPM-家族模型\"><a href=\"#5-MiniCPM-家族模型\" class=\"headerlink\" title=\"5. MiniCPM 家族模型\"></a>5. MiniCPM 家族模型</h2><p>论文介绍了基于MiniCPM基础模型的几种扩展模型，包括MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE。这些模型在各自的应用领域中展示了卓越的性能。以下是该章节的详细介绍：</p>\n<h3 id=\"5-1-MiniCPM-DPO\"><a href=\"#5-1-MiniCPM-DPO\" class=\"headerlink\" title=\"5.1 MiniCPM-DPO\"></a>5.1 MiniCPM-DPO</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154302859.png\" alt=\"image-20241223154302859\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154345626.png\" alt=\"image-20241223154345626\"></p>\n<ul>\n<li><strong>背景</strong>：在微调阶段之后，使用DPO（Direct Preference Optimization）进行人类偏好对齐。</li>\n<li><strong>训练</strong>：使用UltraFeedback作为主要对齐数据集，并构建了一个专有的偏好数据集以增强模型的代码和数学能力。</li>\n<li><strong>结果</strong>：在MTBench上的得分从SFT后的6.89提高到7.25，超过了像Llama2-70B-Chat这样的大型模型。然而，基准测试结果略有下降，这是对齐税（alignment tax）的表现。</li>\n</ul>\n<h3 id=\"5-2-MiniCPM-128K\"><a href=\"#5-2-MiniCPM-128K\" class=\"headerlink\" title=\"5.2 MiniCPM-128K\"></a>5.2 MiniCPM-128K</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154425567.png\" alt=\"image-20241223154425567\"></p>\n<ul>\n<li><strong>背景</strong>：处理长上下文任务需要模型能够隐含地理解长文本中的信息。</li>\n<li><strong>初始化</strong>：禁用输入和输出之间的嵌入共享，以适应长上下文训练所需的词汇并行性。</li>\n<li><strong>训练</strong>：使用WSD学习率调度器，训练数据分为“短数据”和“长数据”，长数据占44%，短数据占56%。使用Adjusted Base Frequency (ABF)和NTK-Aware RoPE Scaling进行扩展。</li>\n<li><strong>评估</strong>：在∞Bench基准测试中表现优异，特别是在长上下文推理任务中，超越了ChatGLM3-6B-128K。</li>\n</ul>\n<h3 id=\"5-3-MiniCPM-MoE\"><a href=\"#5-3-MiniCPM-MoE\" class=\"headerlink\" title=\"5.3 MiniCPM-MoE\"></a>5.3 MiniCPM-MoE</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241223154445784.png\" alt=\"image-20241223154445784\"></p>\n<ul>\n<li><strong>背景</strong>：通过混合专家（MoE）技术扩展MiniCPM的能力。</li>\n<li><strong>初始化</strong>：使用Sparse Upcycling进行初始化，将密集模型的每个MLP层替换为MoE层，路由参数随机初始化。</li>\n<li><strong>训练</strong>：使用WSD学习率调度器，训练批量大小在稳定和衰减阶段为4M，在SFT阶段减少到2M。</li>\n<li><strong>结果</strong>：在多个基准测试中表现优异，特别是在C-Eval、CMMLU、MMLU、HumanEval、MBPP、GSM8K和MATH等任务上。</li>\n</ul>\n<p>MiniCPM家族的扩展模型在各自的领域中展示了卓越的性能，证明了MiniCPM在多样化的SLM应用中的潜力。未来的研究方向包括深入分析衰减阶段的损失下降，并通过扩展模型规模和数据规模来增强MiniCPM的能力。</p>\n<h2 id=\"6-研究结论\"><a href=\"#6-研究结论\" class=\"headerlink\" title=\"6. 研究结论\"></a>6. 研究结论</h2><ul>\n<li>MiniCPM 系列模型展示了小型语言模型在资源效率和性能上的巨大潜力。通过创新的训练方法和架构设计，MiniCPM 不仅在小型模型中表现出色，还能够与大型模型相媲美。WSD 学习率调度器的引入为模型的持续训练和数据-模型缩放规律的研究提供了新的思路。此外，MiniCPM 家族的多样化模型进一步巩固了其在不同应用场景中的基础地位。</li>\n</ul>\n<h2 id=\"7-论文研究的不足\"><a href=\"#7-论文研究的不足\" class=\"headerlink\" title=\"7. 论文研究的不足\"></a>7. 论文研究的不足</h2><p>尽管 MiniCPM 在小型语言模型的研究中取得了显著进展，但仍存在一些不足之处：</p>\n<ol>\n<li><strong>未验证在大型模型上的应用</strong>：论文主要集中在小型模型的研究上，尚未验证 WSD 调度器在大型模型上的应用效果。</li>\n<li><strong>缺乏对损失下降机制的深入分析</strong>：尽管 WSD 调度器在 Decay 阶段表现出色，但其背后的机制尚未得到深入分析，未来需要进一步研究。</li>\n<li><strong>未考虑实际部署中的优化</strong>：虽然 MiniCPM 在资源效率上表现出色，但在实际部署中，仍需进一步优化以适应不同的硬件环境。</li>\n</ol>\n<h2 id=\"8-论文评价\"><a href=\"#8-论文评价\" class=\"headerlink\" title=\"8.论文评价\"></a>8.论文评价</h2><h3 id=\"优点与创新\"><a href=\"#优点与创新\" class=\"headerlink\" title=\"优点与创新\"></a>优点与创新</h3><ol>\n<li><strong>MiniCPM模型系列</strong>：论文介绍了MiniCPM系列小型语言模型，包括1.2B和2.4B非嵌入参数变体，这些模型在各自的小规模类别中表现卓越，并且与7B-13B大型语言模型的能力相当。</li>\n<li><strong>可扩展性</strong>：研究展示了在模型和数据维度上的可扩展性，为未来的大型语言模型（LLM）研究提供了潜力。</li>\n<li><strong>模型风洞实验</strong>：通过广泛的模型风洞实验，确保了稳定和最优的模型扩展。</li>\n<li><strong>温暖的稳定衰减（WSD）学习率调度器（LRS）</strong>：引入了WSD LRS，有利于连续训练和领域适应，并能够高效地研究数据-模型扩展规律。</li>\n<li><strong>训练动态分析</strong>：对WSD LRS的训练动态进行了深入分析，揭示了模型预训练的有趣损失景观。</li>\n<li><strong>更高的计算最优数据-模型比率</strong>：通过WSD LRS，能够在模型轴上线性努力，在数据轴上忽略不计的努力，从而得出比Chinchilla Optimal更高的计算最优数据-模型比率。</li>\n<li><strong>MiniCPM家族</strong>：介绍了MiniCPM家族，包括MiniCPM-DPO、MiniCPM-MoE和MiniCPM-128K，进一步巩固了MiniCPM在多样化小型语言模型应用中的基础。</li>\n<li><strong>公开可用</strong>：MiniCPM模型系列公开发布，便于其他研究人员使用和改进。</li>\n</ol>\n<h3 id=\"不足与反思\"><a href=\"#不足与反思\" class=\"headerlink\" title=\"不足与反思\"></a>不足与反思</h3><ol>\n<li><strong>未扩展到大型语言模型</strong>：尽管研究了小型语言模型的扩展规律，但论文并未扩展到训练大型语言模型以验证扩展规律。</li>\n<li><strong>WSD LRS在大型语言模型上的应用未完全探索</strong>：尽管对WSD LRS在大型语言模型上的潜在优势保持乐观，但目前尚未完全探索其在大型语言模型上的应用。</li>\n</ol>\n<h2 id=\"9-关键问题及回答\"><a href=\"#9-关键问题及回答\" class=\"headerlink\" title=\"9. 关键问题及回答\"></a>9. 关键问题及回答</h2><h3 id=\"问题1：MiniCPM模型在模型风洞实验中是如何进行超参数优化的？\"><a href=\"#问题1：MiniCPM模型在模型风洞实验中是如何进行超参数优化的？\" class=\"headerlink\" title=\"问题1：MiniCPM模型在模型风洞实验中是如何进行超参数优化的？\"></a><strong>问题1：MiniCPM模型在模型风洞实验中是如何进行超参数优化的？</strong></h3><p>MiniCPM模型在模型风洞实验中进行了广泛的超参数优化，主要包括以下几个方面：</p>\n<ol>\n<li><strong>宽度缩放</strong>：使用Tensor Program技术进行宽度缩放，支持CerebrasGPT等模型在不同模型规模下的超参数一致性。</li>\n<li><strong>深度缩放</strong>：同样使用Tensor Program技术进行深度缩放，尽管对于深度大于2的网络，深度缩放的效果不如预期，但实验结果显示最优学习率是稳定的。</li>\n<li><strong>学习率调度器</strong>：引入了Warmup-Stable-Decay（WSD）学习率调度器，适用于连续训练和领域适应。WSD调度器将训练阶段明确分为高学习率阶段和衰减阶段。</li>\n</ol>\n<p>通过这些超参数优化技术，MiniCPM模型能够在不同模型规模下实现稳定的训练和优化。</p>\n<h3 id=\"问题2：Warmup-Stable-Decay（WSD）学习率调度器在MiniCPM模型中的具体实现和效果如何？\"><a href=\"#问题2：Warmup-Stable-Decay（WSD）学习率调度器在MiniCPM模型中的具体实现和效果如何？\" class=\"headerlink\" title=\"问题2：Warmup-Stable-Decay（WSD）学习率调度器在MiniCPM模型中的具体实现和效果如何？\"></a><strong>问题2：Warmup-Stable-Decay（WSD）学习率调度器在MiniCPM模型中的具体实现和效果如何？</strong></h3><p>Warmup-Stable-Decay（WSD）学习率调度器在MiniCPM模型中的具体实现如下：</p>\n<ol>\n<li><strong>高学习率阶段</strong>：模型在初始阶段采用较高的学习率进行训练，以便快速找到全局最优解。</li>\n<li><strong>衰减阶段</strong>：当学习率达到一定值后，学习率逐渐减小，直至达到最小值。这一阶段的学习率衰减是线性的，并且在衰减结束后保持恒定。</li>\n<li><strong>连续训练</strong>：WSD调度器允许模型在衰减阶段之后继续进行训练，从而实现连续训练。</li>\n</ol>\n<p>效果方面，WSD调度器在MiniCPM模型中表现出显著的优势：</p>\n<ol>\n<li><strong>损失降低</strong>：在衰减阶段，学习率的突然减小导致损失显著下降，并且损失迅速降至与Cosine LRS相当的水平。</li>\n<li><strong>连续训练</strong>：通过WSD调度器，模型可以在衰减阶段之后继续训练，达到与较大模型相似的性能，同时节省了大量的计算资源。</li>\n<li><strong>数据-模型缩放定律</strong>：WSD调度器使得研究数据-模型缩放定律变得更加高效，能够在模型轴和数据轴上以线性努力进行研究。</li>\n</ol>\n<h3 id=\"问题3：MiniCPM家族中的其他成员（如MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE）有哪些具体功能和表现？\"><a href=\"#问题3：MiniCPM家族中的其他成员（如MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE）有哪些具体功能和表现？\" class=\"headerlink\" title=\"问题3：MiniCPM家族中的其他成员（如MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE）有哪些具体功能和表现？\"></a><strong>问题3：MiniCPM家族中的其他成员（如MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE）有哪些具体功能和表现？</strong></h3><p>MiniCPM家族中的其他成员包括MiniCPM-DPO、MiniCPM-128K和MiniCPM-MoE，它们各自具有不同的功能和表现：</p>\n<ol>\n<li><strong>MiniCPM-DPO</strong>：在SFT阶段之后，MiniCPM-DPO通过DPO（Direct Preference Optimization）进行人类偏好对齐。使用UltraFeedback作为主要对齐数据集，并构建了一个专有的偏好数据集以增强模型的代码和数学能力。在MTBench基准测试中，MiniCPM-DPO的性能从SFT后的6.89提高到7.25，超过了多个较大的模型。</li>\n<li><strong>MiniCPM-128K</strong>：将MiniCPM-2.4B的上下文长度从4096扩展到128,000 tokens，展示了小型语言模型在处理长上下文任务中的能力。通过调整基础频率和使用NTK-Aware RoPE Scaling等技术，MiniCPM-128K在∞Bench基准测试中取得了与Mistral-7B-Instruct-v0.2相当的结果，尽管其模型规模较小。</li>\n<li><strong>MiniCPM-MoE</strong>：通过引入Mixture-of-Expert（MoE），MiniCPM-MoE进一步扩展了MiniCPM的能力。MoE模型在每个token上激活两个专家，并使用Router参数进行路由。在MBPP基准测试中，MiniCPM-MoE的性能与Llama2-34B相当，表明其在多任务语言理解方面的强大能力。</li>\n</ol>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink\">https://github.com/chongzicbo/ReadWriteThink</a></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n"},{"title":"Python开发中常用工具函数","date":"2024-12-14T04:00:00.000Z","_content":"\n## 1.函数执行时间统计装饰器\n\n### 功能：\n\n用于统计函数执行的时间，常用于性能优化。\n\n### 示例代码：\n\n```python\nfrom time import perf_counter\nfrom functools import wraps\nfrom typing import List\n\n\ndef timeit(loop: int = 1):\n    \"\"\"\n    函数执行失败时，重试\n\n    :param loop: 循环执行次数\n    :return:\n    \"\"\"\n\n    # 校验参数，参数值不正确时使用默认参数\n    if loop < 1:\n        loop = 1\n\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            sum_time: float = 0.0\n            for i in range(loop):\n                start_time: float = perf_counter()\n                ret = func(*args, **kwargs)\n                end_time: float = perf_counter()\n                sum_time += end_time - start_time\n\n            print(\n                f\"函数({func.__name__})共执行{loop}次，平均执行时间 {(sum_time/loop):.3f} 秒\"\n            )\n            return ret\n\n        return wrapper\n\n    return decorator\n\n```\n\n在 Python 开发中，工具函数（Utility Functions）是提高代码效率和可维护性的重要组成部分。这些函数可以帮助我们完成常见的任务，如时间统计、类型检查、字符串处理、文件操作等。以下是一些常用的工具函数及其使用场景。\n\n---\n\n## 2. 类型检查装饰器\n\n### 功能：\n用于检查函数参数的类型是否符合预期。\n\n### 示例代码：\n\n```python\nfrom functools import wraps\n\ndef type_check(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        sig = inspect.signature(func)\n        params = sig.parameters\n        for i, (arg_name, arg_value) in enumerate(zip(params, args)):\n            param = params[arg_name]\n            if param.annotation != inspect.Parameter.empty and not isinstance(arg_value, param.annotation):\n                raise TypeError(f\"参数 {arg_name} 的类型应为 {param.annotation}，但传入的是 {type(arg_value)}\")\n        return func(*args, **kwargs)\n    return wrapper\n\n@type_check\ndef add(a: int, b: int) -> int:\n    return a + b\n\nprint(add(1, 2))  # 正常\nprint(add(1, \"2\"))  # 抛出 TypeError\n```\n\n---\n\n## 3. 重试装饰器\n\n### 功能：\n用于在函数执行失败时自动重试。\n\n### 示例代码：\n\n```python\nfrom functools import wraps\n\ndef retry(max_retries=3, delay=1):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            retries = 0\n            while retries < max_retries:\n                try:\n                    return func(*args, **kwargs)\n                except Exception as e:\n                    retries += 1\n                    print(f\"重试 {retries}/{max_retries}: {e}\")\n                    time.sleep(delay)\n            raise Exception(f\"达到最大重试次数 {max_retries}\")\n        return wrapper\n    return decorator\n\n@retry(max_retries=3, delay=1)\ndef flaky_function():\n    if random.randint(0, 1) == 0:\n        raise Exception(\"随机失败\")\n    return \"成功\"\n\nprint(flaky_function())\n```\n\n---\n\n## 4. 批量处理函数\n\n### 功能：\n用于将一个列表或迭代器分批处理。\n\n### 示例代码：\n\n```python\ndef batch_process(data, batch_size=10):\n    for i in range(0, len(data), batch_size):\n        yield data[i:i + batch_size]\n\ndata = list(range(1, 101))\nfor batch in batch_process(data, batch_size=20):\n    print(batch)\n```\n\n### 输出：\n```\n[1, 2, 3, ..., 20]\n[21, 22, 33, ..., 40]\n...\n[81, 82, 83, ..., 100]\n```\n\n---\n\n## 5. 文件操作工具函数\n\n### 功能：\n用于读取、写入和处理文件。\n\n### 示例代码：\n\n```python\ndef read_file(file_path):\n    with open(file_path, 'r', encoding='utf-8') as f:\n        return f.read()\n\ndef write_file(file_path, content):\n    with open(file_path, 'w', encoding='utf-8') as f:\n        f.write(content)\n\ndef append_file(file_path, content):\n    with open(file_path, 'a', encoding='utf-8') as f:\n        f.write(content)\n\n# 示例\nwrite_file(\"example.txt\", \"Hello, World!\\n\")\nappend_file(\"example.txt\", \"This is a new line.\\n\")\nprint(read_file(\"example.txt\"))\n```\n\n---\n\n## 6. 字符串处理工具函数\n\n### 功能：\n用于字符串的格式化、分割、替换等操作。\n\n### 示例代码：\n\n```python\ndef format_string(template, **kwargs):\n    return template.format(**kwargs)\n\ndef split_string(text, delimiter=\",\"):\n    return text.split(delimiter)\n\ndef replace_string(text, old, new):\n    return text.replace(old, new)\n\n# 示例\ntemplate = \"My name is {name} and I am {age} years old.\"\nprint(format_string(template, name=\"Alice\", age=30))\n\ntext = \"apple,banana,cherry\"\nprint(split_string(text))\n\ntext = \"Hello, World!\"\nprint(replace_string(text, \"World\", \"Python\"))\n```\n\n---\n\n## 7. 日志记录工具函数\n\n### 功能：\n用于记录程序的运行日志。\n\n### 示例代码：\n\n```python\nimport logging\nfrom logging.handlers import RotatingFileHandler\n\ndef setup_logger(module_name, log_dir=\"logs\"):\n    \"\"\"\n    根据模块名称配置日志记录器，并自动生成日志文件名。\n\n    :param module_name: 模块名称，用于生成日志文件名\n    :param log_dir: 日志文件存储目录，默认为 \"logs\"\n    :return: 配置好的日志记录器\n    \"\"\"\n    # 创建日志记录器\n    logger = logging.getLogger(module_name)\n    logger.setLevel(logging.DEBUG)  # 设置全局日志级别为 DEBUG\n\n    # 配置日志格式化\n    formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n\n    # 配置控制台处理器（输出到终端）\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.INFO)  # 控制台日志级别为 INFO\n    console_handler.setFormatter(formatter)\n    logger.addHandler(console_handler)\n\n    # 配置文件处理器（根据模块名称生成日志文件名）\n    log_file = f\"{log_dir}/{module_name}.log\"\n    file_handler = RotatingFileHandler(\n        log_file,  # 日志文件路径\n        maxBytes=1024 * 1024,  # 每个日志文件的最大大小（1MB）\n        backupCount=5  # 保留的旧日志文件数量\n    )\n    file_handler.setLevel(logging.DEBUG)  # 文件日志级别为 DEBUG\n    file_handler.setFormatter(formatter)\n    logger.addHandler(file_handler)\n\n    return logger\n```\n\n```python\nfrom loguru import logger\nimport sys\n\ndef setup_logger(module_name, log_dir=\"logs\"):\n    \"\"\"\n    根据模块名称配置日志记录器，并自动生成日志文件名。\n\n    :param module_name: 模块名称，用于生成日志文件名\n    :param log_dir: 日志文件存储目录，默认为 \"logs\"\n    \"\"\"\n    # 配置日志格式\n    log_format = (\n        \"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | \"\n        \"<level>{level: <8}</level> | \"\n        \"<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>\"\n    )\n\n    # 配置控制台日志\n    logger.remove()  # 移除默认的日志处理器\n    logger.add(sys.stdout, format=log_format, level=\"INFO\")\n\n    # 配置文件日志（根据模块名称生成日志文件名）\n    log_file = f\"{log_dir}/{module_name}.log\"\n    logger.add(\n        log_file,  # 日志文件路径\n        format=log_format,\n        level=\"DEBUG\",\n        rotation=\"10 MB\",  # 日志文件轮转大小\n        retention=\"7 days\",  # 保留日志文件的时间\n        compression=\"zip\",  # 日志文件压缩格式\n    )\n\n    return logger\n```\n\n---\n\n## 8. 缓存工具函数\n\n### 功能：\n用于缓存函数的返回值，避免重复计算。\n\n### 示例代码：\n\n```python\nfrom functools import lru_cache\n\n@lru_cache(maxsize=128)\ndef fibonacci(n):\n    if n <= 1:\n        return n\n    return fibonacci(n - 1) + fibonacci(n - 2)\n\nprint(fibonacci(10))  # 计算并缓存\nprint(fibonacci(10))  # 直接从缓存中获取\n```\n\n---\n\n## 9. 随机数据生成工具函数\n\n### 功能：\n用于生成随机数据，如随机字符串、随机数等。\n\n### 示例代码：\n\n```python\nimport random\nimport string\n\ndef random_string(length=10):\n    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n\ndef random_number(start=1, end=100):\n    return random.randint(start, end)\n\n# 示例\nprint(random_string(15))\nprint(random_number(1, 10))\n```\n\n---\n\n## 10. 并发执行工具函数\n\n### 功能：\n用于并发执行多个任务。\n\n### 示例代码：\n\n```python\nimport concurrent.futures\n\ndef task(n):\n    return n * n\n\ndef parallel_execute(tasks):\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        results = list(executor.map(task, tasks))\n    return results\n\n# 示例\ntasks = [1, 2, 3, 4, 5]\nprint(parallel_execute(tasks))\n```\n\n---\n\n## 总结\n\n以上是 Python 中常用的一些工具函数，涵盖了时间统计、类型检查、重试机制、文件操作、字符串处理、日志记录、缓存、随机数据生成和并发执行等多个方面。这些工具函数可以帮助我们提高代码的可读性、可维护性和性能。\n\n根据具体需求，你可以选择合适的工具函数，或者将它们组合起来，构建更复杂的工具链。","source":"_posts/开发/Python/Python-002：python开发中常用的工具函数.md","raw":"---\ntitle: 'Python开发中常用工具函数'\ncategories:\n  - [开发,python]\ntags:\n  - python\ndate: 2024-12-14 12:00:00\n---\n\n## 1.函数执行时间统计装饰器\n\n### 功能：\n\n用于统计函数执行的时间，常用于性能优化。\n\n### 示例代码：\n\n```python\nfrom time import perf_counter\nfrom functools import wraps\nfrom typing import List\n\n\ndef timeit(loop: int = 1):\n    \"\"\"\n    函数执行失败时，重试\n\n    :param loop: 循环执行次数\n    :return:\n    \"\"\"\n\n    # 校验参数，参数值不正确时使用默认参数\n    if loop < 1:\n        loop = 1\n\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            sum_time: float = 0.0\n            for i in range(loop):\n                start_time: float = perf_counter()\n                ret = func(*args, **kwargs)\n                end_time: float = perf_counter()\n                sum_time += end_time - start_time\n\n            print(\n                f\"函数({func.__name__})共执行{loop}次，平均执行时间 {(sum_time/loop):.3f} 秒\"\n            )\n            return ret\n\n        return wrapper\n\n    return decorator\n\n```\n\n在 Python 开发中，工具函数（Utility Functions）是提高代码效率和可维护性的重要组成部分。这些函数可以帮助我们完成常见的任务，如时间统计、类型检查、字符串处理、文件操作等。以下是一些常用的工具函数及其使用场景。\n\n---\n\n## 2. 类型检查装饰器\n\n### 功能：\n用于检查函数参数的类型是否符合预期。\n\n### 示例代码：\n\n```python\nfrom functools import wraps\n\ndef type_check(func):\n    @wraps(func)\n    def wrapper(*args, **kwargs):\n        sig = inspect.signature(func)\n        params = sig.parameters\n        for i, (arg_name, arg_value) in enumerate(zip(params, args)):\n            param = params[arg_name]\n            if param.annotation != inspect.Parameter.empty and not isinstance(arg_value, param.annotation):\n                raise TypeError(f\"参数 {arg_name} 的类型应为 {param.annotation}，但传入的是 {type(arg_value)}\")\n        return func(*args, **kwargs)\n    return wrapper\n\n@type_check\ndef add(a: int, b: int) -> int:\n    return a + b\n\nprint(add(1, 2))  # 正常\nprint(add(1, \"2\"))  # 抛出 TypeError\n```\n\n---\n\n## 3. 重试装饰器\n\n### 功能：\n用于在函数执行失败时自动重试。\n\n### 示例代码：\n\n```python\nfrom functools import wraps\n\ndef retry(max_retries=3, delay=1):\n    def decorator(func):\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            retries = 0\n            while retries < max_retries:\n                try:\n                    return func(*args, **kwargs)\n                except Exception as e:\n                    retries += 1\n                    print(f\"重试 {retries}/{max_retries}: {e}\")\n                    time.sleep(delay)\n            raise Exception(f\"达到最大重试次数 {max_retries}\")\n        return wrapper\n    return decorator\n\n@retry(max_retries=3, delay=1)\ndef flaky_function():\n    if random.randint(0, 1) == 0:\n        raise Exception(\"随机失败\")\n    return \"成功\"\n\nprint(flaky_function())\n```\n\n---\n\n## 4. 批量处理函数\n\n### 功能：\n用于将一个列表或迭代器分批处理。\n\n### 示例代码：\n\n```python\ndef batch_process(data, batch_size=10):\n    for i in range(0, len(data), batch_size):\n        yield data[i:i + batch_size]\n\ndata = list(range(1, 101))\nfor batch in batch_process(data, batch_size=20):\n    print(batch)\n```\n\n### 输出：\n```\n[1, 2, 3, ..., 20]\n[21, 22, 33, ..., 40]\n...\n[81, 82, 83, ..., 100]\n```\n\n---\n\n## 5. 文件操作工具函数\n\n### 功能：\n用于读取、写入和处理文件。\n\n### 示例代码：\n\n```python\ndef read_file(file_path):\n    with open(file_path, 'r', encoding='utf-8') as f:\n        return f.read()\n\ndef write_file(file_path, content):\n    with open(file_path, 'w', encoding='utf-8') as f:\n        f.write(content)\n\ndef append_file(file_path, content):\n    with open(file_path, 'a', encoding='utf-8') as f:\n        f.write(content)\n\n# 示例\nwrite_file(\"example.txt\", \"Hello, World!\\n\")\nappend_file(\"example.txt\", \"This is a new line.\\n\")\nprint(read_file(\"example.txt\"))\n```\n\n---\n\n## 6. 字符串处理工具函数\n\n### 功能：\n用于字符串的格式化、分割、替换等操作。\n\n### 示例代码：\n\n```python\ndef format_string(template, **kwargs):\n    return template.format(**kwargs)\n\ndef split_string(text, delimiter=\",\"):\n    return text.split(delimiter)\n\ndef replace_string(text, old, new):\n    return text.replace(old, new)\n\n# 示例\ntemplate = \"My name is {name} and I am {age} years old.\"\nprint(format_string(template, name=\"Alice\", age=30))\n\ntext = \"apple,banana,cherry\"\nprint(split_string(text))\n\ntext = \"Hello, World!\"\nprint(replace_string(text, \"World\", \"Python\"))\n```\n\n---\n\n## 7. 日志记录工具函数\n\n### 功能：\n用于记录程序的运行日志。\n\n### 示例代码：\n\n```python\nimport logging\nfrom logging.handlers import RotatingFileHandler\n\ndef setup_logger(module_name, log_dir=\"logs\"):\n    \"\"\"\n    根据模块名称配置日志记录器，并自动生成日志文件名。\n\n    :param module_name: 模块名称，用于生成日志文件名\n    :param log_dir: 日志文件存储目录，默认为 \"logs\"\n    :return: 配置好的日志记录器\n    \"\"\"\n    # 创建日志记录器\n    logger = logging.getLogger(module_name)\n    logger.setLevel(logging.DEBUG)  # 设置全局日志级别为 DEBUG\n\n    # 配置日志格式化\n    formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n\n    # 配置控制台处理器（输出到终端）\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.INFO)  # 控制台日志级别为 INFO\n    console_handler.setFormatter(formatter)\n    logger.addHandler(console_handler)\n\n    # 配置文件处理器（根据模块名称生成日志文件名）\n    log_file = f\"{log_dir}/{module_name}.log\"\n    file_handler = RotatingFileHandler(\n        log_file,  # 日志文件路径\n        maxBytes=1024 * 1024,  # 每个日志文件的最大大小（1MB）\n        backupCount=5  # 保留的旧日志文件数量\n    )\n    file_handler.setLevel(logging.DEBUG)  # 文件日志级别为 DEBUG\n    file_handler.setFormatter(formatter)\n    logger.addHandler(file_handler)\n\n    return logger\n```\n\n```python\nfrom loguru import logger\nimport sys\n\ndef setup_logger(module_name, log_dir=\"logs\"):\n    \"\"\"\n    根据模块名称配置日志记录器，并自动生成日志文件名。\n\n    :param module_name: 模块名称，用于生成日志文件名\n    :param log_dir: 日志文件存储目录，默认为 \"logs\"\n    \"\"\"\n    # 配置日志格式\n    log_format = (\n        \"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | \"\n        \"<level>{level: <8}</level> | \"\n        \"<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>\"\n    )\n\n    # 配置控制台日志\n    logger.remove()  # 移除默认的日志处理器\n    logger.add(sys.stdout, format=log_format, level=\"INFO\")\n\n    # 配置文件日志（根据模块名称生成日志文件名）\n    log_file = f\"{log_dir}/{module_name}.log\"\n    logger.add(\n        log_file,  # 日志文件路径\n        format=log_format,\n        level=\"DEBUG\",\n        rotation=\"10 MB\",  # 日志文件轮转大小\n        retention=\"7 days\",  # 保留日志文件的时间\n        compression=\"zip\",  # 日志文件压缩格式\n    )\n\n    return logger\n```\n\n---\n\n## 8. 缓存工具函数\n\n### 功能：\n用于缓存函数的返回值，避免重复计算。\n\n### 示例代码：\n\n```python\nfrom functools import lru_cache\n\n@lru_cache(maxsize=128)\ndef fibonacci(n):\n    if n <= 1:\n        return n\n    return fibonacci(n - 1) + fibonacci(n - 2)\n\nprint(fibonacci(10))  # 计算并缓存\nprint(fibonacci(10))  # 直接从缓存中获取\n```\n\n---\n\n## 9. 随机数据生成工具函数\n\n### 功能：\n用于生成随机数据，如随机字符串、随机数等。\n\n### 示例代码：\n\n```python\nimport random\nimport string\n\ndef random_string(length=10):\n    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n\ndef random_number(start=1, end=100):\n    return random.randint(start, end)\n\n# 示例\nprint(random_string(15))\nprint(random_number(1, 10))\n```\n\n---\n\n## 10. 并发执行工具函数\n\n### 功能：\n用于并发执行多个任务。\n\n### 示例代码：\n\n```python\nimport concurrent.futures\n\ndef task(n):\n    return n * n\n\ndef parallel_execute(tasks):\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        results = list(executor.map(task, tasks))\n    return results\n\n# 示例\ntasks = [1, 2, 3, 4, 5]\nprint(parallel_execute(tasks))\n```\n\n---\n\n## 总结\n\n以上是 Python 中常用的一些工具函数，涵盖了时间统计、类型检查、重试机制、文件操作、字符串处理、日志记录、缓存、随机数据生成和并发执行等多个方面。这些工具函数可以帮助我们提高代码的可读性、可维护性和性能。\n\n根据具体需求，你可以选择合适的工具函数，或者将它们组合起来，构建更复杂的工具链。","slug":"开发/Python/Python-002：python开发中常用的工具函数","published":1,"updated":"2024-12-26T06:21:02.973Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3f000ahghi1toi3mtv","content":"<h2 id=\"1-函数执行时间统计装饰器\"><a href=\"#1-函数执行时间统计装饰器\" class=\"headerlink\" title=\"1.函数执行时间统计装饰器\"></a>1.函数执行时间统计装饰器</h2><h3 id=\"功能：\"><a href=\"#功能：\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于统计函数执行的时间，常用于性能优化。</p>\n<h3 id=\"示例代码：\"><a href=\"#示例代码：\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> time <span class=\"hljs-keyword\">import</span> perf_counter<br><span class=\"hljs-keyword\">from</span> functools <span class=\"hljs-keyword\">import</span> wraps<br><span class=\"hljs-keyword\">from</span> typing <span class=\"hljs-keyword\">import</span> <span class=\"hljs-type\">List</span><br><br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">timeit</span>(<span class=\"hljs-params\">loop: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">1</span></span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    函数执行失败时，重试</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    :param loop: 循环执行次数</span><br><span class=\"hljs-string\">    :return:</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br><br>    <span class=\"hljs-comment\"># 校验参数，参数值不正确时使用默认参数</span><br>    <span class=\"hljs-keyword\">if</span> loop &lt; <span class=\"hljs-number\">1</span>:<br>        loop = <span class=\"hljs-number\">1</span><br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">decorator</span>(<span class=\"hljs-params\">func</span>):<br><span class=\"hljs-meta\">        @wraps(<span class=\"hljs-params\">func</span>)</span><br>        <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">wrapper</span>(<span class=\"hljs-params\">*args, **kwargs</span>):<br>            sum_time: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">0.0</span><br>            <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(loop):<br>                start_time: <span class=\"hljs-built_in\">float</span> = perf_counter()<br>                ret = func(*args, **kwargs)<br>                end_time: <span class=\"hljs-built_in\">float</span> = perf_counter()<br>                sum_time += end_time - start_time<br><br>            <span class=\"hljs-built_in\">print</span>(<br>                <span class=\"hljs-string\">f&quot;函数(<span class=\"hljs-subst\">&#123;func.__name__&#125;</span>)共执行<span class=\"hljs-subst\">&#123;loop&#125;</span>次，平均执行时间 <span class=\"hljs-subst\">&#123;(sum_time/loop):<span class=\"hljs-number\">.3</span>f&#125;</span> 秒&quot;</span><br>            )<br>            <span class=\"hljs-keyword\">return</span> ret<br><br>        <span class=\"hljs-keyword\">return</span> wrapper<br><br>    <span class=\"hljs-keyword\">return</span> decorator<br><br></code></pre></td></tr></table></figure>\n\n<p>在 Python 开发中，工具函数（Utility Functions）是提高代码效率和可维护性的重要组成部分。这些函数可以帮助我们完成常见的任务，如时间统计、类型检查、字符串处理、文件操作等。以下是一些常用的工具函数及其使用场景。</p>\n<hr>\n<h2 id=\"2-类型检查装饰器\"><a href=\"#2-类型检查装饰器\" class=\"headerlink\" title=\"2. 类型检查装饰器\"></a>2. 类型检查装饰器</h2><h3 id=\"功能：-1\"><a href=\"#功能：-1\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于检查函数参数的类型是否符合预期。</p>\n<h3 id=\"示例代码：-1\"><a href=\"#示例代码：-1\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> functools <span class=\"hljs-keyword\">import</span> wraps<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">type_check</span>(<span class=\"hljs-params\">func</span>):<br><span class=\"hljs-meta\">    @wraps(<span class=\"hljs-params\">func</span>)</span><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">wrapper</span>(<span class=\"hljs-params\">*args, **kwargs</span>):<br>        sig = inspect.signature(func)<br>        params = sig.parameters<br>        <span class=\"hljs-keyword\">for</span> i, (arg_name, arg_value) <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(<span class=\"hljs-built_in\">zip</span>(params, args)):<br>            param = params[arg_name]<br>            <span class=\"hljs-keyword\">if</span> param.annotation != inspect.Parameter.empty <span class=\"hljs-keyword\">and</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-built_in\">isinstance</span>(arg_value, param.annotation):<br>                <span class=\"hljs-keyword\">raise</span> TypeError(<span class=\"hljs-string\">f&quot;参数 <span class=\"hljs-subst\">&#123;arg_name&#125;</span> 的类型应为 <span class=\"hljs-subst\">&#123;param.annotation&#125;</span>，但传入的是 <span class=\"hljs-subst\">&#123;<span class=\"hljs-built_in\">type</span>(arg_value)&#125;</span>&quot;</span>)<br>        <span class=\"hljs-keyword\">return</span> func(*args, **kwargs)<br>    <span class=\"hljs-keyword\">return</span> wrapper<br><br><span class=\"hljs-meta\">@type_check</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">add</span>(<span class=\"hljs-params\">a: <span class=\"hljs-built_in\">int</span>, b: <span class=\"hljs-built_in\">int</span></span>) -&gt; <span class=\"hljs-built_in\">int</span>:<br>    <span class=\"hljs-keyword\">return</span> a + b<br><br><span class=\"hljs-built_in\">print</span>(add(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>))  <span class=\"hljs-comment\"># 正常</span><br><span class=\"hljs-built_in\">print</span>(add(<span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">&quot;2&quot;</span>))  <span class=\"hljs-comment\"># 抛出 TypeError</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"3-重试装饰器\"><a href=\"#3-重试装饰器\" class=\"headerlink\" title=\"3. 重试装饰器\"></a>3. 重试装饰器</h2><h3 id=\"功能：-2\"><a href=\"#功能：-2\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于在函数执行失败时自动重试。</p>\n<h3 id=\"示例代码：-2\"><a href=\"#示例代码：-2\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> functools <span class=\"hljs-keyword\">import</span> wraps<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">retry</span>(<span class=\"hljs-params\">max_retries=<span class=\"hljs-number\">3</span>, delay=<span class=\"hljs-number\">1</span></span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">decorator</span>(<span class=\"hljs-params\">func</span>):<br><span class=\"hljs-meta\">        @wraps(<span class=\"hljs-params\">func</span>)</span><br>        <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">wrapper</span>(<span class=\"hljs-params\">*args, **kwargs</span>):<br>            retries = <span class=\"hljs-number\">0</span><br>            <span class=\"hljs-keyword\">while</span> retries &lt; max_retries:<br>                <span class=\"hljs-keyword\">try</span>:<br>                    <span class=\"hljs-keyword\">return</span> func(*args, **kwargs)<br>                <span class=\"hljs-keyword\">except</span> Exception <span class=\"hljs-keyword\">as</span> e:<br>                    retries += <span class=\"hljs-number\">1</span><br>                    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;重试 <span class=\"hljs-subst\">&#123;retries&#125;</span>/<span class=\"hljs-subst\">&#123;max_retries&#125;</span>: <span class=\"hljs-subst\">&#123;e&#125;</span>&quot;</span>)<br>                    time.sleep(delay)<br>            <span class=\"hljs-keyword\">raise</span> Exception(<span class=\"hljs-string\">f&quot;达到最大重试次数 <span class=\"hljs-subst\">&#123;max_retries&#125;</span>&quot;</span>)<br>        <span class=\"hljs-keyword\">return</span> wrapper<br>    <span class=\"hljs-keyword\">return</span> decorator<br><br><span class=\"hljs-meta\">@retry(<span class=\"hljs-params\">max_retries=<span class=\"hljs-number\">3</span>, delay=<span class=\"hljs-number\">1</span></span>)</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">flaky_function</span>():<br>    <span class=\"hljs-keyword\">if</span> random.randint(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>) == <span class=\"hljs-number\">0</span>:<br>        <span class=\"hljs-keyword\">raise</span> Exception(<span class=\"hljs-string\">&quot;随机失败&quot;</span>)<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;成功&quot;</span><br><br><span class=\"hljs-built_in\">print</span>(flaky_function())<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"4-批量处理函数\"><a href=\"#4-批量处理函数\" class=\"headerlink\" title=\"4. 批量处理函数\"></a>4. 批量处理函数</h2><h3 id=\"功能：-3\"><a href=\"#功能：-3\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于将一个列表或迭代器分批处理。</p>\n<h3 id=\"示例代码：-3\"><a href=\"#示例代码：-3\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">batch_process</span>(<span class=\"hljs-params\">data, batch_size=<span class=\"hljs-number\">10</span></span>):<br>    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-built_in\">len</span>(data), batch_size):<br>        <span class=\"hljs-keyword\">yield</span> data[i:i + batch_size]<br><br>data = <span class=\"hljs-built_in\">list</span>(<span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">101</span>))<br><span class=\"hljs-keyword\">for</span> batch <span class=\"hljs-keyword\">in</span> batch_process(data, batch_size=<span class=\"hljs-number\">20</span>):<br>    <span class=\"hljs-built_in\">print</span>(batch)<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"输出：\"><a href=\"#输出：\" class=\"headerlink\" title=\"输出：\"></a>输出：</h3><figure class=\"highlight jboss-cli\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs jboss-cli\">[1, 2, 3, <span class=\"hljs-string\">...</span>, 20]<br>[21, 22, 33, <span class=\"hljs-string\">...</span>, 40]<br><span class=\"hljs-string\">...</span><br>[81, 82, 83, <span class=\"hljs-string\">...</span>, 100]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"5-文件操作工具函数\"><a href=\"#5-文件操作工具函数\" class=\"headerlink\" title=\"5. 文件操作工具函数\"></a>5. 文件操作工具函数</h2><h3 id=\"功能：-4\"><a href=\"#功能：-4\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于读取、写入和处理文件。</p>\n<h3 id=\"示例代码：-4\"><a href=\"#示例代码：-4\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">read_file</span>(<span class=\"hljs-params\">file_path</span>):<br>    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(file_path, <span class=\"hljs-string\">&#x27;r&#x27;</span>, encoding=<span class=\"hljs-string\">&#x27;utf-8&#x27;</span>) <span class=\"hljs-keyword\">as</span> f:<br>        <span class=\"hljs-keyword\">return</span> f.read()<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">write_file</span>(<span class=\"hljs-params\">file_path, content</span>):<br>    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(file_path, <span class=\"hljs-string\">&#x27;w&#x27;</span>, encoding=<span class=\"hljs-string\">&#x27;utf-8&#x27;</span>) <span class=\"hljs-keyword\">as</span> f:<br>        f.write(content)<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">append_file</span>(<span class=\"hljs-params\">file_path, content</span>):<br>    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(file_path, <span class=\"hljs-string\">&#x27;a&#x27;</span>, encoding=<span class=\"hljs-string\">&#x27;utf-8&#x27;</span>) <span class=\"hljs-keyword\">as</span> f:<br>        f.write(content)<br><br><span class=\"hljs-comment\"># 示例</span><br>write_file(<span class=\"hljs-string\">&quot;example.txt&quot;</span>, <span class=\"hljs-string\">&quot;Hello, World!\\n&quot;</span>)<br>append_file(<span class=\"hljs-string\">&quot;example.txt&quot;</span>, <span class=\"hljs-string\">&quot;This is a new line.\\n&quot;</span>)<br><span class=\"hljs-built_in\">print</span>(read_file(<span class=\"hljs-string\">&quot;example.txt&quot;</span>))<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"6-字符串处理工具函数\"><a href=\"#6-字符串处理工具函数\" class=\"headerlink\" title=\"6. 字符串处理工具函数\"></a>6. 字符串处理工具函数</h2><h3 id=\"功能：-5\"><a href=\"#功能：-5\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于字符串的格式化、分割、替换等操作。</p>\n<h3 id=\"示例代码：-5\"><a href=\"#示例代码：-5\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">format_string</span>(<span class=\"hljs-params\">template, **kwargs</span>):<br>    <span class=\"hljs-keyword\">return</span> template.<span class=\"hljs-built_in\">format</span>(**kwargs)<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">split_string</span>(<span class=\"hljs-params\">text, delimiter=<span class=\"hljs-string\">&quot;,&quot;</span></span>):<br>    <span class=\"hljs-keyword\">return</span> text.split(delimiter)<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">replace_string</span>(<span class=\"hljs-params\">text, old, new</span>):<br>    <span class=\"hljs-keyword\">return</span> text.replace(old, new)<br><br><span class=\"hljs-comment\"># 示例</span><br>template = <span class=\"hljs-string\">&quot;My name is &#123;name&#125; and I am &#123;age&#125; years old.&quot;</span><br><span class=\"hljs-built_in\">print</span>(format_string(template, name=<span class=\"hljs-string\">&quot;Alice&quot;</span>, age=<span class=\"hljs-number\">30</span>))<br><br>text = <span class=\"hljs-string\">&quot;apple,banana,cherry&quot;</span><br><span class=\"hljs-built_in\">print</span>(split_string(text))<br><br>text = <span class=\"hljs-string\">&quot;Hello, World!&quot;</span><br><span class=\"hljs-built_in\">print</span>(replace_string(text, <span class=\"hljs-string\">&quot;World&quot;</span>, <span class=\"hljs-string\">&quot;Python&quot;</span>))<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"7-日志记录工具函数\"><a href=\"#7-日志记录工具函数\" class=\"headerlink\" title=\"7. 日志记录工具函数\"></a>7. 日志记录工具函数</h2><h3 id=\"功能：-6\"><a href=\"#功能：-6\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于记录程序的运行日志。</p>\n<h3 id=\"示例代码：-6\"><a href=\"#示例代码：-6\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> logging<br><span class=\"hljs-keyword\">from</span> logging.handlers <span class=\"hljs-keyword\">import</span> RotatingFileHandler<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">setup_logger</span>(<span class=\"hljs-params\">module_name, log_dir=<span class=\"hljs-string\">&quot;logs&quot;</span></span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    根据模块名称配置日志记录器，并自动生成日志文件名。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    :param module_name: 模块名称，用于生成日志文件名</span><br><span class=\"hljs-string\">    :param log_dir: 日志文件存储目录，默认为 &quot;logs&quot;</span><br><span class=\"hljs-string\">    :return: 配置好的日志记录器</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 创建日志记录器</span><br>    logger = logging.getLogger(module_name)<br>    logger.setLevel(logging.DEBUG)  <span class=\"hljs-comment\"># 设置全局日志级别为 DEBUG</span><br><br>    <span class=\"hljs-comment\"># 配置日志格式化</span><br>    formatter = logging.Formatter(<span class=\"hljs-string\">&quot;%(asctime)s - %(name)s - %(levelname)s - %(message)s&quot;</span>)<br><br>    <span class=\"hljs-comment\"># 配置控制台处理器（输出到终端）</span><br>    console_handler = logging.StreamHandler()<br>    console_handler.setLevel(logging.INFO)  <span class=\"hljs-comment\"># 控制台日志级别为 INFO</span><br>    console_handler.setFormatter(formatter)<br>    logger.addHandler(console_handler)<br><br>    <span class=\"hljs-comment\"># 配置文件处理器（根据模块名称生成日志文件名）</span><br>    log_file = <span class=\"hljs-string\">f&quot;<span class=\"hljs-subst\">&#123;log_dir&#125;</span>/<span class=\"hljs-subst\">&#123;module_name&#125;</span>.log&quot;</span><br>    file_handler = RotatingFileHandler(<br>        log_file,  <span class=\"hljs-comment\"># 日志文件路径</span><br>        maxBytes=<span class=\"hljs-number\">1024</span> * <span class=\"hljs-number\">1024</span>,  <span class=\"hljs-comment\"># 每个日志文件的最大大小（1MB）</span><br>        backupCount=<span class=\"hljs-number\">5</span>  <span class=\"hljs-comment\"># 保留的旧日志文件数量</span><br>    )<br>    file_handler.setLevel(logging.DEBUG)  <span class=\"hljs-comment\"># 文件日志级别为 DEBUG</span><br>    file_handler.setFormatter(formatter)<br>    logger.addHandler(file_handler)<br><br>    <span class=\"hljs-keyword\">return</span> logger<br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> loguru <span class=\"hljs-keyword\">import</span> logger<br><span class=\"hljs-keyword\">import</span> sys<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">setup_logger</span>(<span class=\"hljs-params\">module_name, log_dir=<span class=\"hljs-string\">&quot;logs&quot;</span></span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    根据模块名称配置日志记录器，并自动生成日志文件名。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    :param module_name: 模块名称，用于生成日志文件名</span><br><span class=\"hljs-string\">    :param log_dir: 日志文件存储目录，默认为 &quot;logs&quot;</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 配置日志格式</span><br>    log_format = (<br>        <span class=\"hljs-string\">&quot;&lt;green&gt;&#123;time:YYYY-MM-DD HH:mm:ss&#125;&lt;/green&gt; | &quot;</span><br>        <span class=\"hljs-string\">&quot;&lt;level&gt;&#123;level: &lt;8&#125;&lt;/level&gt; | &quot;</span><br>        <span class=\"hljs-string\">&quot;&lt;cyan&gt;&#123;name&#125;&lt;/cyan&gt;:&lt;cyan&gt;&#123;function&#125;&lt;/cyan&gt;:&lt;cyan&gt;&#123;line&#125;&lt;/cyan&gt; - &lt;level&gt;&#123;message&#125;&lt;/level&gt;&quot;</span><br>    )<br><br>    <span class=\"hljs-comment\"># 配置控制台日志</span><br>    logger.remove()  <span class=\"hljs-comment\"># 移除默认的日志处理器</span><br>    logger.add(sys.stdout, <span class=\"hljs-built_in\">format</span>=log_format, level=<span class=\"hljs-string\">&quot;INFO&quot;</span>)<br><br>    <span class=\"hljs-comment\"># 配置文件日志（根据模块名称生成日志文件名）</span><br>    log_file = <span class=\"hljs-string\">f&quot;<span class=\"hljs-subst\">&#123;log_dir&#125;</span>/<span class=\"hljs-subst\">&#123;module_name&#125;</span>.log&quot;</span><br>    logger.add(<br>        log_file,  <span class=\"hljs-comment\"># 日志文件路径</span><br>        <span class=\"hljs-built_in\">format</span>=log_format,<br>        level=<span class=\"hljs-string\">&quot;DEBUG&quot;</span>,<br>        rotation=<span class=\"hljs-string\">&quot;10 MB&quot;</span>,  <span class=\"hljs-comment\"># 日志文件轮转大小</span><br>        retention=<span class=\"hljs-string\">&quot;7 days&quot;</span>,  <span class=\"hljs-comment\"># 保留日志文件的时间</span><br>        compression=<span class=\"hljs-string\">&quot;zip&quot;</span>,  <span class=\"hljs-comment\"># 日志文件压缩格式</span><br>    )<br><br>    <span class=\"hljs-keyword\">return</span> logger<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"8-缓存工具函数\"><a href=\"#8-缓存工具函数\" class=\"headerlink\" title=\"8. 缓存工具函数\"></a>8. 缓存工具函数</h2><h3 id=\"功能：-7\"><a href=\"#功能：-7\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于缓存函数的返回值，避免重复计算。</p>\n<h3 id=\"示例代码：-7\"><a href=\"#示例代码：-7\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> functools <span class=\"hljs-keyword\">import</span> lru_cache<br><br><span class=\"hljs-meta\">@lru_cache(<span class=\"hljs-params\">maxsize=<span class=\"hljs-number\">128</span></span>)</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">fibonacci</span>(<span class=\"hljs-params\">n</span>):<br>    <span class=\"hljs-keyword\">if</span> n &lt;= <span class=\"hljs-number\">1</span>:<br>        <span class=\"hljs-keyword\">return</span> n<br>    <span class=\"hljs-keyword\">return</span> fibonacci(n - <span class=\"hljs-number\">1</span>) + fibonacci(n - <span class=\"hljs-number\">2</span>)<br><br><span class=\"hljs-built_in\">print</span>(fibonacci(<span class=\"hljs-number\">10</span>))  <span class=\"hljs-comment\"># 计算并缓存</span><br><span class=\"hljs-built_in\">print</span>(fibonacci(<span class=\"hljs-number\">10</span>))  <span class=\"hljs-comment\"># 直接从缓存中获取</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"9-随机数据生成工具函数\"><a href=\"#9-随机数据生成工具函数\" class=\"headerlink\" title=\"9. 随机数据生成工具函数\"></a>9. 随机数据生成工具函数</h2><h3 id=\"功能：-8\"><a href=\"#功能：-8\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于生成随机数据，如随机字符串、随机数等。</p>\n<h3 id=\"示例代码：-8\"><a href=\"#示例代码：-8\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> random<br><span class=\"hljs-keyword\">import</span> string<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">random_string</span>(<span class=\"hljs-params\">length=<span class=\"hljs-number\">10</span></span>):<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&#x27;&#x27;</span>.join(random.choices(string.ascii_letters + string.digits, k=length))<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">random_number</span>(<span class=\"hljs-params\">start=<span class=\"hljs-number\">1</span>, end=<span class=\"hljs-number\">100</span></span>):<br>    <span class=\"hljs-keyword\">return</span> random.randint(start, end)<br><br><span class=\"hljs-comment\"># 示例</span><br><span class=\"hljs-built_in\">print</span>(random_string(<span class=\"hljs-number\">15</span>))<br><span class=\"hljs-built_in\">print</span>(random_number(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">10</span>))<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"10-并发执行工具函数\"><a href=\"#10-并发执行工具函数\" class=\"headerlink\" title=\"10. 并发执行工具函数\"></a>10. 并发执行工具函数</h2><h3 id=\"功能：-9\"><a href=\"#功能：-9\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于并发执行多个任务。</p>\n<h3 id=\"示例代码：-9\"><a href=\"#示例代码：-9\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> concurrent.futures<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">task</span>(<span class=\"hljs-params\">n</span>):<br>    <span class=\"hljs-keyword\">return</span> n * n<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">parallel_execute</span>(<span class=\"hljs-params\">tasks</span>):<br>    <span class=\"hljs-keyword\">with</span> concurrent.futures.ThreadPoolExecutor() <span class=\"hljs-keyword\">as</span> executor:<br>        results = <span class=\"hljs-built_in\">list</span>(executor.<span class=\"hljs-built_in\">map</span>(task, tasks))<br>    <span class=\"hljs-keyword\">return</span> results<br><br><span class=\"hljs-comment\"># 示例</span><br>tasks = [<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">5</span>]<br><span class=\"hljs-built_in\">print</span>(parallel_execute(tasks))<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>以上是 Python 中常用的一些工具函数，涵盖了时间统计、类型检查、重试机制、文件操作、字符串处理、日志记录、缓存、随机数据生成和并发执行等多个方面。这些工具函数可以帮助我们提高代码的可读性、可维护性和性能。</p>\n<p>根据具体需求，你可以选择合适的工具函数，或者将它们组合起来，构建更复杂的工具链。</p>\n","excerpt":"","more":"<h2 id=\"1-函数执行时间统计装饰器\"><a href=\"#1-函数执行时间统计装饰器\" class=\"headerlink\" title=\"1.函数执行时间统计装饰器\"></a>1.函数执行时间统计装饰器</h2><h3 id=\"功能：\"><a href=\"#功能：\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于统计函数执行的时间，常用于性能优化。</p>\n<h3 id=\"示例代码：\"><a href=\"#示例代码：\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> time <span class=\"hljs-keyword\">import</span> perf_counter<br><span class=\"hljs-keyword\">from</span> functools <span class=\"hljs-keyword\">import</span> wraps<br><span class=\"hljs-keyword\">from</span> typing <span class=\"hljs-keyword\">import</span> <span class=\"hljs-type\">List</span><br><br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">timeit</span>(<span class=\"hljs-params\">loop: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">1</span></span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    函数执行失败时，重试</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    :param loop: 循环执行次数</span><br><span class=\"hljs-string\">    :return:</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br><br>    <span class=\"hljs-comment\"># 校验参数，参数值不正确时使用默认参数</span><br>    <span class=\"hljs-keyword\">if</span> loop &lt; <span class=\"hljs-number\">1</span>:<br>        loop = <span class=\"hljs-number\">1</span><br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">decorator</span>(<span class=\"hljs-params\">func</span>):<br><span class=\"hljs-meta\">        @wraps(<span class=\"hljs-params\">func</span>)</span><br>        <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">wrapper</span>(<span class=\"hljs-params\">*args, **kwargs</span>):<br>            sum_time: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">0.0</span><br>            <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(loop):<br>                start_time: <span class=\"hljs-built_in\">float</span> = perf_counter()<br>                ret = func(*args, **kwargs)<br>                end_time: <span class=\"hljs-built_in\">float</span> = perf_counter()<br>                sum_time += end_time - start_time<br><br>            <span class=\"hljs-built_in\">print</span>(<br>                <span class=\"hljs-string\">f&quot;函数(<span class=\"hljs-subst\">&#123;func.__name__&#125;</span>)共执行<span class=\"hljs-subst\">&#123;loop&#125;</span>次，平均执行时间 <span class=\"hljs-subst\">&#123;(sum_time/loop):<span class=\"hljs-number\">.3</span>f&#125;</span> 秒&quot;</span><br>            )<br>            <span class=\"hljs-keyword\">return</span> ret<br><br>        <span class=\"hljs-keyword\">return</span> wrapper<br><br>    <span class=\"hljs-keyword\">return</span> decorator<br><br></code></pre></td></tr></table></figure>\n\n<p>在 Python 开发中，工具函数（Utility Functions）是提高代码效率和可维护性的重要组成部分。这些函数可以帮助我们完成常见的任务，如时间统计、类型检查、字符串处理、文件操作等。以下是一些常用的工具函数及其使用场景。</p>\n<hr>\n<h2 id=\"2-类型检查装饰器\"><a href=\"#2-类型检查装饰器\" class=\"headerlink\" title=\"2. 类型检查装饰器\"></a>2. 类型检查装饰器</h2><h3 id=\"功能：-1\"><a href=\"#功能：-1\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于检查函数参数的类型是否符合预期。</p>\n<h3 id=\"示例代码：-1\"><a href=\"#示例代码：-1\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> functools <span class=\"hljs-keyword\">import</span> wraps<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">type_check</span>(<span class=\"hljs-params\">func</span>):<br><span class=\"hljs-meta\">    @wraps(<span class=\"hljs-params\">func</span>)</span><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">wrapper</span>(<span class=\"hljs-params\">*args, **kwargs</span>):<br>        sig = inspect.signature(func)<br>        params = sig.parameters<br>        <span class=\"hljs-keyword\">for</span> i, (arg_name, arg_value) <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(<span class=\"hljs-built_in\">zip</span>(params, args)):<br>            param = params[arg_name]<br>            <span class=\"hljs-keyword\">if</span> param.annotation != inspect.Parameter.empty <span class=\"hljs-keyword\">and</span> <span class=\"hljs-keyword\">not</span> <span class=\"hljs-built_in\">isinstance</span>(arg_value, param.annotation):<br>                <span class=\"hljs-keyword\">raise</span> TypeError(<span class=\"hljs-string\">f&quot;参数 <span class=\"hljs-subst\">&#123;arg_name&#125;</span> 的类型应为 <span class=\"hljs-subst\">&#123;param.annotation&#125;</span>，但传入的是 <span class=\"hljs-subst\">&#123;<span class=\"hljs-built_in\">type</span>(arg_value)&#125;</span>&quot;</span>)<br>        <span class=\"hljs-keyword\">return</span> func(*args, **kwargs)<br>    <span class=\"hljs-keyword\">return</span> wrapper<br><br><span class=\"hljs-meta\">@type_check</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">add</span>(<span class=\"hljs-params\">a: <span class=\"hljs-built_in\">int</span>, b: <span class=\"hljs-built_in\">int</span></span>) -&gt; <span class=\"hljs-built_in\">int</span>:<br>    <span class=\"hljs-keyword\">return</span> a + b<br><br><span class=\"hljs-built_in\">print</span>(add(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>))  <span class=\"hljs-comment\"># 正常</span><br><span class=\"hljs-built_in\">print</span>(add(<span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">&quot;2&quot;</span>))  <span class=\"hljs-comment\"># 抛出 TypeError</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"3-重试装饰器\"><a href=\"#3-重试装饰器\" class=\"headerlink\" title=\"3. 重试装饰器\"></a>3. 重试装饰器</h2><h3 id=\"功能：-2\"><a href=\"#功能：-2\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于在函数执行失败时自动重试。</p>\n<h3 id=\"示例代码：-2\"><a href=\"#示例代码：-2\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> functools <span class=\"hljs-keyword\">import</span> wraps<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">retry</span>(<span class=\"hljs-params\">max_retries=<span class=\"hljs-number\">3</span>, delay=<span class=\"hljs-number\">1</span></span>):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">decorator</span>(<span class=\"hljs-params\">func</span>):<br><span class=\"hljs-meta\">        @wraps(<span class=\"hljs-params\">func</span>)</span><br>        <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">wrapper</span>(<span class=\"hljs-params\">*args, **kwargs</span>):<br>            retries = <span class=\"hljs-number\">0</span><br>            <span class=\"hljs-keyword\">while</span> retries &lt; max_retries:<br>                <span class=\"hljs-keyword\">try</span>:<br>                    <span class=\"hljs-keyword\">return</span> func(*args, **kwargs)<br>                <span class=\"hljs-keyword\">except</span> Exception <span class=\"hljs-keyword\">as</span> e:<br>                    retries += <span class=\"hljs-number\">1</span><br>                    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;重试 <span class=\"hljs-subst\">&#123;retries&#125;</span>/<span class=\"hljs-subst\">&#123;max_retries&#125;</span>: <span class=\"hljs-subst\">&#123;e&#125;</span>&quot;</span>)<br>                    time.sleep(delay)<br>            <span class=\"hljs-keyword\">raise</span> Exception(<span class=\"hljs-string\">f&quot;达到最大重试次数 <span class=\"hljs-subst\">&#123;max_retries&#125;</span>&quot;</span>)<br>        <span class=\"hljs-keyword\">return</span> wrapper<br>    <span class=\"hljs-keyword\">return</span> decorator<br><br><span class=\"hljs-meta\">@retry(<span class=\"hljs-params\">max_retries=<span class=\"hljs-number\">3</span>, delay=<span class=\"hljs-number\">1</span></span>)</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">flaky_function</span>():<br>    <span class=\"hljs-keyword\">if</span> random.randint(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">1</span>) == <span class=\"hljs-number\">0</span>:<br>        <span class=\"hljs-keyword\">raise</span> Exception(<span class=\"hljs-string\">&quot;随机失败&quot;</span>)<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&quot;成功&quot;</span><br><br><span class=\"hljs-built_in\">print</span>(flaky_function())<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"4-批量处理函数\"><a href=\"#4-批量处理函数\" class=\"headerlink\" title=\"4. 批量处理函数\"></a>4. 批量处理函数</h2><h3 id=\"功能：-3\"><a href=\"#功能：-3\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于将一个列表或迭代器分批处理。</p>\n<h3 id=\"示例代码：-3\"><a href=\"#示例代码：-3\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">batch_process</span>(<span class=\"hljs-params\">data, batch_size=<span class=\"hljs-number\">10</span></span>):<br>    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-built_in\">len</span>(data), batch_size):<br>        <span class=\"hljs-keyword\">yield</span> data[i:i + batch_size]<br><br>data = <span class=\"hljs-built_in\">list</span>(<span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">101</span>))<br><span class=\"hljs-keyword\">for</span> batch <span class=\"hljs-keyword\">in</span> batch_process(data, batch_size=<span class=\"hljs-number\">20</span>):<br>    <span class=\"hljs-built_in\">print</span>(batch)<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"输出：\"><a href=\"#输出：\" class=\"headerlink\" title=\"输出：\"></a>输出：</h3><figure class=\"highlight jboss-cli\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs jboss-cli\">[1, 2, 3, <span class=\"hljs-string\">...</span>, 20]<br>[21, 22, 33, <span class=\"hljs-string\">...</span>, 40]<br><span class=\"hljs-string\">...</span><br>[81, 82, 83, <span class=\"hljs-string\">...</span>, 100]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"5-文件操作工具函数\"><a href=\"#5-文件操作工具函数\" class=\"headerlink\" title=\"5. 文件操作工具函数\"></a>5. 文件操作工具函数</h2><h3 id=\"功能：-4\"><a href=\"#功能：-4\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于读取、写入和处理文件。</p>\n<h3 id=\"示例代码：-4\"><a href=\"#示例代码：-4\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">read_file</span>(<span class=\"hljs-params\">file_path</span>):<br>    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(file_path, <span class=\"hljs-string\">&#x27;r&#x27;</span>, encoding=<span class=\"hljs-string\">&#x27;utf-8&#x27;</span>) <span class=\"hljs-keyword\">as</span> f:<br>        <span class=\"hljs-keyword\">return</span> f.read()<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">write_file</span>(<span class=\"hljs-params\">file_path, content</span>):<br>    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(file_path, <span class=\"hljs-string\">&#x27;w&#x27;</span>, encoding=<span class=\"hljs-string\">&#x27;utf-8&#x27;</span>) <span class=\"hljs-keyword\">as</span> f:<br>        f.write(content)<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">append_file</span>(<span class=\"hljs-params\">file_path, content</span>):<br>    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(file_path, <span class=\"hljs-string\">&#x27;a&#x27;</span>, encoding=<span class=\"hljs-string\">&#x27;utf-8&#x27;</span>) <span class=\"hljs-keyword\">as</span> f:<br>        f.write(content)<br><br><span class=\"hljs-comment\"># 示例</span><br>write_file(<span class=\"hljs-string\">&quot;example.txt&quot;</span>, <span class=\"hljs-string\">&quot;Hello, World!\\n&quot;</span>)<br>append_file(<span class=\"hljs-string\">&quot;example.txt&quot;</span>, <span class=\"hljs-string\">&quot;This is a new line.\\n&quot;</span>)<br><span class=\"hljs-built_in\">print</span>(read_file(<span class=\"hljs-string\">&quot;example.txt&quot;</span>))<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"6-字符串处理工具函数\"><a href=\"#6-字符串处理工具函数\" class=\"headerlink\" title=\"6. 字符串处理工具函数\"></a>6. 字符串处理工具函数</h2><h3 id=\"功能：-5\"><a href=\"#功能：-5\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于字符串的格式化、分割、替换等操作。</p>\n<h3 id=\"示例代码：-5\"><a href=\"#示例代码：-5\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">format_string</span>(<span class=\"hljs-params\">template, **kwargs</span>):<br>    <span class=\"hljs-keyword\">return</span> template.<span class=\"hljs-built_in\">format</span>(**kwargs)<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">split_string</span>(<span class=\"hljs-params\">text, delimiter=<span class=\"hljs-string\">&quot;,&quot;</span></span>):<br>    <span class=\"hljs-keyword\">return</span> text.split(delimiter)<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">replace_string</span>(<span class=\"hljs-params\">text, old, new</span>):<br>    <span class=\"hljs-keyword\">return</span> text.replace(old, new)<br><br><span class=\"hljs-comment\"># 示例</span><br>template = <span class=\"hljs-string\">&quot;My name is &#123;name&#125; and I am &#123;age&#125; years old.&quot;</span><br><span class=\"hljs-built_in\">print</span>(format_string(template, name=<span class=\"hljs-string\">&quot;Alice&quot;</span>, age=<span class=\"hljs-number\">30</span>))<br><br>text = <span class=\"hljs-string\">&quot;apple,banana,cherry&quot;</span><br><span class=\"hljs-built_in\">print</span>(split_string(text))<br><br>text = <span class=\"hljs-string\">&quot;Hello, World!&quot;</span><br><span class=\"hljs-built_in\">print</span>(replace_string(text, <span class=\"hljs-string\">&quot;World&quot;</span>, <span class=\"hljs-string\">&quot;Python&quot;</span>))<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"7-日志记录工具函数\"><a href=\"#7-日志记录工具函数\" class=\"headerlink\" title=\"7. 日志记录工具函数\"></a>7. 日志记录工具函数</h2><h3 id=\"功能：-6\"><a href=\"#功能：-6\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于记录程序的运行日志。</p>\n<h3 id=\"示例代码：-6\"><a href=\"#示例代码：-6\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> logging<br><span class=\"hljs-keyword\">from</span> logging.handlers <span class=\"hljs-keyword\">import</span> RotatingFileHandler<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">setup_logger</span>(<span class=\"hljs-params\">module_name, log_dir=<span class=\"hljs-string\">&quot;logs&quot;</span></span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    根据模块名称配置日志记录器，并自动生成日志文件名。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    :param module_name: 模块名称，用于生成日志文件名</span><br><span class=\"hljs-string\">    :param log_dir: 日志文件存储目录，默认为 &quot;logs&quot;</span><br><span class=\"hljs-string\">    :return: 配置好的日志记录器</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 创建日志记录器</span><br>    logger = logging.getLogger(module_name)<br>    logger.setLevel(logging.DEBUG)  <span class=\"hljs-comment\"># 设置全局日志级别为 DEBUG</span><br><br>    <span class=\"hljs-comment\"># 配置日志格式化</span><br>    formatter = logging.Formatter(<span class=\"hljs-string\">&quot;%(asctime)s - %(name)s - %(levelname)s - %(message)s&quot;</span>)<br><br>    <span class=\"hljs-comment\"># 配置控制台处理器（输出到终端）</span><br>    console_handler = logging.StreamHandler()<br>    console_handler.setLevel(logging.INFO)  <span class=\"hljs-comment\"># 控制台日志级别为 INFO</span><br>    console_handler.setFormatter(formatter)<br>    logger.addHandler(console_handler)<br><br>    <span class=\"hljs-comment\"># 配置文件处理器（根据模块名称生成日志文件名）</span><br>    log_file = <span class=\"hljs-string\">f&quot;<span class=\"hljs-subst\">&#123;log_dir&#125;</span>/<span class=\"hljs-subst\">&#123;module_name&#125;</span>.log&quot;</span><br>    file_handler = RotatingFileHandler(<br>        log_file,  <span class=\"hljs-comment\"># 日志文件路径</span><br>        maxBytes=<span class=\"hljs-number\">1024</span> * <span class=\"hljs-number\">1024</span>,  <span class=\"hljs-comment\"># 每个日志文件的最大大小（1MB）</span><br>        backupCount=<span class=\"hljs-number\">5</span>  <span class=\"hljs-comment\"># 保留的旧日志文件数量</span><br>    )<br>    file_handler.setLevel(logging.DEBUG)  <span class=\"hljs-comment\"># 文件日志级别为 DEBUG</span><br>    file_handler.setFormatter(formatter)<br>    logger.addHandler(file_handler)<br><br>    <span class=\"hljs-keyword\">return</span> logger<br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> loguru <span class=\"hljs-keyword\">import</span> logger<br><span class=\"hljs-keyword\">import</span> sys<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">setup_logger</span>(<span class=\"hljs-params\">module_name, log_dir=<span class=\"hljs-string\">&quot;logs&quot;</span></span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    根据模块名称配置日志记录器，并自动生成日志文件名。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    :param module_name: 模块名称，用于生成日志文件名</span><br><span class=\"hljs-string\">    :param log_dir: 日志文件存储目录，默认为 &quot;logs&quot;</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 配置日志格式</span><br>    log_format = (<br>        <span class=\"hljs-string\">&quot;&lt;green&gt;&#123;time:YYYY-MM-DD HH:mm:ss&#125;&lt;/green&gt; | &quot;</span><br>        <span class=\"hljs-string\">&quot;&lt;level&gt;&#123;level: &lt;8&#125;&lt;/level&gt; | &quot;</span><br>        <span class=\"hljs-string\">&quot;&lt;cyan&gt;&#123;name&#125;&lt;/cyan&gt;:&lt;cyan&gt;&#123;function&#125;&lt;/cyan&gt;:&lt;cyan&gt;&#123;line&#125;&lt;/cyan&gt; - &lt;level&gt;&#123;message&#125;&lt;/level&gt;&quot;</span><br>    )<br><br>    <span class=\"hljs-comment\"># 配置控制台日志</span><br>    logger.remove()  <span class=\"hljs-comment\"># 移除默认的日志处理器</span><br>    logger.add(sys.stdout, <span class=\"hljs-built_in\">format</span>=log_format, level=<span class=\"hljs-string\">&quot;INFO&quot;</span>)<br><br>    <span class=\"hljs-comment\"># 配置文件日志（根据模块名称生成日志文件名）</span><br>    log_file = <span class=\"hljs-string\">f&quot;<span class=\"hljs-subst\">&#123;log_dir&#125;</span>/<span class=\"hljs-subst\">&#123;module_name&#125;</span>.log&quot;</span><br>    logger.add(<br>        log_file,  <span class=\"hljs-comment\"># 日志文件路径</span><br>        <span class=\"hljs-built_in\">format</span>=log_format,<br>        level=<span class=\"hljs-string\">&quot;DEBUG&quot;</span>,<br>        rotation=<span class=\"hljs-string\">&quot;10 MB&quot;</span>,  <span class=\"hljs-comment\"># 日志文件轮转大小</span><br>        retention=<span class=\"hljs-string\">&quot;7 days&quot;</span>,  <span class=\"hljs-comment\"># 保留日志文件的时间</span><br>        compression=<span class=\"hljs-string\">&quot;zip&quot;</span>,  <span class=\"hljs-comment\"># 日志文件压缩格式</span><br>    )<br><br>    <span class=\"hljs-keyword\">return</span> logger<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"8-缓存工具函数\"><a href=\"#8-缓存工具函数\" class=\"headerlink\" title=\"8. 缓存工具函数\"></a>8. 缓存工具函数</h2><h3 id=\"功能：-7\"><a href=\"#功能：-7\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于缓存函数的返回值，避免重复计算。</p>\n<h3 id=\"示例代码：-7\"><a href=\"#示例代码：-7\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> functools <span class=\"hljs-keyword\">import</span> lru_cache<br><br><span class=\"hljs-meta\">@lru_cache(<span class=\"hljs-params\">maxsize=<span class=\"hljs-number\">128</span></span>)</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">fibonacci</span>(<span class=\"hljs-params\">n</span>):<br>    <span class=\"hljs-keyword\">if</span> n &lt;= <span class=\"hljs-number\">1</span>:<br>        <span class=\"hljs-keyword\">return</span> n<br>    <span class=\"hljs-keyword\">return</span> fibonacci(n - <span class=\"hljs-number\">1</span>) + fibonacci(n - <span class=\"hljs-number\">2</span>)<br><br><span class=\"hljs-built_in\">print</span>(fibonacci(<span class=\"hljs-number\">10</span>))  <span class=\"hljs-comment\"># 计算并缓存</span><br><span class=\"hljs-built_in\">print</span>(fibonacci(<span class=\"hljs-number\">10</span>))  <span class=\"hljs-comment\"># 直接从缓存中获取</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"9-随机数据生成工具函数\"><a href=\"#9-随机数据生成工具函数\" class=\"headerlink\" title=\"9. 随机数据生成工具函数\"></a>9. 随机数据生成工具函数</h2><h3 id=\"功能：-8\"><a href=\"#功能：-8\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于生成随机数据，如随机字符串、随机数等。</p>\n<h3 id=\"示例代码：-8\"><a href=\"#示例代码：-8\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> random<br><span class=\"hljs-keyword\">import</span> string<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">random_string</span>(<span class=\"hljs-params\">length=<span class=\"hljs-number\">10</span></span>):<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-string\">&#x27;&#x27;</span>.join(random.choices(string.ascii_letters + string.digits, k=length))<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">random_number</span>(<span class=\"hljs-params\">start=<span class=\"hljs-number\">1</span>, end=<span class=\"hljs-number\">100</span></span>):<br>    <span class=\"hljs-keyword\">return</span> random.randint(start, end)<br><br><span class=\"hljs-comment\"># 示例</span><br><span class=\"hljs-built_in\">print</span>(random_string(<span class=\"hljs-number\">15</span>))<br><span class=\"hljs-built_in\">print</span>(random_number(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">10</span>))<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"10-并发执行工具函数\"><a href=\"#10-并发执行工具函数\" class=\"headerlink\" title=\"10. 并发执行工具函数\"></a>10. 并发执行工具函数</h2><h3 id=\"功能：-9\"><a href=\"#功能：-9\" class=\"headerlink\" title=\"功能：\"></a>功能：</h3><p>用于并发执行多个任务。</p>\n<h3 id=\"示例代码：-9\"><a href=\"#示例代码：-9\" class=\"headerlink\" title=\"示例代码：\"></a>示例代码：</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> concurrent.futures<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">task</span>(<span class=\"hljs-params\">n</span>):<br>    <span class=\"hljs-keyword\">return</span> n * n<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">parallel_execute</span>(<span class=\"hljs-params\">tasks</span>):<br>    <span class=\"hljs-keyword\">with</span> concurrent.futures.ThreadPoolExecutor() <span class=\"hljs-keyword\">as</span> executor:<br>        results = <span class=\"hljs-built_in\">list</span>(executor.<span class=\"hljs-built_in\">map</span>(task, tasks))<br>    <span class=\"hljs-keyword\">return</span> results<br><br><span class=\"hljs-comment\"># 示例</span><br>tasks = [<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">5</span>]<br><span class=\"hljs-built_in\">print</span>(parallel_execute(tasks))<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h2><p>以上是 Python 中常用的一些工具函数，涵盖了时间统计、类型检查、重试机制、文件操作、字符串处理、日志记录、缓存、随机数据生成和并发执行等多个方面。这些工具函数可以帮助我们提高代码的可读性、可维护性和性能。</p>\n<p>根据具体需求，你可以选择合适的工具函数，或者将它们组合起来，构建更复杂的工具链。</p>\n"},{"title":"Python 日志处理最佳实践：使用logging模块构建高效日志系统","date":"2024-12-15T04:00:00.000Z","_content":"\n# Python 日志处理最佳实践：使用 `logging` 模块构建高效日志系统\n\n在现代软件开发中，日志记录是不可或缺的一部分。它不仅可以帮助我们调试和排查问题，还可以为系统的运行状态提供有价值的信息。Python 的标准库 `logging` 是一个强大且灵活的日志记录工具，但在实际项目中，如何高效地使用它却是一个值得探讨的话题。本文将结合实际项目经验，总结使用 `logging` 模块的最佳实践，并提供一个完整的代码示例。\n\n---\n\n## 1. 为什么选择 `logging` 模块？\n\n相比于简单的 `print` 语句，`logging` 模块提供了以下优势：\n\n- **日志级别**：支持 `DEBUG`、`INFO`、`WARNING`、`ERROR` 和 `CRITICAL` 五种日志级别，便于控制日志的详细程度。\n- **日志格式化**：可以自定义日志的输出格式，包括时间、日志级别、模块名称等。\n- **日志处理器**：支持将日志输出到文件、控制台、网络等多种目标。\n- **日志轮转**：支持日志文件的自动轮转，避免日志文件过大。\n- **日志过滤器**：可以过滤敏感信息，确保日志安全。\n\n---\n\n## 2. 最佳实践概述\n\n在实际项目中，日志记录的最佳实践包括以下几点：\n\n1. **统一的日志配置**：通过一个统一的日志配置函数，避免在每个模块中重复编写日志配置代码。\n2. **根据模块名称自动命名日志文件**：每个模块的日志存储在独立的文件中，便于管理和分析。\n3. **日志轮转**：使用 `RotatingFileHandler` 或 `TimedRotatingFileHandler` 管理日志文件的大小和数量。\n4. **日志级别控制**：在开发环境中使用 `DEBUG` 级别，在生产环境中使用 `INFO` 或 `WARNING` 级别。\n5. **日志格式化**：使用统一的日志格式，便于阅读和分析。\n6. **日志安全**：避免记录敏感信息，如密码、密钥等。\n\n---\n\n## 3. 示例项目结构\n\n```\nmy_project/\n├── main.py\n├── module_a.py\n├── module_b.py\n├── logger_config.py\n└── logs/\n    ├── module_a.log\n    ├── module_b.log\n    └── app.log\n```\n\n---\n\n## 4. 统一的日志配置函数\n\n为了减少重复代码，我们可以在一个单独的模块中定义一个统一的日志配置函数 `setup_logger`，并在每个模块中调用它。\n\n### `logger_config.py`\n\n```python\nimport logging\nfrom logging.handlers import RotatingFileHandler\n\ndef setup_logger(module_name, log_dir=\"logs\"):\n    \"\"\"\n    根据模块名称配置日志记录器，并自动生成日志文件名。\n\n    :param module_name: 模块名称，用于生成日志文件名\n    :param log_dir: 日志文件存储目录，默认为 \"logs\"\n    :return: 配置好的日志记录器\n    \"\"\"\n    # 创建日志记录器\n    logger = logging.getLogger(module_name)\n    logger.setLevel(logging.DEBUG)  # 设置全局日志级别为 DEBUG\n\n    # 配置日志格式化\n    formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n\n    # 配置控制台处理器（输出到终端）\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.INFO)  # 控制台日志级别为 INFO\n    console_handler.setFormatter(formatter)\n    logger.addHandler(console_handler)\n\n    # 配置文件处理器（根据模块名称生成日志文件名）\n    log_file = f\"{log_dir}/{module_name}.log\"\n    file_handler = RotatingFileHandler(\n        log_file,  # 日志文件路径\n        maxBytes=1024 * 1024,  # 每个日志文件的最大大小（1MB）\n        backupCount=5  # 保留的旧日志文件数量\n    )\n    file_handler.setLevel(logging.DEBUG)  # 文件日志级别为 DEBUG\n    file_handler.setFormatter(formatter)\n    logger.addHandler(file_handler)\n\n    return logger\n```\n\n---\n\n## 5. 主模块：`main.py`\n\n在主模块中，我们调用 `setup_logger` 函数来配置日志记录器，并记录日志。\n\n```python\nfrom logger_config import setup_logger\nimport module_a\nimport module_b\n\n# 配置主模块的日志记录器\nlogger = setup_logger(\"main\")\n\n# 记录日志\ndef main():\n    logger.info(\"主模块启动\")\n    module_a.run()\n    module_b.run()\n    logger.info(\"主模块结束\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\n---\n\n## 6. 模块 A：`module_a.py`\n\n在模块 A 中，我们同样调用 `setup_logger` 函数来配置日志记录器，并记录日志。\n\n```python\nfrom logger_config import setup_logger\n\n# 配置模块 A 的日志记录器\nlogger = setup_logger(\"module_a\")\n\n# 记录日志\ndef run():\n    logger.debug(\"模块 A 的调试信息\")\n    logger.info(\"模块 A 的普通信息\")\n    logger.warning(\"模块 A 的警告信息\")\n    logger.error(\"模块 A 的错误信息\")\n    logger.critical(\"模块 A 的严重错误信息\")\n```\n\n---\n\n## 7. 模块 B：`module_b.py`\n\n在模块 B 中，我们同样调用 `setup_logger` 函数来配置日志记录器，并记录日志。\n\n```python\nfrom logger_config import setup_logger\n\n# 配置模块 B 的日志记录器\nlogger = setup_logger(\"module_b\")\n\n# 记录日志\ndef run():\n    logger.debug(\"模块 B 的调试信息\")\n    logger.info(\"模块 B 的普通信息\")\n    logger.warning(\"模块 B 的警告信息\")\n    logger.error(\"模块 B 的错误信息\")\n    logger.critical(\"模块 B 的严重错误信息\")\n```\n\n---\n\n## 8. 运行结果\n\n### 控制台输出\n\n```\n2023-10-01 12:00:00 - main - INFO - 主模块启动\n2023-10-01 12:00:00 - module_a - INFO - 模块 A 的普通信息\n2023-10-01 12:00:00 - module_a - WARNING - 模块 A 的警告信息\n2023-10-01 12:00:00 - module_a - ERROR - 模块 A 的错误信息\n2023-10-01 12:00:00 - module_a - CRITICAL - 模块 A 的严重错误信息\n2023-10-01 12:00:00 - module_b - INFO - 模块 B 的普通信息\n2023-10-01 12:00:00 - module_b - WARNING - 模块 B 的警告信息\n2023-10-01 12:00:00 - module_b - ERROR - 模块 B 的错误信息\n2023-10-01 12:00:00 - module_b - CRITICAL - 模块 B 的严重错误信息\n2023-10-01 12:00:00 - main - INFO - 主模块结束\n```\n\n### 日志文件内容\n\n#### `logs/app.log`（主模块日志）：\n```\n2023-10-01 12:00:00 - main - INFO - 主模块启动\n2023-10-01 12:00:00 - main - INFO - 主模块结束\n```\n\n#### `logs/module_a.log`（模块 A 日志）：\n```\n2023-10-01 12:00:00 - module_a - DEBUG - 模块 A 的调试信息\n2023-10-01 12:00:00 - module_a - INFO - 模块 A 的普通信息\n2023-10-01 12:00:00 - module_a - WARNING - 模块 A 的警告信息\n2023-10-01 12:00:00 - module_a - ERROR - 模块 A 的错误信息\n2023-10-01 12:00:00 - module_a - CRITICAL - 模块 A 的严重错误信息\n```\n\n#### `logs/module_b.log`（模块 B 日志）：\n```\n2023-10-01 12:00:00 - module_b - DEBUG - 模块 B 的调试信息\n2023-10-01 12:00:00 - module_b - INFO - 模块 B 的普通信息\n2023-10-01 12:00:00 - module_b - WARNING - 模块 B 的警告信息\n2023-10-01 12:00:00 - module_b - ERROR - 模块 B 的错误信息\n2023-10-01 12:00:00 - module_b - CRITICAL - 模块 B 的严重错误信息\n```\n\n---\n\n## 9. 总结\n\n通过统一的日志配置函数 `setup_logger`，我们实现了以下目标：\n\n1. **自动生成日志文件名**：根据模块名称动态生成日志文件名，避免手动指定文件名。\n2. **减少重复代码**：在每个模块中只需调用 `setup_logger` 函数，无需重复编写日志配置代码。\n3. **灵活的日志管理**：每个模块的日志存储在独立的文件中，便于管理和分析。\n4. **日志轮转**：通过 `RotatingFileHandler`，可以自动管理日志文件的大小和数量。\n5. **日志级别控制**：在开发环境中使用 `DEBUG` 级别，在生产环境中使用 `INFO` 或 `WARNING` 级别。\n6. **日志格式化**：使用统一的日志格式，便于阅读和分析。\n7. **日志安全**：避免记录敏感信息，如密码、密钥等。\n\n这种设计模式非常适合大型项目，能够有效提高日志管理的灵活性和可维护性。","source":"_posts/开发/Python/Python-003：Python 日志处理最佳实践：使用logging模块构建高效日志系统.md","raw":"---\ntitle: 'Python 日志处理最佳实践：使用logging模块构建高效日志系统'\ncategories:\n  - [开发,python]\ntags:\n  - python\ndate: 2024-12-15 12:00:00\n---\n\n# Python 日志处理最佳实践：使用 `logging` 模块构建高效日志系统\n\n在现代软件开发中，日志记录是不可或缺的一部分。它不仅可以帮助我们调试和排查问题，还可以为系统的运行状态提供有价值的信息。Python 的标准库 `logging` 是一个强大且灵活的日志记录工具，但在实际项目中，如何高效地使用它却是一个值得探讨的话题。本文将结合实际项目经验，总结使用 `logging` 模块的最佳实践，并提供一个完整的代码示例。\n\n---\n\n## 1. 为什么选择 `logging` 模块？\n\n相比于简单的 `print` 语句，`logging` 模块提供了以下优势：\n\n- **日志级别**：支持 `DEBUG`、`INFO`、`WARNING`、`ERROR` 和 `CRITICAL` 五种日志级别，便于控制日志的详细程度。\n- **日志格式化**：可以自定义日志的输出格式，包括时间、日志级别、模块名称等。\n- **日志处理器**：支持将日志输出到文件、控制台、网络等多种目标。\n- **日志轮转**：支持日志文件的自动轮转，避免日志文件过大。\n- **日志过滤器**：可以过滤敏感信息，确保日志安全。\n\n---\n\n## 2. 最佳实践概述\n\n在实际项目中，日志记录的最佳实践包括以下几点：\n\n1. **统一的日志配置**：通过一个统一的日志配置函数，避免在每个模块中重复编写日志配置代码。\n2. **根据模块名称自动命名日志文件**：每个模块的日志存储在独立的文件中，便于管理和分析。\n3. **日志轮转**：使用 `RotatingFileHandler` 或 `TimedRotatingFileHandler` 管理日志文件的大小和数量。\n4. **日志级别控制**：在开发环境中使用 `DEBUG` 级别，在生产环境中使用 `INFO` 或 `WARNING` 级别。\n5. **日志格式化**：使用统一的日志格式，便于阅读和分析。\n6. **日志安全**：避免记录敏感信息，如密码、密钥等。\n\n---\n\n## 3. 示例项目结构\n\n```\nmy_project/\n├── main.py\n├── module_a.py\n├── module_b.py\n├── logger_config.py\n└── logs/\n    ├── module_a.log\n    ├── module_b.log\n    └── app.log\n```\n\n---\n\n## 4. 统一的日志配置函数\n\n为了减少重复代码，我们可以在一个单独的模块中定义一个统一的日志配置函数 `setup_logger`，并在每个模块中调用它。\n\n### `logger_config.py`\n\n```python\nimport logging\nfrom logging.handlers import RotatingFileHandler\n\ndef setup_logger(module_name, log_dir=\"logs\"):\n    \"\"\"\n    根据模块名称配置日志记录器，并自动生成日志文件名。\n\n    :param module_name: 模块名称，用于生成日志文件名\n    :param log_dir: 日志文件存储目录，默认为 \"logs\"\n    :return: 配置好的日志记录器\n    \"\"\"\n    # 创建日志记录器\n    logger = logging.getLogger(module_name)\n    logger.setLevel(logging.DEBUG)  # 设置全局日志级别为 DEBUG\n\n    # 配置日志格式化\n    formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n\n    # 配置控制台处理器（输出到终端）\n    console_handler = logging.StreamHandler()\n    console_handler.setLevel(logging.INFO)  # 控制台日志级别为 INFO\n    console_handler.setFormatter(formatter)\n    logger.addHandler(console_handler)\n\n    # 配置文件处理器（根据模块名称生成日志文件名）\n    log_file = f\"{log_dir}/{module_name}.log\"\n    file_handler = RotatingFileHandler(\n        log_file,  # 日志文件路径\n        maxBytes=1024 * 1024,  # 每个日志文件的最大大小（1MB）\n        backupCount=5  # 保留的旧日志文件数量\n    )\n    file_handler.setLevel(logging.DEBUG)  # 文件日志级别为 DEBUG\n    file_handler.setFormatter(formatter)\n    logger.addHandler(file_handler)\n\n    return logger\n```\n\n---\n\n## 5. 主模块：`main.py`\n\n在主模块中，我们调用 `setup_logger` 函数来配置日志记录器，并记录日志。\n\n```python\nfrom logger_config import setup_logger\nimport module_a\nimport module_b\n\n# 配置主模块的日志记录器\nlogger = setup_logger(\"main\")\n\n# 记录日志\ndef main():\n    logger.info(\"主模块启动\")\n    module_a.run()\n    module_b.run()\n    logger.info(\"主模块结束\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\n---\n\n## 6. 模块 A：`module_a.py`\n\n在模块 A 中，我们同样调用 `setup_logger` 函数来配置日志记录器，并记录日志。\n\n```python\nfrom logger_config import setup_logger\n\n# 配置模块 A 的日志记录器\nlogger = setup_logger(\"module_a\")\n\n# 记录日志\ndef run():\n    logger.debug(\"模块 A 的调试信息\")\n    logger.info(\"模块 A 的普通信息\")\n    logger.warning(\"模块 A 的警告信息\")\n    logger.error(\"模块 A 的错误信息\")\n    logger.critical(\"模块 A 的严重错误信息\")\n```\n\n---\n\n## 7. 模块 B：`module_b.py`\n\n在模块 B 中，我们同样调用 `setup_logger` 函数来配置日志记录器，并记录日志。\n\n```python\nfrom logger_config import setup_logger\n\n# 配置模块 B 的日志记录器\nlogger = setup_logger(\"module_b\")\n\n# 记录日志\ndef run():\n    logger.debug(\"模块 B 的调试信息\")\n    logger.info(\"模块 B 的普通信息\")\n    logger.warning(\"模块 B 的警告信息\")\n    logger.error(\"模块 B 的错误信息\")\n    logger.critical(\"模块 B 的严重错误信息\")\n```\n\n---\n\n## 8. 运行结果\n\n### 控制台输出\n\n```\n2023-10-01 12:00:00 - main - INFO - 主模块启动\n2023-10-01 12:00:00 - module_a - INFO - 模块 A 的普通信息\n2023-10-01 12:00:00 - module_a - WARNING - 模块 A 的警告信息\n2023-10-01 12:00:00 - module_a - ERROR - 模块 A 的错误信息\n2023-10-01 12:00:00 - module_a - CRITICAL - 模块 A 的严重错误信息\n2023-10-01 12:00:00 - module_b - INFO - 模块 B 的普通信息\n2023-10-01 12:00:00 - module_b - WARNING - 模块 B 的警告信息\n2023-10-01 12:00:00 - module_b - ERROR - 模块 B 的错误信息\n2023-10-01 12:00:00 - module_b - CRITICAL - 模块 B 的严重错误信息\n2023-10-01 12:00:00 - main - INFO - 主模块结束\n```\n\n### 日志文件内容\n\n#### `logs/app.log`（主模块日志）：\n```\n2023-10-01 12:00:00 - main - INFO - 主模块启动\n2023-10-01 12:00:00 - main - INFO - 主模块结束\n```\n\n#### `logs/module_a.log`（模块 A 日志）：\n```\n2023-10-01 12:00:00 - module_a - DEBUG - 模块 A 的调试信息\n2023-10-01 12:00:00 - module_a - INFO - 模块 A 的普通信息\n2023-10-01 12:00:00 - module_a - WARNING - 模块 A 的警告信息\n2023-10-01 12:00:00 - module_a - ERROR - 模块 A 的错误信息\n2023-10-01 12:00:00 - module_a - CRITICAL - 模块 A 的严重错误信息\n```\n\n#### `logs/module_b.log`（模块 B 日志）：\n```\n2023-10-01 12:00:00 - module_b - DEBUG - 模块 B 的调试信息\n2023-10-01 12:00:00 - module_b - INFO - 模块 B 的普通信息\n2023-10-01 12:00:00 - module_b - WARNING - 模块 B 的警告信息\n2023-10-01 12:00:00 - module_b - ERROR - 模块 B 的错误信息\n2023-10-01 12:00:00 - module_b - CRITICAL - 模块 B 的严重错误信息\n```\n\n---\n\n## 9. 总结\n\n通过统一的日志配置函数 `setup_logger`，我们实现了以下目标：\n\n1. **自动生成日志文件名**：根据模块名称动态生成日志文件名，避免手动指定文件名。\n2. **减少重复代码**：在每个模块中只需调用 `setup_logger` 函数，无需重复编写日志配置代码。\n3. **灵活的日志管理**：每个模块的日志存储在独立的文件中，便于管理和分析。\n4. **日志轮转**：通过 `RotatingFileHandler`，可以自动管理日志文件的大小和数量。\n5. **日志级别控制**：在开发环境中使用 `DEBUG` 级别，在生产环境中使用 `INFO` 或 `WARNING` 级别。\n6. **日志格式化**：使用统一的日志格式，便于阅读和分析。\n7. **日志安全**：避免记录敏感信息，如密码、密钥等。\n\n这种设计模式非常适合大型项目，能够有效提高日志管理的灵活性和可维护性。","slug":"开发/Python/Python-003：Python 日志处理最佳实践：使用logging模块构建高效日志系统","published":1,"updated":"2024-12-26T06:21:08.743Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3f000bhghidw761x0s","content":"<h1 id=\"Python-日志处理最佳实践：使用-logging-模块构建高效日志系统\"><a href=\"#Python-日志处理最佳实践：使用-logging-模块构建高效日志系统\" class=\"headerlink\" title=\"Python 日志处理最佳实践：使用 logging 模块构建高效日志系统\"></a>Python 日志处理最佳实践：使用 <code>logging</code> 模块构建高效日志系统</h1><p>在现代软件开发中，日志记录是不可或缺的一部分。它不仅可以帮助我们调试和排查问题，还可以为系统的运行状态提供有价值的信息。Python 的标准库 <code>logging</code> 是一个强大且灵活的日志记录工具，但在实际项目中，如何高效地使用它却是一个值得探讨的话题。本文将结合实际项目经验，总结使用 <code>logging</code> 模块的最佳实践，并提供一个完整的代码示例。</p>\n<hr>\n<h2 id=\"1-为什么选择-logging-模块？\"><a href=\"#1-为什么选择-logging-模块？\" class=\"headerlink\" title=\"1. 为什么选择 logging 模块？\"></a>1. 为什么选择 <code>logging</code> 模块？</h2><p>相比于简单的 <code>print</code> 语句，<code>logging</code> 模块提供了以下优势：</p>\n<ul>\n<li><strong>日志级别</strong>：支持 <code>DEBUG</code>、<code>INFO</code>、<code>WARNING</code>、<code>ERROR</code> 和 <code>CRITICAL</code> 五种日志级别，便于控制日志的详细程度。</li>\n<li><strong>日志格式化</strong>：可以自定义日志的输出格式，包括时间、日志级别、模块名称等。</li>\n<li><strong>日志处理器</strong>：支持将日志输出到文件、控制台、网络等多种目标。</li>\n<li><strong>日志轮转</strong>：支持日志文件的自动轮转，避免日志文件过大。</li>\n<li><strong>日志过滤器</strong>：可以过滤敏感信息，确保日志安全。</li>\n</ul>\n<hr>\n<h2 id=\"2-最佳实践概述\"><a href=\"#2-最佳实践概述\" class=\"headerlink\" title=\"2. 最佳实践概述\"></a>2. 最佳实践概述</h2><p>在实际项目中，日志记录的最佳实践包括以下几点：</p>\n<ol>\n<li><strong>统一的日志配置</strong>：通过一个统一的日志配置函数，避免在每个模块中重复编写日志配置代码。</li>\n<li><strong>根据模块名称自动命名日志文件</strong>：每个模块的日志存储在独立的文件中，便于管理和分析。</li>\n<li><strong>日志轮转</strong>：使用 <code>RotatingFileHandler</code> 或 <code>TimedRotatingFileHandler</code> 管理日志文件的大小和数量。</li>\n<li><strong>日志级别控制</strong>：在开发环境中使用 <code>DEBUG</code> 级别，在生产环境中使用 <code>INFO</code> 或 <code>WARNING</code> 级别。</li>\n<li><strong>日志格式化</strong>：使用统一的日志格式，便于阅读和分析。</li>\n<li><strong>日志安全</strong>：避免记录敏感信息，如密码、密钥等。</li>\n</ol>\n<hr>\n<h2 id=\"3-示例项目结构\"><a href=\"#3-示例项目结构\" class=\"headerlink\" title=\"3. 示例项目结构\"></a>3. 示例项目结构</h2><figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stylus\">my_project/<br>├── <span class=\"hljs-selector-tag\">main</span><span class=\"hljs-selector-class\">.py</span><br>├── module_a<span class=\"hljs-selector-class\">.py</span><br>├── module_b<span class=\"hljs-selector-class\">.py</span><br>├── logger_config<span class=\"hljs-selector-class\">.py</span><br>└── logs/<br>    ├── module_a<span class=\"hljs-selector-class\">.log</span><br>    ├── module_b<span class=\"hljs-selector-class\">.log</span><br>    └── app.log<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"4-统一的日志配置函数\"><a href=\"#4-统一的日志配置函数\" class=\"headerlink\" title=\"4. 统一的日志配置函数\"></a>4. 统一的日志配置函数</h2><p>为了减少重复代码，我们可以在一个单独的模块中定义一个统一的日志配置函数 <code>setup_logger</code>，并在每个模块中调用它。</p>\n<h3 id=\"logger-config-py\"><a href=\"#logger-config-py\" class=\"headerlink\" title=\"logger_config.py\"></a><code>logger_config.py</code></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> logging<br><span class=\"hljs-keyword\">from</span> logging.handlers <span class=\"hljs-keyword\">import</span> RotatingFileHandler<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">setup_logger</span>(<span class=\"hljs-params\">module_name, log_dir=<span class=\"hljs-string\">&quot;logs&quot;</span></span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    根据模块名称配置日志记录器，并自动生成日志文件名。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    :param module_name: 模块名称，用于生成日志文件名</span><br><span class=\"hljs-string\">    :param log_dir: 日志文件存储目录，默认为 &quot;logs&quot;</span><br><span class=\"hljs-string\">    :return: 配置好的日志记录器</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 创建日志记录器</span><br>    logger = logging.getLogger(module_name)<br>    logger.setLevel(logging.DEBUG)  <span class=\"hljs-comment\"># 设置全局日志级别为 DEBUG</span><br><br>    <span class=\"hljs-comment\"># 配置日志格式化</span><br>    formatter = logging.Formatter(<span class=\"hljs-string\">&quot;%(asctime)s - %(name)s - %(levelname)s - %(message)s&quot;</span>)<br><br>    <span class=\"hljs-comment\"># 配置控制台处理器（输出到终端）</span><br>    console_handler = logging.StreamHandler()<br>    console_handler.setLevel(logging.INFO)  <span class=\"hljs-comment\"># 控制台日志级别为 INFO</span><br>    console_handler.setFormatter(formatter)<br>    logger.addHandler(console_handler)<br><br>    <span class=\"hljs-comment\"># 配置文件处理器（根据模块名称生成日志文件名）</span><br>    log_file = <span class=\"hljs-string\">f&quot;<span class=\"hljs-subst\">&#123;log_dir&#125;</span>/<span class=\"hljs-subst\">&#123;module_name&#125;</span>.log&quot;</span><br>    file_handler = RotatingFileHandler(<br>        log_file,  <span class=\"hljs-comment\"># 日志文件路径</span><br>        maxBytes=<span class=\"hljs-number\">1024</span> * <span class=\"hljs-number\">1024</span>,  <span class=\"hljs-comment\"># 每个日志文件的最大大小（1MB）</span><br>        backupCount=<span class=\"hljs-number\">5</span>  <span class=\"hljs-comment\"># 保留的旧日志文件数量</span><br>    )<br>    file_handler.setLevel(logging.DEBUG)  <span class=\"hljs-comment\"># 文件日志级别为 DEBUG</span><br>    file_handler.setFormatter(formatter)<br>    logger.addHandler(file_handler)<br><br>    <span class=\"hljs-keyword\">return</span> logger<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"5-主模块：main-py\"><a href=\"#5-主模块：main-py\" class=\"headerlink\" title=\"5. 主模块：main.py\"></a>5. 主模块：<code>main.py</code></h2><p>在主模块中，我们调用 <code>setup_logger</code> 函数来配置日志记录器，并记录日志。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> logger_config <span class=\"hljs-keyword\">import</span> setup_logger<br><span class=\"hljs-keyword\">import</span> module_a<br><span class=\"hljs-keyword\">import</span> module_b<br><br><span class=\"hljs-comment\"># 配置主模块的日志记录器</span><br>logger = setup_logger(<span class=\"hljs-string\">&quot;main&quot;</span>)<br><br><span class=\"hljs-comment\"># 记录日志</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():<br>    logger.info(<span class=\"hljs-string\">&quot;主模块启动&quot;</span>)<br>    module_a.run()<br>    module_b.run()<br>    logger.info(<span class=\"hljs-string\">&quot;主模块结束&quot;</span>)<br><br><span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">&quot;__main__&quot;</span>:<br>    main()<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"6-模块-A：module-a-py\"><a href=\"#6-模块-A：module-a-py\" class=\"headerlink\" title=\"6. 模块 A：module_a.py\"></a>6. 模块 A：<code>module_a.py</code></h2><p>在模块 A 中，我们同样调用 <code>setup_logger</code> 函数来配置日志记录器，并记录日志。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> logger_config <span class=\"hljs-keyword\">import</span> setup_logger<br><br><span class=\"hljs-comment\"># 配置模块 A 的日志记录器</span><br>logger = setup_logger(<span class=\"hljs-string\">&quot;module_a&quot;</span>)<br><br><span class=\"hljs-comment\"># 记录日志</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">run</span>():<br>    logger.debug(<span class=\"hljs-string\">&quot;模块 A 的调试信息&quot;</span>)<br>    logger.info(<span class=\"hljs-string\">&quot;模块 A 的普通信息&quot;</span>)<br>    logger.warning(<span class=\"hljs-string\">&quot;模块 A 的警告信息&quot;</span>)<br>    logger.error(<span class=\"hljs-string\">&quot;模块 A 的错误信息&quot;</span>)<br>    logger.critical(<span class=\"hljs-string\">&quot;模块 A 的严重错误信息&quot;</span>)<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"7-模块-B：module-b-py\"><a href=\"#7-模块-B：module-b-py\" class=\"headerlink\" title=\"7. 模块 B：module_b.py\"></a>7. 模块 B：<code>module_b.py</code></h2><p>在模块 B 中，我们同样调用 <code>setup_logger</code> 函数来配置日志记录器，并记录日志。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> logger_config <span class=\"hljs-keyword\">import</span> setup_logger<br><br><span class=\"hljs-comment\"># 配置模块 B 的日志记录器</span><br>logger = setup_logger(<span class=\"hljs-string\">&quot;module_b&quot;</span>)<br><br><span class=\"hljs-comment\"># 记录日志</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">run</span>():<br>    logger.debug(<span class=\"hljs-string\">&quot;模块 B 的调试信息&quot;</span>)<br>    logger.info(<span class=\"hljs-string\">&quot;模块 B 的普通信息&quot;</span>)<br>    logger.warning(<span class=\"hljs-string\">&quot;模块 B 的警告信息&quot;</span>)<br>    logger.error(<span class=\"hljs-string\">&quot;模块 B 的错误信息&quot;</span>)<br>    logger.critical(<span class=\"hljs-string\">&quot;模块 B 的严重错误信息&quot;</span>)<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"8-运行结果\"><a href=\"#8-运行结果\" class=\"headerlink\" title=\"8. 运行结果\"></a>8. 运行结果</h2><h3 id=\"控制台输出\"><a href=\"#控制台输出\" class=\"headerlink\" title=\"控制台输出\"></a>控制台输出</h3><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - main - INFO - 主模块启动<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - INFO - 模块 A 的普通信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - WARNING - 模块 A 的警告信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - ERROR - 模块 A 的错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - CRITICAL - 模块 A 的严重错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - INFO - 模块 B 的普通信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - WARNING - 模块 B 的警告信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - ERROR - 模块 B 的错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - CRITICAL - 模块 B 的严重错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - main - INFO - 主模块结束<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"日志文件内容\"><a href=\"#日志文件内容\" class=\"headerlink\" title=\"日志文件内容\"></a>日志文件内容</h3><h4 id=\"logs-app-log（主模块日志）：\"><a href=\"#logs-app-log（主模块日志）：\" class=\"headerlink\" title=\"logs/app.log（主模块日志）：\"></a><code>logs/app.log</code>（主模块日志）：</h4><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - main - INFO - 主模块启动<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - main - INFO - 主模块结束<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"logs-module-a-log（模块-A-日志）：\"><a href=\"#logs-module-a-log（模块-A-日志）：\" class=\"headerlink\" title=\"logs/module_a.log（模块 A 日志）：\"></a><code>logs/module_a.log</code>（模块 A 日志）：</h4><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - DEBUG - 模块 A 的调试信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - INFO - 模块 A 的普通信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - WARNING - 模块 A 的警告信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - ERROR - 模块 A 的错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - CRITICAL - 模块 A 的严重错误信息<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"logs-module-b-log（模块-B-日志）：\"><a href=\"#logs-module-b-log（模块-B-日志）：\" class=\"headerlink\" title=\"logs/module_b.log（模块 B 日志）：\"></a><code>logs/module_b.log</code>（模块 B 日志）：</h4><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - DEBUG - 模块 B 的调试信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - INFO - 模块 B 的普通信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - WARNING - 模块 B 的警告信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - ERROR - 模块 B 的错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - CRITICAL - 模块 B 的严重错误信息<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"9-总结\"><a href=\"#9-总结\" class=\"headerlink\" title=\"9. 总结\"></a>9. 总结</h2><p>通过统一的日志配置函数 <code>setup_logger</code>，我们实现了以下目标：</p>\n<ol>\n<li><strong>自动生成日志文件名</strong>：根据模块名称动态生成日志文件名，避免手动指定文件名。</li>\n<li><strong>减少重复代码</strong>：在每个模块中只需调用 <code>setup_logger</code> 函数，无需重复编写日志配置代码。</li>\n<li><strong>灵活的日志管理</strong>：每个模块的日志存储在独立的文件中，便于管理和分析。</li>\n<li><strong>日志轮转</strong>：通过 <code>RotatingFileHandler</code>，可以自动管理日志文件的大小和数量。</li>\n<li><strong>日志级别控制</strong>：在开发环境中使用 <code>DEBUG</code> 级别，在生产环境中使用 <code>INFO</code> 或 <code>WARNING</code> 级别。</li>\n<li><strong>日志格式化</strong>：使用统一的日志格式，便于阅读和分析。</li>\n<li><strong>日志安全</strong>：避免记录敏感信息，如密码、密钥等。</li>\n</ol>\n<p>这种设计模式非常适合大型项目，能够有效提高日志管理的灵活性和可维护性。</p>\n","excerpt":"","more":"<h1 id=\"Python-日志处理最佳实践：使用-logging-模块构建高效日志系统\"><a href=\"#Python-日志处理最佳实践：使用-logging-模块构建高效日志系统\" class=\"headerlink\" title=\"Python 日志处理最佳实践：使用 logging 模块构建高效日志系统\"></a>Python 日志处理最佳实践：使用 <code>logging</code> 模块构建高效日志系统</h1><p>在现代软件开发中，日志记录是不可或缺的一部分。它不仅可以帮助我们调试和排查问题，还可以为系统的运行状态提供有价值的信息。Python 的标准库 <code>logging</code> 是一个强大且灵活的日志记录工具，但在实际项目中，如何高效地使用它却是一个值得探讨的话题。本文将结合实际项目经验，总结使用 <code>logging</code> 模块的最佳实践，并提供一个完整的代码示例。</p>\n<hr>\n<h2 id=\"1-为什么选择-logging-模块？\"><a href=\"#1-为什么选择-logging-模块？\" class=\"headerlink\" title=\"1. 为什么选择 logging 模块？\"></a>1. 为什么选择 <code>logging</code> 模块？</h2><p>相比于简单的 <code>print</code> 语句，<code>logging</code> 模块提供了以下优势：</p>\n<ul>\n<li><strong>日志级别</strong>：支持 <code>DEBUG</code>、<code>INFO</code>、<code>WARNING</code>、<code>ERROR</code> 和 <code>CRITICAL</code> 五种日志级别，便于控制日志的详细程度。</li>\n<li><strong>日志格式化</strong>：可以自定义日志的输出格式，包括时间、日志级别、模块名称等。</li>\n<li><strong>日志处理器</strong>：支持将日志输出到文件、控制台、网络等多种目标。</li>\n<li><strong>日志轮转</strong>：支持日志文件的自动轮转，避免日志文件过大。</li>\n<li><strong>日志过滤器</strong>：可以过滤敏感信息，确保日志安全。</li>\n</ul>\n<hr>\n<h2 id=\"2-最佳实践概述\"><a href=\"#2-最佳实践概述\" class=\"headerlink\" title=\"2. 最佳实践概述\"></a>2. 最佳实践概述</h2><p>在实际项目中，日志记录的最佳实践包括以下几点：</p>\n<ol>\n<li><strong>统一的日志配置</strong>：通过一个统一的日志配置函数，避免在每个模块中重复编写日志配置代码。</li>\n<li><strong>根据模块名称自动命名日志文件</strong>：每个模块的日志存储在独立的文件中，便于管理和分析。</li>\n<li><strong>日志轮转</strong>：使用 <code>RotatingFileHandler</code> 或 <code>TimedRotatingFileHandler</code> 管理日志文件的大小和数量。</li>\n<li><strong>日志级别控制</strong>：在开发环境中使用 <code>DEBUG</code> 级别，在生产环境中使用 <code>INFO</code> 或 <code>WARNING</code> 级别。</li>\n<li><strong>日志格式化</strong>：使用统一的日志格式，便于阅读和分析。</li>\n<li><strong>日志安全</strong>：避免记录敏感信息，如密码、密钥等。</li>\n</ol>\n<hr>\n<h2 id=\"3-示例项目结构\"><a href=\"#3-示例项目结构\" class=\"headerlink\" title=\"3. 示例项目结构\"></a>3. 示例项目结构</h2><figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stylus\">my_project/<br>├── <span class=\"hljs-selector-tag\">main</span><span class=\"hljs-selector-class\">.py</span><br>├── module_a<span class=\"hljs-selector-class\">.py</span><br>├── module_b<span class=\"hljs-selector-class\">.py</span><br>├── logger_config<span class=\"hljs-selector-class\">.py</span><br>└── logs/<br>    ├── module_a<span class=\"hljs-selector-class\">.log</span><br>    ├── module_b<span class=\"hljs-selector-class\">.log</span><br>    └── app.log<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"4-统一的日志配置函数\"><a href=\"#4-统一的日志配置函数\" class=\"headerlink\" title=\"4. 统一的日志配置函数\"></a>4. 统一的日志配置函数</h2><p>为了减少重复代码，我们可以在一个单独的模块中定义一个统一的日志配置函数 <code>setup_logger</code>，并在每个模块中调用它。</p>\n<h3 id=\"logger-config-py\"><a href=\"#logger-config-py\" class=\"headerlink\" title=\"logger_config.py\"></a><code>logger_config.py</code></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">import</span> logging<br><span class=\"hljs-keyword\">from</span> logging.handlers <span class=\"hljs-keyword\">import</span> RotatingFileHandler<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">setup_logger</span>(<span class=\"hljs-params\">module_name, log_dir=<span class=\"hljs-string\">&quot;logs&quot;</span></span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    根据模块名称配置日志记录器，并自动生成日志文件名。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    :param module_name: 模块名称，用于生成日志文件名</span><br><span class=\"hljs-string\">    :param log_dir: 日志文件存储目录，默认为 &quot;logs&quot;</span><br><span class=\"hljs-string\">    :return: 配置好的日志记录器</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 创建日志记录器</span><br>    logger = logging.getLogger(module_name)<br>    logger.setLevel(logging.DEBUG)  <span class=\"hljs-comment\"># 设置全局日志级别为 DEBUG</span><br><br>    <span class=\"hljs-comment\"># 配置日志格式化</span><br>    formatter = logging.Formatter(<span class=\"hljs-string\">&quot;%(asctime)s - %(name)s - %(levelname)s - %(message)s&quot;</span>)<br><br>    <span class=\"hljs-comment\"># 配置控制台处理器（输出到终端）</span><br>    console_handler = logging.StreamHandler()<br>    console_handler.setLevel(logging.INFO)  <span class=\"hljs-comment\"># 控制台日志级别为 INFO</span><br>    console_handler.setFormatter(formatter)<br>    logger.addHandler(console_handler)<br><br>    <span class=\"hljs-comment\"># 配置文件处理器（根据模块名称生成日志文件名）</span><br>    log_file = <span class=\"hljs-string\">f&quot;<span class=\"hljs-subst\">&#123;log_dir&#125;</span>/<span class=\"hljs-subst\">&#123;module_name&#125;</span>.log&quot;</span><br>    file_handler = RotatingFileHandler(<br>        log_file,  <span class=\"hljs-comment\"># 日志文件路径</span><br>        maxBytes=<span class=\"hljs-number\">1024</span> * <span class=\"hljs-number\">1024</span>,  <span class=\"hljs-comment\"># 每个日志文件的最大大小（1MB）</span><br>        backupCount=<span class=\"hljs-number\">5</span>  <span class=\"hljs-comment\"># 保留的旧日志文件数量</span><br>    )<br>    file_handler.setLevel(logging.DEBUG)  <span class=\"hljs-comment\"># 文件日志级别为 DEBUG</span><br>    file_handler.setFormatter(formatter)<br>    logger.addHandler(file_handler)<br><br>    <span class=\"hljs-keyword\">return</span> logger<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"5-主模块：main-py\"><a href=\"#5-主模块：main-py\" class=\"headerlink\" title=\"5. 主模块：main.py\"></a>5. 主模块：<code>main.py</code></h2><p>在主模块中，我们调用 <code>setup_logger</code> 函数来配置日志记录器，并记录日志。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> logger_config <span class=\"hljs-keyword\">import</span> setup_logger<br><span class=\"hljs-keyword\">import</span> module_a<br><span class=\"hljs-keyword\">import</span> module_b<br><br><span class=\"hljs-comment\"># 配置主模块的日志记录器</span><br>logger = setup_logger(<span class=\"hljs-string\">&quot;main&quot;</span>)<br><br><span class=\"hljs-comment\"># 记录日志</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():<br>    logger.info(<span class=\"hljs-string\">&quot;主模块启动&quot;</span>)<br>    module_a.run()<br>    module_b.run()<br>    logger.info(<span class=\"hljs-string\">&quot;主模块结束&quot;</span>)<br><br><span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">&quot;__main__&quot;</span>:<br>    main()<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"6-模块-A：module-a-py\"><a href=\"#6-模块-A：module-a-py\" class=\"headerlink\" title=\"6. 模块 A：module_a.py\"></a>6. 模块 A：<code>module_a.py</code></h2><p>在模块 A 中，我们同样调用 <code>setup_logger</code> 函数来配置日志记录器，并记录日志。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> logger_config <span class=\"hljs-keyword\">import</span> setup_logger<br><br><span class=\"hljs-comment\"># 配置模块 A 的日志记录器</span><br>logger = setup_logger(<span class=\"hljs-string\">&quot;module_a&quot;</span>)<br><br><span class=\"hljs-comment\"># 记录日志</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">run</span>():<br>    logger.debug(<span class=\"hljs-string\">&quot;模块 A 的调试信息&quot;</span>)<br>    logger.info(<span class=\"hljs-string\">&quot;模块 A 的普通信息&quot;</span>)<br>    logger.warning(<span class=\"hljs-string\">&quot;模块 A 的警告信息&quot;</span>)<br>    logger.error(<span class=\"hljs-string\">&quot;模块 A 的错误信息&quot;</span>)<br>    logger.critical(<span class=\"hljs-string\">&quot;模块 A 的严重错误信息&quot;</span>)<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"7-模块-B：module-b-py\"><a href=\"#7-模块-B：module-b-py\" class=\"headerlink\" title=\"7. 模块 B：module_b.py\"></a>7. 模块 B：<code>module_b.py</code></h2><p>在模块 B 中，我们同样调用 <code>setup_logger</code> 函数来配置日志记录器，并记录日志。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> logger_config <span class=\"hljs-keyword\">import</span> setup_logger<br><br><span class=\"hljs-comment\"># 配置模块 B 的日志记录器</span><br>logger = setup_logger(<span class=\"hljs-string\">&quot;module_b&quot;</span>)<br><br><span class=\"hljs-comment\"># 记录日志</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">run</span>():<br>    logger.debug(<span class=\"hljs-string\">&quot;模块 B 的调试信息&quot;</span>)<br>    logger.info(<span class=\"hljs-string\">&quot;模块 B 的普通信息&quot;</span>)<br>    logger.warning(<span class=\"hljs-string\">&quot;模块 B 的警告信息&quot;</span>)<br>    logger.error(<span class=\"hljs-string\">&quot;模块 B 的错误信息&quot;</span>)<br>    logger.critical(<span class=\"hljs-string\">&quot;模块 B 的严重错误信息&quot;</span>)<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"8-运行结果\"><a href=\"#8-运行结果\" class=\"headerlink\" title=\"8. 运行结果\"></a>8. 运行结果</h2><h3 id=\"控制台输出\"><a href=\"#控制台输出\" class=\"headerlink\" title=\"控制台输出\"></a>控制台输出</h3><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - main - INFO - 主模块启动<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - INFO - 模块 A 的普通信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - WARNING - 模块 A 的警告信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - ERROR - 模块 A 的错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - CRITICAL - 模块 A 的严重错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - INFO - 模块 B 的普通信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - WARNING - 模块 B 的警告信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - ERROR - 模块 B 的错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - CRITICAL - 模块 B 的严重错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - main - INFO - 主模块结束<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"日志文件内容\"><a href=\"#日志文件内容\" class=\"headerlink\" title=\"日志文件内容\"></a>日志文件内容</h3><h4 id=\"logs-app-log（主模块日志）：\"><a href=\"#logs-app-log（主模块日志）：\" class=\"headerlink\" title=\"logs/app.log（主模块日志）：\"></a><code>logs/app.log</code>（主模块日志）：</h4><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - main - INFO - 主模块启动<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - main - INFO - 主模块结束<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"logs-module-a-log（模块-A-日志）：\"><a href=\"#logs-module-a-log（模块-A-日志）：\" class=\"headerlink\" title=\"logs/module_a.log（模块 A 日志）：\"></a><code>logs/module_a.log</code>（模块 A 日志）：</h4><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - DEBUG - 模块 A 的调试信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - INFO - 模块 A 的普通信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - WARNING - 模块 A 的警告信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - ERROR - 模块 A 的错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_a - CRITICAL - 模块 A 的严重错误信息<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"logs-module-b-log（模块-B-日志）：\"><a href=\"#logs-module-b-log（模块-B-日志）：\" class=\"headerlink\" title=\"logs/module_b.log（模块 B 日志）：\"></a><code>logs/module_b.log</code>（模块 B 日志）：</h4><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - DEBUG - 模块 B 的调试信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - INFO - 模块 B 的普通信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - WARNING - 模块 B 的警告信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - ERROR - 模块 B 的错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> - module_b - CRITICAL - 模块 B 的严重错误信息<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"9-总结\"><a href=\"#9-总结\" class=\"headerlink\" title=\"9. 总结\"></a>9. 总结</h2><p>通过统一的日志配置函数 <code>setup_logger</code>，我们实现了以下目标：</p>\n<ol>\n<li><strong>自动生成日志文件名</strong>：根据模块名称动态生成日志文件名，避免手动指定文件名。</li>\n<li><strong>减少重复代码</strong>：在每个模块中只需调用 <code>setup_logger</code> 函数，无需重复编写日志配置代码。</li>\n<li><strong>灵活的日志管理</strong>：每个模块的日志存储在独立的文件中，便于管理和分析。</li>\n<li><strong>日志轮转</strong>：通过 <code>RotatingFileHandler</code>，可以自动管理日志文件的大小和数量。</li>\n<li><strong>日志级别控制</strong>：在开发环境中使用 <code>DEBUG</code> 级别，在生产环境中使用 <code>INFO</code> 或 <code>WARNING</code> 级别。</li>\n<li><strong>日志格式化</strong>：使用统一的日志格式，便于阅读和分析。</li>\n<li><strong>日志安全</strong>：避免记录敏感信息，如密码、密钥等。</li>\n</ol>\n<p>这种设计模式非常适合大型项目，能够有效提高日志管理的灵活性和可维护性。</p>\n"},{"title":"transformers自定义数据集","date":"2024-12-07T10:30:00.000Z","_content":"\n\n\nhuggingface的transformers和dataset等库都默认把模型或者数据集下载保存到~/.cache目录下，但是模型或者数据集通常都比较大，占用home目录空间，这里就讲下如何设置数据集或者模型的下载保存的目录。\n\n以datasets库数据集下载为例。datasets数据集下载的相关配置在datasets.config.py模块中，如下图：\n\n![image-20231031165446512](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20231031165446512.png)\n\n变量DEFAULT_XDG_CACHE_HOME=\"~/.cache\",如果没有设置环境变量\"XDG_CACHE_HOME\"，则数据集默认保存在\"~/.cache\"目录下，因此，可以通过设置环境变量的方式修改数据集下载目录，如下：\n\n```python\n\"\"\"\nDescripttion: chengbo's code\nversion: 1.0.0\nAuthor: chengbo\nDate: 2023-10-30 12:06:23\nLastEditors: chengbo\nLastEditTime: 2023-10-30 12:06:30\n\"\"\"\nimport os\n\n#修改环境变量要在导入datasets或者transformers模块之前\nos.environ[\"XDG_CACHE_HOME\"] = \"/data/.cache\"  \n# os.environ[\"HF_CACHE_HOME\"] = \"/data/huggingface\"\n# os.environ[\"HF_DATASETS_CACHE\"] = \"/data/huggingface/datasets\"\nfrom datasets import load_dataset, DownloadConfig\nimport datasets\n\n\ndataset = load_dataset(\n    \"Graphcore/vqa\",\n    download_config=DownloadConfig(resume_download=True),\n    split=\"validation[:200]\",\n)\nprint(dataset[0])\nprint(os.getenv(\"XDG_CACHE_HOME\"))\nprint(os.getenv(\"HF_HOME\"))\nprint(datasets.config.HF_CACHE_HOME)\nprint(datasets.config.HF_DATASETS_CACHE)\nprint(datasets.config.EXTRACTED_DATASETS_PATH)\n\n```\n\n通过os.environ[\"XDG_CACHE_HOME\"] = \"/data/.cache\" 代码，后续的模型和数据集都会下载到该目录下。\n\n\n\n另外一种修改模型或者数据集下载目录的方式是通过参数配置。\n\n```python\nload_dataset(\"Graphcore/vqa\",cache_dir=\"/data/.cache\")\n```\n\n但是这种方式有个缺点，有些数据集下载的是个压缩文件，如.zip,下载后会进行自动解压，解压的默认目录还是在\"~/.cache\"目录下。从上面的图片中可以看到有个EXTRACTED_DATASETS_PATH 参数，这个参数就是设置解压的目录，可以通过修改该参数来配置解压后保存的目录。\n\n其它参数也可以参考上图config.py模块中的代码进行设置。\n\n\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n\n\n","source":"_posts/人工智能/nlp/NLP025-huggingface自定义数据集和模型下载存储目录.md","raw":"---\ntitle: 'transformers自定义数据集'\ndate: 2024-12-7 18:30:00\ncategories:\n  - [人工智能,nlp]\ntags:\n  - 人工智能\n  - huggingface\n  - transformers\n\n---\n\n\n\nhuggingface的transformers和dataset等库都默认把模型或者数据集下载保存到~/.cache目录下，但是模型或者数据集通常都比较大，占用home目录空间，这里就讲下如何设置数据集或者模型的下载保存的目录。\n\n以datasets库数据集下载为例。datasets数据集下载的相关配置在datasets.config.py模块中，如下图：\n\n![image-20231031165446512](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20231031165446512.png)\n\n变量DEFAULT_XDG_CACHE_HOME=\"~/.cache\",如果没有设置环境变量\"XDG_CACHE_HOME\"，则数据集默认保存在\"~/.cache\"目录下，因此，可以通过设置环境变量的方式修改数据集下载目录，如下：\n\n```python\n\"\"\"\nDescripttion: chengbo's code\nversion: 1.0.0\nAuthor: chengbo\nDate: 2023-10-30 12:06:23\nLastEditors: chengbo\nLastEditTime: 2023-10-30 12:06:30\n\"\"\"\nimport os\n\n#修改环境变量要在导入datasets或者transformers模块之前\nos.environ[\"XDG_CACHE_HOME\"] = \"/data/.cache\"  \n# os.environ[\"HF_CACHE_HOME\"] = \"/data/huggingface\"\n# os.environ[\"HF_DATASETS_CACHE\"] = \"/data/huggingface/datasets\"\nfrom datasets import load_dataset, DownloadConfig\nimport datasets\n\n\ndataset = load_dataset(\n    \"Graphcore/vqa\",\n    download_config=DownloadConfig(resume_download=True),\n    split=\"validation[:200]\",\n)\nprint(dataset[0])\nprint(os.getenv(\"XDG_CACHE_HOME\"))\nprint(os.getenv(\"HF_HOME\"))\nprint(datasets.config.HF_CACHE_HOME)\nprint(datasets.config.HF_DATASETS_CACHE)\nprint(datasets.config.EXTRACTED_DATASETS_PATH)\n\n```\n\n通过os.environ[\"XDG_CACHE_HOME\"] = \"/data/.cache\" 代码，后续的模型和数据集都会下载到该目录下。\n\n\n\n另外一种修改模型或者数据集下载目录的方式是通过参数配置。\n\n```python\nload_dataset(\"Graphcore/vqa\",cache_dir=\"/data/.cache\")\n```\n\n但是这种方式有个缺点，有些数据集下载的是个压缩文件，如.zip,下载后会进行自动解压，解压的默认目录还是在\"~/.cache\"目录下。从上面的图片中可以看到有个EXTRACTED_DATASETS_PATH 参数，这个参数就是设置解压的目录，可以通过修改该参数来配置解压后保存的目录。\n\n其它参数也可以参考上图config.py模块中的代码进行设置。\n\n\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n\n\n","slug":"人工智能/nlp/NLP025-huggingface自定义数据集和模型下载存储目录","published":1,"updated":"2024-12-26T04:24:42.760Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3g000ehghiac6sa115","content":"<p>huggingface的transformers和dataset等库都默认把模型或者数据集下载保存到~&#x2F;.cache目录下，但是模型或者数据集通常都比较大，占用home目录空间，这里就讲下如何设置数据集或者模型的下载保存的目录。</p>\n<p>以datasets库数据集下载为例。datasets数据集下载的相关配置在datasets.config.py模块中，如下图：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20231031165446512.png\" alt=\"image-20231031165446512\"></p>\n<p>变量DEFAULT_XDG_CACHE_HOME&#x3D;”<del>&#x2F;.cache”,如果没有设置环境变量”XDG_CACHE_HOME”，则数据集默认保存在”</del>&#x2F;.cache”目录下，因此，可以通过设置环境变量的方式修改数据集下载目录，如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">Descripttion: chengbo&#x27;s code</span><br><span class=\"hljs-string\">version: 1.0.0</span><br><span class=\"hljs-string\">Author: chengbo</span><br><span class=\"hljs-string\">Date: 2023-10-30 12:06:23</span><br><span class=\"hljs-string\">LastEditors: chengbo</span><br><span class=\"hljs-string\">LastEditTime: 2023-10-30 12:06:30</span><br><span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-keyword\">import</span> os<br><br><span class=\"hljs-comment\">#修改环境变量要在导入datasets或者transformers模块之前</span><br>os.environ[<span class=\"hljs-string\">&quot;XDG_CACHE_HOME&quot;</span>] = <span class=\"hljs-string\">&quot;/data/.cache&quot;</span>  <br><span class=\"hljs-comment\"># os.environ[&quot;HF_CACHE_HOME&quot;] = &quot;/data/huggingface&quot;</span><br><span class=\"hljs-comment\"># os.environ[&quot;HF_DATASETS_CACHE&quot;] = &quot;/data/huggingface/datasets&quot;</span><br><span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset, DownloadConfig<br><span class=\"hljs-keyword\">import</span> datasets<br><br><br>dataset = load_dataset(<br>    <span class=\"hljs-string\">&quot;Graphcore/vqa&quot;</span>,<br>    download_config=DownloadConfig(resume_download=<span class=\"hljs-literal\">True</span>),<br>    split=<span class=\"hljs-string\">&quot;validation[:200]&quot;</span>,<br>)<br><span class=\"hljs-built_in\">print</span>(dataset[<span class=\"hljs-number\">0</span>])<br><span class=\"hljs-built_in\">print</span>(os.getenv(<span class=\"hljs-string\">&quot;XDG_CACHE_HOME&quot;</span>))<br><span class=\"hljs-built_in\">print</span>(os.getenv(<span class=\"hljs-string\">&quot;HF_HOME&quot;</span>))<br><span class=\"hljs-built_in\">print</span>(datasets.config.HF_CACHE_HOME)<br><span class=\"hljs-built_in\">print</span>(datasets.config.HF_DATASETS_CACHE)<br><span class=\"hljs-built_in\">print</span>(datasets.config.EXTRACTED_DATASETS_PATH)<br><br></code></pre></td></tr></table></figure>\n\n<p>通过os.environ[“XDG_CACHE_HOME”] &#x3D; “&#x2F;data&#x2F;.cache” 代码，后续的模型和数据集都会下载到该目录下。</p>\n<p>另外一种修改模型或者数据集下载目录的方式是通过参数配置。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">load_dataset(<span class=\"hljs-string\">&quot;Graphcore/vqa&quot;</span>,cache_dir=<span class=\"hljs-string\">&quot;/data/.cache&quot;</span>)<br></code></pre></td></tr></table></figure>\n\n<p>但是这种方式有个缺点，有些数据集下载的是个压缩文件，如.zip,下载后会进行自动解压，解压的默认目录还是在”~&#x2F;.cache”目录下。从上面的图片中可以看到有个EXTRACTED_DATASETS_PATH 参数，这个参数就是设置解压的目录，可以通过修改该参数来配置解压后保存的目录。</p>\n<p>其它参数也可以参考上图config.py模块中的代码进行设置。</p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n","excerpt":"","more":"<p>huggingface的transformers和dataset等库都默认把模型或者数据集下载保存到~&#x2F;.cache目录下，但是模型或者数据集通常都比较大，占用home目录空间，这里就讲下如何设置数据集或者模型的下载保存的目录。</p>\n<p>以datasets库数据集下载为例。datasets数据集下载的相关配置在datasets.config.py模块中，如下图：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20231031165446512.png\" alt=\"image-20231031165446512\"></p>\n<p>变量DEFAULT_XDG_CACHE_HOME&#x3D;”<del>&#x2F;.cache”,如果没有设置环境变量”XDG_CACHE_HOME”，则数据集默认保存在”</del>&#x2F;.cache”目录下，因此，可以通过设置环境变量的方式修改数据集下载目录，如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">Descripttion: chengbo&#x27;s code</span><br><span class=\"hljs-string\">version: 1.0.0</span><br><span class=\"hljs-string\">Author: chengbo</span><br><span class=\"hljs-string\">Date: 2023-10-30 12:06:23</span><br><span class=\"hljs-string\">LastEditors: chengbo</span><br><span class=\"hljs-string\">LastEditTime: 2023-10-30 12:06:30</span><br><span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-keyword\">import</span> os<br><br><span class=\"hljs-comment\">#修改环境变量要在导入datasets或者transformers模块之前</span><br>os.environ[<span class=\"hljs-string\">&quot;XDG_CACHE_HOME&quot;</span>] = <span class=\"hljs-string\">&quot;/data/.cache&quot;</span>  <br><span class=\"hljs-comment\"># os.environ[&quot;HF_CACHE_HOME&quot;] = &quot;/data/huggingface&quot;</span><br><span class=\"hljs-comment\"># os.environ[&quot;HF_DATASETS_CACHE&quot;] = &quot;/data/huggingface/datasets&quot;</span><br><span class=\"hljs-keyword\">from</span> datasets <span class=\"hljs-keyword\">import</span> load_dataset, DownloadConfig<br><span class=\"hljs-keyword\">import</span> datasets<br><br><br>dataset = load_dataset(<br>    <span class=\"hljs-string\">&quot;Graphcore/vqa&quot;</span>,<br>    download_config=DownloadConfig(resume_download=<span class=\"hljs-literal\">True</span>),<br>    split=<span class=\"hljs-string\">&quot;validation[:200]&quot;</span>,<br>)<br><span class=\"hljs-built_in\">print</span>(dataset[<span class=\"hljs-number\">0</span>])<br><span class=\"hljs-built_in\">print</span>(os.getenv(<span class=\"hljs-string\">&quot;XDG_CACHE_HOME&quot;</span>))<br><span class=\"hljs-built_in\">print</span>(os.getenv(<span class=\"hljs-string\">&quot;HF_HOME&quot;</span>))<br><span class=\"hljs-built_in\">print</span>(datasets.config.HF_CACHE_HOME)<br><span class=\"hljs-built_in\">print</span>(datasets.config.HF_DATASETS_CACHE)<br><span class=\"hljs-built_in\">print</span>(datasets.config.EXTRACTED_DATASETS_PATH)<br><br></code></pre></td></tr></table></figure>\n\n<p>通过os.environ[“XDG_CACHE_HOME”] &#x3D; “&#x2F;data&#x2F;.cache” 代码，后续的模型和数据集都会下载到该目录下。</p>\n<p>另外一种修改模型或者数据集下载目录的方式是通过参数配置。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">load_dataset(<span class=\"hljs-string\">&quot;Graphcore/vqa&quot;</span>,cache_dir=<span class=\"hljs-string\">&quot;/data/.cache&quot;</span>)<br></code></pre></td></tr></table></figure>\n\n<p>但是这种方式有个缺点，有些数据集下载的是个压缩文件，如.zip,下载后会进行自动解压，解压的默认目录还是在”~&#x2F;.cache”目录下。从上面的图片中可以看到有个EXTRACTED_DATASETS_PATH 参数，这个参数就是设置解压的目录，可以通过修改该参数来配置解压后保存的目录。</p>\n<p>其它参数也可以参考上图config.py模块中的代码进行设置。</p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n"},{"title":"Python 日志处理最佳实践：使用loguru模块构建高效日志系统","date":"2024-12-21T04:00:00.000Z","_content":"\n# Python 日志处理最佳实践：使用 `loguru` 构建高效日志系统\n\n在现代软件开发中，日志记录是不可或缺的一部分。Python 的标准库 `logging` 是一个强大且灵活的日志记录工具，但在实际项目中，配置和管理日志可能会变得复杂。为了简化日志记录的过程，`loguru` 库应运而生。`loguru` 是一个功能强大且易于使用的日志库，它提供了更简洁的 API 和更丰富的功能。本文将结合实际项目经验，总结使用 `loguru` 模块的最佳实践，并提供一个完整的代码示例。\n\n---\n\n## 1. 为什么选择 `loguru`？\n\n相比于 `logging` 模块，`loguru` 提供了以下优势：\n\n- **简洁的 API**：无需复杂的配置，只需几行代码即可完成日志记录。\n- **自动日志轮转**：支持日志文件的自动轮转，避免日志文件过大。\n- **丰富的日志格式**：支持多种日志格式，包括颜色高亮、时间戳等。\n- **异常捕获**：自动捕获未处理的异常，并记录完整的堆栈信息。\n- **日志过滤**：支持基于日志级别和模块的过滤。\n- **高性能**：内部优化了性能，适合高并发场景。\n\n---\n\n## 2. 最佳实践概述\n\n在实际项目中，使用 `loguru` 的最佳实践包括以下几点：\n\n1. **统一的日志配置**：通过一个统一的日志配置函数，避免在每个模块中重复编写日志配置代码。\n2. **根据模块名称自动命名日志文件**：每个模块的日志存储在独立的文件中，便于管理和分析。\n3. **日志轮转**：使用 `loguru` 的日志轮转功能，自动管理日志文件的大小和数量。\n4. **日志级别控制**：在开发环境中使用 `DEBUG` 级别，在生产环境中使用 `INFO` 或 `WARNING` 级别。\n5. **日志格式化**：使用统一的日志格式，便于阅读和分析。\n6. **日志安全**：避免记录敏感信息，如密码、密钥等。\n\n---\n\n## 3. 示例项目结构\n\n```\nmy_project/\n├── main.py\n├── module_a.py\n├── module_b.py\n├── logger_config.py\n└── logs/\n    ├── module_a.log\n    ├── module_b.log\n    └── app.log\n```\n\n---\n\n## 4. 安装 `loguru`\n\n首先，确保你已经安装了 `loguru` 库。如果没有安装，可以使用以下命令进行安装：\n\n```bash\npip install loguru\n```\n\n---\n\n## 5. 统一的日志配置函数\n\n为了减少重复代码，我们可以在一个单独的模块中定义一个统一的日志配置函数 `setup_logger`，并在每个模块中调用它。\n\n### `logger_config.py`\n\n```python\nfrom loguru import logger\nimport sys\n\ndef setup_logger(module_name, log_dir=\"logs\"):\n    \"\"\"\n    根据模块名称配置日志记录器，并自动生成日志文件名。\n\n    :param module_name: 模块名称，用于生成日志文件名\n    :param log_dir: 日志文件存储目录，默认为 \"logs\"\n    \"\"\"\n    # 配置日志格式\n    log_format = (\n        \"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | \"\n        \"<level>{level: <8}</level> | \"\n        \"<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>\"\n    )\n\n    # 配置控制台日志\n    logger.remove()  # 移除默认的日志处理器\n    logger.add(sys.stdout, format=log_format, level=\"INFO\")\n\n    # 配置文件日志（根据模块名称生成日志文件名）\n    log_file = f\"{log_dir}/{module_name}.log\"\n    logger.add(\n        log_file,  # 日志文件路径\n        format=log_format,\n        level=\"DEBUG\",\n        rotation=\"10 MB\",  # 日志文件轮转大小\n        retention=\"7 days\",  # 保留日志文件的时间\n        compression=\"zip\",  # 日志文件压缩格式\n    )\n\n    return logger\n```\n\n---\n\n## 6. 主模块：`main.py`\n\n在主模块中，我们调用 `setup_logger` 函数来配置日志记录器，并记录日志。\n\n```python\nfrom logger_config import setup_logger\nimport module_a\nimport module_b\n\n# 配置主模块的日志记录器\nlogger = setup_logger(\"main\")\n\n# 记录日志\ndef main():\n    logger.info(\"主模块启动\")\n    module_a.run()\n    module_b.run()\n    logger.info(\"主模块结束\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\n---\n\n## 7. 模块 A：`module_a.py`\n\n在模块 A 中，我们同样调用 `setup_logger` 函数来配置日志记录器，并记录日志。\n\n```python\nfrom logger_config import setup_logger\n\n# 配置模块 A 的日志记录器\nlogger = setup_logger(\"module_a\")\n\n# 记录日志\ndef run():\n    logger.debug(\"模块 A 的调试信息\")\n    logger.info(\"模块 A 的普通信息\")\n    logger.warning(\"模块 A 的警告信息\")\n    logger.error(\"模块 A 的错误信息\")\n    logger.critical(\"模块 A 的严重错误信息\")\n```\n\n---\n\n## 8. 模块 B：`module_b.py`\n\n在模块 B 中，我们同样调用 `setup_logger` 函数来配置日志记录器，并记录日志。\n\n```python\nfrom logger_config import setup_logger\n\n# 配置模块 B 的日志记录器\nlogger = setup_logger(\"module_b\")\n\n# 记录日志\ndef run():\n    logger.debug(\"模块 B 的调试信息\")\n    logger.info(\"模块 B 的普通信息\")\n    logger.warning(\"模块 B 的警告信息\")\n    logger.error(\"模块 B 的错误信息\")\n    logger.critical(\"模块 B 的严重错误信息\")\n```\n\n---\n\n## 9. 运行结果\n\n### 控制台输出\n\n```\n2023-10-01 12:00:00 | INFO     | main:main:10 - 主模块启动\n2023-10-01 12:00:00 | INFO     | module_a:run:6 - 模块 A 的普通信息\n2023-10-01 12:00:00 | WARNING  | module_a:run:8 - 模块 A 的警告信息\n2023-10-01 12:00:00 | ERROR    | module_a:run:10 - 模块 A 的错误信息\n2023-10-01 12:00:00 | CRITICAL | module_a:run:12 - 模块 A 的严重错误信息\n2023-10-01 12:00:00 | INFO     | module_b:run:6 - 模块 B 的普通信息\n2023-10-01 12:00:00 | WARNING  | module_b:run:8 - 模块 B 的警告信息\n2023-10-01 12:00:00 | ERROR    | module_b:run:10 - 模块 B 的错误信息\n2023-10-01 12:00:00 | CRITICAL | module_b:run:12 - 模块 B 的严重错误信息\n2023-10-01 12:00:00 | INFO     | main:main:14 - 主模块结束\n```\n\n### 日志文件内容\n\n#### `logs/app.log`（主模块日志）：\n```\n2023-10-01 12:00:00 | INFO     | main:main:10 - 主模块启动\n2023-10-01 12:00:00 | INFO     | main:main:14 - 主模块结束\n```\n\n#### `logs/module_a.log`（模块 A 日志）：\n```\n2023-10-01 12:00:00 | DEBUG    | module_a:run:4 - 模块 A 的调试信息\n2023-10-01 12:00:00 | INFO     | module_a:run:6 - 模块 A 的普通信息\n2023-10-01 12:00:00 | WARNING  | module_a:run:8 - 模块 A 的警告信息\n2023-10-01 12:00:00 | ERROR    | module_a:run:10 - 模块 A 的错误信息\n2023-10-01 12:00:00 | CRITICAL | module_a:run:12 - 模块 A 的严重错误信息\n```\n\n#### `logs/module_b.log`（模块 B 日志）：\n```\n2023-10-01 12:00:00 | DEBUG    | module_b:run:4 - 模块 B 的调试信息\n2023-10-01 12:00:00 | INFO     | module_b:run:6 - 模块 B 的普通信息\n2023-10-01 12:00:00 | WARNING  | module_b:run:8 - 模块 B 的警告信息\n2023-10-01 12:00:00 | ERROR    | module_b:run:10 - 模块 B 的错误信息\n2023-10-01 12:00:00 | CRITICAL | module_b:run:12 - 模块 B 的严重错误信息\n```\n\n---\n\n## 10. 总结\n\n通过统一的日志配置函数 `setup_logger`，我们实现了以下目标：\n\n1. **自动生成日志文件名**：根据模块名称动态生成日志文件名，避免手动指定文件名。\n2. **减少重复代码**：在每个模块中只需调用 `setup_logger` 函数，无需重复编写日志配置代码。\n3. **灵活的日志管理**：每个模块的日志存储在独立的文件中，便于管理和分析。\n4. **日志轮转**：通过 `loguru` 的日志轮转功能，自动管理日志文件的大小和数量。\n5. **日志级别控制**：在开发环境中使用 `DEBUG` 级别，在生产环境中使用 `INFO` 或 `WARNING` 级别。\n6. **日志格式化**：使用统一的日志格式，便于阅读和分析。\n7. **日志安全**：避免记录敏感信息，如密码、密钥等。\n\n`loguru` 的简洁性和强大功能使其成为 Python 日志记录的首选工具。希望本文对你在实际项目中使用 `loguru` 有所帮助！如果你有任何问题或需要进一步的帮助，请随时留言。","source":"_posts/开发/Python/Python-004：Python 日志处理最佳实践：使用loguru模块构建高效日志系统.md","raw":"---\ntitle: 'Python 日志处理最佳实践：使用loguru模块构建高效日志系统'\ncategories:\n  - [开发,python]\ntags:\n  - python\n\ndate: 2024-12-21 12:00:00\n---\n\n# Python 日志处理最佳实践：使用 `loguru` 构建高效日志系统\n\n在现代软件开发中，日志记录是不可或缺的一部分。Python 的标准库 `logging` 是一个强大且灵活的日志记录工具，但在实际项目中，配置和管理日志可能会变得复杂。为了简化日志记录的过程，`loguru` 库应运而生。`loguru` 是一个功能强大且易于使用的日志库，它提供了更简洁的 API 和更丰富的功能。本文将结合实际项目经验，总结使用 `loguru` 模块的最佳实践，并提供一个完整的代码示例。\n\n---\n\n## 1. 为什么选择 `loguru`？\n\n相比于 `logging` 模块，`loguru` 提供了以下优势：\n\n- **简洁的 API**：无需复杂的配置，只需几行代码即可完成日志记录。\n- **自动日志轮转**：支持日志文件的自动轮转，避免日志文件过大。\n- **丰富的日志格式**：支持多种日志格式，包括颜色高亮、时间戳等。\n- **异常捕获**：自动捕获未处理的异常，并记录完整的堆栈信息。\n- **日志过滤**：支持基于日志级别和模块的过滤。\n- **高性能**：内部优化了性能，适合高并发场景。\n\n---\n\n## 2. 最佳实践概述\n\n在实际项目中，使用 `loguru` 的最佳实践包括以下几点：\n\n1. **统一的日志配置**：通过一个统一的日志配置函数，避免在每个模块中重复编写日志配置代码。\n2. **根据模块名称自动命名日志文件**：每个模块的日志存储在独立的文件中，便于管理和分析。\n3. **日志轮转**：使用 `loguru` 的日志轮转功能，自动管理日志文件的大小和数量。\n4. **日志级别控制**：在开发环境中使用 `DEBUG` 级别，在生产环境中使用 `INFO` 或 `WARNING` 级别。\n5. **日志格式化**：使用统一的日志格式，便于阅读和分析。\n6. **日志安全**：避免记录敏感信息，如密码、密钥等。\n\n---\n\n## 3. 示例项目结构\n\n```\nmy_project/\n├── main.py\n├── module_a.py\n├── module_b.py\n├── logger_config.py\n└── logs/\n    ├── module_a.log\n    ├── module_b.log\n    └── app.log\n```\n\n---\n\n## 4. 安装 `loguru`\n\n首先，确保你已经安装了 `loguru` 库。如果没有安装，可以使用以下命令进行安装：\n\n```bash\npip install loguru\n```\n\n---\n\n## 5. 统一的日志配置函数\n\n为了减少重复代码，我们可以在一个单独的模块中定义一个统一的日志配置函数 `setup_logger`，并在每个模块中调用它。\n\n### `logger_config.py`\n\n```python\nfrom loguru import logger\nimport sys\n\ndef setup_logger(module_name, log_dir=\"logs\"):\n    \"\"\"\n    根据模块名称配置日志记录器，并自动生成日志文件名。\n\n    :param module_name: 模块名称，用于生成日志文件名\n    :param log_dir: 日志文件存储目录，默认为 \"logs\"\n    \"\"\"\n    # 配置日志格式\n    log_format = (\n        \"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | \"\n        \"<level>{level: <8}</level> | \"\n        \"<cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>\"\n    )\n\n    # 配置控制台日志\n    logger.remove()  # 移除默认的日志处理器\n    logger.add(sys.stdout, format=log_format, level=\"INFO\")\n\n    # 配置文件日志（根据模块名称生成日志文件名）\n    log_file = f\"{log_dir}/{module_name}.log\"\n    logger.add(\n        log_file,  # 日志文件路径\n        format=log_format,\n        level=\"DEBUG\",\n        rotation=\"10 MB\",  # 日志文件轮转大小\n        retention=\"7 days\",  # 保留日志文件的时间\n        compression=\"zip\",  # 日志文件压缩格式\n    )\n\n    return logger\n```\n\n---\n\n## 6. 主模块：`main.py`\n\n在主模块中，我们调用 `setup_logger` 函数来配置日志记录器，并记录日志。\n\n```python\nfrom logger_config import setup_logger\nimport module_a\nimport module_b\n\n# 配置主模块的日志记录器\nlogger = setup_logger(\"main\")\n\n# 记录日志\ndef main():\n    logger.info(\"主模块启动\")\n    module_a.run()\n    module_b.run()\n    logger.info(\"主模块结束\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\n---\n\n## 7. 模块 A：`module_a.py`\n\n在模块 A 中，我们同样调用 `setup_logger` 函数来配置日志记录器，并记录日志。\n\n```python\nfrom logger_config import setup_logger\n\n# 配置模块 A 的日志记录器\nlogger = setup_logger(\"module_a\")\n\n# 记录日志\ndef run():\n    logger.debug(\"模块 A 的调试信息\")\n    logger.info(\"模块 A 的普通信息\")\n    logger.warning(\"模块 A 的警告信息\")\n    logger.error(\"模块 A 的错误信息\")\n    logger.critical(\"模块 A 的严重错误信息\")\n```\n\n---\n\n## 8. 模块 B：`module_b.py`\n\n在模块 B 中，我们同样调用 `setup_logger` 函数来配置日志记录器，并记录日志。\n\n```python\nfrom logger_config import setup_logger\n\n# 配置模块 B 的日志记录器\nlogger = setup_logger(\"module_b\")\n\n# 记录日志\ndef run():\n    logger.debug(\"模块 B 的调试信息\")\n    logger.info(\"模块 B 的普通信息\")\n    logger.warning(\"模块 B 的警告信息\")\n    logger.error(\"模块 B 的错误信息\")\n    logger.critical(\"模块 B 的严重错误信息\")\n```\n\n---\n\n## 9. 运行结果\n\n### 控制台输出\n\n```\n2023-10-01 12:00:00 | INFO     | main:main:10 - 主模块启动\n2023-10-01 12:00:00 | INFO     | module_a:run:6 - 模块 A 的普通信息\n2023-10-01 12:00:00 | WARNING  | module_a:run:8 - 模块 A 的警告信息\n2023-10-01 12:00:00 | ERROR    | module_a:run:10 - 模块 A 的错误信息\n2023-10-01 12:00:00 | CRITICAL | module_a:run:12 - 模块 A 的严重错误信息\n2023-10-01 12:00:00 | INFO     | module_b:run:6 - 模块 B 的普通信息\n2023-10-01 12:00:00 | WARNING  | module_b:run:8 - 模块 B 的警告信息\n2023-10-01 12:00:00 | ERROR    | module_b:run:10 - 模块 B 的错误信息\n2023-10-01 12:00:00 | CRITICAL | module_b:run:12 - 模块 B 的严重错误信息\n2023-10-01 12:00:00 | INFO     | main:main:14 - 主模块结束\n```\n\n### 日志文件内容\n\n#### `logs/app.log`（主模块日志）：\n```\n2023-10-01 12:00:00 | INFO     | main:main:10 - 主模块启动\n2023-10-01 12:00:00 | INFO     | main:main:14 - 主模块结束\n```\n\n#### `logs/module_a.log`（模块 A 日志）：\n```\n2023-10-01 12:00:00 | DEBUG    | module_a:run:4 - 模块 A 的调试信息\n2023-10-01 12:00:00 | INFO     | module_a:run:6 - 模块 A 的普通信息\n2023-10-01 12:00:00 | WARNING  | module_a:run:8 - 模块 A 的警告信息\n2023-10-01 12:00:00 | ERROR    | module_a:run:10 - 模块 A 的错误信息\n2023-10-01 12:00:00 | CRITICAL | module_a:run:12 - 模块 A 的严重错误信息\n```\n\n#### `logs/module_b.log`（模块 B 日志）：\n```\n2023-10-01 12:00:00 | DEBUG    | module_b:run:4 - 模块 B 的调试信息\n2023-10-01 12:00:00 | INFO     | module_b:run:6 - 模块 B 的普通信息\n2023-10-01 12:00:00 | WARNING  | module_b:run:8 - 模块 B 的警告信息\n2023-10-01 12:00:00 | ERROR    | module_b:run:10 - 模块 B 的错误信息\n2023-10-01 12:00:00 | CRITICAL | module_b:run:12 - 模块 B 的严重错误信息\n```\n\n---\n\n## 10. 总结\n\n通过统一的日志配置函数 `setup_logger`，我们实现了以下目标：\n\n1. **自动生成日志文件名**：根据模块名称动态生成日志文件名，避免手动指定文件名。\n2. **减少重复代码**：在每个模块中只需调用 `setup_logger` 函数，无需重复编写日志配置代码。\n3. **灵活的日志管理**：每个模块的日志存储在独立的文件中，便于管理和分析。\n4. **日志轮转**：通过 `loguru` 的日志轮转功能，自动管理日志文件的大小和数量。\n5. **日志级别控制**：在开发环境中使用 `DEBUG` 级别，在生产环境中使用 `INFO` 或 `WARNING` 级别。\n6. **日志格式化**：使用统一的日志格式，便于阅读和分析。\n7. **日志安全**：避免记录敏感信息，如密码、密钥等。\n\n`loguru` 的简洁性和强大功能使其成为 Python 日志记录的首选工具。希望本文对你在实际项目中使用 `loguru` 有所帮助！如果你有任何问题或需要进一步的帮助，请随时留言。","slug":"开发/Python/Python-004：Python 日志处理最佳实践：使用loguru模块构建高效日志系统","published":1,"updated":"2024-12-26T06:21:17.322Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3g000fhghi4lbd6vgh","content":"<h1 id=\"Python-日志处理最佳实践：使用-loguru-构建高效日志系统\"><a href=\"#Python-日志处理最佳实践：使用-loguru-构建高效日志系统\" class=\"headerlink\" title=\"Python 日志处理最佳实践：使用 loguru 构建高效日志系统\"></a>Python 日志处理最佳实践：使用 <code>loguru</code> 构建高效日志系统</h1><p>在现代软件开发中，日志记录是不可或缺的一部分。Python 的标准库 <code>logging</code> 是一个强大且灵活的日志记录工具，但在实际项目中，配置和管理日志可能会变得复杂。为了简化日志记录的过程，<code>loguru</code> 库应运而生。<code>loguru</code> 是一个功能强大且易于使用的日志库，它提供了更简洁的 API 和更丰富的功能。本文将结合实际项目经验，总结使用 <code>loguru</code> 模块的最佳实践，并提供一个完整的代码示例。</p>\n<hr>\n<h2 id=\"1-为什么选择-loguru？\"><a href=\"#1-为什么选择-loguru？\" class=\"headerlink\" title=\"1. 为什么选择 loguru？\"></a>1. 为什么选择 <code>loguru</code>？</h2><p>相比于 <code>logging</code> 模块，<code>loguru</code> 提供了以下优势：</p>\n<ul>\n<li><strong>简洁的 API</strong>：无需复杂的配置，只需几行代码即可完成日志记录。</li>\n<li><strong>自动日志轮转</strong>：支持日志文件的自动轮转，避免日志文件过大。</li>\n<li><strong>丰富的日志格式</strong>：支持多种日志格式，包括颜色高亮、时间戳等。</li>\n<li><strong>异常捕获</strong>：自动捕获未处理的异常，并记录完整的堆栈信息。</li>\n<li><strong>日志过滤</strong>：支持基于日志级别和模块的过滤。</li>\n<li><strong>高性能</strong>：内部优化了性能，适合高并发场景。</li>\n</ul>\n<hr>\n<h2 id=\"2-最佳实践概述\"><a href=\"#2-最佳实践概述\" class=\"headerlink\" title=\"2. 最佳实践概述\"></a>2. 最佳实践概述</h2><p>在实际项目中，使用 <code>loguru</code> 的最佳实践包括以下几点：</p>\n<ol>\n<li><strong>统一的日志配置</strong>：通过一个统一的日志配置函数，避免在每个模块中重复编写日志配置代码。</li>\n<li><strong>根据模块名称自动命名日志文件</strong>：每个模块的日志存储在独立的文件中，便于管理和分析。</li>\n<li><strong>日志轮转</strong>：使用 <code>loguru</code> 的日志轮转功能，自动管理日志文件的大小和数量。</li>\n<li><strong>日志级别控制</strong>：在开发环境中使用 <code>DEBUG</code> 级别，在生产环境中使用 <code>INFO</code> 或 <code>WARNING</code> 级别。</li>\n<li><strong>日志格式化</strong>：使用统一的日志格式，便于阅读和分析。</li>\n<li><strong>日志安全</strong>：避免记录敏感信息，如密码、密钥等。</li>\n</ol>\n<hr>\n<h2 id=\"3-示例项目结构\"><a href=\"#3-示例项目结构\" class=\"headerlink\" title=\"3. 示例项目结构\"></a>3. 示例项目结构</h2><figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stylus\">my_project/<br>├── <span class=\"hljs-selector-tag\">main</span><span class=\"hljs-selector-class\">.py</span><br>├── module_a<span class=\"hljs-selector-class\">.py</span><br>├── module_b<span class=\"hljs-selector-class\">.py</span><br>├── logger_config<span class=\"hljs-selector-class\">.py</span><br>└── logs/<br>    ├── module_a<span class=\"hljs-selector-class\">.log</span><br>    ├── module_b<span class=\"hljs-selector-class\">.log</span><br>    └── app.log<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"4-安装-loguru\"><a href=\"#4-安装-loguru\" class=\"headerlink\" title=\"4. 安装 loguru\"></a>4. 安装 <code>loguru</code></h2><p>首先，确保你已经安装了 <code>loguru</code> 库。如果没有安装，可以使用以下命令进行安装：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">pip install loguru<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"5-统一的日志配置函数\"><a href=\"#5-统一的日志配置函数\" class=\"headerlink\" title=\"5. 统一的日志配置函数\"></a>5. 统一的日志配置函数</h2><p>为了减少重复代码，我们可以在一个单独的模块中定义一个统一的日志配置函数 <code>setup_logger</code>，并在每个模块中调用它。</p>\n<h3 id=\"logger-config-py\"><a href=\"#logger-config-py\" class=\"headerlink\" title=\"logger_config.py\"></a><code>logger_config.py</code></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> loguru <span class=\"hljs-keyword\">import</span> logger<br><span class=\"hljs-keyword\">import</span> sys<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">setup_logger</span>(<span class=\"hljs-params\">module_name, log_dir=<span class=\"hljs-string\">&quot;logs&quot;</span></span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    根据模块名称配置日志记录器，并自动生成日志文件名。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    :param module_name: 模块名称，用于生成日志文件名</span><br><span class=\"hljs-string\">    :param log_dir: 日志文件存储目录，默认为 &quot;logs&quot;</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 配置日志格式</span><br>    log_format = (<br>        <span class=\"hljs-string\">&quot;&lt;green&gt;&#123;time:YYYY-MM-DD HH:mm:ss&#125;&lt;/green&gt; | &quot;</span><br>        <span class=\"hljs-string\">&quot;&lt;level&gt;&#123;level: &lt;8&#125;&lt;/level&gt; | &quot;</span><br>        <span class=\"hljs-string\">&quot;&lt;cyan&gt;&#123;name&#125;&lt;/cyan&gt;:&lt;cyan&gt;&#123;function&#125;&lt;/cyan&gt;:&lt;cyan&gt;&#123;line&#125;&lt;/cyan&gt; - &lt;level&gt;&#123;message&#125;&lt;/level&gt;&quot;</span><br>    )<br><br>    <span class=\"hljs-comment\"># 配置控制台日志</span><br>    logger.remove()  <span class=\"hljs-comment\"># 移除默认的日志处理器</span><br>    logger.add(sys.stdout, <span class=\"hljs-built_in\">format</span>=log_format, level=<span class=\"hljs-string\">&quot;INFO&quot;</span>)<br><br>    <span class=\"hljs-comment\"># 配置文件日志（根据模块名称生成日志文件名）</span><br>    log_file = <span class=\"hljs-string\">f&quot;<span class=\"hljs-subst\">&#123;log_dir&#125;</span>/<span class=\"hljs-subst\">&#123;module_name&#125;</span>.log&quot;</span><br>    logger.add(<br>        log_file,  <span class=\"hljs-comment\"># 日志文件路径</span><br>        <span class=\"hljs-built_in\">format</span>=log_format,<br>        level=<span class=\"hljs-string\">&quot;DEBUG&quot;</span>,<br>        rotation=<span class=\"hljs-string\">&quot;10 MB&quot;</span>,  <span class=\"hljs-comment\"># 日志文件轮转大小</span><br>        retention=<span class=\"hljs-string\">&quot;7 days&quot;</span>,  <span class=\"hljs-comment\"># 保留日志文件的时间</span><br>        compression=<span class=\"hljs-string\">&quot;zip&quot;</span>,  <span class=\"hljs-comment\"># 日志文件压缩格式</span><br>    )<br><br>    <span class=\"hljs-keyword\">return</span> logger<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"6-主模块：main-py\"><a href=\"#6-主模块：main-py\" class=\"headerlink\" title=\"6. 主模块：main.py\"></a>6. 主模块：<code>main.py</code></h2><p>在主模块中，我们调用 <code>setup_logger</code> 函数来配置日志记录器，并记录日志。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> logger_config <span class=\"hljs-keyword\">import</span> setup_logger<br><span class=\"hljs-keyword\">import</span> module_a<br><span class=\"hljs-keyword\">import</span> module_b<br><br><span class=\"hljs-comment\"># 配置主模块的日志记录器</span><br>logger = setup_logger(<span class=\"hljs-string\">&quot;main&quot;</span>)<br><br><span class=\"hljs-comment\"># 记录日志</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():<br>    logger.info(<span class=\"hljs-string\">&quot;主模块启动&quot;</span>)<br>    module_a.run()<br>    module_b.run()<br>    logger.info(<span class=\"hljs-string\">&quot;主模块结束&quot;</span>)<br><br><span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">&quot;__main__&quot;</span>:<br>    main()<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"7-模块-A：module-a-py\"><a href=\"#7-模块-A：module-a-py\" class=\"headerlink\" title=\"7. 模块 A：module_a.py\"></a>7. 模块 A：<code>module_a.py</code></h2><p>在模块 A 中，我们同样调用 <code>setup_logger</code> 函数来配置日志记录器，并记录日志。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> logger_config <span class=\"hljs-keyword\">import</span> setup_logger<br><br><span class=\"hljs-comment\"># 配置模块 A 的日志记录器</span><br>logger = setup_logger(<span class=\"hljs-string\">&quot;module_a&quot;</span>)<br><br><span class=\"hljs-comment\"># 记录日志</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">run</span>():<br>    logger.debug(<span class=\"hljs-string\">&quot;模块 A 的调试信息&quot;</span>)<br>    logger.info(<span class=\"hljs-string\">&quot;模块 A 的普通信息&quot;</span>)<br>    logger.warning(<span class=\"hljs-string\">&quot;模块 A 的警告信息&quot;</span>)<br>    logger.error(<span class=\"hljs-string\">&quot;模块 A 的错误信息&quot;</span>)<br>    logger.critical(<span class=\"hljs-string\">&quot;模块 A 的严重错误信息&quot;</span>)<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"8-模块-B：module-b-py\"><a href=\"#8-模块-B：module-b-py\" class=\"headerlink\" title=\"8. 模块 B：module_b.py\"></a>8. 模块 B：<code>module_b.py</code></h2><p>在模块 B 中，我们同样调用 <code>setup_logger</code> 函数来配置日志记录器，并记录日志。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> logger_config <span class=\"hljs-keyword\">import</span> setup_logger<br><br><span class=\"hljs-comment\"># 配置模块 B 的日志记录器</span><br>logger = setup_logger(<span class=\"hljs-string\">&quot;module_b&quot;</span>)<br><br><span class=\"hljs-comment\"># 记录日志</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">run</span>():<br>    logger.debug(<span class=\"hljs-string\">&quot;模块 B 的调试信息&quot;</span>)<br>    logger.info(<span class=\"hljs-string\">&quot;模块 B 的普通信息&quot;</span>)<br>    logger.warning(<span class=\"hljs-string\">&quot;模块 B 的警告信息&quot;</span>)<br>    logger.error(<span class=\"hljs-string\">&quot;模块 B 的错误信息&quot;</span>)<br>    logger.critical(<span class=\"hljs-string\">&quot;模块 B 的严重错误信息&quot;</span>)<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"9-运行结果\"><a href=\"#9-运行结果\" class=\"headerlink\" title=\"9. 运行结果\"></a>9. 运行结果</h2><h3 id=\"控制台输出\"><a href=\"#控制台输出\" class=\"headerlink\" title=\"控制台输出\"></a>控制台输出</h3><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | INFO     | main:main:<span class=\"hljs-number\">10</span> - 主模块启动<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | INFO     | module_a:run:<span class=\"hljs-number\">6</span> - 模块 A 的普通信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | WARNING  | module_a:run:<span class=\"hljs-number\">8</span> - 模块 A 的警告信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | ERROR    | module_a:run:<span class=\"hljs-number\">10</span> - 模块 A 的错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | CRITICAL | module_a:run:<span class=\"hljs-number\">12</span> - 模块 A 的严重错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | INFO     | module_b:run:<span class=\"hljs-number\">6</span> - 模块 B 的普通信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | WARNING  | module_b:run:<span class=\"hljs-number\">8</span> - 模块 B 的警告信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | ERROR    | module_b:run:<span class=\"hljs-number\">10</span> - 模块 B 的错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | CRITICAL | module_b:run:<span class=\"hljs-number\">12</span> - 模块 B 的严重错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | INFO     | main:main:<span class=\"hljs-number\">14</span> - 主模块结束<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"日志文件内容\"><a href=\"#日志文件内容\" class=\"headerlink\" title=\"日志文件内容\"></a>日志文件内容</h3><h4 id=\"logs-app-log（主模块日志）：\"><a href=\"#logs-app-log（主模块日志）：\" class=\"headerlink\" title=\"logs/app.log（主模块日志）：\"></a><code>logs/app.log</code>（主模块日志）：</h4><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | INFO     | main:main:<span class=\"hljs-number\">10</span> - 主模块启动<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | INFO     | main:main:<span class=\"hljs-number\">14</span> - 主模块结束<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"logs-module-a-log（模块-A-日志）：\"><a href=\"#logs-module-a-log（模块-A-日志）：\" class=\"headerlink\" title=\"logs/module_a.log（模块 A 日志）：\"></a><code>logs/module_a.log</code>（模块 A 日志）：</h4><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | DEBUG    | module_a:run:<span class=\"hljs-number\">4</span> - 模块 A 的调试信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | INFO     | module_a:run:<span class=\"hljs-number\">6</span> - 模块 A 的普通信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | WARNING  | module_a:run:<span class=\"hljs-number\">8</span> - 模块 A 的警告信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | ERROR    | module_a:run:<span class=\"hljs-number\">10</span> - 模块 A 的错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | CRITICAL | module_a:run:<span class=\"hljs-number\">12</span> - 模块 A 的严重错误信息<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"logs-module-b-log（模块-B-日志）：\"><a href=\"#logs-module-b-log（模块-B-日志）：\" class=\"headerlink\" title=\"logs/module_b.log（模块 B 日志）：\"></a><code>logs/module_b.log</code>（模块 B 日志）：</h4><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | DEBUG    | module_b:run:<span class=\"hljs-number\">4</span> - 模块 B 的调试信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | INFO     | module_b:run:<span class=\"hljs-number\">6</span> - 模块 B 的普通信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | WARNING  | module_b:run:<span class=\"hljs-number\">8</span> - 模块 B 的警告信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | ERROR    | module_b:run:<span class=\"hljs-number\">10</span> - 模块 B 的错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | CRITICAL | module_b:run:<span class=\"hljs-number\">12</span> - 模块 B 的严重错误信息<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"10-总结\"><a href=\"#10-总结\" class=\"headerlink\" title=\"10. 总结\"></a>10. 总结</h2><p>通过统一的日志配置函数 <code>setup_logger</code>，我们实现了以下目标：</p>\n<ol>\n<li><strong>自动生成日志文件名</strong>：根据模块名称动态生成日志文件名，避免手动指定文件名。</li>\n<li><strong>减少重复代码</strong>：在每个模块中只需调用 <code>setup_logger</code> 函数，无需重复编写日志配置代码。</li>\n<li><strong>灵活的日志管理</strong>：每个模块的日志存储在独立的文件中，便于管理和分析。</li>\n<li><strong>日志轮转</strong>：通过 <code>loguru</code> 的日志轮转功能，自动管理日志文件的大小和数量。</li>\n<li><strong>日志级别控制</strong>：在开发环境中使用 <code>DEBUG</code> 级别，在生产环境中使用 <code>INFO</code> 或 <code>WARNING</code> 级别。</li>\n<li><strong>日志格式化</strong>：使用统一的日志格式，便于阅读和分析。</li>\n<li><strong>日志安全</strong>：避免记录敏感信息，如密码、密钥等。</li>\n</ol>\n<p><code>loguru</code> 的简洁性和强大功能使其成为 Python 日志记录的首选工具。希望本文对你在实际项目中使用 <code>loguru</code> 有所帮助！如果你有任何问题或需要进一步的帮助，请随时留言。</p>\n","excerpt":"","more":"<h1 id=\"Python-日志处理最佳实践：使用-loguru-构建高效日志系统\"><a href=\"#Python-日志处理最佳实践：使用-loguru-构建高效日志系统\" class=\"headerlink\" title=\"Python 日志处理最佳实践：使用 loguru 构建高效日志系统\"></a>Python 日志处理最佳实践：使用 <code>loguru</code> 构建高效日志系统</h1><p>在现代软件开发中，日志记录是不可或缺的一部分。Python 的标准库 <code>logging</code> 是一个强大且灵活的日志记录工具，但在实际项目中，配置和管理日志可能会变得复杂。为了简化日志记录的过程，<code>loguru</code> 库应运而生。<code>loguru</code> 是一个功能强大且易于使用的日志库，它提供了更简洁的 API 和更丰富的功能。本文将结合实际项目经验，总结使用 <code>loguru</code> 模块的最佳实践，并提供一个完整的代码示例。</p>\n<hr>\n<h2 id=\"1-为什么选择-loguru？\"><a href=\"#1-为什么选择-loguru？\" class=\"headerlink\" title=\"1. 为什么选择 loguru？\"></a>1. 为什么选择 <code>loguru</code>？</h2><p>相比于 <code>logging</code> 模块，<code>loguru</code> 提供了以下优势：</p>\n<ul>\n<li><strong>简洁的 API</strong>：无需复杂的配置，只需几行代码即可完成日志记录。</li>\n<li><strong>自动日志轮转</strong>：支持日志文件的自动轮转，避免日志文件过大。</li>\n<li><strong>丰富的日志格式</strong>：支持多种日志格式，包括颜色高亮、时间戳等。</li>\n<li><strong>异常捕获</strong>：自动捕获未处理的异常，并记录完整的堆栈信息。</li>\n<li><strong>日志过滤</strong>：支持基于日志级别和模块的过滤。</li>\n<li><strong>高性能</strong>：内部优化了性能，适合高并发场景。</li>\n</ul>\n<hr>\n<h2 id=\"2-最佳实践概述\"><a href=\"#2-最佳实践概述\" class=\"headerlink\" title=\"2. 最佳实践概述\"></a>2. 最佳实践概述</h2><p>在实际项目中，使用 <code>loguru</code> 的最佳实践包括以下几点：</p>\n<ol>\n<li><strong>统一的日志配置</strong>：通过一个统一的日志配置函数，避免在每个模块中重复编写日志配置代码。</li>\n<li><strong>根据模块名称自动命名日志文件</strong>：每个模块的日志存储在独立的文件中，便于管理和分析。</li>\n<li><strong>日志轮转</strong>：使用 <code>loguru</code> 的日志轮转功能，自动管理日志文件的大小和数量。</li>\n<li><strong>日志级别控制</strong>：在开发环境中使用 <code>DEBUG</code> 级别，在生产环境中使用 <code>INFO</code> 或 <code>WARNING</code> 级别。</li>\n<li><strong>日志格式化</strong>：使用统一的日志格式，便于阅读和分析。</li>\n<li><strong>日志安全</strong>：避免记录敏感信息，如密码、密钥等。</li>\n</ol>\n<hr>\n<h2 id=\"3-示例项目结构\"><a href=\"#3-示例项目结构\" class=\"headerlink\" title=\"3. 示例项目结构\"></a>3. 示例项目结构</h2><figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stylus\">my_project/<br>├── <span class=\"hljs-selector-tag\">main</span><span class=\"hljs-selector-class\">.py</span><br>├── module_a<span class=\"hljs-selector-class\">.py</span><br>├── module_b<span class=\"hljs-selector-class\">.py</span><br>├── logger_config<span class=\"hljs-selector-class\">.py</span><br>└── logs/<br>    ├── module_a<span class=\"hljs-selector-class\">.log</span><br>    ├── module_b<span class=\"hljs-selector-class\">.log</span><br>    └── app.log<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"4-安装-loguru\"><a href=\"#4-安装-loguru\" class=\"headerlink\" title=\"4. 安装 loguru\"></a>4. 安装 <code>loguru</code></h2><p>首先，确保你已经安装了 <code>loguru</code> 库。如果没有安装，可以使用以下命令进行安装：</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs bash\">pip install loguru<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"5-统一的日志配置函数\"><a href=\"#5-统一的日志配置函数\" class=\"headerlink\" title=\"5. 统一的日志配置函数\"></a>5. 统一的日志配置函数</h2><p>为了减少重复代码，我们可以在一个单独的模块中定义一个统一的日志配置函数 <code>setup_logger</code>，并在每个模块中调用它。</p>\n<h3 id=\"logger-config-py\"><a href=\"#logger-config-py\" class=\"headerlink\" title=\"logger_config.py\"></a><code>logger_config.py</code></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> loguru <span class=\"hljs-keyword\">import</span> logger<br><span class=\"hljs-keyword\">import</span> sys<br><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">setup_logger</span>(<span class=\"hljs-params\">module_name, log_dir=<span class=\"hljs-string\">&quot;logs&quot;</span></span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    根据模块名称配置日志记录器，并自动生成日志文件名。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    :param module_name: 模块名称，用于生成日志文件名</span><br><span class=\"hljs-string\">    :param log_dir: 日志文件存储目录，默认为 &quot;logs&quot;</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 配置日志格式</span><br>    log_format = (<br>        <span class=\"hljs-string\">&quot;&lt;green&gt;&#123;time:YYYY-MM-DD HH:mm:ss&#125;&lt;/green&gt; | &quot;</span><br>        <span class=\"hljs-string\">&quot;&lt;level&gt;&#123;level: &lt;8&#125;&lt;/level&gt; | &quot;</span><br>        <span class=\"hljs-string\">&quot;&lt;cyan&gt;&#123;name&#125;&lt;/cyan&gt;:&lt;cyan&gt;&#123;function&#125;&lt;/cyan&gt;:&lt;cyan&gt;&#123;line&#125;&lt;/cyan&gt; - &lt;level&gt;&#123;message&#125;&lt;/level&gt;&quot;</span><br>    )<br><br>    <span class=\"hljs-comment\"># 配置控制台日志</span><br>    logger.remove()  <span class=\"hljs-comment\"># 移除默认的日志处理器</span><br>    logger.add(sys.stdout, <span class=\"hljs-built_in\">format</span>=log_format, level=<span class=\"hljs-string\">&quot;INFO&quot;</span>)<br><br>    <span class=\"hljs-comment\"># 配置文件日志（根据模块名称生成日志文件名）</span><br>    log_file = <span class=\"hljs-string\">f&quot;<span class=\"hljs-subst\">&#123;log_dir&#125;</span>/<span class=\"hljs-subst\">&#123;module_name&#125;</span>.log&quot;</span><br>    logger.add(<br>        log_file,  <span class=\"hljs-comment\"># 日志文件路径</span><br>        <span class=\"hljs-built_in\">format</span>=log_format,<br>        level=<span class=\"hljs-string\">&quot;DEBUG&quot;</span>,<br>        rotation=<span class=\"hljs-string\">&quot;10 MB&quot;</span>,  <span class=\"hljs-comment\"># 日志文件轮转大小</span><br>        retention=<span class=\"hljs-string\">&quot;7 days&quot;</span>,  <span class=\"hljs-comment\"># 保留日志文件的时间</span><br>        compression=<span class=\"hljs-string\">&quot;zip&quot;</span>,  <span class=\"hljs-comment\"># 日志文件压缩格式</span><br>    )<br><br>    <span class=\"hljs-keyword\">return</span> logger<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"6-主模块：main-py\"><a href=\"#6-主模块：main-py\" class=\"headerlink\" title=\"6. 主模块：main.py\"></a>6. 主模块：<code>main.py</code></h2><p>在主模块中，我们调用 <code>setup_logger</code> 函数来配置日志记录器，并记录日志。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> logger_config <span class=\"hljs-keyword\">import</span> setup_logger<br><span class=\"hljs-keyword\">import</span> module_a<br><span class=\"hljs-keyword\">import</span> module_b<br><br><span class=\"hljs-comment\"># 配置主模块的日志记录器</span><br>logger = setup_logger(<span class=\"hljs-string\">&quot;main&quot;</span>)<br><br><span class=\"hljs-comment\"># 记录日志</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">main</span>():<br>    logger.info(<span class=\"hljs-string\">&quot;主模块启动&quot;</span>)<br>    module_a.run()<br>    module_b.run()<br>    logger.info(<span class=\"hljs-string\">&quot;主模块结束&quot;</span>)<br><br><span class=\"hljs-keyword\">if</span> __name__ == <span class=\"hljs-string\">&quot;__main__&quot;</span>:<br>    main()<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"7-模块-A：module-a-py\"><a href=\"#7-模块-A：module-a-py\" class=\"headerlink\" title=\"7. 模块 A：module_a.py\"></a>7. 模块 A：<code>module_a.py</code></h2><p>在模块 A 中，我们同样调用 <code>setup_logger</code> 函数来配置日志记录器，并记录日志。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> logger_config <span class=\"hljs-keyword\">import</span> setup_logger<br><br><span class=\"hljs-comment\"># 配置模块 A 的日志记录器</span><br>logger = setup_logger(<span class=\"hljs-string\">&quot;module_a&quot;</span>)<br><br><span class=\"hljs-comment\"># 记录日志</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">run</span>():<br>    logger.debug(<span class=\"hljs-string\">&quot;模块 A 的调试信息&quot;</span>)<br>    logger.info(<span class=\"hljs-string\">&quot;模块 A 的普通信息&quot;</span>)<br>    logger.warning(<span class=\"hljs-string\">&quot;模块 A 的警告信息&quot;</span>)<br>    logger.error(<span class=\"hljs-string\">&quot;模块 A 的错误信息&quot;</span>)<br>    logger.critical(<span class=\"hljs-string\">&quot;模块 A 的严重错误信息&quot;</span>)<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"8-模块-B：module-b-py\"><a href=\"#8-模块-B：module-b-py\" class=\"headerlink\" title=\"8. 模块 B：module_b.py\"></a>8. 模块 B：<code>module_b.py</code></h2><p>在模块 B 中，我们同样调用 <code>setup_logger</code> 函数来配置日志记录器，并记录日志。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">from</span> logger_config <span class=\"hljs-keyword\">import</span> setup_logger<br><br><span class=\"hljs-comment\"># 配置模块 B 的日志记录器</span><br>logger = setup_logger(<span class=\"hljs-string\">&quot;module_b&quot;</span>)<br><br><span class=\"hljs-comment\"># 记录日志</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">run</span>():<br>    logger.debug(<span class=\"hljs-string\">&quot;模块 B 的调试信息&quot;</span>)<br>    logger.info(<span class=\"hljs-string\">&quot;模块 B 的普通信息&quot;</span>)<br>    logger.warning(<span class=\"hljs-string\">&quot;模块 B 的警告信息&quot;</span>)<br>    logger.error(<span class=\"hljs-string\">&quot;模块 B 的错误信息&quot;</span>)<br>    logger.critical(<span class=\"hljs-string\">&quot;模块 B 的严重错误信息&quot;</span>)<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"9-运行结果\"><a href=\"#9-运行结果\" class=\"headerlink\" title=\"9. 运行结果\"></a>9. 运行结果</h2><h3 id=\"控制台输出\"><a href=\"#控制台输出\" class=\"headerlink\" title=\"控制台输出\"></a>控制台输出</h3><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | INFO     | main:main:<span class=\"hljs-number\">10</span> - 主模块启动<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | INFO     | module_a:run:<span class=\"hljs-number\">6</span> - 模块 A 的普通信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | WARNING  | module_a:run:<span class=\"hljs-number\">8</span> - 模块 A 的警告信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | ERROR    | module_a:run:<span class=\"hljs-number\">10</span> - 模块 A 的错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | CRITICAL | module_a:run:<span class=\"hljs-number\">12</span> - 模块 A 的严重错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | INFO     | module_b:run:<span class=\"hljs-number\">6</span> - 模块 B 的普通信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | WARNING  | module_b:run:<span class=\"hljs-number\">8</span> - 模块 B 的警告信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | ERROR    | module_b:run:<span class=\"hljs-number\">10</span> - 模块 B 的错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | CRITICAL | module_b:run:<span class=\"hljs-number\">12</span> - 模块 B 的严重错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | INFO     | main:main:<span class=\"hljs-number\">14</span> - 主模块结束<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"日志文件内容\"><a href=\"#日志文件内容\" class=\"headerlink\" title=\"日志文件内容\"></a>日志文件内容</h3><h4 id=\"logs-app-log（主模块日志）：\"><a href=\"#logs-app-log（主模块日志）：\" class=\"headerlink\" title=\"logs/app.log（主模块日志）：\"></a><code>logs/app.log</code>（主模块日志）：</h4><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | INFO     | main:main:<span class=\"hljs-number\">10</span> - 主模块启动<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | INFO     | main:main:<span class=\"hljs-number\">14</span> - 主模块结束<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"logs-module-a-log（模块-A-日志）：\"><a href=\"#logs-module-a-log（模块-A-日志）：\" class=\"headerlink\" title=\"logs/module_a.log（模块 A 日志）：\"></a><code>logs/module_a.log</code>（模块 A 日志）：</h4><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | DEBUG    | module_a:run:<span class=\"hljs-number\">4</span> - 模块 A 的调试信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | INFO     | module_a:run:<span class=\"hljs-number\">6</span> - 模块 A 的普通信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | WARNING  | module_a:run:<span class=\"hljs-number\">8</span> - 模块 A 的警告信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | ERROR    | module_a:run:<span class=\"hljs-number\">10</span> - 模块 A 的错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | CRITICAL | module_a:run:<span class=\"hljs-number\">12</span> - 模块 A 的严重错误信息<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"logs-module-b-log（模块-B-日志）：\"><a href=\"#logs-module-b-log（模块-B-日志）：\" class=\"headerlink\" title=\"logs/module_b.log（模块 B 日志）：\"></a><code>logs/module_b.log</code>（模块 B 日志）：</h4><figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | DEBUG    | module_b:run:<span class=\"hljs-number\">4</span> - 模块 B 的调试信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | INFO     | module_b:run:<span class=\"hljs-number\">6</span> - 模块 B 的普通信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | WARNING  | module_b:run:<span class=\"hljs-number\">8</span> - 模块 B 的警告信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | ERROR    | module_b:run:<span class=\"hljs-number\">10</span> - 模块 B 的错误信息<br><span class=\"hljs-attribute\">2023</span>-<span class=\"hljs-number\">10</span>-<span class=\"hljs-number\">01</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span> | CRITICAL | module_b:run:<span class=\"hljs-number\">12</span> - 模块 B 的严重错误信息<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"10-总结\"><a href=\"#10-总结\" class=\"headerlink\" title=\"10. 总结\"></a>10. 总结</h2><p>通过统一的日志配置函数 <code>setup_logger</code>，我们实现了以下目标：</p>\n<ol>\n<li><strong>自动生成日志文件名</strong>：根据模块名称动态生成日志文件名，避免手动指定文件名。</li>\n<li><strong>减少重复代码</strong>：在每个模块中只需调用 <code>setup_logger</code> 函数，无需重复编写日志配置代码。</li>\n<li><strong>灵活的日志管理</strong>：每个模块的日志存储在独立的文件中，便于管理和分析。</li>\n<li><strong>日志轮转</strong>：通过 <code>loguru</code> 的日志轮转功能，自动管理日志文件的大小和数量。</li>\n<li><strong>日志级别控制</strong>：在开发环境中使用 <code>DEBUG</code> 级别，在生产环境中使用 <code>INFO</code> 或 <code>WARNING</code> 级别。</li>\n<li><strong>日志格式化</strong>：使用统一的日志格式，便于阅读和分析。</li>\n<li><strong>日志安全</strong>：避免记录敏感信息，如密码、密钥等。</li>\n</ol>\n<p><code>loguru</code> 的简洁性和强大功能使其成为 Python 日志记录的首选工具。希望本文对你在实际项目中使用 <code>loguru</code> 有所帮助！如果你有任何问题或需要进一步的帮助，请随时留言。</p>\n"},{"title":"C++ 右值语义详解：从基础到实战","date":"2024-12-19T04:00:00.000Z","category_bar":true,"_content":"\n# C++ 右值语义详解：从基础到实战\n\n在现代 C++ 中，右值语义是一个非常重要的概念，它涉及到右值引用、移动语义、完美转发等核心特性。本文将结合代码实例，详细讲解与右值语义相关的所有知识点，帮助你全面掌握这一主题。\n\n## 1. 左值与右值的基本概念\n\n### 1.1 左值 (Lvalue)\n左值是可以取地址的表达式，通常表示一个对象或变量。左值具有持久性，可以被赋值。\n\n```cpp\n#include <iostream>\n\nint main() {\n    int a = 10; // 'a' 是一个左值\n    std::cout << \"Address of a: \" << &a << std::endl; // 可以取地址\n    return 0;\n}\n```\n\n### 1.2 右值 (Rvalue)\n右值是不能取地址的表达式，通常是**临时对象或字面量**。右值具有**短暂性**，不能被赋值。\n\n```cpp\n#include <iostream>\n\nint main() {\n    int&& r = 42; // '42' 是一个右值\n    // std::cout << \"Address of 42: \" << &42 << std::endl; // 错误：不能取地址\n    return 0;\n}\n```\n\n### 1.3 纯右值 (PRvalue) 与将亡值 (Xvalue)\n- **纯右值**：临时对象或字面量，如 `42`、`std::string(\"hello\")`。\n- **将亡值**：即将被销毁的对象，通常是右值引用的结果，如 `std::move(x)`。\n\n---\n\n## 2. 右值引用 (Rvalue Reference)\n\n### 2.1 右值引用的语法\n右值引用使用 `T&&` 语法，表示对右值的引用。\n\n```cpp\n#include <iostream>\n\nint main() {\n    int&& r = 42; // 右值引用\n    std::cout << \"r = \" << r << std::endl;\n    return 0;\n}\n```\n\n### 2.2 右值引用的作用\n右值引用主要用于支持移动语义和完美转发。\n\n---\n\n## 3. 移动语义 (Move Semantics)\n\n### 3.1 移动构造函数 (Move Constructor)\n移动构造函数接受一个右值引用参数，用于将资源从一个对象“移动”到新对象。\n\n```cpp\n#include <iostream>\n#include <vector>\n\nclass MyVector {\npublic:\n    std::vector<int> data;\n\n    // 移动构造函数\n    MyVector(MyVector&& other) noexcept : data(std::move(other.data)) {\n        std::cout << \"Move Constructor called\" << std::endl;\n    }\n\n    MyVector(const std::vector<int>& d) : data(d) {}\n};\n\nint main() {\n    MyVector v1{std::vector<int>{1, 2, 3}};\n    MyVector v2 = std::move(v1); // 调用移动构造函数\n    return 0;\n}\n```\n\n### 3.2 移动赋值运算符 (Move Assignment Operator)\n移动赋值运算符接受一个右值引用参数，用于将资源从一个对象“移动”到现有对象。\n\n```cpp\n#include <iostream>\n#include <vector>\n\nclass MyVector {\npublic:\n    std::vector<int> data;\n\n    // 移动赋值运算符\n    MyVector& operator=(MyVector&& other) noexcept {\n        if (this != &other) {\n            data = std::move(other.data);\n            std::cout << \"Move Assignment Operator called\" << std::endl;\n        }\n        return *this;\n    }\n\n    MyVector(const std::vector<int>& d) : data(d) {}\n};\n\nint main() {\n    MyVector v1{std::vector<int>{1, 2, 3}};\n    MyVector v2{std::vector<int>{4, 5, 6}};\n    v2 = std::move(v1); // 调用移动赋值运算符\n    return 0;\n}\n```\n\n### 3.3 `std::move`\n`std::move` 将一个左值转换为右值引用，以便调用移动构造函数或移动赋值运算符。\n\n```cpp\n#include <iostream>\n#include <vector>\n\nclass MyVector {\npublic:\n    std::vector<int> data;\n\n    MyVector(MyVector&& other) noexcept : data(std::move(other.data)) {\n        std::cout << \"Move Constructor called\" << std::endl;\n    }\n\n    MyVector(const std::vector<int>& d) : data(d) {}\n};\n\nint main() {\n    MyVector v1{std::vector<int>{1, 2, 3}};\n    MyVector v2 = std::move(v1); // 使用 std::move 调用移动构造函数\n    return 0;\n}\n```\n\n---\n\n## 4. 完美转发 (Perfect Forwarding)\n\n### 4.1 问题背景\n在模板编程中，如何将参数的值类别（左值或右值）保持不变地传递给其他函数。\n\n### 4.2 `std::forward`\n`std::forward` 在模板中保持参数的值类别，实现完美转发。\n\n```cpp\n#include <iostream>\n#include <utility>\n\nvoid print(int& x) {\n    std::cout << \"Lvalue: \" << x << std::endl;\n}\n\nvoid print(int&& x) {\n    std::cout << \"Rvalue: \" << x << std::endl;\n}\n\ntemplate <typename T>\nvoid wrapper(T&& arg) {\n    print(std::forward<T>(arg)); // 完美转发\n}\n\nint main() {\n    int a = 10;\n    wrapper(a);  // 调用 print(int&)\n    wrapper(20); // 调用 print(int&&)\n    return 0;\n}\n```\n\n### 4.3 引用折叠 (Reference Collapsing)\n引用折叠规则：\n- `T& &` 折叠为 `T&`\n- `T& &&` 折叠为 `T&`\n- `T&& &` 折叠为 `T&`\n- `T&& &&` 折叠为 `T&&`\n\n---\n\n## 5. 特殊成员函数与规则\n\n### 5.1 特殊成员函数\n- **移动构造函数**：`ClassName(ClassName&&);`\n- **移动赋值运算符**：`ClassName& operator=(ClassName&&);`\n\n### 5.2 编译器生成的移动操作\n如果用户显式定义了拷贝构造函数、拷贝赋值运算符或析构函数，编译器不会自动生成移动操作。\n\n```cpp\n#include <iostream>\n\nclass NoMove {\npublic:\n    NoMove() = default;\n    NoMove(const NoMove&) { std::cout << \"Copy Constructor\" << std::endl; }\n    NoMove& operator=(const NoMove&) { std::cout << \"Copy Assignment\" << std::endl; return *this; }\n};\n\nint main() {\n    NoMove a;\n    NoMove b = std::move(a); // 调用拷贝构造函数，因为移动操作未生成\n    return 0;\n}\n```\n\n### 5.3 删除的移动操作\n如果移动操作被显式删除或不可访问，对象将无法移动。\n\n```cpp\n#include <iostream>\n\nclass DeletedMove {\npublic:\n    DeletedMove() = default;\n    DeletedMove(DeletedMove&&) = delete; // 显式删除移动构造函数\n};\n\nint main() {\n    DeletedMove a;\n    // DeletedMove b = std::move(a); // 错误：移动构造函数被删除\n    return 0;\n}\n```\n\n---\n\n## 6. 右值语义的应用场景\n\n### 6.1 资源管理类\n在自定义的资源管理类中，使用移动语义避免不必要的资源拷贝。\n\n```cpp\n#include <iostream>\n#include <memory>\n\nclass Resource {\npublic:\n    std::unique_ptr<int> ptr;\n\n    Resource(int value) : ptr(std::make_unique<int>(value)) {}\n\n    Resource(Resource&& other) noexcept : ptr(std::move(other.ptr)) {\n        std::cout << \"Resource moved\" << std::endl;\n    }\n};\n\nint main() {\n    Resource r1(42);\n    Resource r2 = std::move(r1); // 移动资源\n    return 0;\n}\n```\n\n### 6.2 标准库中的右值语义\n`std::unique_ptr`、`std::vector` 等标准库容器和智能指针广泛使用右值语义。\n\n```cpp\n#include <iostream>\n#include <vector>\n\nint main() {\n    std::vector<int> v1{1, 2, 3};\n    std::vector<int> v2 = std::move(v1); // 移动 vector\n    std::cout << \"v2 size: \" << v2.size() << std::endl;\n    return 0;\n}\n```\n\n### 6.3 函数返回值优化 (RVO) 与移动语义\n在函数返回值时，编译器可能使用 RVO 或移动语义优化性能。\n\n```cpp\n#include <iostream>\n#include <vector>\n\nstd::vector<int> createVector() {\n    std::vector<int> v{1, 2, 3};\n    return v; // 可能触发 RVO 或移动语义\n}\n\nint main() {\n    std::vector<int> v = createVector();\n    std::cout << \"v size: \" << v.size() << std::endl;\n    return 0;\n}\n```\n\n---\n\n## 7. 常见问题与注意事项\n\n### 7.1 移动后对象的状态\n移动后的对象处于有效但未定义的状态，通常不应再使用。\n\n```cpp\n#include <iostream>\n#include <vector>\n\nint main() {\n    std::vector<int> v1{1, 2, 3};\n    std::vector<int> v2 = std::move(v1);\n    // v1.size(); // 未定义行为，v1 已被移动\n    return 0;\n}\n```\n\n### 7.2 避免不必要的 `std::move`\n在返回局部变量时，编译器会自动选择移动或拷贝，无需显式调用 `std::move`。\n\n```cpp\n#include <iostream>\n#include <vector>\n\nstd::vector<int> createVector() {\n    std::vector<int> v{1, 2, 3};\n    return std::move(v); // 不必要的 std::move\n}\n\nint main() {\n    std::vector<int> v = createVector();\n    std::cout << \"v size: \" << v.size() << std::endl;\n    return 0;\n}\n```\n\n### 7.3 右值引用的陷阱\n右值引用本身是左值，因此需要使用 `std::move` 或 `std::forward` 来保持其右值特性。\n\n```cpp\n#include <iostream>\n\nvoid print(int&& x) {\n    std::cout << \"Rvalue: \" << x << std::endl;\n}\n\nint main() {\n    int&& r = 42;\n    // print(r); // 错误：r 是左值\n    print(std::move(r)); // 正确\n    return 0;\n}\n```\n\n---\n\n## 8.为什么需要右值\n\n\n\n在 C++ 中，右值（Rvalue）是一个非常重要的概念，它的引入主要是为了解决以下几个核心问题：\n\n---\n\n### 8.1 避免不必要的拷贝\n\n在传统的 C++ 中，对象的拷贝操作可能会带来性能问题，尤其是在处理大对象或资源密集型对象时。例如，当你将一个对象从一个地方移动到另一个地方时，如果使用拷贝操作，会浪费大量的时间和资源。\n\n#### 例子：\n```cpp\n#include <iostream>\n#include <vector>\n\nstd::vector<int> createVector() {\n    std::vector<int> v{1, 2, 3, 4, 5};\n    return v; // 返回局部对象\n}\n\nint main() {\n    std::vector<int> v = createVector(); // 拷贝构造\n    std::cout << \"v size: \" << v.size() << std::endl;\n    return 0;\n}\n```\n\n在这个例子中，`createVector` 返回一个局部对象 `v`，如果编译器没有优化（如 RVO 或 NRVO），那么 `v` 会被拷贝到 `main` 中的 `v`。对于大对象来说，拷贝操作的代价非常高。\n\n**右值的引入**：通过右值引用和移动语义，可以将对象的资源“移动”到目标对象，而不是拷贝，从而避免不必要的开销。\n\n---\n\n### 8.2 支持移动语义\n\n移动语义是 C++11 引入的一个重要特性，它允许将资源从一个对象“移动”到另一个对象，而不是拷贝。移动语义的核心是右值引用（`T&&`）。\n\n#### 例子：\n```cpp\n#include <iostream>\n#include <vector>\n\nclass MyVector {\npublic:\n    std::vector<int> data;\n\n    // 移动构造函数\n    MyVector(MyVector&& other) noexcept : data(std::move(other.data)) {\n        std::cout << \"Move Constructor called\" << std::endl;\n    }\n\n    MyVector(const std::vector<int>& d) : data(d) {}\n};\n\nint main() {\n    MyVector v1{std::vector<int>{1, 2, 3}};\n    MyVector v2 = std::move(v1); // 调用移动构造函数\n    return 0;\n}\n```\n\n在这个例子中，`v1` 的资源被“移动”到 `v2`，而不是拷贝。移动操作的代价非常低，通常只是指针的交换。\n\n---\n\n### 8.3 支持完美转发\n\n在模板编程中，函数参数的值类别（左值或右值）可能会丢失，导致无法正确地传递参数。完美转发（Perfect Forwarding）通过右值引用和 `std::forward` 解决了这个问题。\n\n#### 例子：\n```cpp\n#include <iostream>\n#include <utility>\n\nvoid print(int& x) {\n    std::cout << \"Lvalue: \" << x << std::endl;\n}\n\nvoid print(int&& x) {\n    std::cout << \"Rvalue: \" << x << std::endl;\n}\n\ntemplate <typename T>\nvoid wrapper(T&& arg) {\n    print(std::forward<T>(arg)); // 完美转发\n}\n\nint main() {\n    int a = 10;\n    wrapper(a);  // 调用 print(int&)\n    wrapper(20); // 调用 print(int&&)\n    return 0;\n}\n```\n\n在这个例子中，`wrapper` 函数能够正确地转发参数的值类别，无论是左值还是右值。\n\n---\n\n### 8.4 优化资源管理\n\n在资源管理类（如智能指针、文件句柄等）中，右值引用和移动语义可以显著提高性能。例如，`std::unique_ptr` 是一个典型的例子，它只能通过移动语义来传递所有权，而不能拷贝。\n\n#### 例子：\n```cpp\n#include <iostream>\n#include <memory>\n\nclass Resource {\npublic:\n    std::unique_ptr<int> ptr;\n\n    Resource(int value) : ptr(std::make_unique<int>(value)) {}\n\n    Resource(Resource&& other) noexcept : ptr(std::move(other.ptr)) {\n        std::cout << \"Resource moved\" << std::endl;\n    }\n};\n\nint main() {\n    Resource r1(42);\n    Resource r2 = std::move(r1); // 移动资源\n    return 0;\n}\n```\n\n在这个例子中，`std::unique_ptr` 的资源被移动到 `r2`，而不是拷贝。这确保了资源的唯一所有权。\n\n---\n\n### 8.5 提高代码的表达能力\n\n右值引用的引入使得 C++ 的表达能力更强。通过移动语义和完美转发，开发者可以编写更高效、更简洁的代码。例如，标准库中的容器（如 `std::vector`）和算法（如 `std::sort`）都广泛使用了右值语义。\n\n#### 例子：\n```cpp\n#include <iostream>\n#include <vector>\n\nint main() {\n    std::vector<int> v1{1, 2, 3};\n    std::vector<int> v2 = std::move(v1); // 移动 vector\n    std::cout << \"v2 size: \" << v2.size() << std::endl;\n    return 0;\n}\n```\n\n在这个例子中，`v1` 的资源被移动到 `v2`，而不是拷贝。这使得代码更加高效。\n\n---\n\n### 8.6 解决临时对象的资源浪费\n\n在传统的 C++ 中，临时对象（如函数返回值）的生命周期很短，但它们的资源可能会被浪费。通过右值引用和移动语义，可以有效地利用这些临时对象的资源。\n\n#### 例子：\n```cpp\n#include <iostream>\n#include <vector>\n\nstd::vector<int> createVector() {\n    std::vector<int> v{1, 2, 3};\n    return v; // 返回局部对象\n}\n\nint main() {\n    std::vector<int> v = createVector(); // 可能触发 RVO 或移动语义\n    std::cout << \"v size: \" << v.size() << std::endl;\n    return 0;\n}\n```\n\n在这个例子中，`createVector` 返回的临时对象 `v` 的资源被移动到 `main` 中的 `v`，而不是拷贝。\n\n---\n\n## 9.总结\n\n右值的引入解决了以下几个核心问题：\n1. **避免不必要的拷贝**：通过移动语义，减少大对象或资源密集型对象的拷贝开销。\n2. **支持移动语义**：允许将资源从一个对象“移动”到另一个对象，而不是拷贝。\n3. **支持完美转发**：在模板编程中，保持参数的值类别，确保参数能够正确传递。\n4. **优化资源管理**：在智能指针和资源管理类中，确保资源的唯一所有权。\n5. **提高代码的表达能力**：使代码更加高效、简洁。\n6. **解决临时对象的资源浪费**：利用临时对象的资源，避免浪费。\n\n通过右值引用和移动语义，C++ 的性能和表达能力得到了显著提升，使得现代 C++ 代码更加高效和现代化。\n\n![公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","source":"_posts/开发/cpp/C++001：C++右值语义详解：从基础到实战.md","raw":"---\ntitle: 'C++ 右值语义详解：从基础到实战'\ncategories:\n  - [开发,cpp]\ntags:\n  - c++\n  - cpp\ndate: 2024-12-19 12:00:00\ncategory_bar: true\n---\n\n# C++ 右值语义详解：从基础到实战\n\n在现代 C++ 中，右值语义是一个非常重要的概念，它涉及到右值引用、移动语义、完美转发等核心特性。本文将结合代码实例，详细讲解与右值语义相关的所有知识点，帮助你全面掌握这一主题。\n\n## 1. 左值与右值的基本概念\n\n### 1.1 左值 (Lvalue)\n左值是可以取地址的表达式，通常表示一个对象或变量。左值具有持久性，可以被赋值。\n\n```cpp\n#include <iostream>\n\nint main() {\n    int a = 10; // 'a' 是一个左值\n    std::cout << \"Address of a: \" << &a << std::endl; // 可以取地址\n    return 0;\n}\n```\n\n### 1.2 右值 (Rvalue)\n右值是不能取地址的表达式，通常是**临时对象或字面量**。右值具有**短暂性**，不能被赋值。\n\n```cpp\n#include <iostream>\n\nint main() {\n    int&& r = 42; // '42' 是一个右值\n    // std::cout << \"Address of 42: \" << &42 << std::endl; // 错误：不能取地址\n    return 0;\n}\n```\n\n### 1.3 纯右值 (PRvalue) 与将亡值 (Xvalue)\n- **纯右值**：临时对象或字面量，如 `42`、`std::string(\"hello\")`。\n- **将亡值**：即将被销毁的对象，通常是右值引用的结果，如 `std::move(x)`。\n\n---\n\n## 2. 右值引用 (Rvalue Reference)\n\n### 2.1 右值引用的语法\n右值引用使用 `T&&` 语法，表示对右值的引用。\n\n```cpp\n#include <iostream>\n\nint main() {\n    int&& r = 42; // 右值引用\n    std::cout << \"r = \" << r << std::endl;\n    return 0;\n}\n```\n\n### 2.2 右值引用的作用\n右值引用主要用于支持移动语义和完美转发。\n\n---\n\n## 3. 移动语义 (Move Semantics)\n\n### 3.1 移动构造函数 (Move Constructor)\n移动构造函数接受一个右值引用参数，用于将资源从一个对象“移动”到新对象。\n\n```cpp\n#include <iostream>\n#include <vector>\n\nclass MyVector {\npublic:\n    std::vector<int> data;\n\n    // 移动构造函数\n    MyVector(MyVector&& other) noexcept : data(std::move(other.data)) {\n        std::cout << \"Move Constructor called\" << std::endl;\n    }\n\n    MyVector(const std::vector<int>& d) : data(d) {}\n};\n\nint main() {\n    MyVector v1{std::vector<int>{1, 2, 3}};\n    MyVector v2 = std::move(v1); // 调用移动构造函数\n    return 0;\n}\n```\n\n### 3.2 移动赋值运算符 (Move Assignment Operator)\n移动赋值运算符接受一个右值引用参数，用于将资源从一个对象“移动”到现有对象。\n\n```cpp\n#include <iostream>\n#include <vector>\n\nclass MyVector {\npublic:\n    std::vector<int> data;\n\n    // 移动赋值运算符\n    MyVector& operator=(MyVector&& other) noexcept {\n        if (this != &other) {\n            data = std::move(other.data);\n            std::cout << \"Move Assignment Operator called\" << std::endl;\n        }\n        return *this;\n    }\n\n    MyVector(const std::vector<int>& d) : data(d) {}\n};\n\nint main() {\n    MyVector v1{std::vector<int>{1, 2, 3}};\n    MyVector v2{std::vector<int>{4, 5, 6}};\n    v2 = std::move(v1); // 调用移动赋值运算符\n    return 0;\n}\n```\n\n### 3.3 `std::move`\n`std::move` 将一个左值转换为右值引用，以便调用移动构造函数或移动赋值运算符。\n\n```cpp\n#include <iostream>\n#include <vector>\n\nclass MyVector {\npublic:\n    std::vector<int> data;\n\n    MyVector(MyVector&& other) noexcept : data(std::move(other.data)) {\n        std::cout << \"Move Constructor called\" << std::endl;\n    }\n\n    MyVector(const std::vector<int>& d) : data(d) {}\n};\n\nint main() {\n    MyVector v1{std::vector<int>{1, 2, 3}};\n    MyVector v2 = std::move(v1); // 使用 std::move 调用移动构造函数\n    return 0;\n}\n```\n\n---\n\n## 4. 完美转发 (Perfect Forwarding)\n\n### 4.1 问题背景\n在模板编程中，如何将参数的值类别（左值或右值）保持不变地传递给其他函数。\n\n### 4.2 `std::forward`\n`std::forward` 在模板中保持参数的值类别，实现完美转发。\n\n```cpp\n#include <iostream>\n#include <utility>\n\nvoid print(int& x) {\n    std::cout << \"Lvalue: \" << x << std::endl;\n}\n\nvoid print(int&& x) {\n    std::cout << \"Rvalue: \" << x << std::endl;\n}\n\ntemplate <typename T>\nvoid wrapper(T&& arg) {\n    print(std::forward<T>(arg)); // 完美转发\n}\n\nint main() {\n    int a = 10;\n    wrapper(a);  // 调用 print(int&)\n    wrapper(20); // 调用 print(int&&)\n    return 0;\n}\n```\n\n### 4.3 引用折叠 (Reference Collapsing)\n引用折叠规则：\n- `T& &` 折叠为 `T&`\n- `T& &&` 折叠为 `T&`\n- `T&& &` 折叠为 `T&`\n- `T&& &&` 折叠为 `T&&`\n\n---\n\n## 5. 特殊成员函数与规则\n\n### 5.1 特殊成员函数\n- **移动构造函数**：`ClassName(ClassName&&);`\n- **移动赋值运算符**：`ClassName& operator=(ClassName&&);`\n\n### 5.2 编译器生成的移动操作\n如果用户显式定义了拷贝构造函数、拷贝赋值运算符或析构函数，编译器不会自动生成移动操作。\n\n```cpp\n#include <iostream>\n\nclass NoMove {\npublic:\n    NoMove() = default;\n    NoMove(const NoMove&) { std::cout << \"Copy Constructor\" << std::endl; }\n    NoMove& operator=(const NoMove&) { std::cout << \"Copy Assignment\" << std::endl; return *this; }\n};\n\nint main() {\n    NoMove a;\n    NoMove b = std::move(a); // 调用拷贝构造函数，因为移动操作未生成\n    return 0;\n}\n```\n\n### 5.3 删除的移动操作\n如果移动操作被显式删除或不可访问，对象将无法移动。\n\n```cpp\n#include <iostream>\n\nclass DeletedMove {\npublic:\n    DeletedMove() = default;\n    DeletedMove(DeletedMove&&) = delete; // 显式删除移动构造函数\n};\n\nint main() {\n    DeletedMove a;\n    // DeletedMove b = std::move(a); // 错误：移动构造函数被删除\n    return 0;\n}\n```\n\n---\n\n## 6. 右值语义的应用场景\n\n### 6.1 资源管理类\n在自定义的资源管理类中，使用移动语义避免不必要的资源拷贝。\n\n```cpp\n#include <iostream>\n#include <memory>\n\nclass Resource {\npublic:\n    std::unique_ptr<int> ptr;\n\n    Resource(int value) : ptr(std::make_unique<int>(value)) {}\n\n    Resource(Resource&& other) noexcept : ptr(std::move(other.ptr)) {\n        std::cout << \"Resource moved\" << std::endl;\n    }\n};\n\nint main() {\n    Resource r1(42);\n    Resource r2 = std::move(r1); // 移动资源\n    return 0;\n}\n```\n\n### 6.2 标准库中的右值语义\n`std::unique_ptr`、`std::vector` 等标准库容器和智能指针广泛使用右值语义。\n\n```cpp\n#include <iostream>\n#include <vector>\n\nint main() {\n    std::vector<int> v1{1, 2, 3};\n    std::vector<int> v2 = std::move(v1); // 移动 vector\n    std::cout << \"v2 size: \" << v2.size() << std::endl;\n    return 0;\n}\n```\n\n### 6.3 函数返回值优化 (RVO) 与移动语义\n在函数返回值时，编译器可能使用 RVO 或移动语义优化性能。\n\n```cpp\n#include <iostream>\n#include <vector>\n\nstd::vector<int> createVector() {\n    std::vector<int> v{1, 2, 3};\n    return v; // 可能触发 RVO 或移动语义\n}\n\nint main() {\n    std::vector<int> v = createVector();\n    std::cout << \"v size: \" << v.size() << std::endl;\n    return 0;\n}\n```\n\n---\n\n## 7. 常见问题与注意事项\n\n### 7.1 移动后对象的状态\n移动后的对象处于有效但未定义的状态，通常不应再使用。\n\n```cpp\n#include <iostream>\n#include <vector>\n\nint main() {\n    std::vector<int> v1{1, 2, 3};\n    std::vector<int> v2 = std::move(v1);\n    // v1.size(); // 未定义行为，v1 已被移动\n    return 0;\n}\n```\n\n### 7.2 避免不必要的 `std::move`\n在返回局部变量时，编译器会自动选择移动或拷贝，无需显式调用 `std::move`。\n\n```cpp\n#include <iostream>\n#include <vector>\n\nstd::vector<int> createVector() {\n    std::vector<int> v{1, 2, 3};\n    return std::move(v); // 不必要的 std::move\n}\n\nint main() {\n    std::vector<int> v = createVector();\n    std::cout << \"v size: \" << v.size() << std::endl;\n    return 0;\n}\n```\n\n### 7.3 右值引用的陷阱\n右值引用本身是左值，因此需要使用 `std::move` 或 `std::forward` 来保持其右值特性。\n\n```cpp\n#include <iostream>\n\nvoid print(int&& x) {\n    std::cout << \"Rvalue: \" << x << std::endl;\n}\n\nint main() {\n    int&& r = 42;\n    // print(r); // 错误：r 是左值\n    print(std::move(r)); // 正确\n    return 0;\n}\n```\n\n---\n\n## 8.为什么需要右值\n\n\n\n在 C++ 中，右值（Rvalue）是一个非常重要的概念，它的引入主要是为了解决以下几个核心问题：\n\n---\n\n### 8.1 避免不必要的拷贝\n\n在传统的 C++ 中，对象的拷贝操作可能会带来性能问题，尤其是在处理大对象或资源密集型对象时。例如，当你将一个对象从一个地方移动到另一个地方时，如果使用拷贝操作，会浪费大量的时间和资源。\n\n#### 例子：\n```cpp\n#include <iostream>\n#include <vector>\n\nstd::vector<int> createVector() {\n    std::vector<int> v{1, 2, 3, 4, 5};\n    return v; // 返回局部对象\n}\n\nint main() {\n    std::vector<int> v = createVector(); // 拷贝构造\n    std::cout << \"v size: \" << v.size() << std::endl;\n    return 0;\n}\n```\n\n在这个例子中，`createVector` 返回一个局部对象 `v`，如果编译器没有优化（如 RVO 或 NRVO），那么 `v` 会被拷贝到 `main` 中的 `v`。对于大对象来说，拷贝操作的代价非常高。\n\n**右值的引入**：通过右值引用和移动语义，可以将对象的资源“移动”到目标对象，而不是拷贝，从而避免不必要的开销。\n\n---\n\n### 8.2 支持移动语义\n\n移动语义是 C++11 引入的一个重要特性，它允许将资源从一个对象“移动”到另一个对象，而不是拷贝。移动语义的核心是右值引用（`T&&`）。\n\n#### 例子：\n```cpp\n#include <iostream>\n#include <vector>\n\nclass MyVector {\npublic:\n    std::vector<int> data;\n\n    // 移动构造函数\n    MyVector(MyVector&& other) noexcept : data(std::move(other.data)) {\n        std::cout << \"Move Constructor called\" << std::endl;\n    }\n\n    MyVector(const std::vector<int>& d) : data(d) {}\n};\n\nint main() {\n    MyVector v1{std::vector<int>{1, 2, 3}};\n    MyVector v2 = std::move(v1); // 调用移动构造函数\n    return 0;\n}\n```\n\n在这个例子中，`v1` 的资源被“移动”到 `v2`，而不是拷贝。移动操作的代价非常低，通常只是指针的交换。\n\n---\n\n### 8.3 支持完美转发\n\n在模板编程中，函数参数的值类别（左值或右值）可能会丢失，导致无法正确地传递参数。完美转发（Perfect Forwarding）通过右值引用和 `std::forward` 解决了这个问题。\n\n#### 例子：\n```cpp\n#include <iostream>\n#include <utility>\n\nvoid print(int& x) {\n    std::cout << \"Lvalue: \" << x << std::endl;\n}\n\nvoid print(int&& x) {\n    std::cout << \"Rvalue: \" << x << std::endl;\n}\n\ntemplate <typename T>\nvoid wrapper(T&& arg) {\n    print(std::forward<T>(arg)); // 完美转发\n}\n\nint main() {\n    int a = 10;\n    wrapper(a);  // 调用 print(int&)\n    wrapper(20); // 调用 print(int&&)\n    return 0;\n}\n```\n\n在这个例子中，`wrapper` 函数能够正确地转发参数的值类别，无论是左值还是右值。\n\n---\n\n### 8.4 优化资源管理\n\n在资源管理类（如智能指针、文件句柄等）中，右值引用和移动语义可以显著提高性能。例如，`std::unique_ptr` 是一个典型的例子，它只能通过移动语义来传递所有权，而不能拷贝。\n\n#### 例子：\n```cpp\n#include <iostream>\n#include <memory>\n\nclass Resource {\npublic:\n    std::unique_ptr<int> ptr;\n\n    Resource(int value) : ptr(std::make_unique<int>(value)) {}\n\n    Resource(Resource&& other) noexcept : ptr(std::move(other.ptr)) {\n        std::cout << \"Resource moved\" << std::endl;\n    }\n};\n\nint main() {\n    Resource r1(42);\n    Resource r2 = std::move(r1); // 移动资源\n    return 0;\n}\n```\n\n在这个例子中，`std::unique_ptr` 的资源被移动到 `r2`，而不是拷贝。这确保了资源的唯一所有权。\n\n---\n\n### 8.5 提高代码的表达能力\n\n右值引用的引入使得 C++ 的表达能力更强。通过移动语义和完美转发，开发者可以编写更高效、更简洁的代码。例如，标准库中的容器（如 `std::vector`）和算法（如 `std::sort`）都广泛使用了右值语义。\n\n#### 例子：\n```cpp\n#include <iostream>\n#include <vector>\n\nint main() {\n    std::vector<int> v1{1, 2, 3};\n    std::vector<int> v2 = std::move(v1); // 移动 vector\n    std::cout << \"v2 size: \" << v2.size() << std::endl;\n    return 0;\n}\n```\n\n在这个例子中，`v1` 的资源被移动到 `v2`，而不是拷贝。这使得代码更加高效。\n\n---\n\n### 8.6 解决临时对象的资源浪费\n\n在传统的 C++ 中，临时对象（如函数返回值）的生命周期很短，但它们的资源可能会被浪费。通过右值引用和移动语义，可以有效地利用这些临时对象的资源。\n\n#### 例子：\n```cpp\n#include <iostream>\n#include <vector>\n\nstd::vector<int> createVector() {\n    std::vector<int> v{1, 2, 3};\n    return v; // 返回局部对象\n}\n\nint main() {\n    std::vector<int> v = createVector(); // 可能触发 RVO 或移动语义\n    std::cout << \"v size: \" << v.size() << std::endl;\n    return 0;\n}\n```\n\n在这个例子中，`createVector` 返回的临时对象 `v` 的资源被移动到 `main` 中的 `v`，而不是拷贝。\n\n---\n\n## 9.总结\n\n右值的引入解决了以下几个核心问题：\n1. **避免不必要的拷贝**：通过移动语义，减少大对象或资源密集型对象的拷贝开销。\n2. **支持移动语义**：允许将资源从一个对象“移动”到另一个对象，而不是拷贝。\n3. **支持完美转发**：在模板编程中，保持参数的值类别，确保参数能够正确传递。\n4. **优化资源管理**：在智能指针和资源管理类中，确保资源的唯一所有权。\n5. **提高代码的表达能力**：使代码更加高效、简洁。\n6. **解决临时对象的资源浪费**：利用临时对象的资源，避免浪费。\n\n通过右值引用和移动语义，C++ 的性能和表达能力得到了显著提升，使得现代 C++ 代码更加高效和现代化。\n\n![公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","slug":"开发/cpp/C++001：C++右值语义详解：从基础到实战","published":1,"updated":"2024-12-26T06:37:36.909Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3h000ihghi9p974qxc","content":"<h1 id=\"C-右值语义详解：从基础到实战\"><a href=\"#C-右值语义详解：从基础到实战\" class=\"headerlink\" title=\"C++ 右值语义详解：从基础到实战\"></a>C++ 右值语义详解：从基础到实战</h1><p>在现代 C++ 中，右值语义是一个非常重要的概念，它涉及到右值引用、移动语义、完美转发等核心特性。本文将结合代码实例，详细讲解与右值语义相关的所有知识点，帮助你全面掌握这一主题。</p>\n<h2 id=\"1-左值与右值的基本概念\"><a href=\"#1-左值与右值的基本概念\" class=\"headerlink\" title=\"1. 左值与右值的基本概念\"></a>1. 左值与右值的基本概念</h2><h3 id=\"1-1-左值-Lvalue\"><a href=\"#1-1-左值-Lvalue\" class=\"headerlink\" title=\"1.1 左值 (Lvalue)\"></a>1.1 左值 (Lvalue)</h3><p>左值是可以取地址的表达式，通常表示一个对象或变量。左值具有持久性，可以被赋值。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> a = <span class=\"hljs-number\">10</span>; <span class=\"hljs-comment\">// &#x27;a&#x27; 是一个左值</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Address of a: &quot;</span> &lt;&lt; &amp;a &lt;&lt; std::endl; <span class=\"hljs-comment\">// 可以取地址</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"1-2-右值-Rvalue\"><a href=\"#1-2-右值-Rvalue\" class=\"headerlink\" title=\"1.2 右值 (Rvalue)\"></a>1.2 右值 (Rvalue)</h3><p>右值是不能取地址的表达式，通常是<strong>临时对象或字面量</strong>。右值具有<strong>短暂性</strong>，不能被赋值。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span>&amp;&amp; r = <span class=\"hljs-number\">42</span>; <span class=\"hljs-comment\">// &#x27;42&#x27; 是一个右值</span><br>    <span class=\"hljs-comment\">// std::cout &lt;&lt; &quot;Address of 42: &quot; &lt;&lt; &amp;42 &lt;&lt; std::endl; // 错误：不能取地址</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"1-3-纯右值-PRvalue-与将亡值-Xvalue\"><a href=\"#1-3-纯右值-PRvalue-与将亡值-Xvalue\" class=\"headerlink\" title=\"1.3 纯右值 (PRvalue) 与将亡值 (Xvalue)\"></a>1.3 纯右值 (PRvalue) 与将亡值 (Xvalue)</h3><ul>\n<li><strong>纯右值</strong>：临时对象或字面量，如 <code>42</code>、<code>std::string(&quot;hello&quot;)</code>。</li>\n<li><strong>将亡值</strong>：即将被销毁的对象，通常是右值引用的结果，如 <code>std::move(x)</code>。</li>\n</ul>\n<hr>\n<h2 id=\"2-右值引用-Rvalue-Reference\"><a href=\"#2-右值引用-Rvalue-Reference\" class=\"headerlink\" title=\"2. 右值引用 (Rvalue Reference)\"></a>2. 右值引用 (Rvalue Reference)</h2><h3 id=\"2-1-右值引用的语法\"><a href=\"#2-1-右值引用的语法\" class=\"headerlink\" title=\"2.1 右值引用的语法\"></a>2.1 右值引用的语法</h3><p>右值引用使用 <code>T&amp;&amp;</code> 语法，表示对右值的引用。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span>&amp;&amp; r = <span class=\"hljs-number\">42</span>; <span class=\"hljs-comment\">// 右值引用</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;r = &quot;</span> &lt;&lt; r &lt;&lt; std::endl;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"2-2-右值引用的作用\"><a href=\"#2-2-右值引用的作用\" class=\"headerlink\" title=\"2.2 右值引用的作用\"></a>2.2 右值引用的作用</h3><p>右值引用主要用于支持移动语义和完美转发。</p>\n<hr>\n<h2 id=\"3-移动语义-Move-Semantics\"><a href=\"#3-移动语义-Move-Semantics\" class=\"headerlink\" title=\"3. 移动语义 (Move Semantics)\"></a>3. 移动语义 (Move Semantics)</h2><h3 id=\"3-1-移动构造函数-Move-Constructor\"><a href=\"#3-1-移动构造函数-Move-Constructor\" class=\"headerlink\" title=\"3.1 移动构造函数 (Move Constructor)\"></a>3.1 移动构造函数 (Move Constructor)</h3><p>移动构造函数接受一个右值引用参数，用于将资源从一个对象“移动”到新对象。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyVector</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; data;<br><br>    <span class=\"hljs-comment\">// 移动构造函数</span><br>    <span class=\"hljs-built_in\">MyVector</span>(MyVector&amp;&amp; other) <span class=\"hljs-keyword\">noexcept</span> : <span class=\"hljs-built_in\">data</span>(std::<span class=\"hljs-built_in\">move</span>(other.data)) &#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Move Constructor called&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br><br>    <span class=\"hljs-built_in\">MyVector</span>(<span class=\"hljs-type\">const</span> std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; d) : <span class=\"hljs-built_in\">data</span>(d) &#123;&#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    MyVector v1&#123;std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;&#125;;<br>    MyVector v2 = std::<span class=\"hljs-built_in\">move</span>(v1); <span class=\"hljs-comment\">// 调用移动构造函数</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"3-2-移动赋值运算符-Move-Assignment-Operator\"><a href=\"#3-2-移动赋值运算符-Move-Assignment-Operator\" class=\"headerlink\" title=\"3.2 移动赋值运算符 (Move Assignment Operator)\"></a>3.2 移动赋值运算符 (Move Assignment Operator)</h3><p>移动赋值运算符接受一个右值引用参数，用于将资源从一个对象“移动”到现有对象。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyVector</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; data;<br><br>    <span class=\"hljs-comment\">// 移动赋值运算符</span><br>    MyVector&amp; <span class=\"hljs-keyword\">operator</span>=(MyVector&amp;&amp; other) <span class=\"hljs-keyword\">noexcept</span> &#123;<br>        <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-keyword\">this</span> != &amp;other) &#123;<br>            data = std::<span class=\"hljs-built_in\">move</span>(other.data);<br>            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Move Assignment Operator called&quot;</span> &lt;&lt; std::endl;<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> *<span class=\"hljs-keyword\">this</span>;<br>    &#125;<br><br>    <span class=\"hljs-built_in\">MyVector</span>(<span class=\"hljs-type\">const</span> std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; d) : <span class=\"hljs-built_in\">data</span>(d) &#123;&#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    MyVector v1&#123;std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;&#125;;<br>    MyVector v2&#123;std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&#123;<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">6</span>&#125;&#125;;<br>    v2 = std::<span class=\"hljs-built_in\">move</span>(v1); <span class=\"hljs-comment\">// 调用移动赋值运算符</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"3-3-std-move\"><a href=\"#3-3-std-move\" class=\"headerlink\" title=\"3.3 std::move\"></a>3.3 <code>std::move</code></h3><p><code>std::move</code> 将一个左值转换为右值引用，以便调用移动构造函数或移动赋值运算符。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyVector</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; data;<br><br>    <span class=\"hljs-built_in\">MyVector</span>(MyVector&amp;&amp; other) <span class=\"hljs-keyword\">noexcept</span> : <span class=\"hljs-built_in\">data</span>(std::<span class=\"hljs-built_in\">move</span>(other.data)) &#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Move Constructor called&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br><br>    <span class=\"hljs-built_in\">MyVector</span>(<span class=\"hljs-type\">const</span> std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; d) : <span class=\"hljs-built_in\">data</span>(d) &#123;&#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    MyVector v1&#123;std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;&#125;;<br>    MyVector v2 = std::<span class=\"hljs-built_in\">move</span>(v1); <span class=\"hljs-comment\">// 使用 std::move 调用移动构造函数</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"4-完美转发-Perfect-Forwarding\"><a href=\"#4-完美转发-Perfect-Forwarding\" class=\"headerlink\" title=\"4. 完美转发 (Perfect Forwarding)\"></a>4. 完美转发 (Perfect Forwarding)</h2><h3 id=\"4-1-问题背景\"><a href=\"#4-1-问题背景\" class=\"headerlink\" title=\"4.1 问题背景\"></a>4.1 问题背景</h3><p>在模板编程中，如何将参数的值类别（左值或右值）保持不变地传递给其他函数。</p>\n<h3 id=\"4-2-std-forward\"><a href=\"#4-2-std-forward\" class=\"headerlink\" title=\"4.2 std::forward\"></a>4.2 <code>std::forward</code></h3><p><code>std::forward</code> 在模板中保持参数的值类别，实现完美转发。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;utility&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">print</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span>&amp; x)</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Lvalue: &quot;</span> &lt;&lt; x &lt;&lt; std::endl;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">print</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span>&amp;&amp; x)</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Rvalue: &quot;</span> &lt;&lt; x &lt;&lt; std::endl;<br>&#125;<br><br><span class=\"hljs-keyword\">template</span> &lt;<span class=\"hljs-keyword\">typename</span> T&gt;<br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">wrapper</span><span class=\"hljs-params\">(T&amp;&amp; arg)</span> </span>&#123;<br>    <span class=\"hljs-built_in\">print</span>(std::forward&lt;T&gt;(arg)); <span class=\"hljs-comment\">// 完美转发</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> a = <span class=\"hljs-number\">10</span>;<br>    <span class=\"hljs-built_in\">wrapper</span>(a);  <span class=\"hljs-comment\">// 调用 print(int&amp;)</span><br>    <span class=\"hljs-built_in\">wrapper</span>(<span class=\"hljs-number\">20</span>); <span class=\"hljs-comment\">// 调用 print(int&amp;&amp;)</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"4-3-引用折叠-Reference-Collapsing\"><a href=\"#4-3-引用折叠-Reference-Collapsing\" class=\"headerlink\" title=\"4.3 引用折叠 (Reference Collapsing)\"></a>4.3 引用折叠 (Reference Collapsing)</h3><p>引用折叠规则：</p>\n<ul>\n<li><code>T&amp; &amp;</code> 折叠为 <code>T&amp;</code></li>\n<li><code>T&amp; &amp;&amp;</code> 折叠为 <code>T&amp;</code></li>\n<li><code>T&amp;&amp; &amp;</code> 折叠为 <code>T&amp;</code></li>\n<li><code>T&amp;&amp; &amp;&amp;</code> 折叠为 <code>T&amp;&amp;</code></li>\n</ul>\n<hr>\n<h2 id=\"5-特殊成员函数与规则\"><a href=\"#5-特殊成员函数与规则\" class=\"headerlink\" title=\"5. 特殊成员函数与规则\"></a>5. 特殊成员函数与规则</h2><h3 id=\"5-1-特殊成员函数\"><a href=\"#5-1-特殊成员函数\" class=\"headerlink\" title=\"5.1 特殊成员函数\"></a>5.1 特殊成员函数</h3><ul>\n<li><strong>移动构造函数</strong>：<code>ClassName(ClassName&amp;&amp;);</code></li>\n<li><strong>移动赋值运算符</strong>：<code>ClassName&amp; operator=(ClassName&amp;&amp;);</code></li>\n</ul>\n<h3 id=\"5-2-编译器生成的移动操作\"><a href=\"#5-2-编译器生成的移动操作\" class=\"headerlink\" title=\"5.2 编译器生成的移动操作\"></a>5.2 编译器生成的移动操作</h3><p>如果用户显式定义了拷贝构造函数、拷贝赋值运算符或析构函数，编译器不会自动生成移动操作。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">NoMove</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">NoMove</span>() = <span class=\"hljs-keyword\">default</span>;<br>    <span class=\"hljs-built_in\">NoMove</span>(<span class=\"hljs-type\">const</span> NoMove&amp;) &#123; std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Copy Constructor&quot;</span> &lt;&lt; std::endl; &#125;<br>    NoMove&amp; <span class=\"hljs-keyword\">operator</span>=(<span class=\"hljs-type\">const</span> NoMove&amp;) &#123; std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Copy Assignment&quot;</span> &lt;&lt; std::endl; <span class=\"hljs-keyword\">return</span> *<span class=\"hljs-keyword\">this</span>; &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    NoMove a;<br>    NoMove b = std::<span class=\"hljs-built_in\">move</span>(a); <span class=\"hljs-comment\">// 调用拷贝构造函数，因为移动操作未生成</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"5-3-删除的移动操作\"><a href=\"#5-3-删除的移动操作\" class=\"headerlink\" title=\"5.3 删除的移动操作\"></a>5.3 删除的移动操作</h3><p>如果移动操作被显式删除或不可访问，对象将无法移动。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">DeletedMove</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">DeletedMove</span>() = <span class=\"hljs-keyword\">default</span>;<br>    <span class=\"hljs-built_in\">DeletedMove</span>(DeletedMove&amp;&amp;) = <span class=\"hljs-keyword\">delete</span>; <span class=\"hljs-comment\">// 显式删除移动构造函数</span><br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    DeletedMove a;<br>    <span class=\"hljs-comment\">// DeletedMove b = std::move(a); // 错误：移动构造函数被删除</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"6-右值语义的应用场景\"><a href=\"#6-右值语义的应用场景\" class=\"headerlink\" title=\"6. 右值语义的应用场景\"></a>6. 右值语义的应用场景</h2><h3 id=\"6-1-资源管理类\"><a href=\"#6-1-资源管理类\" class=\"headerlink\" title=\"6.1 资源管理类\"></a>6.1 资源管理类</h3><p>在自定义的资源管理类中，使用移动语义避免不必要的资源拷贝。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;memory&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Resource</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    std::unique_ptr&lt;<span class=\"hljs-type\">int</span>&gt; ptr;<br><br>    <span class=\"hljs-built_in\">Resource</span>(<span class=\"hljs-type\">int</span> value) : <span class=\"hljs-built_in\">ptr</span>(std::<span class=\"hljs-built_in\">make_unique</span>&lt;<span class=\"hljs-type\">int</span>&gt;(value)) &#123;&#125;<br><br>    <span class=\"hljs-built_in\">Resource</span>(Resource&amp;&amp; other) <span class=\"hljs-keyword\">noexcept</span> : <span class=\"hljs-built_in\">ptr</span>(std::<span class=\"hljs-built_in\">move</span>(other.ptr)) &#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Resource moved&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-function\">Resource <span class=\"hljs-title\">r1</span><span class=\"hljs-params\">(<span class=\"hljs-number\">42</span>)</span></span>;<br>    Resource r2 = std::<span class=\"hljs-built_in\">move</span>(r1); <span class=\"hljs-comment\">// 移动资源</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"6-2-标准库中的右值语义\"><a href=\"#6-2-标准库中的右值语义\" class=\"headerlink\" title=\"6.2 标准库中的右值语义\"></a>6.2 标准库中的右值语义</h3><p><code>std::unique_ptr</code>、<code>std::vector</code> 等标准库容器和智能指针广泛使用右值语义。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v1&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v2 = std::<span class=\"hljs-built_in\">move</span>(v1); <span class=\"hljs-comment\">// 移动 vector</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;v2 size: &quot;</span> &lt;&lt; v<span class=\"hljs-number\">2.</span><span class=\"hljs-built_in\">size</span>() &lt;&lt; std::endl;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"6-3-函数返回值优化-RVO-与移动语义\"><a href=\"#6-3-函数返回值优化-RVO-与移动语义\" class=\"headerlink\" title=\"6.3 函数返回值优化 (RVO) 与移动语义\"></a>6.3 函数返回值优化 (RVO) 与移动语义</h3><p>在函数返回值时，编译器可能使用 RVO 或移动语义优化性能。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-function\">std::vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">createVector</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;;<br>    <span class=\"hljs-keyword\">return</span> v; <span class=\"hljs-comment\">// 可能触发 RVO 或移动语义</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v = <span class=\"hljs-built_in\">createVector</span>();<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;v size: &quot;</span> &lt;&lt; v.<span class=\"hljs-built_in\">size</span>() &lt;&lt; std::endl;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"7-常见问题与注意事项\"><a href=\"#7-常见问题与注意事项\" class=\"headerlink\" title=\"7. 常见问题与注意事项\"></a>7. 常见问题与注意事项</h2><h3 id=\"7-1-移动后对象的状态\"><a href=\"#7-1-移动后对象的状态\" class=\"headerlink\" title=\"7.1 移动后对象的状态\"></a>7.1 移动后对象的状态</h3><p>移动后的对象处于有效但未定义的状态，通常不应再使用。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v1&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v2 = std::<span class=\"hljs-built_in\">move</span>(v1);<br>    <span class=\"hljs-comment\">// v1.size(); // 未定义行为，v1 已被移动</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"7-2-避免不必要的-std-move\"><a href=\"#7-2-避免不必要的-std-move\" class=\"headerlink\" title=\"7.2 避免不必要的 std::move\"></a>7.2 避免不必要的 <code>std::move</code></h3><p>在返回局部变量时，编译器会自动选择移动或拷贝，无需显式调用 <code>std::move</code>。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-function\">std::vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">createVector</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;;<br>    <span class=\"hljs-keyword\">return</span> std::<span class=\"hljs-built_in\">move</span>(v); <span class=\"hljs-comment\">// 不必要的 std::move</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v = <span class=\"hljs-built_in\">createVector</span>();<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;v size: &quot;</span> &lt;&lt; v.<span class=\"hljs-built_in\">size</span>() &lt;&lt; std::endl;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"7-3-右值引用的陷阱\"><a href=\"#7-3-右值引用的陷阱\" class=\"headerlink\" title=\"7.3 右值引用的陷阱\"></a>7.3 右值引用的陷阱</h3><p>右值引用本身是左值，因此需要使用 <code>std::move</code> 或 <code>std::forward</code> 来保持其右值特性。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">print</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span>&amp;&amp; x)</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Rvalue: &quot;</span> &lt;&lt; x &lt;&lt; std::endl;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span>&amp;&amp; r = <span class=\"hljs-number\">42</span>;<br>    <span class=\"hljs-comment\">// print(r); // 错误：r 是左值</span><br>    <span class=\"hljs-built_in\">print</span>(std::<span class=\"hljs-built_in\">move</span>(r)); <span class=\"hljs-comment\">// 正确</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"8-为什么需要右值\"><a href=\"#8-为什么需要右值\" class=\"headerlink\" title=\"8.为什么需要右值\"></a>8.为什么需要右值</h2><p>在 C++ 中，右值（Rvalue）是一个非常重要的概念，它的引入主要是为了解决以下几个核心问题：</p>\n<hr>\n<h3 id=\"8-1-避免不必要的拷贝\"><a href=\"#8-1-避免不必要的拷贝\" class=\"headerlink\" title=\"8.1 避免不必要的拷贝\"></a>8.1 避免不必要的拷贝</h3><p>在传统的 C++ 中，对象的拷贝操作可能会带来性能问题，尤其是在处理大对象或资源密集型对象时。例如，当你将一个对象从一个地方移动到另一个地方时，如果使用拷贝操作，会浪费大量的时间和资源。</p>\n<h4 id=\"例子：\"><a href=\"#例子：\" class=\"headerlink\" title=\"例子：\"></a>例子：</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-function\">std::vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">createVector</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">5</span>&#125;;<br>    <span class=\"hljs-keyword\">return</span> v; <span class=\"hljs-comment\">// 返回局部对象</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v = <span class=\"hljs-built_in\">createVector</span>(); <span class=\"hljs-comment\">// 拷贝构造</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;v size: &quot;</span> &lt;&lt; v.<span class=\"hljs-built_in\">size</span>() &lt;&lt; std::endl;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，<code>createVector</code> 返回一个局部对象 <code>v</code>，如果编译器没有优化（如 RVO 或 NRVO），那么 <code>v</code> 会被拷贝到 <code>main</code> 中的 <code>v</code>。对于大对象来说，拷贝操作的代价非常高。</p>\n<p><strong>右值的引入</strong>：通过右值引用和移动语义，可以将对象的资源“移动”到目标对象，而不是拷贝，从而避免不必要的开销。</p>\n<hr>\n<h3 id=\"8-2-支持移动语义\"><a href=\"#8-2-支持移动语义\" class=\"headerlink\" title=\"8.2 支持移动语义\"></a>8.2 支持移动语义</h3><p>移动语义是 C++11 引入的一个重要特性，它允许将资源从一个对象“移动”到另一个对象，而不是拷贝。移动语义的核心是右值引用（<code>T&amp;&amp;</code>）。</p>\n<h4 id=\"例子：-1\"><a href=\"#例子：-1\" class=\"headerlink\" title=\"例子：\"></a>例子：</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyVector</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; data;<br><br>    <span class=\"hljs-comment\">// 移动构造函数</span><br>    <span class=\"hljs-built_in\">MyVector</span>(MyVector&amp;&amp; other) <span class=\"hljs-keyword\">noexcept</span> : <span class=\"hljs-built_in\">data</span>(std::<span class=\"hljs-built_in\">move</span>(other.data)) &#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Move Constructor called&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br><br>    <span class=\"hljs-built_in\">MyVector</span>(<span class=\"hljs-type\">const</span> std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; d) : <span class=\"hljs-built_in\">data</span>(d) &#123;&#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    MyVector v1&#123;std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;&#125;;<br>    MyVector v2 = std::<span class=\"hljs-built_in\">move</span>(v1); <span class=\"hljs-comment\">// 调用移动构造函数</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，<code>v1</code> 的资源被“移动”到 <code>v2</code>，而不是拷贝。移动操作的代价非常低，通常只是指针的交换。</p>\n<hr>\n<h3 id=\"8-3-支持完美转发\"><a href=\"#8-3-支持完美转发\" class=\"headerlink\" title=\"8.3 支持完美转发\"></a>8.3 支持完美转发</h3><p>在模板编程中，函数参数的值类别（左值或右值）可能会丢失，导致无法正确地传递参数。完美转发（Perfect Forwarding）通过右值引用和 <code>std::forward</code> 解决了这个问题。</p>\n<h4 id=\"例子：-2\"><a href=\"#例子：-2\" class=\"headerlink\" title=\"例子：\"></a>例子：</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;utility&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">print</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span>&amp; x)</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Lvalue: &quot;</span> &lt;&lt; x &lt;&lt; std::endl;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">print</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span>&amp;&amp; x)</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Rvalue: &quot;</span> &lt;&lt; x &lt;&lt; std::endl;<br>&#125;<br><br><span class=\"hljs-keyword\">template</span> &lt;<span class=\"hljs-keyword\">typename</span> T&gt;<br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">wrapper</span><span class=\"hljs-params\">(T&amp;&amp; arg)</span> </span>&#123;<br>    <span class=\"hljs-built_in\">print</span>(std::forward&lt;T&gt;(arg)); <span class=\"hljs-comment\">// 完美转发</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> a = <span class=\"hljs-number\">10</span>;<br>    <span class=\"hljs-built_in\">wrapper</span>(a);  <span class=\"hljs-comment\">// 调用 print(int&amp;)</span><br>    <span class=\"hljs-built_in\">wrapper</span>(<span class=\"hljs-number\">20</span>); <span class=\"hljs-comment\">// 调用 print(int&amp;&amp;)</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，<code>wrapper</code> 函数能够正确地转发参数的值类别，无论是左值还是右值。</p>\n<hr>\n<h3 id=\"8-4-优化资源管理\"><a href=\"#8-4-优化资源管理\" class=\"headerlink\" title=\"8.4 优化资源管理\"></a>8.4 优化资源管理</h3><p>在资源管理类（如智能指针、文件句柄等）中，右值引用和移动语义可以显著提高性能。例如，<code>std::unique_ptr</code> 是一个典型的例子，它只能通过移动语义来传递所有权，而不能拷贝。</p>\n<h4 id=\"例子：-3\"><a href=\"#例子：-3\" class=\"headerlink\" title=\"例子：\"></a>例子：</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;memory&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Resource</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    std::unique_ptr&lt;<span class=\"hljs-type\">int</span>&gt; ptr;<br><br>    <span class=\"hljs-built_in\">Resource</span>(<span class=\"hljs-type\">int</span> value) : <span class=\"hljs-built_in\">ptr</span>(std::<span class=\"hljs-built_in\">make_unique</span>&lt;<span class=\"hljs-type\">int</span>&gt;(value)) &#123;&#125;<br><br>    <span class=\"hljs-built_in\">Resource</span>(Resource&amp;&amp; other) <span class=\"hljs-keyword\">noexcept</span> : <span class=\"hljs-built_in\">ptr</span>(std::<span class=\"hljs-built_in\">move</span>(other.ptr)) &#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Resource moved&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-function\">Resource <span class=\"hljs-title\">r1</span><span class=\"hljs-params\">(<span class=\"hljs-number\">42</span>)</span></span>;<br>    Resource r2 = std::<span class=\"hljs-built_in\">move</span>(r1); <span class=\"hljs-comment\">// 移动资源</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，<code>std::unique_ptr</code> 的资源被移动到 <code>r2</code>，而不是拷贝。这确保了资源的唯一所有权。</p>\n<hr>\n<h3 id=\"8-5-提高代码的表达能力\"><a href=\"#8-5-提高代码的表达能力\" class=\"headerlink\" title=\"8.5 提高代码的表达能力\"></a>8.5 提高代码的表达能力</h3><p>右值引用的引入使得 C++ 的表达能力更强。通过移动语义和完美转发，开发者可以编写更高效、更简洁的代码。例如，标准库中的容器（如 <code>std::vector</code>）和算法（如 <code>std::sort</code>）都广泛使用了右值语义。</p>\n<h4 id=\"例子：-4\"><a href=\"#例子：-4\" class=\"headerlink\" title=\"例子：\"></a>例子：</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v1&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v2 = std::<span class=\"hljs-built_in\">move</span>(v1); <span class=\"hljs-comment\">// 移动 vector</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;v2 size: &quot;</span> &lt;&lt; v<span class=\"hljs-number\">2.</span><span class=\"hljs-built_in\">size</span>() &lt;&lt; std::endl;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，<code>v1</code> 的资源被移动到 <code>v2</code>，而不是拷贝。这使得代码更加高效。</p>\n<hr>\n<h3 id=\"8-6-解决临时对象的资源浪费\"><a href=\"#8-6-解决临时对象的资源浪费\" class=\"headerlink\" title=\"8.6 解决临时对象的资源浪费\"></a>8.6 解决临时对象的资源浪费</h3><p>在传统的 C++ 中，临时对象（如函数返回值）的生命周期很短，但它们的资源可能会被浪费。通过右值引用和移动语义，可以有效地利用这些临时对象的资源。</p>\n<h4 id=\"例子：-5\"><a href=\"#例子：-5\" class=\"headerlink\" title=\"例子：\"></a>例子：</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-function\">std::vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">createVector</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;;<br>    <span class=\"hljs-keyword\">return</span> v; <span class=\"hljs-comment\">// 返回局部对象</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v = <span class=\"hljs-built_in\">createVector</span>(); <span class=\"hljs-comment\">// 可能触发 RVO 或移动语义</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;v size: &quot;</span> &lt;&lt; v.<span class=\"hljs-built_in\">size</span>() &lt;&lt; std::endl;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，<code>createVector</code> 返回的临时对象 <code>v</code> 的资源被移动到 <code>main</code> 中的 <code>v</code>，而不是拷贝。</p>\n<hr>\n<h2 id=\"9-总结\"><a href=\"#9-总结\" class=\"headerlink\" title=\"9.总结\"></a>9.总结</h2><p>右值的引入解决了以下几个核心问题：</p>\n<ol>\n<li><strong>避免不必要的拷贝</strong>：通过移动语义，减少大对象或资源密集型对象的拷贝开销。</li>\n<li><strong>支持移动语义</strong>：允许将资源从一个对象“移动”到另一个对象，而不是拷贝。</li>\n<li><strong>支持完美转发</strong>：在模板编程中，保持参数的值类别，确保参数能够正确传递。</li>\n<li><strong>优化资源管理</strong>：在智能指针和资源管理类中，确保资源的唯一所有权。</li>\n<li><strong>提高代码的表达能力</strong>：使代码更加高效、简洁。</li>\n<li><strong>解决临时对象的资源浪费</strong>：利用临时对象的资源，避免浪费。</li>\n</ol>\n<p>通过右值引用和移动语义，C++ 的性能和表达能力得到了显著提升，使得现代 C++ 代码更加高效和现代化。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"公众号\"></p>\n","excerpt":"","more":"<h1 id=\"C-右值语义详解：从基础到实战\"><a href=\"#C-右值语义详解：从基础到实战\" class=\"headerlink\" title=\"C++ 右值语义详解：从基础到实战\"></a>C++ 右值语义详解：从基础到实战</h1><p>在现代 C++ 中，右值语义是一个非常重要的概念，它涉及到右值引用、移动语义、完美转发等核心特性。本文将结合代码实例，详细讲解与右值语义相关的所有知识点，帮助你全面掌握这一主题。</p>\n<h2 id=\"1-左值与右值的基本概念\"><a href=\"#1-左值与右值的基本概念\" class=\"headerlink\" title=\"1. 左值与右值的基本概念\"></a>1. 左值与右值的基本概念</h2><h3 id=\"1-1-左值-Lvalue\"><a href=\"#1-1-左值-Lvalue\" class=\"headerlink\" title=\"1.1 左值 (Lvalue)\"></a>1.1 左值 (Lvalue)</h3><p>左值是可以取地址的表达式，通常表示一个对象或变量。左值具有持久性，可以被赋值。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> a = <span class=\"hljs-number\">10</span>; <span class=\"hljs-comment\">// &#x27;a&#x27; 是一个左值</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Address of a: &quot;</span> &lt;&lt; &amp;a &lt;&lt; std::endl; <span class=\"hljs-comment\">// 可以取地址</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"1-2-右值-Rvalue\"><a href=\"#1-2-右值-Rvalue\" class=\"headerlink\" title=\"1.2 右值 (Rvalue)\"></a>1.2 右值 (Rvalue)</h3><p>右值是不能取地址的表达式，通常是<strong>临时对象或字面量</strong>。右值具有<strong>短暂性</strong>，不能被赋值。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span>&amp;&amp; r = <span class=\"hljs-number\">42</span>; <span class=\"hljs-comment\">// &#x27;42&#x27; 是一个右值</span><br>    <span class=\"hljs-comment\">// std::cout &lt;&lt; &quot;Address of 42: &quot; &lt;&lt; &amp;42 &lt;&lt; std::endl; // 错误：不能取地址</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"1-3-纯右值-PRvalue-与将亡值-Xvalue\"><a href=\"#1-3-纯右值-PRvalue-与将亡值-Xvalue\" class=\"headerlink\" title=\"1.3 纯右值 (PRvalue) 与将亡值 (Xvalue)\"></a>1.3 纯右值 (PRvalue) 与将亡值 (Xvalue)</h3><ul>\n<li><strong>纯右值</strong>：临时对象或字面量，如 <code>42</code>、<code>std::string(&quot;hello&quot;)</code>。</li>\n<li><strong>将亡值</strong>：即将被销毁的对象，通常是右值引用的结果，如 <code>std::move(x)</code>。</li>\n</ul>\n<hr>\n<h2 id=\"2-右值引用-Rvalue-Reference\"><a href=\"#2-右值引用-Rvalue-Reference\" class=\"headerlink\" title=\"2. 右值引用 (Rvalue Reference)\"></a>2. 右值引用 (Rvalue Reference)</h2><h3 id=\"2-1-右值引用的语法\"><a href=\"#2-1-右值引用的语法\" class=\"headerlink\" title=\"2.1 右值引用的语法\"></a>2.1 右值引用的语法</h3><p>右值引用使用 <code>T&amp;&amp;</code> 语法，表示对右值的引用。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span>&amp;&amp; r = <span class=\"hljs-number\">42</span>; <span class=\"hljs-comment\">// 右值引用</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;r = &quot;</span> &lt;&lt; r &lt;&lt; std::endl;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"2-2-右值引用的作用\"><a href=\"#2-2-右值引用的作用\" class=\"headerlink\" title=\"2.2 右值引用的作用\"></a>2.2 右值引用的作用</h3><p>右值引用主要用于支持移动语义和完美转发。</p>\n<hr>\n<h2 id=\"3-移动语义-Move-Semantics\"><a href=\"#3-移动语义-Move-Semantics\" class=\"headerlink\" title=\"3. 移动语义 (Move Semantics)\"></a>3. 移动语义 (Move Semantics)</h2><h3 id=\"3-1-移动构造函数-Move-Constructor\"><a href=\"#3-1-移动构造函数-Move-Constructor\" class=\"headerlink\" title=\"3.1 移动构造函数 (Move Constructor)\"></a>3.1 移动构造函数 (Move Constructor)</h3><p>移动构造函数接受一个右值引用参数，用于将资源从一个对象“移动”到新对象。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyVector</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; data;<br><br>    <span class=\"hljs-comment\">// 移动构造函数</span><br>    <span class=\"hljs-built_in\">MyVector</span>(MyVector&amp;&amp; other) <span class=\"hljs-keyword\">noexcept</span> : <span class=\"hljs-built_in\">data</span>(std::<span class=\"hljs-built_in\">move</span>(other.data)) &#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Move Constructor called&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br><br>    <span class=\"hljs-built_in\">MyVector</span>(<span class=\"hljs-type\">const</span> std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; d) : <span class=\"hljs-built_in\">data</span>(d) &#123;&#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    MyVector v1&#123;std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;&#125;;<br>    MyVector v2 = std::<span class=\"hljs-built_in\">move</span>(v1); <span class=\"hljs-comment\">// 调用移动构造函数</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"3-2-移动赋值运算符-Move-Assignment-Operator\"><a href=\"#3-2-移动赋值运算符-Move-Assignment-Operator\" class=\"headerlink\" title=\"3.2 移动赋值运算符 (Move Assignment Operator)\"></a>3.2 移动赋值运算符 (Move Assignment Operator)</h3><p>移动赋值运算符接受一个右值引用参数，用于将资源从一个对象“移动”到现有对象。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyVector</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; data;<br><br>    <span class=\"hljs-comment\">// 移动赋值运算符</span><br>    MyVector&amp; <span class=\"hljs-keyword\">operator</span>=(MyVector&amp;&amp; other) <span class=\"hljs-keyword\">noexcept</span> &#123;<br>        <span class=\"hljs-keyword\">if</span> (<span class=\"hljs-keyword\">this</span> != &amp;other) &#123;<br>            data = std::<span class=\"hljs-built_in\">move</span>(other.data);<br>            std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Move Assignment Operator called&quot;</span> &lt;&lt; std::endl;<br>        &#125;<br>        <span class=\"hljs-keyword\">return</span> *<span class=\"hljs-keyword\">this</span>;<br>    &#125;<br><br>    <span class=\"hljs-built_in\">MyVector</span>(<span class=\"hljs-type\">const</span> std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; d) : <span class=\"hljs-built_in\">data</span>(d) &#123;&#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    MyVector v1&#123;std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;&#125;;<br>    MyVector v2&#123;std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&#123;<span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">6</span>&#125;&#125;;<br>    v2 = std::<span class=\"hljs-built_in\">move</span>(v1); <span class=\"hljs-comment\">// 调用移动赋值运算符</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"3-3-std-move\"><a href=\"#3-3-std-move\" class=\"headerlink\" title=\"3.3 std::move\"></a>3.3 <code>std::move</code></h3><p><code>std::move</code> 将一个左值转换为右值引用，以便调用移动构造函数或移动赋值运算符。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyVector</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; data;<br><br>    <span class=\"hljs-built_in\">MyVector</span>(MyVector&amp;&amp; other) <span class=\"hljs-keyword\">noexcept</span> : <span class=\"hljs-built_in\">data</span>(std::<span class=\"hljs-built_in\">move</span>(other.data)) &#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Move Constructor called&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br><br>    <span class=\"hljs-built_in\">MyVector</span>(<span class=\"hljs-type\">const</span> std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; d) : <span class=\"hljs-built_in\">data</span>(d) &#123;&#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    MyVector v1&#123;std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;&#125;;<br>    MyVector v2 = std::<span class=\"hljs-built_in\">move</span>(v1); <span class=\"hljs-comment\">// 使用 std::move 调用移动构造函数</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"4-完美转发-Perfect-Forwarding\"><a href=\"#4-完美转发-Perfect-Forwarding\" class=\"headerlink\" title=\"4. 完美转发 (Perfect Forwarding)\"></a>4. 完美转发 (Perfect Forwarding)</h2><h3 id=\"4-1-问题背景\"><a href=\"#4-1-问题背景\" class=\"headerlink\" title=\"4.1 问题背景\"></a>4.1 问题背景</h3><p>在模板编程中，如何将参数的值类别（左值或右值）保持不变地传递给其他函数。</p>\n<h3 id=\"4-2-std-forward\"><a href=\"#4-2-std-forward\" class=\"headerlink\" title=\"4.2 std::forward\"></a>4.2 <code>std::forward</code></h3><p><code>std::forward</code> 在模板中保持参数的值类别，实现完美转发。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;utility&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">print</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span>&amp; x)</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Lvalue: &quot;</span> &lt;&lt; x &lt;&lt; std::endl;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">print</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span>&amp;&amp; x)</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Rvalue: &quot;</span> &lt;&lt; x &lt;&lt; std::endl;<br>&#125;<br><br><span class=\"hljs-keyword\">template</span> &lt;<span class=\"hljs-keyword\">typename</span> T&gt;<br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">wrapper</span><span class=\"hljs-params\">(T&amp;&amp; arg)</span> </span>&#123;<br>    <span class=\"hljs-built_in\">print</span>(std::forward&lt;T&gt;(arg)); <span class=\"hljs-comment\">// 完美转发</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> a = <span class=\"hljs-number\">10</span>;<br>    <span class=\"hljs-built_in\">wrapper</span>(a);  <span class=\"hljs-comment\">// 调用 print(int&amp;)</span><br>    <span class=\"hljs-built_in\">wrapper</span>(<span class=\"hljs-number\">20</span>); <span class=\"hljs-comment\">// 调用 print(int&amp;&amp;)</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"4-3-引用折叠-Reference-Collapsing\"><a href=\"#4-3-引用折叠-Reference-Collapsing\" class=\"headerlink\" title=\"4.3 引用折叠 (Reference Collapsing)\"></a>4.3 引用折叠 (Reference Collapsing)</h3><p>引用折叠规则：</p>\n<ul>\n<li><code>T&amp; &amp;</code> 折叠为 <code>T&amp;</code></li>\n<li><code>T&amp; &amp;&amp;</code> 折叠为 <code>T&amp;</code></li>\n<li><code>T&amp;&amp; &amp;</code> 折叠为 <code>T&amp;</code></li>\n<li><code>T&amp;&amp; &amp;&amp;</code> 折叠为 <code>T&amp;&amp;</code></li>\n</ul>\n<hr>\n<h2 id=\"5-特殊成员函数与规则\"><a href=\"#5-特殊成员函数与规则\" class=\"headerlink\" title=\"5. 特殊成员函数与规则\"></a>5. 特殊成员函数与规则</h2><h3 id=\"5-1-特殊成员函数\"><a href=\"#5-1-特殊成员函数\" class=\"headerlink\" title=\"5.1 特殊成员函数\"></a>5.1 特殊成员函数</h3><ul>\n<li><strong>移动构造函数</strong>：<code>ClassName(ClassName&amp;&amp;);</code></li>\n<li><strong>移动赋值运算符</strong>：<code>ClassName&amp; operator=(ClassName&amp;&amp;);</code></li>\n</ul>\n<h3 id=\"5-2-编译器生成的移动操作\"><a href=\"#5-2-编译器生成的移动操作\" class=\"headerlink\" title=\"5.2 编译器生成的移动操作\"></a>5.2 编译器生成的移动操作</h3><p>如果用户显式定义了拷贝构造函数、拷贝赋值运算符或析构函数，编译器不会自动生成移动操作。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">NoMove</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">NoMove</span>() = <span class=\"hljs-keyword\">default</span>;<br>    <span class=\"hljs-built_in\">NoMove</span>(<span class=\"hljs-type\">const</span> NoMove&amp;) &#123; std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Copy Constructor&quot;</span> &lt;&lt; std::endl; &#125;<br>    NoMove&amp; <span class=\"hljs-keyword\">operator</span>=(<span class=\"hljs-type\">const</span> NoMove&amp;) &#123; std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Copy Assignment&quot;</span> &lt;&lt; std::endl; <span class=\"hljs-keyword\">return</span> *<span class=\"hljs-keyword\">this</span>; &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    NoMove a;<br>    NoMove b = std::<span class=\"hljs-built_in\">move</span>(a); <span class=\"hljs-comment\">// 调用拷贝构造函数，因为移动操作未生成</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"5-3-删除的移动操作\"><a href=\"#5-3-删除的移动操作\" class=\"headerlink\" title=\"5.3 删除的移动操作\"></a>5.3 删除的移动操作</h3><p>如果移动操作被显式删除或不可访问，对象将无法移动。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">DeletedMove</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-built_in\">DeletedMove</span>() = <span class=\"hljs-keyword\">default</span>;<br>    <span class=\"hljs-built_in\">DeletedMove</span>(DeletedMove&amp;&amp;) = <span class=\"hljs-keyword\">delete</span>; <span class=\"hljs-comment\">// 显式删除移动构造函数</span><br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    DeletedMove a;<br>    <span class=\"hljs-comment\">// DeletedMove b = std::move(a); // 错误：移动构造函数被删除</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"6-右值语义的应用场景\"><a href=\"#6-右值语义的应用场景\" class=\"headerlink\" title=\"6. 右值语义的应用场景\"></a>6. 右值语义的应用场景</h2><h3 id=\"6-1-资源管理类\"><a href=\"#6-1-资源管理类\" class=\"headerlink\" title=\"6.1 资源管理类\"></a>6.1 资源管理类</h3><p>在自定义的资源管理类中，使用移动语义避免不必要的资源拷贝。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;memory&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Resource</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    std::unique_ptr&lt;<span class=\"hljs-type\">int</span>&gt; ptr;<br><br>    <span class=\"hljs-built_in\">Resource</span>(<span class=\"hljs-type\">int</span> value) : <span class=\"hljs-built_in\">ptr</span>(std::<span class=\"hljs-built_in\">make_unique</span>&lt;<span class=\"hljs-type\">int</span>&gt;(value)) &#123;&#125;<br><br>    <span class=\"hljs-built_in\">Resource</span>(Resource&amp;&amp; other) <span class=\"hljs-keyword\">noexcept</span> : <span class=\"hljs-built_in\">ptr</span>(std::<span class=\"hljs-built_in\">move</span>(other.ptr)) &#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Resource moved&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-function\">Resource <span class=\"hljs-title\">r1</span><span class=\"hljs-params\">(<span class=\"hljs-number\">42</span>)</span></span>;<br>    Resource r2 = std::<span class=\"hljs-built_in\">move</span>(r1); <span class=\"hljs-comment\">// 移动资源</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"6-2-标准库中的右值语义\"><a href=\"#6-2-标准库中的右值语义\" class=\"headerlink\" title=\"6.2 标准库中的右值语义\"></a>6.2 标准库中的右值语义</h3><p><code>std::unique_ptr</code>、<code>std::vector</code> 等标准库容器和智能指针广泛使用右值语义。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v1&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v2 = std::<span class=\"hljs-built_in\">move</span>(v1); <span class=\"hljs-comment\">// 移动 vector</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;v2 size: &quot;</span> &lt;&lt; v<span class=\"hljs-number\">2.</span><span class=\"hljs-built_in\">size</span>() &lt;&lt; std::endl;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"6-3-函数返回值优化-RVO-与移动语义\"><a href=\"#6-3-函数返回值优化-RVO-与移动语义\" class=\"headerlink\" title=\"6.3 函数返回值优化 (RVO) 与移动语义\"></a>6.3 函数返回值优化 (RVO) 与移动语义</h3><p>在函数返回值时，编译器可能使用 RVO 或移动语义优化性能。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-function\">std::vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">createVector</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;;<br>    <span class=\"hljs-keyword\">return</span> v; <span class=\"hljs-comment\">// 可能触发 RVO 或移动语义</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v = <span class=\"hljs-built_in\">createVector</span>();<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;v size: &quot;</span> &lt;&lt; v.<span class=\"hljs-built_in\">size</span>() &lt;&lt; std::endl;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"7-常见问题与注意事项\"><a href=\"#7-常见问题与注意事项\" class=\"headerlink\" title=\"7. 常见问题与注意事项\"></a>7. 常见问题与注意事项</h2><h3 id=\"7-1-移动后对象的状态\"><a href=\"#7-1-移动后对象的状态\" class=\"headerlink\" title=\"7.1 移动后对象的状态\"></a>7.1 移动后对象的状态</h3><p>移动后的对象处于有效但未定义的状态，通常不应再使用。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v1&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v2 = std::<span class=\"hljs-built_in\">move</span>(v1);<br>    <span class=\"hljs-comment\">// v1.size(); // 未定义行为，v1 已被移动</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"7-2-避免不必要的-std-move\"><a href=\"#7-2-避免不必要的-std-move\" class=\"headerlink\" title=\"7.2 避免不必要的 std::move\"></a>7.2 避免不必要的 <code>std::move</code></h3><p>在返回局部变量时，编译器会自动选择移动或拷贝，无需显式调用 <code>std::move</code>。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-function\">std::vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">createVector</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;;<br>    <span class=\"hljs-keyword\">return</span> std::<span class=\"hljs-built_in\">move</span>(v); <span class=\"hljs-comment\">// 不必要的 std::move</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v = <span class=\"hljs-built_in\">createVector</span>();<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;v size: &quot;</span> &lt;&lt; v.<span class=\"hljs-built_in\">size</span>() &lt;&lt; std::endl;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"7-3-右值引用的陷阱\"><a href=\"#7-3-右值引用的陷阱\" class=\"headerlink\" title=\"7.3 右值引用的陷阱\"></a>7.3 右值引用的陷阱</h3><p>右值引用本身是左值，因此需要使用 <code>std::move</code> 或 <code>std::forward</code> 来保持其右值特性。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">print</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span>&amp;&amp; x)</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Rvalue: &quot;</span> &lt;&lt; x &lt;&lt; std::endl;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span>&amp;&amp; r = <span class=\"hljs-number\">42</span>;<br>    <span class=\"hljs-comment\">// print(r); // 错误：r 是左值</span><br>    <span class=\"hljs-built_in\">print</span>(std::<span class=\"hljs-built_in\">move</span>(r)); <span class=\"hljs-comment\">// 正确</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h2 id=\"8-为什么需要右值\"><a href=\"#8-为什么需要右值\" class=\"headerlink\" title=\"8.为什么需要右值\"></a>8.为什么需要右值</h2><p>在 C++ 中，右值（Rvalue）是一个非常重要的概念，它的引入主要是为了解决以下几个核心问题：</p>\n<hr>\n<h3 id=\"8-1-避免不必要的拷贝\"><a href=\"#8-1-避免不必要的拷贝\" class=\"headerlink\" title=\"8.1 避免不必要的拷贝\"></a>8.1 避免不必要的拷贝</h3><p>在传统的 C++ 中，对象的拷贝操作可能会带来性能问题，尤其是在处理大对象或资源密集型对象时。例如，当你将一个对象从一个地方移动到另一个地方时，如果使用拷贝操作，会浪费大量的时间和资源。</p>\n<h4 id=\"例子：\"><a href=\"#例子：\" class=\"headerlink\" title=\"例子：\"></a>例子：</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-function\">std::vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">createVector</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">4</span>, <span class=\"hljs-number\">5</span>&#125;;<br>    <span class=\"hljs-keyword\">return</span> v; <span class=\"hljs-comment\">// 返回局部对象</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v = <span class=\"hljs-built_in\">createVector</span>(); <span class=\"hljs-comment\">// 拷贝构造</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;v size: &quot;</span> &lt;&lt; v.<span class=\"hljs-built_in\">size</span>() &lt;&lt; std::endl;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，<code>createVector</code> 返回一个局部对象 <code>v</code>，如果编译器没有优化（如 RVO 或 NRVO），那么 <code>v</code> 会被拷贝到 <code>main</code> 中的 <code>v</code>。对于大对象来说，拷贝操作的代价非常高。</p>\n<p><strong>右值的引入</strong>：通过右值引用和移动语义，可以将对象的资源“移动”到目标对象，而不是拷贝，从而避免不必要的开销。</p>\n<hr>\n<h3 id=\"8-2-支持移动语义\"><a href=\"#8-2-支持移动语义\" class=\"headerlink\" title=\"8.2 支持移动语义\"></a>8.2 支持移动语义</h3><p>移动语义是 C++11 引入的一个重要特性，它允许将资源从一个对象“移动”到另一个对象，而不是拷贝。移动语义的核心是右值引用（<code>T&amp;&amp;</code>）。</p>\n<h4 id=\"例子：-1\"><a href=\"#例子：-1\" class=\"headerlink\" title=\"例子：\"></a>例子：</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyVector</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; data;<br><br>    <span class=\"hljs-comment\">// 移动构造函数</span><br>    <span class=\"hljs-built_in\">MyVector</span>(MyVector&amp;&amp; other) <span class=\"hljs-keyword\">noexcept</span> : <span class=\"hljs-built_in\">data</span>(std::<span class=\"hljs-built_in\">move</span>(other.data)) &#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Move Constructor called&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br><br>    <span class=\"hljs-built_in\">MyVector</span>(<span class=\"hljs-type\">const</span> std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&amp; d) : <span class=\"hljs-built_in\">data</span>(d) &#123;&#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    MyVector v1&#123;std::vector&lt;<span class=\"hljs-type\">int</span>&gt;&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;&#125;;<br>    MyVector v2 = std::<span class=\"hljs-built_in\">move</span>(v1); <span class=\"hljs-comment\">// 调用移动构造函数</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，<code>v1</code> 的资源被“移动”到 <code>v2</code>，而不是拷贝。移动操作的代价非常低，通常只是指针的交换。</p>\n<hr>\n<h3 id=\"8-3-支持完美转发\"><a href=\"#8-3-支持完美转发\" class=\"headerlink\" title=\"8.3 支持完美转发\"></a>8.3 支持完美转发</h3><p>在模板编程中，函数参数的值类别（左值或右值）可能会丢失，导致无法正确地传递参数。完美转发（Perfect Forwarding）通过右值引用和 <code>std::forward</code> 解决了这个问题。</p>\n<h4 id=\"例子：-2\"><a href=\"#例子：-2\" class=\"headerlink\" title=\"例子：\"></a>例子：</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;utility&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">print</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span>&amp; x)</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Lvalue: &quot;</span> &lt;&lt; x &lt;&lt; std::endl;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">print</span><span class=\"hljs-params\">(<span class=\"hljs-type\">int</span>&amp;&amp; x)</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Rvalue: &quot;</span> &lt;&lt; x &lt;&lt; std::endl;<br>&#125;<br><br><span class=\"hljs-keyword\">template</span> &lt;<span class=\"hljs-keyword\">typename</span> T&gt;<br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">wrapper</span><span class=\"hljs-params\">(T&amp;&amp; arg)</span> </span>&#123;<br>    <span class=\"hljs-built_in\">print</span>(std::forward&lt;T&gt;(arg)); <span class=\"hljs-comment\">// 完美转发</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">int</span> a = <span class=\"hljs-number\">10</span>;<br>    <span class=\"hljs-built_in\">wrapper</span>(a);  <span class=\"hljs-comment\">// 调用 print(int&amp;)</span><br>    <span class=\"hljs-built_in\">wrapper</span>(<span class=\"hljs-number\">20</span>); <span class=\"hljs-comment\">// 调用 print(int&amp;&amp;)</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，<code>wrapper</code> 函数能够正确地转发参数的值类别，无论是左值还是右值。</p>\n<hr>\n<h3 id=\"8-4-优化资源管理\"><a href=\"#8-4-优化资源管理\" class=\"headerlink\" title=\"8.4 优化资源管理\"></a>8.4 优化资源管理</h3><p>在资源管理类（如智能指针、文件句柄等）中，右值引用和移动语义可以显著提高性能。例如，<code>std::unique_ptr</code> 是一个典型的例子，它只能通过移动语义来传递所有权，而不能拷贝。</p>\n<h4 id=\"例子：-3\"><a href=\"#例子：-3\" class=\"headerlink\" title=\"例子：\"></a>例子：</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;memory&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Resource</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    std::unique_ptr&lt;<span class=\"hljs-type\">int</span>&gt; ptr;<br><br>    <span class=\"hljs-built_in\">Resource</span>(<span class=\"hljs-type\">int</span> value) : <span class=\"hljs-built_in\">ptr</span>(std::<span class=\"hljs-built_in\">make_unique</span>&lt;<span class=\"hljs-type\">int</span>&gt;(value)) &#123;&#125;<br><br>    <span class=\"hljs-built_in\">Resource</span>(Resource&amp;&amp; other) <span class=\"hljs-keyword\">noexcept</span> : <span class=\"hljs-built_in\">ptr</span>(std::<span class=\"hljs-built_in\">move</span>(other.ptr)) &#123;<br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Resource moved&quot;</span> &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-function\">Resource <span class=\"hljs-title\">r1</span><span class=\"hljs-params\">(<span class=\"hljs-number\">42</span>)</span></span>;<br>    Resource r2 = std::<span class=\"hljs-built_in\">move</span>(r1); <span class=\"hljs-comment\">// 移动资源</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，<code>std::unique_ptr</code> 的资源被移动到 <code>r2</code>，而不是拷贝。这确保了资源的唯一所有权。</p>\n<hr>\n<h3 id=\"8-5-提高代码的表达能力\"><a href=\"#8-5-提高代码的表达能力\" class=\"headerlink\" title=\"8.5 提高代码的表达能力\"></a>8.5 提高代码的表达能力</h3><p>右值引用的引入使得 C++ 的表达能力更强。通过移动语义和完美转发，开发者可以编写更高效、更简洁的代码。例如，标准库中的容器（如 <code>std::vector</code>）和算法（如 <code>std::sort</code>）都广泛使用了右值语义。</p>\n<h4 id=\"例子：-4\"><a href=\"#例子：-4\" class=\"headerlink\" title=\"例子：\"></a>例子：</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v1&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v2 = std::<span class=\"hljs-built_in\">move</span>(v1); <span class=\"hljs-comment\">// 移动 vector</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;v2 size: &quot;</span> &lt;&lt; v<span class=\"hljs-number\">2.</span><span class=\"hljs-built_in\">size</span>() &lt;&lt; std::endl;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，<code>v1</code> 的资源被移动到 <code>v2</code>，而不是拷贝。这使得代码更加高效。</p>\n<hr>\n<h3 id=\"8-6-解决临时对象的资源浪费\"><a href=\"#8-6-解决临时对象的资源浪费\" class=\"headerlink\" title=\"8.6 解决临时对象的资源浪费\"></a>8.6 解决临时对象的资源浪费</h3><p>在传统的 C++ 中，临时对象（如函数返回值）的生命周期很短，但它们的资源可能会被浪费。通过右值引用和移动语义，可以有效地利用这些临时对象的资源。</p>\n<h4 id=\"例子：-5\"><a href=\"#例子：-5\" class=\"headerlink\" title=\"例子：\"></a>例子：</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;vector&gt;</span></span><br><br><span class=\"hljs-function\">std::vector&lt;<span class=\"hljs-type\">int</span>&gt; <span class=\"hljs-title\">createVector</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v&#123;<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>, <span class=\"hljs-number\">3</span>&#125;;<br>    <span class=\"hljs-keyword\">return</span> v; <span class=\"hljs-comment\">// 返回局部对象</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::vector&lt;<span class=\"hljs-type\">int</span>&gt; v = <span class=\"hljs-built_in\">createVector</span>(); <span class=\"hljs-comment\">// 可能触发 RVO 或移动语义</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;v size: &quot;</span> &lt;&lt; v.<span class=\"hljs-built_in\">size</span>() &lt;&lt; std::endl;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，<code>createVector</code> 返回的临时对象 <code>v</code> 的资源被移动到 <code>main</code> 中的 <code>v</code>，而不是拷贝。</p>\n<hr>\n<h2 id=\"9-总结\"><a href=\"#9-总结\" class=\"headerlink\" title=\"9.总结\"></a>9.总结</h2><p>右值的引入解决了以下几个核心问题：</p>\n<ol>\n<li><strong>避免不必要的拷贝</strong>：通过移动语义，减少大对象或资源密集型对象的拷贝开销。</li>\n<li><strong>支持移动语义</strong>：允许将资源从一个对象“移动”到另一个对象，而不是拷贝。</li>\n<li><strong>支持完美转发</strong>：在模板编程中，保持参数的值类别，确保参数能够正确传递。</li>\n<li><strong>优化资源管理</strong>：在智能指针和资源管理类中，确保资源的唯一所有权。</li>\n<li><strong>提高代码的表达能力</strong>：使代码更加高效、简洁。</li>\n<li><strong>解决临时对象的资源浪费</strong>：利用临时对象的资源，避免浪费。</li>\n</ol>\n<p>通过右值引用和移动语义，C++ 的性能和表达能力得到了显著提升，使得现代 C++ 代码更加高效和现代化。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"公众号\"></p>\n"},{"title":"HTTP基础01：HTTP协议概述","date":"2024-12-30T04:00:00.000Z","_content":"\n\n\n# HTTP协议概述\n\n在当今数字化的时代，我们每天都在与网络进行着无数次的交互，而这背后离不开众多网络协议的支撑，其中 HTTP（超文本传输协议）起着至关重要的作用。无论是浏览网页、使用手机应用获取数据，还是各种智能设备之间的信息传输，HTTP 都在默默地为我们服务。今天，就让我们深入了解一下 HTTP 的奥秘。\n\n## 1. HTTP 的定义与作用\n### 1.1 定义\nHTTP 是一种用于分布式、协作式和超媒体信息系统的应用层协议。简单来说，它定义了客户端和服务器之间如何进行通信，规定了数据的格式、传输方式以及各种操作的方法。它工作在 **TCP/IP 协议栈的应用层**，**基于传输层的 TCP 协议**来确保数据的可靠传输。\n\n例如，当你在浏览器中输入一个网址并按下回车键时，浏览器就会作为客户端向服务器发送一个 HTTP 请求，请求获取特定的网页资源。服务器接收到请求后，根据 HTTP 协议的规范对请求进行处理，并将相应的网页内容以 HTTP 响应的形式返回给浏览器，浏览器再将这些内容解析并展示给用户，这就是 HTTP 在我们日常网络浏览中最基本的工作流程。\n\n### 1.2 作用\nHTTP 的主要作用是**实现客户端和服务器之间的超文本数据传输**，从而使得我们能够在互联网上获取和交换各种信息。它使得不同的系统和平台能够相互通信，无论是大型的服务器集群还是小型的嵌入式设备，只要遵循 HTTP 协议，就能够进行有效的数据交互。\n\n比如，\n\n电子商务网站依靠 HTTP 协议来实现商品信息的展示、用户订单的提交和处理；\n\n社交媒体平台利用它来加载动态内容、上传和下载图片视频等；\n\n在线教育平台借助 HTTP 让学生获取课程资料、参与直播互动等。\n\n可以说，HTTP 是现代互联网应用的基石，没有它，我们所熟悉的丰富多彩的网络世界将不复存在。\n\n## 2. HTTP 的发展历史\n\n| 版本     | 主要特性                                                     | 优点                                                         | 缺点                                                         |\n| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| HTTP/0.9 | 只支持 GET 方法，无请求和响应头部信息，服务器仅响应 HTML 文档，连接在响应后立即关闭 | 简单，满足基本网页浏览需求                                   | 功能单一，仅支持 HTML 文档获取，无连接复用                   |\n| HTTP/1.0 | 引入更多请求方法（如 POST、HEAD 等），增加请求和响应头部信息，支持多种文件类型传输 | 丰富了网页内容呈现形式，能传输多种类型资源                   | 每个请求需建立新的 TCP 连接，性能较低                        |\n| HTTP/1.1 | 引入持久连接（Keep-Alive），增加更多请求方法（如 PUT、DELETE 等）和头部字段 | 减少连接建立和关闭开销，提高网络传输效率，增强协议功能和灵活性 | 仍存在性能瓶颈，如队头阻塞问题                               |\n| HTTP/2   | 采用二进制分帧层，实现多路复用，支持服务器推送               | 显著提高资源并行传输能力，降低延迟，优化网络性能             | 对服务器和客户端实现要求较高，部分老旧基础设施和设备支持不佳 |\n| HTTP/3   | 基于 UDP 协议，引入 QUIC 协议，继承 HTTP/2 特性              | 进一步降低延迟，具备更好连接迁移能力和拥塞控制，提升性能和可靠性 | UDP 协议本身的可靠性相对 TCP 较弱，应用普及需要时间          |\n\n### 2.1 HTTP/0.9\nHTTP 的最初版本 HTTP/0.9 极其简单，它**只支持 GET 方法**，主要用于获取 HTML 文档。在这个版本中，请求和响应都没有头部信息，服务器只能响应 HTML 格式的内容，并且连接在响应后立即关闭，不支持其他类型的资源传输和复杂的交互操作。但正是这个简单的版本开启了 HTTP 协议的发展之路，满足了当时人们对网页浏览的基本需求，使得网络信息的获取变得更加便捷。\n\n### 2.2 HTTP/1.0\n随着网络应用的逐渐丰富，HTTP/1.0 应运而生。它引入了**更多的请求方法（如 POST、HEAD** 等），并且增加了请求和响应的头部信息，使得客户端和服务器能够传递更多关于请求和响应的元数据，例如内容类型、编码方式等。这一版本还支持多种类型的文件传输，如图片、样式表等，大大丰富了网页的内容呈现形式。然而，HTTP/1.0 存在一个显著的问题，即每个请求都需要建立一个新的 TCP 连接，这导致了在请求大量资源时效率较低，因为建立和关闭 TCP 连接的开销较大。\n\n### 2.3 HTTP/1.1\n为了解决 HTTP/1.0 的性能问题，HTTP/1.1 进行了一系列重要的改进。它引入了**持久连接（Keep-Alive）**，允许在一个 TCP 连接上进行多个 HTTP 请求和响应的交互，减少了建立和关闭连接的开销，提高了网络传输效率。同时，还增加了更多的请求方法（如 PUT、DELETE 等）和头部字段，进一步增强了协议的功能和灵活性。HTTP/1.1 成为了应用最广泛且持续时间最长的 HTTP 版本，至今仍在许多场景中被大量使用，但随着网络技术的不断发展和应用需求的日益增长，它也逐渐暴露出一些性能瓶颈。\n\n### 2.4 HTTP/2\nHTTP/2 在性能优化方面迈出了重大一步。它采用了二进制分帧层，将 HTTP 消息分解为更小的帧进行传输，这些帧可以在同一个 TCP 连接上交错发送和接收，从而实现了多路复用，大大提高了资源的并行传输能力，进一步提升了网络性能。同时，HTTP/2 还支持服务器推送，服务器可以主动向客户端推送资源，减少了客户端请求的延迟。不过，HTTP/2 的推广和应用也面临一些挑战，例如对服务器和客户端的实现要求较高，部分老旧的网络基础设施和设备可能无法很好地支持它。\n\n### 2.5 HTTP/3\n为了克服 HTTP/2 在 TCP 协议上的一些性能限制，HTTP/3 基于 UDP 协议进行了全新的设计，引入了 QUIC 协议。QUIC 协议在 UDP 之上实现了类似 TCP 的可靠传输功能，同时还具备更低的延迟、更好的连接迁移能力以及对网络拥塞的优化控制。HTTP/3 继承了 HTTP/2 的许多优秀特性，如二进制分帧、多路复用和服务器推送等，并通过 QUIC 协议进一步提升了性能和可靠性。目前，HTTP/3 正在逐渐得到广泛的应用和支持，有望成为未来网络通信的主流协议之一。\n\n\n\n## 3. HTTP 的基本特点\n\n### 3.1 无状态\nHTTP 的无状态特性是指协议对于事务处理没有记忆能力。每一次的 HTTP 请求都是独立的，服务器不会记住之前的请求信息，也不会在不同的请求之间保留任何状态数据。\n\n例如，当你在一个电商网站上先后将两件商品加入购物车，对于服务器来说，这是两个完全独立的 HTTP 请求，它不会自动关联这两个操作，因为 HTTP 协议本身并不知道这两个请求来自同一个用户的同一次购物行为。这种无状态性使得服务器的设计更加简单高效，能够轻松应对大量并发的请求。但在某些需要保持用户状态的应用场景中，如用户登录后的权限管理、购物车功能等，就需要通过其他技术手段（如使用 Cookie、Session 等）来在客户端和服务器之间维护状态信息。\n\n### 3.2 无连接\n在 HTTP/1.0 中，默认采用的是无连接的方式，即客户端与服务器在完成一次 HTTP 请求和响应后，会立即关闭连接。这种方式在每次请求都需要重新建立连接，虽然简单直接，但在请求频繁的情况下，会造成较大的性能开销，因为建立和关闭 TCP 连接需要消耗一定的时间和资源。\n\n而在 HTTP/1.1 及以后的版本中，引入了持久连接（Keep-Alive）来改善这一问题，使得在一个 TCP 连接上可以进行多次 HTTP 请求和响应的交互，减少了连接建立和关闭的次数，从而提高了网络传输效率。但从协议本身的设计初衷来看，HTTP 最初是基于无连接的理念构建的，这种理念在一定程度上简化了服务器的实现和资源管理，同时也使得 HTTP 能够更灵活地适应不同的网络环境和应用场景。\n\nHTTP 作为网络通信领域的重要协议，从诞生之初到不断发展演变，始终在适应着互联网的发展需求。了解 HTTP 的定义、作用、发展历史和基本特点，不仅有助于我们深入理解网络通信的原理，更能为我们在开发高效、稳定的网络应用时提供有力的理论支持和实践指导。随着技术的不断进步，HTTP 协议也将继续进化，为构建更加智能、便捷的网络世界贡献力量。\n\n### 3.3 **基于请求 - 响应模型**\n\n- **工作方式**：客户端发起请求，服务器接收请求后进行处理并返回响应。例如，当用户在浏览器中访问一个网页时，浏览器会构建一个HTTP请求，这个请求包含请求方法（如GET、POST等）、请求URL、请求头和请求体（如果是POST等方法可能有）等信息。服务器根据请求中的信息，查找相应的资源，然后构建一个HTTP响应，其中包含状态码、响应头和响应体（如网页内容、文件数据等），并将其发送回客户端。\n- **优点**：这种模型简单直观，使得客户端和服务器之间的交互逻辑清晰。开发人员可以很容易地理解和实现通信过程，方便构建各种网络应用。而且它允许服务器对不同的请求进行不同的处理，具有很好的灵活性。\n- **应用场景**：广泛应用于各种网络服务，如网页浏览、API调用等。在网页浏览中，浏览器根据用户输入的网址或者操作（如点击链接、提交表单）发送请求，服务器返回对应的网页或者处理结果。在API调用场景下，客户端（如移动应用、其他服务器等）通过HTTP请求向提供API的服务器获取或更新数据。\n\n### 3.4 **简单性和通用性**\n\n- **协议格式简单**：HTTP是一种基于文本的协议，它的请求和响应消息格式相对简单，易于理解和实现。例如，一个简单的HTTP GET请求可能如下所示：\n  \n  ```\n  GET /index.html HTTP/1.1\n  Host: www.example.com\n  ```\n  这是一个请求获取`www.example.com`网站的`index.html`文件的HTTP请求。第一行是请求行，包含请求方法（GET）、请求的资源路径（`/index.html`）和协议版本（`HTTP/1.1`）。后面的行是请求头，这里的`Host`头指定了请求的目标主机。\n- **通用性高**：几乎所有的网络编程语言都提供了对HTTP的支持，无论是Python（通过`requests`库等）、Java（通过`java.net.HttpURLConnection`等）还是JavaScript（在浏览器中通过`XMLHttpRequest`或者`fetch` API）。这使得不同平台和语言编写的客户端和服务器能够很容易地进行通信。\n- **优点**：由于简单性，开发人员可以快速上手，降低了开发网络应用的难度。通用性使得HTTP能够在各种不同的设备和系统中广泛应用，促进了网络的互联互通。\n- **应用场景**：在物联网设备中，简单的传感器设备可以使用HTTP将采集的数据发送到服务器，或者接收服务器的控制指令。小型的Web应用开发，尤其是初学者或者快速原型开发，利用HTTP的简单性可以快速搭建起基本的功能架构。\n\n### 3.5 **可扩展性**\n\n- **协议扩展机制**：HTTP允许通过添加新的请求方法、头部字段等来扩展其功能。例如，随着Web应用的发展，出现了新的请求方法如PATCH（用于部分更新资源）。同时，自定义的头部字段也可以用于在客户端和服务器之间传递特定的元数据。\n- **版本更新支持进步**：从HTTP/0.9到HTTP/3的发展历程也体现了它的可扩展性。每个新版本都在保留基本的通信模式的基础上，对性能、功能等方面进行了扩展和优化。例如，HTTP/2的二进制分帧和多路复用就是对原有协议传输机制的重大扩展，提高了协议的性能和效率。\n- **优点**：能够适应不断变化的网络应用需求。随着技术的发展，如移动互联网、云计算、物联网等新兴领域的出现，HTTP可以通过扩展来满足这些新场景下的数据传输和交互需求。\n- **应用场景**：在现代的微服务架构中，HTTP可以通过扩展来支持服务之间的复杂通信和协调。例如，在一个包含多个微服务的电商系统中，不同微服务之间（如用户服务、商品服务、订单服务等）可以通过自定义的HTTP请求方法和头部字段来实现高效的业务逻辑交互。\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","source":"_posts/计算机基础/计算机网络/HTTP基础01：HTTP协议概述.md","raw":"---\ntitle: 'HTTP基础01：HTTP协议概述'\ncategories:\n  - [计算机基础,计算机网络]\ntags:\n  - 计算机网络\n  - 计算机基础\n  - HTTP\ndate: 2024-12-30 12:00:00\n---\n\n\n\n# HTTP协议概述\n\n在当今数字化的时代，我们每天都在与网络进行着无数次的交互，而这背后离不开众多网络协议的支撑，其中 HTTP（超文本传输协议）起着至关重要的作用。无论是浏览网页、使用手机应用获取数据，还是各种智能设备之间的信息传输，HTTP 都在默默地为我们服务。今天，就让我们深入了解一下 HTTP 的奥秘。\n\n## 1. HTTP 的定义与作用\n### 1.1 定义\nHTTP 是一种用于分布式、协作式和超媒体信息系统的应用层协议。简单来说，它定义了客户端和服务器之间如何进行通信，规定了数据的格式、传输方式以及各种操作的方法。它工作在 **TCP/IP 协议栈的应用层**，**基于传输层的 TCP 协议**来确保数据的可靠传输。\n\n例如，当你在浏览器中输入一个网址并按下回车键时，浏览器就会作为客户端向服务器发送一个 HTTP 请求，请求获取特定的网页资源。服务器接收到请求后，根据 HTTP 协议的规范对请求进行处理，并将相应的网页内容以 HTTP 响应的形式返回给浏览器，浏览器再将这些内容解析并展示给用户，这就是 HTTP 在我们日常网络浏览中最基本的工作流程。\n\n### 1.2 作用\nHTTP 的主要作用是**实现客户端和服务器之间的超文本数据传输**，从而使得我们能够在互联网上获取和交换各种信息。它使得不同的系统和平台能够相互通信，无论是大型的服务器集群还是小型的嵌入式设备，只要遵循 HTTP 协议，就能够进行有效的数据交互。\n\n比如，\n\n电子商务网站依靠 HTTP 协议来实现商品信息的展示、用户订单的提交和处理；\n\n社交媒体平台利用它来加载动态内容、上传和下载图片视频等；\n\n在线教育平台借助 HTTP 让学生获取课程资料、参与直播互动等。\n\n可以说，HTTP 是现代互联网应用的基石，没有它，我们所熟悉的丰富多彩的网络世界将不复存在。\n\n## 2. HTTP 的发展历史\n\n| 版本     | 主要特性                                                     | 优点                                                         | 缺点                                                         |\n| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| HTTP/0.9 | 只支持 GET 方法，无请求和响应头部信息，服务器仅响应 HTML 文档，连接在响应后立即关闭 | 简单，满足基本网页浏览需求                                   | 功能单一，仅支持 HTML 文档获取，无连接复用                   |\n| HTTP/1.0 | 引入更多请求方法（如 POST、HEAD 等），增加请求和响应头部信息，支持多种文件类型传输 | 丰富了网页内容呈现形式，能传输多种类型资源                   | 每个请求需建立新的 TCP 连接，性能较低                        |\n| HTTP/1.1 | 引入持久连接（Keep-Alive），增加更多请求方法（如 PUT、DELETE 等）和头部字段 | 减少连接建立和关闭开销，提高网络传输效率，增强协议功能和灵活性 | 仍存在性能瓶颈，如队头阻塞问题                               |\n| HTTP/2   | 采用二进制分帧层，实现多路复用，支持服务器推送               | 显著提高资源并行传输能力，降低延迟，优化网络性能             | 对服务器和客户端实现要求较高，部分老旧基础设施和设备支持不佳 |\n| HTTP/3   | 基于 UDP 协议，引入 QUIC 协议，继承 HTTP/2 特性              | 进一步降低延迟，具备更好连接迁移能力和拥塞控制，提升性能和可靠性 | UDP 协议本身的可靠性相对 TCP 较弱，应用普及需要时间          |\n\n### 2.1 HTTP/0.9\nHTTP 的最初版本 HTTP/0.9 极其简单，它**只支持 GET 方法**，主要用于获取 HTML 文档。在这个版本中，请求和响应都没有头部信息，服务器只能响应 HTML 格式的内容，并且连接在响应后立即关闭，不支持其他类型的资源传输和复杂的交互操作。但正是这个简单的版本开启了 HTTP 协议的发展之路，满足了当时人们对网页浏览的基本需求，使得网络信息的获取变得更加便捷。\n\n### 2.2 HTTP/1.0\n随着网络应用的逐渐丰富，HTTP/1.0 应运而生。它引入了**更多的请求方法（如 POST、HEAD** 等），并且增加了请求和响应的头部信息，使得客户端和服务器能够传递更多关于请求和响应的元数据，例如内容类型、编码方式等。这一版本还支持多种类型的文件传输，如图片、样式表等，大大丰富了网页的内容呈现形式。然而，HTTP/1.0 存在一个显著的问题，即每个请求都需要建立一个新的 TCP 连接，这导致了在请求大量资源时效率较低，因为建立和关闭 TCP 连接的开销较大。\n\n### 2.3 HTTP/1.1\n为了解决 HTTP/1.0 的性能问题，HTTP/1.1 进行了一系列重要的改进。它引入了**持久连接（Keep-Alive）**，允许在一个 TCP 连接上进行多个 HTTP 请求和响应的交互，减少了建立和关闭连接的开销，提高了网络传输效率。同时，还增加了更多的请求方法（如 PUT、DELETE 等）和头部字段，进一步增强了协议的功能和灵活性。HTTP/1.1 成为了应用最广泛且持续时间最长的 HTTP 版本，至今仍在许多场景中被大量使用，但随着网络技术的不断发展和应用需求的日益增长，它也逐渐暴露出一些性能瓶颈。\n\n### 2.4 HTTP/2\nHTTP/2 在性能优化方面迈出了重大一步。它采用了二进制分帧层，将 HTTP 消息分解为更小的帧进行传输，这些帧可以在同一个 TCP 连接上交错发送和接收，从而实现了多路复用，大大提高了资源的并行传输能力，进一步提升了网络性能。同时，HTTP/2 还支持服务器推送，服务器可以主动向客户端推送资源，减少了客户端请求的延迟。不过，HTTP/2 的推广和应用也面临一些挑战，例如对服务器和客户端的实现要求较高，部分老旧的网络基础设施和设备可能无法很好地支持它。\n\n### 2.5 HTTP/3\n为了克服 HTTP/2 在 TCP 协议上的一些性能限制，HTTP/3 基于 UDP 协议进行了全新的设计，引入了 QUIC 协议。QUIC 协议在 UDP 之上实现了类似 TCP 的可靠传输功能，同时还具备更低的延迟、更好的连接迁移能力以及对网络拥塞的优化控制。HTTP/3 继承了 HTTP/2 的许多优秀特性，如二进制分帧、多路复用和服务器推送等，并通过 QUIC 协议进一步提升了性能和可靠性。目前，HTTP/3 正在逐渐得到广泛的应用和支持，有望成为未来网络通信的主流协议之一。\n\n\n\n## 3. HTTP 的基本特点\n\n### 3.1 无状态\nHTTP 的无状态特性是指协议对于事务处理没有记忆能力。每一次的 HTTP 请求都是独立的，服务器不会记住之前的请求信息，也不会在不同的请求之间保留任何状态数据。\n\n例如，当你在一个电商网站上先后将两件商品加入购物车，对于服务器来说，这是两个完全独立的 HTTP 请求，它不会自动关联这两个操作，因为 HTTP 协议本身并不知道这两个请求来自同一个用户的同一次购物行为。这种无状态性使得服务器的设计更加简单高效，能够轻松应对大量并发的请求。但在某些需要保持用户状态的应用场景中，如用户登录后的权限管理、购物车功能等，就需要通过其他技术手段（如使用 Cookie、Session 等）来在客户端和服务器之间维护状态信息。\n\n### 3.2 无连接\n在 HTTP/1.0 中，默认采用的是无连接的方式，即客户端与服务器在完成一次 HTTP 请求和响应后，会立即关闭连接。这种方式在每次请求都需要重新建立连接，虽然简单直接，但在请求频繁的情况下，会造成较大的性能开销，因为建立和关闭 TCP 连接需要消耗一定的时间和资源。\n\n而在 HTTP/1.1 及以后的版本中，引入了持久连接（Keep-Alive）来改善这一问题，使得在一个 TCP 连接上可以进行多次 HTTP 请求和响应的交互，减少了连接建立和关闭的次数，从而提高了网络传输效率。但从协议本身的设计初衷来看，HTTP 最初是基于无连接的理念构建的，这种理念在一定程度上简化了服务器的实现和资源管理，同时也使得 HTTP 能够更灵活地适应不同的网络环境和应用场景。\n\nHTTP 作为网络通信领域的重要协议，从诞生之初到不断发展演变，始终在适应着互联网的发展需求。了解 HTTP 的定义、作用、发展历史和基本特点，不仅有助于我们深入理解网络通信的原理，更能为我们在开发高效、稳定的网络应用时提供有力的理论支持和实践指导。随着技术的不断进步，HTTP 协议也将继续进化，为构建更加智能、便捷的网络世界贡献力量。\n\n### 3.3 **基于请求 - 响应模型**\n\n- **工作方式**：客户端发起请求，服务器接收请求后进行处理并返回响应。例如，当用户在浏览器中访问一个网页时，浏览器会构建一个HTTP请求，这个请求包含请求方法（如GET、POST等）、请求URL、请求头和请求体（如果是POST等方法可能有）等信息。服务器根据请求中的信息，查找相应的资源，然后构建一个HTTP响应，其中包含状态码、响应头和响应体（如网页内容、文件数据等），并将其发送回客户端。\n- **优点**：这种模型简单直观，使得客户端和服务器之间的交互逻辑清晰。开发人员可以很容易地理解和实现通信过程，方便构建各种网络应用。而且它允许服务器对不同的请求进行不同的处理，具有很好的灵活性。\n- **应用场景**：广泛应用于各种网络服务，如网页浏览、API调用等。在网页浏览中，浏览器根据用户输入的网址或者操作（如点击链接、提交表单）发送请求，服务器返回对应的网页或者处理结果。在API调用场景下，客户端（如移动应用、其他服务器等）通过HTTP请求向提供API的服务器获取或更新数据。\n\n### 3.4 **简单性和通用性**\n\n- **协议格式简单**：HTTP是一种基于文本的协议，它的请求和响应消息格式相对简单，易于理解和实现。例如，一个简单的HTTP GET请求可能如下所示：\n  \n  ```\n  GET /index.html HTTP/1.1\n  Host: www.example.com\n  ```\n  这是一个请求获取`www.example.com`网站的`index.html`文件的HTTP请求。第一行是请求行，包含请求方法（GET）、请求的资源路径（`/index.html`）和协议版本（`HTTP/1.1`）。后面的行是请求头，这里的`Host`头指定了请求的目标主机。\n- **通用性高**：几乎所有的网络编程语言都提供了对HTTP的支持，无论是Python（通过`requests`库等）、Java（通过`java.net.HttpURLConnection`等）还是JavaScript（在浏览器中通过`XMLHttpRequest`或者`fetch` API）。这使得不同平台和语言编写的客户端和服务器能够很容易地进行通信。\n- **优点**：由于简单性，开发人员可以快速上手，降低了开发网络应用的难度。通用性使得HTTP能够在各种不同的设备和系统中广泛应用，促进了网络的互联互通。\n- **应用场景**：在物联网设备中，简单的传感器设备可以使用HTTP将采集的数据发送到服务器，或者接收服务器的控制指令。小型的Web应用开发，尤其是初学者或者快速原型开发，利用HTTP的简单性可以快速搭建起基本的功能架构。\n\n### 3.5 **可扩展性**\n\n- **协议扩展机制**：HTTP允许通过添加新的请求方法、头部字段等来扩展其功能。例如，随着Web应用的发展，出现了新的请求方法如PATCH（用于部分更新资源）。同时，自定义的头部字段也可以用于在客户端和服务器之间传递特定的元数据。\n- **版本更新支持进步**：从HTTP/0.9到HTTP/3的发展历程也体现了它的可扩展性。每个新版本都在保留基本的通信模式的基础上，对性能、功能等方面进行了扩展和优化。例如，HTTP/2的二进制分帧和多路复用就是对原有协议传输机制的重大扩展，提高了协议的性能和效率。\n- **优点**：能够适应不断变化的网络应用需求。随着技术的发展，如移动互联网、云计算、物联网等新兴领域的出现，HTTP可以通过扩展来满足这些新场景下的数据传输和交互需求。\n- **应用场景**：在现代的微服务架构中，HTTP可以通过扩展来支持服务之间的复杂通信和协调。例如，在一个包含多个微服务的电商系统中，不同微服务之间（如用户服务、商品服务、订单服务等）可以通过自定义的HTTP请求方法和头部字段来实现高效的业务逻辑交互。\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","slug":"计算机基础/计算机网络/HTTP基础01：HTTP协议概述","published":1,"updated":"2024-12-31T06:35:52.924Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3i000khghih9bv44x0","content":"<h1 id=\"HTTP协议概述\"><a href=\"#HTTP协议概述\" class=\"headerlink\" title=\"HTTP协议概述\"></a>HTTP协议概述</h1><p>在当今数字化的时代，我们每天都在与网络进行着无数次的交互，而这背后离不开众多网络协议的支撑，其中 HTTP（超文本传输协议）起着至关重要的作用。无论是浏览网页、使用手机应用获取数据，还是各种智能设备之间的信息传输，HTTP 都在默默地为我们服务。今天，就让我们深入了解一下 HTTP 的奥秘。</p>\n<h2 id=\"1-HTTP-的定义与作用\"><a href=\"#1-HTTP-的定义与作用\" class=\"headerlink\" title=\"1. HTTP 的定义与作用\"></a>1. HTTP 的定义与作用</h2><h3 id=\"1-1-定义\"><a href=\"#1-1-定义\" class=\"headerlink\" title=\"1.1 定义\"></a>1.1 定义</h3><p>HTTP 是一种用于分布式、协作式和超媒体信息系统的应用层协议。简单来说，它定义了客户端和服务器之间如何进行通信，规定了数据的格式、传输方式以及各种操作的方法。它工作在 <strong>TCP&#x2F;IP 协议栈的应用层</strong>，<strong>基于传输层的 TCP 协议</strong>来确保数据的可靠传输。</p>\n<p>例如，当你在浏览器中输入一个网址并按下回车键时，浏览器就会作为客户端向服务器发送一个 HTTP 请求，请求获取特定的网页资源。服务器接收到请求后，根据 HTTP 协议的规范对请求进行处理，并将相应的网页内容以 HTTP 响应的形式返回给浏览器，浏览器再将这些内容解析并展示给用户，这就是 HTTP 在我们日常网络浏览中最基本的工作流程。</p>\n<h3 id=\"1-2-作用\"><a href=\"#1-2-作用\" class=\"headerlink\" title=\"1.2 作用\"></a>1.2 作用</h3><p>HTTP 的主要作用是<strong>实现客户端和服务器之间的超文本数据传输</strong>，从而使得我们能够在互联网上获取和交换各种信息。它使得不同的系统和平台能够相互通信，无论是大型的服务器集群还是小型的嵌入式设备，只要遵循 HTTP 协议，就能够进行有效的数据交互。</p>\n<p>比如，</p>\n<p>电子商务网站依靠 HTTP 协议来实现商品信息的展示、用户订单的提交和处理；</p>\n<p>社交媒体平台利用它来加载动态内容、上传和下载图片视频等；</p>\n<p>在线教育平台借助 HTTP 让学生获取课程资料、参与直播互动等。</p>\n<p>可以说，HTTP 是现代互联网应用的基石，没有它，我们所熟悉的丰富多彩的网络世界将不复存在。</p>\n<h2 id=\"2-HTTP-的发展历史\"><a href=\"#2-HTTP-的发展历史\" class=\"headerlink\" title=\"2. HTTP 的发展历史\"></a>2. HTTP 的发展历史</h2><table>\n<thead>\n<tr>\n<th>版本</th>\n<th>主要特性</th>\n<th>优点</th>\n<th>缺点</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HTTP&#x2F;0.9</td>\n<td>只支持 GET 方法，无请求和响应头部信息，服务器仅响应 HTML 文档，连接在响应后立即关闭</td>\n<td>简单，满足基本网页浏览需求</td>\n<td>功能单一，仅支持 HTML 文档获取，无连接复用</td>\n</tr>\n<tr>\n<td>HTTP&#x2F;1.0</td>\n<td>引入更多请求方法（如 POST、HEAD 等），增加请求和响应头部信息，支持多种文件类型传输</td>\n<td>丰富了网页内容呈现形式，能传输多种类型资源</td>\n<td>每个请求需建立新的 TCP 连接，性能较低</td>\n</tr>\n<tr>\n<td>HTTP&#x2F;1.1</td>\n<td>引入持久连接（Keep-Alive），增加更多请求方法（如 PUT、DELETE 等）和头部字段</td>\n<td>减少连接建立和关闭开销，提高网络传输效率，增强协议功能和灵活性</td>\n<td>仍存在性能瓶颈，如队头阻塞问题</td>\n</tr>\n<tr>\n<td>HTTP&#x2F;2</td>\n<td>采用二进制分帧层，实现多路复用，支持服务器推送</td>\n<td>显著提高资源并行传输能力，降低延迟，优化网络性能</td>\n<td>对服务器和客户端实现要求较高，部分老旧基础设施和设备支持不佳</td>\n</tr>\n<tr>\n<td>HTTP&#x2F;3</td>\n<td>基于 UDP 协议，引入 QUIC 协议，继承 HTTP&#x2F;2 特性</td>\n<td>进一步降低延迟，具备更好连接迁移能力和拥塞控制，提升性能和可靠性</td>\n<td>UDP 协议本身的可靠性相对 TCP 较弱，应用普及需要时间</td>\n</tr>\n</tbody></table>\n<h3 id=\"2-1-HTTP-0-9\"><a href=\"#2-1-HTTP-0-9\" class=\"headerlink\" title=\"2.1 HTTP&#x2F;0.9\"></a>2.1 HTTP&#x2F;0.9</h3><p>HTTP 的最初版本 HTTP&#x2F;0.9 极其简单，它<strong>只支持 GET 方法</strong>，主要用于获取 HTML 文档。在这个版本中，请求和响应都没有头部信息，服务器只能响应 HTML 格式的内容，并且连接在响应后立即关闭，不支持其他类型的资源传输和复杂的交互操作。但正是这个简单的版本开启了 HTTP 协议的发展之路，满足了当时人们对网页浏览的基本需求，使得网络信息的获取变得更加便捷。</p>\n<h3 id=\"2-2-HTTP-1-0\"><a href=\"#2-2-HTTP-1-0\" class=\"headerlink\" title=\"2.2 HTTP&#x2F;1.0\"></a>2.2 HTTP&#x2F;1.0</h3><p>随着网络应用的逐渐丰富，HTTP&#x2F;1.0 应运而生。它引入了<strong>更多的请求方法（如 POST、HEAD</strong> 等），并且增加了请求和响应的头部信息，使得客户端和服务器能够传递更多关于请求和响应的元数据，例如内容类型、编码方式等。这一版本还支持多种类型的文件传输，如图片、样式表等，大大丰富了网页的内容呈现形式。然而，HTTP&#x2F;1.0 存在一个显著的问题，即每个请求都需要建立一个新的 TCP 连接，这导致了在请求大量资源时效率较低，因为建立和关闭 TCP 连接的开销较大。</p>\n<h3 id=\"2-3-HTTP-1-1\"><a href=\"#2-3-HTTP-1-1\" class=\"headerlink\" title=\"2.3 HTTP&#x2F;1.1\"></a>2.3 HTTP&#x2F;1.1</h3><p>为了解决 HTTP&#x2F;1.0 的性能问题，HTTP&#x2F;1.1 进行了一系列重要的改进。它引入了<strong>持久连接（Keep-Alive）</strong>，允许在一个 TCP 连接上进行多个 HTTP 请求和响应的交互，减少了建立和关闭连接的开销，提高了网络传输效率。同时，还增加了更多的请求方法（如 PUT、DELETE 等）和头部字段，进一步增强了协议的功能和灵活性。HTTP&#x2F;1.1 成为了应用最广泛且持续时间最长的 HTTP 版本，至今仍在许多场景中被大量使用，但随着网络技术的不断发展和应用需求的日益增长，它也逐渐暴露出一些性能瓶颈。</p>\n<h3 id=\"2-4-HTTP-2\"><a href=\"#2-4-HTTP-2\" class=\"headerlink\" title=\"2.4 HTTP&#x2F;2\"></a>2.4 HTTP&#x2F;2</h3><p>HTTP&#x2F;2 在性能优化方面迈出了重大一步。它采用了二进制分帧层，将 HTTP 消息分解为更小的帧进行传输，这些帧可以在同一个 TCP 连接上交错发送和接收，从而实现了多路复用，大大提高了资源的并行传输能力，进一步提升了网络性能。同时，HTTP&#x2F;2 还支持服务器推送，服务器可以主动向客户端推送资源，减少了客户端请求的延迟。不过，HTTP&#x2F;2 的推广和应用也面临一些挑战，例如对服务器和客户端的实现要求较高，部分老旧的网络基础设施和设备可能无法很好地支持它。</p>\n<h3 id=\"2-5-HTTP-3\"><a href=\"#2-5-HTTP-3\" class=\"headerlink\" title=\"2.5 HTTP&#x2F;3\"></a>2.5 HTTP&#x2F;3</h3><p>为了克服 HTTP&#x2F;2 在 TCP 协议上的一些性能限制，HTTP&#x2F;3 基于 UDP 协议进行了全新的设计，引入了 QUIC 协议。QUIC 协议在 UDP 之上实现了类似 TCP 的可靠传输功能，同时还具备更低的延迟、更好的连接迁移能力以及对网络拥塞的优化控制。HTTP&#x2F;3 继承了 HTTP&#x2F;2 的许多优秀特性，如二进制分帧、多路复用和服务器推送等，并通过 QUIC 协议进一步提升了性能和可靠性。目前，HTTP&#x2F;3 正在逐渐得到广泛的应用和支持，有望成为未来网络通信的主流协议之一。</p>\n<h2 id=\"3-HTTP-的基本特点\"><a href=\"#3-HTTP-的基本特点\" class=\"headerlink\" title=\"3. HTTP 的基本特点\"></a>3. HTTP 的基本特点</h2><h3 id=\"3-1-无状态\"><a href=\"#3-1-无状态\" class=\"headerlink\" title=\"3.1 无状态\"></a>3.1 无状态</h3><p>HTTP 的无状态特性是指协议对于事务处理没有记忆能力。每一次的 HTTP 请求都是独立的，服务器不会记住之前的请求信息，也不会在不同的请求之间保留任何状态数据。</p>\n<p>例如，当你在一个电商网站上先后将两件商品加入购物车，对于服务器来说，这是两个完全独立的 HTTP 请求，它不会自动关联这两个操作，因为 HTTP 协议本身并不知道这两个请求来自同一个用户的同一次购物行为。这种无状态性使得服务器的设计更加简单高效，能够轻松应对大量并发的请求。但在某些需要保持用户状态的应用场景中，如用户登录后的权限管理、购物车功能等，就需要通过其他技术手段（如使用 Cookie、Session 等）来在客户端和服务器之间维护状态信息。</p>\n<h3 id=\"3-2-无连接\"><a href=\"#3-2-无连接\" class=\"headerlink\" title=\"3.2 无连接\"></a>3.2 无连接</h3><p>在 HTTP&#x2F;1.0 中，默认采用的是无连接的方式，即客户端与服务器在完成一次 HTTP 请求和响应后，会立即关闭连接。这种方式在每次请求都需要重新建立连接，虽然简单直接，但在请求频繁的情况下，会造成较大的性能开销，因为建立和关闭 TCP 连接需要消耗一定的时间和资源。</p>\n<p>而在 HTTP&#x2F;1.1 及以后的版本中，引入了持久连接（Keep-Alive）来改善这一问题，使得在一个 TCP 连接上可以进行多次 HTTP 请求和响应的交互，减少了连接建立和关闭的次数，从而提高了网络传输效率。但从协议本身的设计初衷来看，HTTP 最初是基于无连接的理念构建的，这种理念在一定程度上简化了服务器的实现和资源管理，同时也使得 HTTP 能够更灵活地适应不同的网络环境和应用场景。</p>\n<p>HTTP 作为网络通信领域的重要协议，从诞生之初到不断发展演变，始终在适应着互联网的发展需求。了解 HTTP 的定义、作用、发展历史和基本特点，不仅有助于我们深入理解网络通信的原理，更能为我们在开发高效、稳定的网络应用时提供有力的理论支持和实践指导。随着技术的不断进步，HTTP 协议也将继续进化，为构建更加智能、便捷的网络世界贡献力量。</p>\n<h3 id=\"3-3-基于请求-响应模型\"><a href=\"#3-3-基于请求-响应模型\" class=\"headerlink\" title=\"3.3 基于请求 - 响应模型\"></a>3.3 <strong>基于请求 - 响应模型</strong></h3><ul>\n<li><strong>工作方式</strong>：客户端发起请求，服务器接收请求后进行处理并返回响应。例如，当用户在浏览器中访问一个网页时，浏览器会构建一个HTTP请求，这个请求包含请求方法（如GET、POST等）、请求URL、请求头和请求体（如果是POST等方法可能有）等信息。服务器根据请求中的信息，查找相应的资源，然后构建一个HTTP响应，其中包含状态码、响应头和响应体（如网页内容、文件数据等），并将其发送回客户端。</li>\n<li><strong>优点</strong>：这种模型简单直观，使得客户端和服务器之间的交互逻辑清晰。开发人员可以很容易地理解和实现通信过程，方便构建各种网络应用。而且它允许服务器对不同的请求进行不同的处理，具有很好的灵活性。</li>\n<li><strong>应用场景</strong>：广泛应用于各种网络服务，如网页浏览、API调用等。在网页浏览中，浏览器根据用户输入的网址或者操作（如点击链接、提交表单）发送请求，服务器返回对应的网页或者处理结果。在API调用场景下，客户端（如移动应用、其他服务器等）通过HTTP请求向提供API的服务器获取或更新数据。</li>\n</ul>\n<h3 id=\"3-4-简单性和通用性\"><a href=\"#3-4-简单性和通用性\" class=\"headerlink\" title=\"3.4 简单性和通用性\"></a>3.4 <strong>简单性和通用性</strong></h3><ul>\n<li><p><strong>协议格式简单</strong>：HTTP是一种基于文本的协议，它的请求和响应消息格式相对简单，易于理解和实现。例如，一个简单的HTTP GET请求可能如下所示：</p>\n<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-keyword\">GET</span> <span class=\"hljs-string\">/index.html</span> <span class=\"hljs-meta\">HTTP/1.1</span><br><span class=\"hljs-attribute\">Host</span><span class=\"hljs-punctuation\">: </span>www.example.com<br></code></pre></td></tr></table></figure>\n<p>这是一个请求获取<code>www.example.com</code>网站的<code>index.html</code>文件的HTTP请求。第一行是请求行，包含请求方法（GET）、请求的资源路径（<code>/index.html</code>）和协议版本（<code>HTTP/1.1</code>）。后面的行是请求头，这里的<code>Host</code>头指定了请求的目标主机。</p>\n</li>\n<li><p><strong>通用性高</strong>：几乎所有的网络编程语言都提供了对HTTP的支持，无论是Python（通过<code>requests</code>库等）、Java（通过<code>java.net.HttpURLConnection</code>等）还是JavaScript（在浏览器中通过<code>XMLHttpRequest</code>或者<code>fetch</code> API）。这使得不同平台和语言编写的客户端和服务器能够很容易地进行通信。</p>\n</li>\n<li><p><strong>优点</strong>：由于简单性，开发人员可以快速上手，降低了开发网络应用的难度。通用性使得HTTP能够在各种不同的设备和系统中广泛应用，促进了网络的互联互通。</p>\n</li>\n<li><p><strong>应用场景</strong>：在物联网设备中，简单的传感器设备可以使用HTTP将采集的数据发送到服务器，或者接收服务器的控制指令。小型的Web应用开发，尤其是初学者或者快速原型开发，利用HTTP的简单性可以快速搭建起基本的功能架构。</p>\n</li>\n</ul>\n<h3 id=\"3-5-可扩展性\"><a href=\"#3-5-可扩展性\" class=\"headerlink\" title=\"3.5 可扩展性\"></a>3.5 <strong>可扩展性</strong></h3><ul>\n<li><strong>协议扩展机制</strong>：HTTP允许通过添加新的请求方法、头部字段等来扩展其功能。例如，随着Web应用的发展，出现了新的请求方法如PATCH（用于部分更新资源）。同时，自定义的头部字段也可以用于在客户端和服务器之间传递特定的元数据。</li>\n<li><strong>版本更新支持进步</strong>：从HTTP&#x2F;0.9到HTTP&#x2F;3的发展历程也体现了它的可扩展性。每个新版本都在保留基本的通信模式的基础上，对性能、功能等方面进行了扩展和优化。例如，HTTP&#x2F;2的二进制分帧和多路复用就是对原有协议传输机制的重大扩展，提高了协议的性能和效率。</li>\n<li><strong>优点</strong>：能够适应不断变化的网络应用需求。随着技术的发展，如移动互联网、云计算、物联网等新兴领域的出现，HTTP可以通过扩展来满足这些新场景下的数据传输和交互需求。</li>\n<li><strong>应用场景</strong>：在现代的微服务架构中，HTTP可以通过扩展来支持服务之间的复杂通信和协调。例如，在一个包含多个微服务的电商系统中，不同微服务之间（如用户服务、商品服务、订单服务等）可以通过自定义的HTTP请求方法和头部字段来实现高效的业务逻辑交互。</li>\n</ul>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n","excerpt":"","more":"<h1 id=\"HTTP协议概述\"><a href=\"#HTTP协议概述\" class=\"headerlink\" title=\"HTTP协议概述\"></a>HTTP协议概述</h1><p>在当今数字化的时代，我们每天都在与网络进行着无数次的交互，而这背后离不开众多网络协议的支撑，其中 HTTP（超文本传输协议）起着至关重要的作用。无论是浏览网页、使用手机应用获取数据，还是各种智能设备之间的信息传输，HTTP 都在默默地为我们服务。今天，就让我们深入了解一下 HTTP 的奥秘。</p>\n<h2 id=\"1-HTTP-的定义与作用\"><a href=\"#1-HTTP-的定义与作用\" class=\"headerlink\" title=\"1. HTTP 的定义与作用\"></a>1. HTTP 的定义与作用</h2><h3 id=\"1-1-定义\"><a href=\"#1-1-定义\" class=\"headerlink\" title=\"1.1 定义\"></a>1.1 定义</h3><p>HTTP 是一种用于分布式、协作式和超媒体信息系统的应用层协议。简单来说，它定义了客户端和服务器之间如何进行通信，规定了数据的格式、传输方式以及各种操作的方法。它工作在 <strong>TCP&#x2F;IP 协议栈的应用层</strong>，<strong>基于传输层的 TCP 协议</strong>来确保数据的可靠传输。</p>\n<p>例如，当你在浏览器中输入一个网址并按下回车键时，浏览器就会作为客户端向服务器发送一个 HTTP 请求，请求获取特定的网页资源。服务器接收到请求后，根据 HTTP 协议的规范对请求进行处理，并将相应的网页内容以 HTTP 响应的形式返回给浏览器，浏览器再将这些内容解析并展示给用户，这就是 HTTP 在我们日常网络浏览中最基本的工作流程。</p>\n<h3 id=\"1-2-作用\"><a href=\"#1-2-作用\" class=\"headerlink\" title=\"1.2 作用\"></a>1.2 作用</h3><p>HTTP 的主要作用是<strong>实现客户端和服务器之间的超文本数据传输</strong>，从而使得我们能够在互联网上获取和交换各种信息。它使得不同的系统和平台能够相互通信，无论是大型的服务器集群还是小型的嵌入式设备，只要遵循 HTTP 协议，就能够进行有效的数据交互。</p>\n<p>比如，</p>\n<p>电子商务网站依靠 HTTP 协议来实现商品信息的展示、用户订单的提交和处理；</p>\n<p>社交媒体平台利用它来加载动态内容、上传和下载图片视频等；</p>\n<p>在线教育平台借助 HTTP 让学生获取课程资料、参与直播互动等。</p>\n<p>可以说，HTTP 是现代互联网应用的基石，没有它，我们所熟悉的丰富多彩的网络世界将不复存在。</p>\n<h2 id=\"2-HTTP-的发展历史\"><a href=\"#2-HTTP-的发展历史\" class=\"headerlink\" title=\"2. HTTP 的发展历史\"></a>2. HTTP 的发展历史</h2><table>\n<thead>\n<tr>\n<th>版本</th>\n<th>主要特性</th>\n<th>优点</th>\n<th>缺点</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>HTTP&#x2F;0.9</td>\n<td>只支持 GET 方法，无请求和响应头部信息，服务器仅响应 HTML 文档，连接在响应后立即关闭</td>\n<td>简单，满足基本网页浏览需求</td>\n<td>功能单一，仅支持 HTML 文档获取，无连接复用</td>\n</tr>\n<tr>\n<td>HTTP&#x2F;1.0</td>\n<td>引入更多请求方法（如 POST、HEAD 等），增加请求和响应头部信息，支持多种文件类型传输</td>\n<td>丰富了网页内容呈现形式，能传输多种类型资源</td>\n<td>每个请求需建立新的 TCP 连接，性能较低</td>\n</tr>\n<tr>\n<td>HTTP&#x2F;1.1</td>\n<td>引入持久连接（Keep-Alive），增加更多请求方法（如 PUT、DELETE 等）和头部字段</td>\n<td>减少连接建立和关闭开销，提高网络传输效率，增强协议功能和灵活性</td>\n<td>仍存在性能瓶颈，如队头阻塞问题</td>\n</tr>\n<tr>\n<td>HTTP&#x2F;2</td>\n<td>采用二进制分帧层，实现多路复用，支持服务器推送</td>\n<td>显著提高资源并行传输能力，降低延迟，优化网络性能</td>\n<td>对服务器和客户端实现要求较高，部分老旧基础设施和设备支持不佳</td>\n</tr>\n<tr>\n<td>HTTP&#x2F;3</td>\n<td>基于 UDP 协议，引入 QUIC 协议，继承 HTTP&#x2F;2 特性</td>\n<td>进一步降低延迟，具备更好连接迁移能力和拥塞控制，提升性能和可靠性</td>\n<td>UDP 协议本身的可靠性相对 TCP 较弱，应用普及需要时间</td>\n</tr>\n</tbody></table>\n<h3 id=\"2-1-HTTP-0-9\"><a href=\"#2-1-HTTP-0-9\" class=\"headerlink\" title=\"2.1 HTTP&#x2F;0.9\"></a>2.1 HTTP&#x2F;0.9</h3><p>HTTP 的最初版本 HTTP&#x2F;0.9 极其简单，它<strong>只支持 GET 方法</strong>，主要用于获取 HTML 文档。在这个版本中，请求和响应都没有头部信息，服务器只能响应 HTML 格式的内容，并且连接在响应后立即关闭，不支持其他类型的资源传输和复杂的交互操作。但正是这个简单的版本开启了 HTTP 协议的发展之路，满足了当时人们对网页浏览的基本需求，使得网络信息的获取变得更加便捷。</p>\n<h3 id=\"2-2-HTTP-1-0\"><a href=\"#2-2-HTTP-1-0\" class=\"headerlink\" title=\"2.2 HTTP&#x2F;1.0\"></a>2.2 HTTP&#x2F;1.0</h3><p>随着网络应用的逐渐丰富，HTTP&#x2F;1.0 应运而生。它引入了<strong>更多的请求方法（如 POST、HEAD</strong> 等），并且增加了请求和响应的头部信息，使得客户端和服务器能够传递更多关于请求和响应的元数据，例如内容类型、编码方式等。这一版本还支持多种类型的文件传输，如图片、样式表等，大大丰富了网页的内容呈现形式。然而，HTTP&#x2F;1.0 存在一个显著的问题，即每个请求都需要建立一个新的 TCP 连接，这导致了在请求大量资源时效率较低，因为建立和关闭 TCP 连接的开销较大。</p>\n<h3 id=\"2-3-HTTP-1-1\"><a href=\"#2-3-HTTP-1-1\" class=\"headerlink\" title=\"2.3 HTTP&#x2F;1.1\"></a>2.3 HTTP&#x2F;1.1</h3><p>为了解决 HTTP&#x2F;1.0 的性能问题，HTTP&#x2F;1.1 进行了一系列重要的改进。它引入了<strong>持久连接（Keep-Alive）</strong>，允许在一个 TCP 连接上进行多个 HTTP 请求和响应的交互，减少了建立和关闭连接的开销，提高了网络传输效率。同时，还增加了更多的请求方法（如 PUT、DELETE 等）和头部字段，进一步增强了协议的功能和灵活性。HTTP&#x2F;1.1 成为了应用最广泛且持续时间最长的 HTTP 版本，至今仍在许多场景中被大量使用，但随着网络技术的不断发展和应用需求的日益增长，它也逐渐暴露出一些性能瓶颈。</p>\n<h3 id=\"2-4-HTTP-2\"><a href=\"#2-4-HTTP-2\" class=\"headerlink\" title=\"2.4 HTTP&#x2F;2\"></a>2.4 HTTP&#x2F;2</h3><p>HTTP&#x2F;2 在性能优化方面迈出了重大一步。它采用了二进制分帧层，将 HTTP 消息分解为更小的帧进行传输，这些帧可以在同一个 TCP 连接上交错发送和接收，从而实现了多路复用，大大提高了资源的并行传输能力，进一步提升了网络性能。同时，HTTP&#x2F;2 还支持服务器推送，服务器可以主动向客户端推送资源，减少了客户端请求的延迟。不过，HTTP&#x2F;2 的推广和应用也面临一些挑战，例如对服务器和客户端的实现要求较高，部分老旧的网络基础设施和设备可能无法很好地支持它。</p>\n<h3 id=\"2-5-HTTP-3\"><a href=\"#2-5-HTTP-3\" class=\"headerlink\" title=\"2.5 HTTP&#x2F;3\"></a>2.5 HTTP&#x2F;3</h3><p>为了克服 HTTP&#x2F;2 在 TCP 协议上的一些性能限制，HTTP&#x2F;3 基于 UDP 协议进行了全新的设计，引入了 QUIC 协议。QUIC 协议在 UDP 之上实现了类似 TCP 的可靠传输功能，同时还具备更低的延迟、更好的连接迁移能力以及对网络拥塞的优化控制。HTTP&#x2F;3 继承了 HTTP&#x2F;2 的许多优秀特性，如二进制分帧、多路复用和服务器推送等，并通过 QUIC 协议进一步提升了性能和可靠性。目前，HTTP&#x2F;3 正在逐渐得到广泛的应用和支持，有望成为未来网络通信的主流协议之一。</p>\n<h2 id=\"3-HTTP-的基本特点\"><a href=\"#3-HTTP-的基本特点\" class=\"headerlink\" title=\"3. HTTP 的基本特点\"></a>3. HTTP 的基本特点</h2><h3 id=\"3-1-无状态\"><a href=\"#3-1-无状态\" class=\"headerlink\" title=\"3.1 无状态\"></a>3.1 无状态</h3><p>HTTP 的无状态特性是指协议对于事务处理没有记忆能力。每一次的 HTTP 请求都是独立的，服务器不会记住之前的请求信息，也不会在不同的请求之间保留任何状态数据。</p>\n<p>例如，当你在一个电商网站上先后将两件商品加入购物车，对于服务器来说，这是两个完全独立的 HTTP 请求，它不会自动关联这两个操作，因为 HTTP 协议本身并不知道这两个请求来自同一个用户的同一次购物行为。这种无状态性使得服务器的设计更加简单高效，能够轻松应对大量并发的请求。但在某些需要保持用户状态的应用场景中，如用户登录后的权限管理、购物车功能等，就需要通过其他技术手段（如使用 Cookie、Session 等）来在客户端和服务器之间维护状态信息。</p>\n<h3 id=\"3-2-无连接\"><a href=\"#3-2-无连接\" class=\"headerlink\" title=\"3.2 无连接\"></a>3.2 无连接</h3><p>在 HTTP&#x2F;1.0 中，默认采用的是无连接的方式，即客户端与服务器在完成一次 HTTP 请求和响应后，会立即关闭连接。这种方式在每次请求都需要重新建立连接，虽然简单直接，但在请求频繁的情况下，会造成较大的性能开销，因为建立和关闭 TCP 连接需要消耗一定的时间和资源。</p>\n<p>而在 HTTP&#x2F;1.1 及以后的版本中，引入了持久连接（Keep-Alive）来改善这一问题，使得在一个 TCP 连接上可以进行多次 HTTP 请求和响应的交互，减少了连接建立和关闭的次数，从而提高了网络传输效率。但从协议本身的设计初衷来看，HTTP 最初是基于无连接的理念构建的，这种理念在一定程度上简化了服务器的实现和资源管理，同时也使得 HTTP 能够更灵活地适应不同的网络环境和应用场景。</p>\n<p>HTTP 作为网络通信领域的重要协议，从诞生之初到不断发展演变，始终在适应着互联网的发展需求。了解 HTTP 的定义、作用、发展历史和基本特点，不仅有助于我们深入理解网络通信的原理，更能为我们在开发高效、稳定的网络应用时提供有力的理论支持和实践指导。随着技术的不断进步，HTTP 协议也将继续进化，为构建更加智能、便捷的网络世界贡献力量。</p>\n<h3 id=\"3-3-基于请求-响应模型\"><a href=\"#3-3-基于请求-响应模型\" class=\"headerlink\" title=\"3.3 基于请求 - 响应模型\"></a>3.3 <strong>基于请求 - 响应模型</strong></h3><ul>\n<li><strong>工作方式</strong>：客户端发起请求，服务器接收请求后进行处理并返回响应。例如，当用户在浏览器中访问一个网页时，浏览器会构建一个HTTP请求，这个请求包含请求方法（如GET、POST等）、请求URL、请求头和请求体（如果是POST等方法可能有）等信息。服务器根据请求中的信息，查找相应的资源，然后构建一个HTTP响应，其中包含状态码、响应头和响应体（如网页内容、文件数据等），并将其发送回客户端。</li>\n<li><strong>优点</strong>：这种模型简单直观，使得客户端和服务器之间的交互逻辑清晰。开发人员可以很容易地理解和实现通信过程，方便构建各种网络应用。而且它允许服务器对不同的请求进行不同的处理，具有很好的灵活性。</li>\n<li><strong>应用场景</strong>：广泛应用于各种网络服务，如网页浏览、API调用等。在网页浏览中，浏览器根据用户输入的网址或者操作（如点击链接、提交表单）发送请求，服务器返回对应的网页或者处理结果。在API调用场景下，客户端（如移动应用、其他服务器等）通过HTTP请求向提供API的服务器获取或更新数据。</li>\n</ul>\n<h3 id=\"3-4-简单性和通用性\"><a href=\"#3-4-简单性和通用性\" class=\"headerlink\" title=\"3.4 简单性和通用性\"></a>3.4 <strong>简单性和通用性</strong></h3><ul>\n<li><p><strong>协议格式简单</strong>：HTTP是一种基于文本的协议，它的请求和响应消息格式相对简单，易于理解和实现。例如，一个简单的HTTP GET请求可能如下所示：</p>\n<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-keyword\">GET</span> <span class=\"hljs-string\">/index.html</span> <span class=\"hljs-meta\">HTTP/1.1</span><br><span class=\"hljs-attribute\">Host</span><span class=\"hljs-punctuation\">: </span>www.example.com<br></code></pre></td></tr></table></figure>\n<p>这是一个请求获取<code>www.example.com</code>网站的<code>index.html</code>文件的HTTP请求。第一行是请求行，包含请求方法（GET）、请求的资源路径（<code>/index.html</code>）和协议版本（<code>HTTP/1.1</code>）。后面的行是请求头，这里的<code>Host</code>头指定了请求的目标主机。</p>\n</li>\n<li><p><strong>通用性高</strong>：几乎所有的网络编程语言都提供了对HTTP的支持，无论是Python（通过<code>requests</code>库等）、Java（通过<code>java.net.HttpURLConnection</code>等）还是JavaScript（在浏览器中通过<code>XMLHttpRequest</code>或者<code>fetch</code> API）。这使得不同平台和语言编写的客户端和服务器能够很容易地进行通信。</p>\n</li>\n<li><p><strong>优点</strong>：由于简单性，开发人员可以快速上手，降低了开发网络应用的难度。通用性使得HTTP能够在各种不同的设备和系统中广泛应用，促进了网络的互联互通。</p>\n</li>\n<li><p><strong>应用场景</strong>：在物联网设备中，简单的传感器设备可以使用HTTP将采集的数据发送到服务器，或者接收服务器的控制指令。小型的Web应用开发，尤其是初学者或者快速原型开发，利用HTTP的简单性可以快速搭建起基本的功能架构。</p>\n</li>\n</ul>\n<h3 id=\"3-5-可扩展性\"><a href=\"#3-5-可扩展性\" class=\"headerlink\" title=\"3.5 可扩展性\"></a>3.5 <strong>可扩展性</strong></h3><ul>\n<li><strong>协议扩展机制</strong>：HTTP允许通过添加新的请求方法、头部字段等来扩展其功能。例如，随着Web应用的发展，出现了新的请求方法如PATCH（用于部分更新资源）。同时，自定义的头部字段也可以用于在客户端和服务器之间传递特定的元数据。</li>\n<li><strong>版本更新支持进步</strong>：从HTTP&#x2F;0.9到HTTP&#x2F;3的发展历程也体现了它的可扩展性。每个新版本都在保留基本的通信模式的基础上，对性能、功能等方面进行了扩展和优化。例如，HTTP&#x2F;2的二进制分帧和多路复用就是对原有协议传输机制的重大扩展，提高了协议的性能和效率。</li>\n<li><strong>优点</strong>：能够适应不断变化的网络应用需求。随着技术的发展，如移动互联网、云计算、物联网等新兴领域的出现，HTTP可以通过扩展来满足这些新场景下的数据传输和交互需求。</li>\n<li><strong>应用场景</strong>：在现代的微服务架构中，HTTP可以通过扩展来支持服务之间的复杂通信和协调。例如，在一个包含多个微服务的电商系统中，不同微服务之间（如用户服务、商品服务、订单服务等）可以通过自定义的HTTP请求方法和头部字段来实现高效的业务逻辑交互。</li>\n</ul>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n"},{"title":"C++ 中的 static 关键字：深入理解与应用","date":"2024-12-16T04:00:00.000Z","category_bar":true,"_content":"\n\n\n# C++ 中的 static 关键字：深入理解与应用\n\n## 一、引言\n\nC++ 语言以其强大的功能和灵活性著称，能够满足从底层系统编程到高层应用开发的广泛需求。在 C++ 中，`static` 关键字是一个非常重要且常用的关键字，它具有多种用途，能够帮助开发者更好地管理内存、控制作用域以及实现一些特定的编程模式。本文将详细探讨 `static` 关键字在 C++ 中的多种用途，并通过代码示例帮助读者深入理解其应用。\n\n## 二、static 关键字的基本概念\n\n### 1. 基本含义\n\n`static` 关键字在 C++ 中有两个基本含义：**静态存储期**和**内部链接性**。\n\n- **静态存储期**：静态存储期的变量在程序的整个运行期间都存在，不会在作用域结束时被销毁。\n- **内部链接性**：具有内部链接性的变量或函数只能在声明它的文件内部访问，不能被其他文件访问。\n\n### 2. static 与非 static 变量/函数的对比\n\n| 特性         | 非 static 变量/函数    | static 变量/函数           |\n| ------------ | ---------------------- | -------------------------- |\n| **存储位置** | 栈或堆                 | 静态存储区                 |\n| **生命周期** | 作用域结束时销毁       | 程序运行期间一直存在       |\n| **作用域**   | 局部作用域或全局作用域 | 局部作用域或文件内部作用域 |\n\n## 三、static 关键字在不同场景下的应用\n\n### 1. 静态局部变量\n\n#### 定义和语法\n\n静态局部变量是在局部作用域中使用 `static` 关键字声明的变量。\n\n```cpp\nvoid exampleFunction() {\n    static int count = 0;  // 静态局部变量\n    count++;\n    std::cout << \"Count: \" << count << std::endl;\n}\n```\n\n#### 特性\n\n- **只初始化一次**：静态局部变量在第一次进入该作用域时进行初始化，之后不再初始化。\n- **生命周期贯穿整个程序运行期间**：即使函数执行结束，静态局部变量的值仍然保留。\n- **作用域仅限于声明它的局部作用域**：静态局部变量只能在声明它的函数内部访问。\n\n#### 应用场景\n\n- **实现单例模式**：静态局部变量可以用于实现线程安全的单例模式。\n- **保存函数调用之间的状态**：静态局部变量可以用于保存函数调用之间的状态信息。\n\n#### 代码示例\n\n```cpp\n#include <iostream>\n\nvoid exampleFunction() {\n    static int count = 0;  // 静态局部变量，只初始化一次\n    count++;\n    std::cout << \"Count: \" << count << std::endl;\n}\n\nint main() {\n    exampleFunction();  // 输出: Count: 1\n    exampleFunction();  // 输出: Count: 2\n    exampleFunction();  // 输出: Count: 3\n    return 0;\n}\n```\n\n### 2. 静态全局变量和静态函数\n\n#### 定义和语法\n\n静态全局变量和静态函数是在全局作用域中使用 `static` 关键字声明的变量或函数。\n\n```cpp\nstatic int globalVar = 10;  // 静态全局变量\n\nstatic void staticFunction() {\n    std::cout << \"This is a static function.\" << std::endl;\n}\n```\n\n#### 特性\n\n- **限制作用域**：静态全局变量和静态函数的作用域仅限于声明它的文件内部。\n- **避免命名冲突**：静态全局变量和静态函数可以避免与其他文件中的同名变量或函数发生冲突。\n\n#### 应用场景\n\n- **实现文件级别的私有变量和函数**：静态全局变量和静态函数可以用于实现文件内部的私有变量和函数。\n- **组织代码**：静态全局变量和静态函数可以用于组织代码，提高代码的可读性和可维护性。\n\n#### 代码示例\n\n```cpp\n// file1.cpp\n#include <iostream>\n\nstatic int globalVar = 10;  // 静态全局变量，仅在 file1.cpp 中可见\n\nstatic void staticFunction() {  // 静态函数，仅在 file1.cpp 中可见\n    std::cout << \"GlobalVar: \" << globalVar << std::endl;\n}\n\nvoid callStaticFunction() {\n    staticFunction();  // 调用静态函数\n}\n\n// main.cpp\n#include <iostream>\n\nextern void callStaticFunction();\n\nint main() {\n    callStaticFunction();  // 输出: GlobalVar: 10\n    return 0;\n}\n```\n\n### 3. 静态成员变量和静态成员函数\n\n#### 定义和语法\n\n静态成员变量和静态成员函数是在类中使用 `static` 关键字声明的成员变量或成员函数。\n\n```cpp\nclass MyClass {\npublic:\n    static int staticVar;  // 静态成员变量\n\n    static void staticFunction() {  // 静态成员函数\n        std::cout << \"StaticVar: \" << staticVar << std::endl;\n    }\n};\n\nint MyClass::staticVar = 20;  // 静态成员变量的初始化\n```\n\n#### 特性\n\n- **属于类本身**：静态成员变量和静态成员函数属于类本身，而非类的实例，所有对象共享同一个静态成员变量。\n- **只能访问静态成员**：静态成员函数只能访问静态成员变量和静态成员函数，不能访问非静态成员变量和非静态成员函数。\n- **必须在类外初始化**：静态成员变量必须在类外进行初始化。\n\n#### 应用场景\n\n- **实现类级别的计数器、共享资源等**：静态成员变量可以用于实现类级别的计数器或共享资源。\n- **提供与对象无关的类级别接口**：静态成员函数可以用于提供与对象无关的类级别接口。\n\n#### 代码示例\n\n```cpp\n#include <iostream>\n\nclass MyClass {\npublic:\n    static int staticVar;  // 静态成员变量\n\n    static void staticFunction() {  // 静态成员函数\n        std::cout << \"StaticVar: \" << staticVar << std::endl;\n    }\n};\n\nint MyClass::staticVar = 20;  // 静态成员变量的初始化\n\nint main() {\n    MyClass::staticFunction();  // 输出: StaticVar: 20\n    return 0;\n}\n```\n\n## 四、static 关键字的注意事项\n\n### 1. 静态局部变量的初始化顺序问题\n\n静态局部变量的初始化顺序是按照它们在代码中出现的顺序进行的。如果多个静态局部变量之间存在依赖关系，可能会导致未定义行为。\n\n### 2. 静态成员变量的初始化顺序问题\n\n静态成员变量的初始化顺序是按照它们在类中声明的顺序进行的。如果多个静态成员变量之间存在依赖关系，可能会导致未定义行为。\n\n### 3. 静态成员函数不能访问非静态成员变量和非静态成员函数的原因\n\n静态成员函数没有 `this` 指针，因此无法访问非静态成员变量和非静态成员函数。\n\n### 4. 避免滥用 static 关键字\n\n滥用 `static` 关键字可能会导致代码的可读性和可维护性下降。因此，在使用 `static` 关键字时，应谨慎考虑其适用场景。\n\n## 五、总结\n\n本文详细探讨了 `static` 关键字在 C++ 中的多种用途，包括静态局部变量、静态全局变量和静态函数、静态成员变量和静态成员函数。通过代码示例，我们深入理解了 `static` 关键字的工作原理和应用场景。\n\n理解 `static` 关键字的重要性不言而喻，它能够帮助我们更好地管理内存、控制作用域以及实现一些特定的编程模式。在实际编程中，合理使用 `static` 关键字可以提高代码的可读性和可维护性。\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)\n","source":"_posts/开发/cpp/C++基础：C++ 中的 static 关键字：深入理解与应用.md","raw":"---\ntitle: 'C++ 中的 static 关键字：深入理解与应用'\ncategories:\n  - [开发,cpp]\ntags:\n  - c++\n  - cpp\n  - c++基础\ndate: 2024-12-16 12:00:00\ncategory_bar: true\n---\n\n\n\n# C++ 中的 static 关键字：深入理解与应用\n\n## 一、引言\n\nC++ 语言以其强大的功能和灵活性著称，能够满足从底层系统编程到高层应用开发的广泛需求。在 C++ 中，`static` 关键字是一个非常重要且常用的关键字，它具有多种用途，能够帮助开发者更好地管理内存、控制作用域以及实现一些特定的编程模式。本文将详细探讨 `static` 关键字在 C++ 中的多种用途，并通过代码示例帮助读者深入理解其应用。\n\n## 二、static 关键字的基本概念\n\n### 1. 基本含义\n\n`static` 关键字在 C++ 中有两个基本含义：**静态存储期**和**内部链接性**。\n\n- **静态存储期**：静态存储期的变量在程序的整个运行期间都存在，不会在作用域结束时被销毁。\n- **内部链接性**：具有内部链接性的变量或函数只能在声明它的文件内部访问，不能被其他文件访问。\n\n### 2. static 与非 static 变量/函数的对比\n\n| 特性         | 非 static 变量/函数    | static 变量/函数           |\n| ------------ | ---------------------- | -------------------------- |\n| **存储位置** | 栈或堆                 | 静态存储区                 |\n| **生命周期** | 作用域结束时销毁       | 程序运行期间一直存在       |\n| **作用域**   | 局部作用域或全局作用域 | 局部作用域或文件内部作用域 |\n\n## 三、static 关键字在不同场景下的应用\n\n### 1. 静态局部变量\n\n#### 定义和语法\n\n静态局部变量是在局部作用域中使用 `static` 关键字声明的变量。\n\n```cpp\nvoid exampleFunction() {\n    static int count = 0;  // 静态局部变量\n    count++;\n    std::cout << \"Count: \" << count << std::endl;\n}\n```\n\n#### 特性\n\n- **只初始化一次**：静态局部变量在第一次进入该作用域时进行初始化，之后不再初始化。\n- **生命周期贯穿整个程序运行期间**：即使函数执行结束，静态局部变量的值仍然保留。\n- **作用域仅限于声明它的局部作用域**：静态局部变量只能在声明它的函数内部访问。\n\n#### 应用场景\n\n- **实现单例模式**：静态局部变量可以用于实现线程安全的单例模式。\n- **保存函数调用之间的状态**：静态局部变量可以用于保存函数调用之间的状态信息。\n\n#### 代码示例\n\n```cpp\n#include <iostream>\n\nvoid exampleFunction() {\n    static int count = 0;  // 静态局部变量，只初始化一次\n    count++;\n    std::cout << \"Count: \" << count << std::endl;\n}\n\nint main() {\n    exampleFunction();  // 输出: Count: 1\n    exampleFunction();  // 输出: Count: 2\n    exampleFunction();  // 输出: Count: 3\n    return 0;\n}\n```\n\n### 2. 静态全局变量和静态函数\n\n#### 定义和语法\n\n静态全局变量和静态函数是在全局作用域中使用 `static` 关键字声明的变量或函数。\n\n```cpp\nstatic int globalVar = 10;  // 静态全局变量\n\nstatic void staticFunction() {\n    std::cout << \"This is a static function.\" << std::endl;\n}\n```\n\n#### 特性\n\n- **限制作用域**：静态全局变量和静态函数的作用域仅限于声明它的文件内部。\n- **避免命名冲突**：静态全局变量和静态函数可以避免与其他文件中的同名变量或函数发生冲突。\n\n#### 应用场景\n\n- **实现文件级别的私有变量和函数**：静态全局变量和静态函数可以用于实现文件内部的私有变量和函数。\n- **组织代码**：静态全局变量和静态函数可以用于组织代码，提高代码的可读性和可维护性。\n\n#### 代码示例\n\n```cpp\n// file1.cpp\n#include <iostream>\n\nstatic int globalVar = 10;  // 静态全局变量，仅在 file1.cpp 中可见\n\nstatic void staticFunction() {  // 静态函数，仅在 file1.cpp 中可见\n    std::cout << \"GlobalVar: \" << globalVar << std::endl;\n}\n\nvoid callStaticFunction() {\n    staticFunction();  // 调用静态函数\n}\n\n// main.cpp\n#include <iostream>\n\nextern void callStaticFunction();\n\nint main() {\n    callStaticFunction();  // 输出: GlobalVar: 10\n    return 0;\n}\n```\n\n### 3. 静态成员变量和静态成员函数\n\n#### 定义和语法\n\n静态成员变量和静态成员函数是在类中使用 `static` 关键字声明的成员变量或成员函数。\n\n```cpp\nclass MyClass {\npublic:\n    static int staticVar;  // 静态成员变量\n\n    static void staticFunction() {  // 静态成员函数\n        std::cout << \"StaticVar: \" << staticVar << std::endl;\n    }\n};\n\nint MyClass::staticVar = 20;  // 静态成员变量的初始化\n```\n\n#### 特性\n\n- **属于类本身**：静态成员变量和静态成员函数属于类本身，而非类的实例，所有对象共享同一个静态成员变量。\n- **只能访问静态成员**：静态成员函数只能访问静态成员变量和静态成员函数，不能访问非静态成员变量和非静态成员函数。\n- **必须在类外初始化**：静态成员变量必须在类外进行初始化。\n\n#### 应用场景\n\n- **实现类级别的计数器、共享资源等**：静态成员变量可以用于实现类级别的计数器或共享资源。\n- **提供与对象无关的类级别接口**：静态成员函数可以用于提供与对象无关的类级别接口。\n\n#### 代码示例\n\n```cpp\n#include <iostream>\n\nclass MyClass {\npublic:\n    static int staticVar;  // 静态成员变量\n\n    static void staticFunction() {  // 静态成员函数\n        std::cout << \"StaticVar: \" << staticVar << std::endl;\n    }\n};\n\nint MyClass::staticVar = 20;  // 静态成员变量的初始化\n\nint main() {\n    MyClass::staticFunction();  // 输出: StaticVar: 20\n    return 0;\n}\n```\n\n## 四、static 关键字的注意事项\n\n### 1. 静态局部变量的初始化顺序问题\n\n静态局部变量的初始化顺序是按照它们在代码中出现的顺序进行的。如果多个静态局部变量之间存在依赖关系，可能会导致未定义行为。\n\n### 2. 静态成员变量的初始化顺序问题\n\n静态成员变量的初始化顺序是按照它们在类中声明的顺序进行的。如果多个静态成员变量之间存在依赖关系，可能会导致未定义行为。\n\n### 3. 静态成员函数不能访问非静态成员变量和非静态成员函数的原因\n\n静态成员函数没有 `this` 指针，因此无法访问非静态成员变量和非静态成员函数。\n\n### 4. 避免滥用 static 关键字\n\n滥用 `static` 关键字可能会导致代码的可读性和可维护性下降。因此，在使用 `static` 关键字时，应谨慎考虑其适用场景。\n\n## 五、总结\n\n本文详细探讨了 `static` 关键字在 C++ 中的多种用途，包括静态局部变量、静态全局变量和静态函数、静态成员变量和静态成员函数。通过代码示例，我们深入理解了 `static` 关键字的工作原理和应用场景。\n\n理解 `static` 关键字的重要性不言而喻，它能够帮助我们更好地管理内存、控制作用域以及实现一些特定的编程模式。在实际编程中，合理使用 `static` 关键字可以提高代码的可读性和可维护性。\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)\n","slug":"开发/cpp/C++基础：C++ 中的 static 关键字：深入理解与应用","published":1,"updated":"2024-12-26T06:37:41.944Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3j000ohghid1ndcnw1","content":"<h1 id=\"C-中的-static-关键字：深入理解与应用\"><a href=\"#C-中的-static-关键字：深入理解与应用\" class=\"headerlink\" title=\"C++ 中的 static 关键字：深入理解与应用\"></a>C++ 中的 static 关键字：深入理解与应用</h1><h2 id=\"一、引言\"><a href=\"#一、引言\" class=\"headerlink\" title=\"一、引言\"></a>一、引言</h2><p>C++ 语言以其强大的功能和灵活性著称，能够满足从底层系统编程到高层应用开发的广泛需求。在 C++ 中，<code>static</code> 关键字是一个非常重要且常用的关键字，它具有多种用途，能够帮助开发者更好地管理内存、控制作用域以及实现一些特定的编程模式。本文将详细探讨 <code>static</code> 关键字在 C++ 中的多种用途，并通过代码示例帮助读者深入理解其应用。</p>\n<h2 id=\"二、static-关键字的基本概念\"><a href=\"#二、static-关键字的基本概念\" class=\"headerlink\" title=\"二、static 关键字的基本概念\"></a>二、static 关键字的基本概念</h2><h3 id=\"1-基本含义\"><a href=\"#1-基本含义\" class=\"headerlink\" title=\"1. 基本含义\"></a>1. 基本含义</h3><p><code>static</code> 关键字在 C++ 中有两个基本含义：<strong>静态存储期</strong>和<strong>内部链接性</strong>。</p>\n<ul>\n<li><strong>静态存储期</strong>：静态存储期的变量在程序的整个运行期间都存在，不会在作用域结束时被销毁。</li>\n<li><strong>内部链接性</strong>：具有内部链接性的变量或函数只能在声明它的文件内部访问，不能被其他文件访问。</li>\n</ul>\n<h3 id=\"2-static-与非-static-变量-函数的对比\"><a href=\"#2-static-与非-static-变量-函数的对比\" class=\"headerlink\" title=\"2. static 与非 static 变量&#x2F;函数的对比\"></a>2. static 与非 static 变量&#x2F;函数的对比</h3><table>\n<thead>\n<tr>\n<th>特性</th>\n<th>非 static 变量&#x2F;函数</th>\n<th>static 变量&#x2F;函数</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>存储位置</strong></td>\n<td>栈或堆</td>\n<td>静态存储区</td>\n</tr>\n<tr>\n<td><strong>生命周期</strong></td>\n<td>作用域结束时销毁</td>\n<td>程序运行期间一直存在</td>\n</tr>\n<tr>\n<td><strong>作用域</strong></td>\n<td>局部作用域或全局作用域</td>\n<td>局部作用域或文件内部作用域</td>\n</tr>\n</tbody></table>\n<h2 id=\"三、static-关键字在不同场景下的应用\"><a href=\"#三、static-关键字在不同场景下的应用\" class=\"headerlink\" title=\"三、static 关键字在不同场景下的应用\"></a>三、static 关键字在不同场景下的应用</h2><h3 id=\"1-静态局部变量\"><a href=\"#1-静态局部变量\" class=\"headerlink\" title=\"1. 静态局部变量\"></a>1. 静态局部变量</h3><h4 id=\"定义和语法\"><a href=\"#定义和语法\" class=\"headerlink\" title=\"定义和语法\"></a>定义和语法</h4><p>静态局部变量是在局部作用域中使用 <code>static</code> 关键字声明的变量。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">exampleFunction</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">static</span> <span class=\"hljs-type\">int</span> count = <span class=\"hljs-number\">0</span>;  <span class=\"hljs-comment\">// 静态局部变量</span><br>    count++;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Count: &quot;</span> &lt;&lt; count &lt;&lt; std::endl;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"特性\"><a href=\"#特性\" class=\"headerlink\" title=\"特性\"></a>特性</h4><ul>\n<li><strong>只初始化一次</strong>：静态局部变量在第一次进入该作用域时进行初始化，之后不再初始化。</li>\n<li><strong>生命周期贯穿整个程序运行期间</strong>：即使函数执行结束，静态局部变量的值仍然保留。</li>\n<li><strong>作用域仅限于声明它的局部作用域</strong>：静态局部变量只能在声明它的函数内部访问。</li>\n</ul>\n<h4 id=\"应用场景\"><a href=\"#应用场景\" class=\"headerlink\" title=\"应用场景\"></a>应用场景</h4><ul>\n<li><strong>实现单例模式</strong>：静态局部变量可以用于实现线程安全的单例模式。</li>\n<li><strong>保存函数调用之间的状态</strong>：静态局部变量可以用于保存函数调用之间的状态信息。</li>\n</ul>\n<h4 id=\"代码示例\"><a href=\"#代码示例\" class=\"headerlink\" title=\"代码示例\"></a>代码示例</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">exampleFunction</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">static</span> <span class=\"hljs-type\">int</span> count = <span class=\"hljs-number\">0</span>;  <span class=\"hljs-comment\">// 静态局部变量，只初始化一次</span><br>    count++;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Count: &quot;</span> &lt;&lt; count &lt;&lt; std::endl;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-built_in\">exampleFunction</span>();  <span class=\"hljs-comment\">// 输出: Count: 1</span><br>    <span class=\"hljs-built_in\">exampleFunction</span>();  <span class=\"hljs-comment\">// 输出: Count: 2</span><br>    <span class=\"hljs-built_in\">exampleFunction</span>();  <span class=\"hljs-comment\">// 输出: Count: 3</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"2-静态全局变量和静态函数\"><a href=\"#2-静态全局变量和静态函数\" class=\"headerlink\" title=\"2. 静态全局变量和静态函数\"></a>2. 静态全局变量和静态函数</h3><h4 id=\"定义和语法-1\"><a href=\"#定义和语法-1\" class=\"headerlink\" title=\"定义和语法\"></a>定义和语法</h4><p>静态全局变量和静态函数是在全局作用域中使用 <code>static</code> 关键字声明的变量或函数。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-type\">static</span> <span class=\"hljs-type\">int</span> globalVar = <span class=\"hljs-number\">10</span>;  <span class=\"hljs-comment\">// 静态全局变量</span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">static</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">staticFunction</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;This is a static function.&quot;</span> &lt;&lt; std::endl;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"特性-1\"><a href=\"#特性-1\" class=\"headerlink\" title=\"特性\"></a>特性</h4><ul>\n<li><strong>限制作用域</strong>：静态全局变量和静态函数的作用域仅限于声明它的文件内部。</li>\n<li><strong>避免命名冲突</strong>：静态全局变量和静态函数可以避免与其他文件中的同名变量或函数发生冲突。</li>\n</ul>\n<h4 id=\"应用场景-1\"><a href=\"#应用场景-1\" class=\"headerlink\" title=\"应用场景\"></a>应用场景</h4><ul>\n<li><strong>实现文件级别的私有变量和函数</strong>：静态全局变量和静态函数可以用于实现文件内部的私有变量和函数。</li>\n<li><strong>组织代码</strong>：静态全局变量和静态函数可以用于组织代码，提高代码的可读性和可维护性。</li>\n</ul>\n<h4 id=\"代码示例-1\"><a href=\"#代码示例-1\" class=\"headerlink\" title=\"代码示例\"></a>代码示例</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// file1.cpp</span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-type\">static</span> <span class=\"hljs-type\">int</span> globalVar = <span class=\"hljs-number\">10</span>;  <span class=\"hljs-comment\">// 静态全局变量，仅在 file1.cpp 中可见</span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">static</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">staticFunction</span><span class=\"hljs-params\">()</span> </span>&#123;  <span class=\"hljs-comment\">// 静态函数，仅在 file1.cpp 中可见</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;GlobalVar: &quot;</span> &lt;&lt; globalVar &lt;&lt; std::endl;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">callStaticFunction</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-built_in\">staticFunction</span>();  <span class=\"hljs-comment\">// 调用静态函数</span><br>&#125;<br><br><span class=\"hljs-comment\">// main.cpp</span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">extern</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">callStaticFunction</span><span class=\"hljs-params\">()</span></span>;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-built_in\">callStaticFunction</span>();  <span class=\"hljs-comment\">// 输出: GlobalVar: 10</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"3-静态成员变量和静态成员函数\"><a href=\"#3-静态成员变量和静态成员函数\" class=\"headerlink\" title=\"3. 静态成员变量和静态成员函数\"></a>3. 静态成员变量和静态成员函数</h3><h4 id=\"定义和语法-2\"><a href=\"#定义和语法-2\" class=\"headerlink\" title=\"定义和语法\"></a>定义和语法</h4><p>静态成员变量和静态成员函数是在类中使用 <code>static</code> 关键字声明的成员变量或成员函数。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyClass</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-type\">static</span> <span class=\"hljs-type\">int</span> staticVar;  <span class=\"hljs-comment\">// 静态成员变量</span><br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">staticFunction</span><span class=\"hljs-params\">()</span> </span>&#123;  <span class=\"hljs-comment\">// 静态成员函数</span><br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;StaticVar: &quot;</span> &lt;&lt; staticVar &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-type\">int</span> MyClass::staticVar = <span class=\"hljs-number\">20</span>;  <span class=\"hljs-comment\">// 静态成员变量的初始化</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"特性-2\"><a href=\"#特性-2\" class=\"headerlink\" title=\"特性\"></a>特性</h4><ul>\n<li><strong>属于类本身</strong>：静态成员变量和静态成员函数属于类本身，而非类的实例，所有对象共享同一个静态成员变量。</li>\n<li><strong>只能访问静态成员</strong>：静态成员函数只能访问静态成员变量和静态成员函数，不能访问非静态成员变量和非静态成员函数。</li>\n<li><strong>必须在类外初始化</strong>：静态成员变量必须在类外进行初始化。</li>\n</ul>\n<h4 id=\"应用场景-2\"><a href=\"#应用场景-2\" class=\"headerlink\" title=\"应用场景\"></a>应用场景</h4><ul>\n<li><strong>实现类级别的计数器、共享资源等</strong>：静态成员变量可以用于实现类级别的计数器或共享资源。</li>\n<li><strong>提供与对象无关的类级别接口</strong>：静态成员函数可以用于提供与对象无关的类级别接口。</li>\n</ul>\n<h4 id=\"代码示例-2\"><a href=\"#代码示例-2\" class=\"headerlink\" title=\"代码示例\"></a>代码示例</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyClass</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-type\">static</span> <span class=\"hljs-type\">int</span> staticVar;  <span class=\"hljs-comment\">// 静态成员变量</span><br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">staticFunction</span><span class=\"hljs-params\">()</span> </span>&#123;  <span class=\"hljs-comment\">// 静态成员函数</span><br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;StaticVar: &quot;</span> &lt;&lt; staticVar &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-type\">int</span> MyClass::staticVar = <span class=\"hljs-number\">20</span>;  <span class=\"hljs-comment\">// 静态成员变量的初始化</span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    MyClass::<span class=\"hljs-built_in\">staticFunction</span>();  <span class=\"hljs-comment\">// 输出: StaticVar: 20</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"四、static-关键字的注意事项\"><a href=\"#四、static-关键字的注意事项\" class=\"headerlink\" title=\"四、static 关键字的注意事项\"></a>四、static 关键字的注意事项</h2><h3 id=\"1-静态局部变量的初始化顺序问题\"><a href=\"#1-静态局部变量的初始化顺序问题\" class=\"headerlink\" title=\"1. 静态局部变量的初始化顺序问题\"></a>1. 静态局部变量的初始化顺序问题</h3><p>静态局部变量的初始化顺序是按照它们在代码中出现的顺序进行的。如果多个静态局部变量之间存在依赖关系，可能会导致未定义行为。</p>\n<h3 id=\"2-静态成员变量的初始化顺序问题\"><a href=\"#2-静态成员变量的初始化顺序问题\" class=\"headerlink\" title=\"2. 静态成员变量的初始化顺序问题\"></a>2. 静态成员变量的初始化顺序问题</h3><p>静态成员变量的初始化顺序是按照它们在类中声明的顺序进行的。如果多个静态成员变量之间存在依赖关系，可能会导致未定义行为。</p>\n<h3 id=\"3-静态成员函数不能访问非静态成员变量和非静态成员函数的原因\"><a href=\"#3-静态成员函数不能访问非静态成员变量和非静态成员函数的原因\" class=\"headerlink\" title=\"3. 静态成员函数不能访问非静态成员变量和非静态成员函数的原因\"></a>3. 静态成员函数不能访问非静态成员变量和非静态成员函数的原因</h3><p>静态成员函数没有 <code>this</code> 指针，因此无法访问非静态成员变量和非静态成员函数。</p>\n<h3 id=\"4-避免滥用-static-关键字\"><a href=\"#4-避免滥用-static-关键字\" class=\"headerlink\" title=\"4. 避免滥用 static 关键字\"></a>4. 避免滥用 static 关键字</h3><p>滥用 <code>static</code> 关键字可能会导致代码的可读性和可维护性下降。因此，在使用 <code>static</code> 关键字时，应谨慎考虑其适用场景。</p>\n<h2 id=\"五、总结\"><a href=\"#五、总结\" class=\"headerlink\" title=\"五、总结\"></a>五、总结</h2><p>本文详细探讨了 <code>static</code> 关键字在 C++ 中的多种用途，包括静态局部变量、静态全局变量和静态函数、静态成员变量和静态成员函数。通过代码示例，我们深入理解了 <code>static</code> 关键字的工作原理和应用场景。</p>\n<p>理解 <code>static</code> 关键字的重要性不言而喻，它能够帮助我们更好地管理内存、控制作用域以及实现一些特定的编程模式。在实际编程中，合理使用 <code>static</code> 关键字可以提高代码的可读性和可维护性。</p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n","excerpt":"","more":"<h1 id=\"C-中的-static-关键字：深入理解与应用\"><a href=\"#C-中的-static-关键字：深入理解与应用\" class=\"headerlink\" title=\"C++ 中的 static 关键字：深入理解与应用\"></a>C++ 中的 static 关键字：深入理解与应用</h1><h2 id=\"一、引言\"><a href=\"#一、引言\" class=\"headerlink\" title=\"一、引言\"></a>一、引言</h2><p>C++ 语言以其强大的功能和灵活性著称，能够满足从底层系统编程到高层应用开发的广泛需求。在 C++ 中，<code>static</code> 关键字是一个非常重要且常用的关键字，它具有多种用途，能够帮助开发者更好地管理内存、控制作用域以及实现一些特定的编程模式。本文将详细探讨 <code>static</code> 关键字在 C++ 中的多种用途，并通过代码示例帮助读者深入理解其应用。</p>\n<h2 id=\"二、static-关键字的基本概念\"><a href=\"#二、static-关键字的基本概念\" class=\"headerlink\" title=\"二、static 关键字的基本概念\"></a>二、static 关键字的基本概念</h2><h3 id=\"1-基本含义\"><a href=\"#1-基本含义\" class=\"headerlink\" title=\"1. 基本含义\"></a>1. 基本含义</h3><p><code>static</code> 关键字在 C++ 中有两个基本含义：<strong>静态存储期</strong>和<strong>内部链接性</strong>。</p>\n<ul>\n<li><strong>静态存储期</strong>：静态存储期的变量在程序的整个运行期间都存在，不会在作用域结束时被销毁。</li>\n<li><strong>内部链接性</strong>：具有内部链接性的变量或函数只能在声明它的文件内部访问，不能被其他文件访问。</li>\n</ul>\n<h3 id=\"2-static-与非-static-变量-函数的对比\"><a href=\"#2-static-与非-static-变量-函数的对比\" class=\"headerlink\" title=\"2. static 与非 static 变量&#x2F;函数的对比\"></a>2. static 与非 static 变量&#x2F;函数的对比</h3><table>\n<thead>\n<tr>\n<th>特性</th>\n<th>非 static 变量&#x2F;函数</th>\n<th>static 变量&#x2F;函数</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>存储位置</strong></td>\n<td>栈或堆</td>\n<td>静态存储区</td>\n</tr>\n<tr>\n<td><strong>生命周期</strong></td>\n<td>作用域结束时销毁</td>\n<td>程序运行期间一直存在</td>\n</tr>\n<tr>\n<td><strong>作用域</strong></td>\n<td>局部作用域或全局作用域</td>\n<td>局部作用域或文件内部作用域</td>\n</tr>\n</tbody></table>\n<h2 id=\"三、static-关键字在不同场景下的应用\"><a href=\"#三、static-关键字在不同场景下的应用\" class=\"headerlink\" title=\"三、static 关键字在不同场景下的应用\"></a>三、static 关键字在不同场景下的应用</h2><h3 id=\"1-静态局部变量\"><a href=\"#1-静态局部变量\" class=\"headerlink\" title=\"1. 静态局部变量\"></a>1. 静态局部变量</h3><h4 id=\"定义和语法\"><a href=\"#定义和语法\" class=\"headerlink\" title=\"定义和语法\"></a>定义和语法</h4><p>静态局部变量是在局部作用域中使用 <code>static</code> 关键字声明的变量。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">exampleFunction</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">static</span> <span class=\"hljs-type\">int</span> count = <span class=\"hljs-number\">0</span>;  <span class=\"hljs-comment\">// 静态局部变量</span><br>    count++;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Count: &quot;</span> &lt;&lt; count &lt;&lt; std::endl;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"特性\"><a href=\"#特性\" class=\"headerlink\" title=\"特性\"></a>特性</h4><ul>\n<li><strong>只初始化一次</strong>：静态局部变量在第一次进入该作用域时进行初始化，之后不再初始化。</li>\n<li><strong>生命周期贯穿整个程序运行期间</strong>：即使函数执行结束，静态局部变量的值仍然保留。</li>\n<li><strong>作用域仅限于声明它的局部作用域</strong>：静态局部变量只能在声明它的函数内部访问。</li>\n</ul>\n<h4 id=\"应用场景\"><a href=\"#应用场景\" class=\"headerlink\" title=\"应用场景\"></a>应用场景</h4><ul>\n<li><strong>实现单例模式</strong>：静态局部变量可以用于实现线程安全的单例模式。</li>\n<li><strong>保存函数调用之间的状态</strong>：静态局部变量可以用于保存函数调用之间的状态信息。</li>\n</ul>\n<h4 id=\"代码示例\"><a href=\"#代码示例\" class=\"headerlink\" title=\"代码示例\"></a>代码示例</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">exampleFunction</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">static</span> <span class=\"hljs-type\">int</span> count = <span class=\"hljs-number\">0</span>;  <span class=\"hljs-comment\">// 静态局部变量，只初始化一次</span><br>    count++;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Count: &quot;</span> &lt;&lt; count &lt;&lt; std::endl;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-built_in\">exampleFunction</span>();  <span class=\"hljs-comment\">// 输出: Count: 1</span><br>    <span class=\"hljs-built_in\">exampleFunction</span>();  <span class=\"hljs-comment\">// 输出: Count: 2</span><br>    <span class=\"hljs-built_in\">exampleFunction</span>();  <span class=\"hljs-comment\">// 输出: Count: 3</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"2-静态全局变量和静态函数\"><a href=\"#2-静态全局变量和静态函数\" class=\"headerlink\" title=\"2. 静态全局变量和静态函数\"></a>2. 静态全局变量和静态函数</h3><h4 id=\"定义和语法-1\"><a href=\"#定义和语法-1\" class=\"headerlink\" title=\"定义和语法\"></a>定义和语法</h4><p>静态全局变量和静态函数是在全局作用域中使用 <code>static</code> 关键字声明的变量或函数。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-type\">static</span> <span class=\"hljs-type\">int</span> globalVar = <span class=\"hljs-number\">10</span>;  <span class=\"hljs-comment\">// 静态全局变量</span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">static</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">staticFunction</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;This is a static function.&quot;</span> &lt;&lt; std::endl;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"特性-1\"><a href=\"#特性-1\" class=\"headerlink\" title=\"特性\"></a>特性</h4><ul>\n<li><strong>限制作用域</strong>：静态全局变量和静态函数的作用域仅限于声明它的文件内部。</li>\n<li><strong>避免命名冲突</strong>：静态全局变量和静态函数可以避免与其他文件中的同名变量或函数发生冲突。</li>\n</ul>\n<h4 id=\"应用场景-1\"><a href=\"#应用场景-1\" class=\"headerlink\" title=\"应用场景\"></a>应用场景</h4><ul>\n<li><strong>实现文件级别的私有变量和函数</strong>：静态全局变量和静态函数可以用于实现文件内部的私有变量和函数。</li>\n<li><strong>组织代码</strong>：静态全局变量和静态函数可以用于组织代码，提高代码的可读性和可维护性。</li>\n</ul>\n<h4 id=\"代码示例-1\"><a href=\"#代码示例-1\" class=\"headerlink\" title=\"代码示例\"></a>代码示例</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-comment\">// file1.cpp</span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-type\">static</span> <span class=\"hljs-type\">int</span> globalVar = <span class=\"hljs-number\">10</span>;  <span class=\"hljs-comment\">// 静态全局变量，仅在 file1.cpp 中可见</span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">static</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">staticFunction</span><span class=\"hljs-params\">()</span> </span>&#123;  <span class=\"hljs-comment\">// 静态函数，仅在 file1.cpp 中可见</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;GlobalVar: &quot;</span> &lt;&lt; globalVar &lt;&lt; std::endl;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">callStaticFunction</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-built_in\">staticFunction</span>();  <span class=\"hljs-comment\">// 调用静态函数</span><br>&#125;<br><br><span class=\"hljs-comment\">// main.cpp</span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">extern</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">callStaticFunction</span><span class=\"hljs-params\">()</span></span>;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-built_in\">callStaticFunction</span>();  <span class=\"hljs-comment\">// 输出: GlobalVar: 10</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"3-静态成员变量和静态成员函数\"><a href=\"#3-静态成员变量和静态成员函数\" class=\"headerlink\" title=\"3. 静态成员变量和静态成员函数\"></a>3. 静态成员变量和静态成员函数</h3><h4 id=\"定义和语法-2\"><a href=\"#定义和语法-2\" class=\"headerlink\" title=\"定义和语法\"></a>定义和语法</h4><p>静态成员变量和静态成员函数是在类中使用 <code>static</code> 关键字声明的成员变量或成员函数。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyClass</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-type\">static</span> <span class=\"hljs-type\">int</span> staticVar;  <span class=\"hljs-comment\">// 静态成员变量</span><br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">staticFunction</span><span class=\"hljs-params\">()</span> </span>&#123;  <span class=\"hljs-comment\">// 静态成员函数</span><br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;StaticVar: &quot;</span> &lt;&lt; staticVar &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-type\">int</span> MyClass::staticVar = <span class=\"hljs-number\">20</span>;  <span class=\"hljs-comment\">// 静态成员变量的初始化</span><br></code></pre></td></tr></table></figure>\n\n<h4 id=\"特性-2\"><a href=\"#特性-2\" class=\"headerlink\" title=\"特性\"></a>特性</h4><ul>\n<li><strong>属于类本身</strong>：静态成员变量和静态成员函数属于类本身，而非类的实例，所有对象共享同一个静态成员变量。</li>\n<li><strong>只能访问静态成员</strong>：静态成员函数只能访问静态成员变量和静态成员函数，不能访问非静态成员变量和非静态成员函数。</li>\n<li><strong>必须在类外初始化</strong>：静态成员变量必须在类外进行初始化。</li>\n</ul>\n<h4 id=\"应用场景-2\"><a href=\"#应用场景-2\" class=\"headerlink\" title=\"应用场景\"></a>应用场景</h4><ul>\n<li><strong>实现类级别的计数器、共享资源等</strong>：静态成员变量可以用于实现类级别的计数器或共享资源。</li>\n<li><strong>提供与对象无关的类级别接口</strong>：静态成员函数可以用于提供与对象无关的类级别接口。</li>\n</ul>\n<h4 id=\"代码示例-2\"><a href=\"#代码示例-2\" class=\"headerlink\" title=\"代码示例\"></a>代码示例</h4><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">MyClass</span> &#123;<br><span class=\"hljs-keyword\">public</span>:<br>    <span class=\"hljs-type\">static</span> <span class=\"hljs-type\">int</span> staticVar;  <span class=\"hljs-comment\">// 静态成员变量</span><br><br>    <span class=\"hljs-function\"><span class=\"hljs-type\">static</span> <span class=\"hljs-type\">void</span> <span class=\"hljs-title\">staticFunction</span><span class=\"hljs-params\">()</span> </span>&#123;  <span class=\"hljs-comment\">// 静态成员函数</span><br>        std::cout &lt;&lt; <span class=\"hljs-string\">&quot;StaticVar: &quot;</span> &lt;&lt; staticVar &lt;&lt; std::endl;<br>    &#125;<br>&#125;;<br><br><span class=\"hljs-type\">int</span> MyClass::staticVar = <span class=\"hljs-number\">20</span>;  <span class=\"hljs-comment\">// 静态成员变量的初始化</span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    MyClass::<span class=\"hljs-built_in\">staticFunction</span>();  <span class=\"hljs-comment\">// 输出: StaticVar: 20</span><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"四、static-关键字的注意事项\"><a href=\"#四、static-关键字的注意事项\" class=\"headerlink\" title=\"四、static 关键字的注意事项\"></a>四、static 关键字的注意事项</h2><h3 id=\"1-静态局部变量的初始化顺序问题\"><a href=\"#1-静态局部变量的初始化顺序问题\" class=\"headerlink\" title=\"1. 静态局部变量的初始化顺序问题\"></a>1. 静态局部变量的初始化顺序问题</h3><p>静态局部变量的初始化顺序是按照它们在代码中出现的顺序进行的。如果多个静态局部变量之间存在依赖关系，可能会导致未定义行为。</p>\n<h3 id=\"2-静态成员变量的初始化顺序问题\"><a href=\"#2-静态成员变量的初始化顺序问题\" class=\"headerlink\" title=\"2. 静态成员变量的初始化顺序问题\"></a>2. 静态成员变量的初始化顺序问题</h3><p>静态成员变量的初始化顺序是按照它们在类中声明的顺序进行的。如果多个静态成员变量之间存在依赖关系，可能会导致未定义行为。</p>\n<h3 id=\"3-静态成员函数不能访问非静态成员变量和非静态成员函数的原因\"><a href=\"#3-静态成员函数不能访问非静态成员变量和非静态成员函数的原因\" class=\"headerlink\" title=\"3. 静态成员函数不能访问非静态成员变量和非静态成员函数的原因\"></a>3. 静态成员函数不能访问非静态成员变量和非静态成员函数的原因</h3><p>静态成员函数没有 <code>this</code> 指针，因此无法访问非静态成员变量和非静态成员函数。</p>\n<h3 id=\"4-避免滥用-static-关键字\"><a href=\"#4-避免滥用-static-关键字\" class=\"headerlink\" title=\"4. 避免滥用 static 关键字\"></a>4. 避免滥用 static 关键字</h3><p>滥用 <code>static</code> 关键字可能会导致代码的可读性和可维护性下降。因此，在使用 <code>static</code> 关键字时，应谨慎考虑其适用场景。</p>\n<h2 id=\"五、总结\"><a href=\"#五、总结\" class=\"headerlink\" title=\"五、总结\"></a>五、总结</h2><p>本文详细探讨了 <code>static</code> 关键字在 C++ 中的多种用途，包括静态局部变量、静态全局变量和静态函数、静态成员变量和静态成员函数。通过代码示例，我们深入理解了 <code>static</code> 关键字的工作原理和应用场景。</p>\n<p>理解 <code>static</code> 关键字的重要性不言而喻，它能够帮助我们更好地管理内存、控制作用域以及实现一些特定的编程模式。在实际编程中，合理使用 <code>static</code> 关键字可以提高代码的可读性和可维护性。</p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n"},{"title":"C++ 常量详解","date":"2024-12-18T04:00:00.000Z","category_bar":true,"_content":"\n\n\n# C++ 常量详解\n\n## 一、引言\n\n在 C++ 编程中，常量是不可或缺的一部分。常量是指在程序运行期间其值不能被改变的量。使用常量可以提高代码的可读性、可维护性和安全性。通过定义常量，我们可以避免在代码中直接使用硬编码的数值或字符串，从而减少错误并使代码更易于理解。\n\n## 二、常量的定义\n\n### 常量的概念\n\n常量是指在程序运行期间其值不能被改变的量。与变量不同，常量的值一旦被定义，就不能在程序的其他部分被修改。\n\n### 常量的类型\n\n常量可以分为两大类：字面常量和符号常量。\n\n#### 1. 字面常量 (Literal Constants)\n\n字面常量是指直接写在代码中的常量值。它们没有名称，直接表示一个固定的值。\n\n- **整型常量 (Integer Constants)**：表示整数值，可以是十进制、八进制或十六进制。\n- **浮点型常量 (Floating-point Constants)**：表示浮点数值，可以是小数形式或指数形式。\n- **字符常量 (Character Constants)**：表示单个字符，用单引号括起来。\n- **字符串常量 (String Constants)**：表示字符序列，用双引号括起来。\n\n#### 2. 符号常量 (Symbolic Constants)\n\n符号常量是指通过某种方式定义的具有名称的常量。它们有名称，可以在代码中多次使用。\n\n- **使用 `#define` 预处理器指令定义的常量**：通过预处理器指令 `#define` 定义的常量。\n- **使用 `const` 关键字定义的常量**：通过 `const` 关键字定义的常量，具有类型检查。\n- **使用 `constexpr` 关键字定义的常量**：通过 `constexpr` 关键字定义的常量，要求在编译时求值。\n\n## 三、常量的使用\n\n### 1. 字面常量的使用\n\n#### 整型常量的表示方法\n\n整型常量可以用十进制、八进制或十六进制表示。\n\n```cpp\n#include <iostream>\n\nint main() {\n    // 十进制整型常量\n    int decimal = 10;\n    \n    // 八进制整型常量（以0开头）\n    int octal = 012; // 相当于十进制的10\n    \n    // 十六进制整型常量（以0x或0X开头）\n    int hexadecimal = 0xA; // 相当于十进制的10\n\n    std::cout << \"Decimal: \" << decimal << std::endl;\n    std::cout << \"Octal: \" << octal << std::endl;\n    std::cout << \"Hexadecimal: \" << hexadecimal << std::endl;\n\n    return 0;\n}\n```\n\n#### 浮点型常量的表示方法\n\n浮点型常量可以用小数形式或指数形式表示。\n\n```cpp\n#include <iostream>\n\nint main() {\n    // 小数形式的浮点型常量\n    double pi = 3.14159;\n    \n    // 指数形式的浮点型常量\n    double e = 2.71828e0; // 相当于2.71828\n\n    std::cout << \"Pi: \" << pi << std::endl;\n    std::cout << \"e: \" << e << std::endl;\n\n    return 0;\n}\n```\n\n#### 字符常量的表示方法\n\n字符常量用单引号括起来。\n\n```cpp\n#include <iostream>\n\nint main() {\n    // 字符常量\n    char ch = 'A';\n\n    std::cout << \"Character: \" << ch << std::endl;\n\n    return 0;\n}\n```\n\n#### 字符串常量的表示方法\n\n字符串常量用双引号括起来。\n\n```cpp\n#include <iostream>\n\nint main() {\n    // 字符串常量\n    std::string str = \"Hello, World!\";\n\n    std::cout << \"String: \" << str << std::endl;\n\n    return 0;\n}\n```\n\n### 2. 符号常量的使用\n\n#### 使用 `#define` 预处理器指令定义的常量\n\n`#define` 是预处理器指令，用于定义符号常量。它的优点是简单易用，缺点是没有类型检查。\n\n```cpp\n#include <iostream>\n\n// 使用 #define 定义常量\n#define PI 3.14159\n\nint main() {\n    std::cout << \"PI: \" << PI << std::endl;\n\n    return 0;\n}\n```\n\n#### 使用 `const` 关键字定义的常量\n\n`const` 关键字用于定义常量，具有类型检查，推荐在现代 C++ 中使用。\n\n```cpp\n#include <iostream>\n\nint main() {\n    // 使用 const 定义常量\n    const double PI = 3.14159;\n\n    std::cout << \"PI: \" << PI << std::endl;\n\n    return 0;\n}\n```\n\n#### 使用 `constexpr` 关键字定义的常量\n\n`constexpr` 关键字用于定义编译时常量，要求在编译时求值。\n\n```cpp\n#include <iostream>\n\nint main() {\n    // 使用 constexpr 定义常量\n    constexpr double PI = 3.14159;\n\n    std::cout << \"PI: \" << PI << std::endl;\n\n    return 0;\n}\n```\n\n### 3. 常量的命名规范\n\n常量的命名应遵循一定的规范，以提高代码的可读性。\n\n- **使用全大写字母和下划线命名常量**：例如 `MAX_VALUE`。\n- **避免使用保留字和关键字作为常量名**：例如不要使用 `int` 或 `const` 作为常量名。\n\n## 四、常量的应用场景\n\n### 1. 定义程序中不变的值\n\n常量常用于定义程序中不变的值，例如数学常数、程序配置参数和错误代码。\n\n```cpp\n#include <iostream>\n\n// 定义数学常数\nconstexpr double PI = 3.14159;\nconstexpr double E = 2.71828;\n\n// 定义程序配置参数\nconst int MAX_CONNECTIONS = 100;\n\n// 定义错误代码\nconst int ERROR_CODE_FILE_NOT_FOUND = 404;\n\nint main() {\n    std::cout << \"PI: \" << PI << std::endl;\n    std::cout << \"E: \" << E << std::endl;\n    std::cout << \"Max Connections: \" << MAX_CONNECTIONS << std::endl;\n    std::cout << \"Error Code: \" << ERROR_CODE_FILE_NOT_FOUND << std::endl;\n\n    return 0;\n}\n```\n\n### 2. 提高代码的可读性和可维护性\n\n使用常量可以避免在代码中直接使用魔法数字，从而提高代码的可读性和可维护性。\n\n```cpp\n#include <iostream>\n\n// 使用常量代替魔法数字\nconst int DAYS_IN_WEEK = 7;\n\nint main() {\n    std::cout << \"Days in a week: \" << DAYS_IN_WEEK << std::endl;\n\n    return 0;\n}\n```\n\n### 3. 提高程序的安全性\n\n使用 `const` 关键字可以防止变量被意外修改，从而提高程序的安全性。\n\n```cpp\n#include <iostream>\n\nvoid printValue(const int value) {\n    // value = 10; // 错误：不能修改 const 变量\n    std::cout << \"Value: \" << value << std::endl;\n}\n\nint main() {\n    const int value = 42;\n    printValue(value);\n\n    return 0;\n}\n```\n\n## 五、常量的注意事项\n\n### 1. `#define` 预处理器指令定义的常量没有类型检查\n\n```cpp\n#include <iostream>\n\n#define VALUE 42\n\nint main() {\n    double value = VALUE; // 没有类型检查，可能会导致错误\n    std::cout << \"Value: \" << value << std::endl;\n\n    return 0;\n}\n```\n\n### \n\n### 2. `constexpr` 关键字定义的常量必须能够在编译时求值\n\n```cpp\n#include <iostream>\n\nconstexpr int getValue() {\n    return 42; // 必须在编译时求值\n}\n\nint main() {\n    constexpr int value = getValue();\n    std::cout << \"Value: \" << value << std::endl;\n\n    return 0;\n}\n```\n\n### 3. 避免过度使用常量，影响代码的可读性\n\n```cpp\n#include <iostream>\n\nconst int A = 1;\nconst int B = 2;\nconst int C = 3;\n\nint main() {\n    // 过度使用常量可能会影响代码的可读性\n    int result = A + B + C;\n    std::cout << \"Result: \" << result << std::endl;\n\n    return 0;\n}\n```\n\n## 六、总结\n\n本文详细介绍了 C++ 中常量的定义、使用和应用场景。常量在提高代码质量方面起着重要作用，能够提高代码的可读性、可维护性和安全性。通过合理使用常量，我们可以避免硬编码的数值和字符串，从而使代码更加清晰和易于维护。\n\n## 七、参考资料\n\n- [C++ Primer](https://www.amazon.com/C-Primer-5th-Stanley-Lippman/dp/0321714113)\n- [cppreference.com](https://en.cppreference.com/w/)\n\n## 八、附录\n\n### 常见常量示例代码\n\n```cpp\n#include <iostream>\n\n// 使用 #define 定义常量\n#define MAX_VALUE 100\n\n// 使用 const 定义常量\nconst int MIN_VALUE = 0;\n\n// 使用 constexpr 定义常量\nconstexpr double PI = 3.14159;\n\nint main() {\n    std::cout << \"Max Value: \" << MAX_VALUE << std::endl;\n    std::cout << \"Min Value: \" << MIN_VALUE << std::endl;\n    std::cout << \"PI: \" << PI << std::endl;\n\n    return 0;\n}\n```\n\n### 常量相关的常见问题解答\n\n1. **问：`const` 和 `constexpr` 有什么区别？**\n   - 答：`const` 用于定义运行时常量，而 `constexpr` 用于定义编译时常量，要求在编译时求值。\n\n2. **问：为什么推荐使用 `const` 而不是 `#define`？**\n   - 答：`const` 具有类型检查，更安全且更易于调试，而 `#define` 没有类型检查，容易出错。\n\n3. **问：`constexpr` 函数有什么要求？**\n   - 答：`constexpr` 函数必须在编译时求值，且不能包含复杂的逻辑或运行时才能确定的值。\n\n\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)\n\n","source":"_posts/开发/cpp/C++基础：C++常量详解.md","raw":"---\ntitle: 'C++ 常量详解'\ncategories:\n  - [开发,cpp]\ntags:\n  - c++\n  - cpp\n  - c++基础\ndate: 2024-12-18 12:00:00\ncategory_bar: true\n---\n\n\n\n# C++ 常量详解\n\n## 一、引言\n\n在 C++ 编程中，常量是不可或缺的一部分。常量是指在程序运行期间其值不能被改变的量。使用常量可以提高代码的可读性、可维护性和安全性。通过定义常量，我们可以避免在代码中直接使用硬编码的数值或字符串，从而减少错误并使代码更易于理解。\n\n## 二、常量的定义\n\n### 常量的概念\n\n常量是指在程序运行期间其值不能被改变的量。与变量不同，常量的值一旦被定义，就不能在程序的其他部分被修改。\n\n### 常量的类型\n\n常量可以分为两大类：字面常量和符号常量。\n\n#### 1. 字面常量 (Literal Constants)\n\n字面常量是指直接写在代码中的常量值。它们没有名称，直接表示一个固定的值。\n\n- **整型常量 (Integer Constants)**：表示整数值，可以是十进制、八进制或十六进制。\n- **浮点型常量 (Floating-point Constants)**：表示浮点数值，可以是小数形式或指数形式。\n- **字符常量 (Character Constants)**：表示单个字符，用单引号括起来。\n- **字符串常量 (String Constants)**：表示字符序列，用双引号括起来。\n\n#### 2. 符号常量 (Symbolic Constants)\n\n符号常量是指通过某种方式定义的具有名称的常量。它们有名称，可以在代码中多次使用。\n\n- **使用 `#define` 预处理器指令定义的常量**：通过预处理器指令 `#define` 定义的常量。\n- **使用 `const` 关键字定义的常量**：通过 `const` 关键字定义的常量，具有类型检查。\n- **使用 `constexpr` 关键字定义的常量**：通过 `constexpr` 关键字定义的常量，要求在编译时求值。\n\n## 三、常量的使用\n\n### 1. 字面常量的使用\n\n#### 整型常量的表示方法\n\n整型常量可以用十进制、八进制或十六进制表示。\n\n```cpp\n#include <iostream>\n\nint main() {\n    // 十进制整型常量\n    int decimal = 10;\n    \n    // 八进制整型常量（以0开头）\n    int octal = 012; // 相当于十进制的10\n    \n    // 十六进制整型常量（以0x或0X开头）\n    int hexadecimal = 0xA; // 相当于十进制的10\n\n    std::cout << \"Decimal: \" << decimal << std::endl;\n    std::cout << \"Octal: \" << octal << std::endl;\n    std::cout << \"Hexadecimal: \" << hexadecimal << std::endl;\n\n    return 0;\n}\n```\n\n#### 浮点型常量的表示方法\n\n浮点型常量可以用小数形式或指数形式表示。\n\n```cpp\n#include <iostream>\n\nint main() {\n    // 小数形式的浮点型常量\n    double pi = 3.14159;\n    \n    // 指数形式的浮点型常量\n    double e = 2.71828e0; // 相当于2.71828\n\n    std::cout << \"Pi: \" << pi << std::endl;\n    std::cout << \"e: \" << e << std::endl;\n\n    return 0;\n}\n```\n\n#### 字符常量的表示方法\n\n字符常量用单引号括起来。\n\n```cpp\n#include <iostream>\n\nint main() {\n    // 字符常量\n    char ch = 'A';\n\n    std::cout << \"Character: \" << ch << std::endl;\n\n    return 0;\n}\n```\n\n#### 字符串常量的表示方法\n\n字符串常量用双引号括起来。\n\n```cpp\n#include <iostream>\n\nint main() {\n    // 字符串常量\n    std::string str = \"Hello, World!\";\n\n    std::cout << \"String: \" << str << std::endl;\n\n    return 0;\n}\n```\n\n### 2. 符号常量的使用\n\n#### 使用 `#define` 预处理器指令定义的常量\n\n`#define` 是预处理器指令，用于定义符号常量。它的优点是简单易用，缺点是没有类型检查。\n\n```cpp\n#include <iostream>\n\n// 使用 #define 定义常量\n#define PI 3.14159\n\nint main() {\n    std::cout << \"PI: \" << PI << std::endl;\n\n    return 0;\n}\n```\n\n#### 使用 `const` 关键字定义的常量\n\n`const` 关键字用于定义常量，具有类型检查，推荐在现代 C++ 中使用。\n\n```cpp\n#include <iostream>\n\nint main() {\n    // 使用 const 定义常量\n    const double PI = 3.14159;\n\n    std::cout << \"PI: \" << PI << std::endl;\n\n    return 0;\n}\n```\n\n#### 使用 `constexpr` 关键字定义的常量\n\n`constexpr` 关键字用于定义编译时常量，要求在编译时求值。\n\n```cpp\n#include <iostream>\n\nint main() {\n    // 使用 constexpr 定义常量\n    constexpr double PI = 3.14159;\n\n    std::cout << \"PI: \" << PI << std::endl;\n\n    return 0;\n}\n```\n\n### 3. 常量的命名规范\n\n常量的命名应遵循一定的规范，以提高代码的可读性。\n\n- **使用全大写字母和下划线命名常量**：例如 `MAX_VALUE`。\n- **避免使用保留字和关键字作为常量名**：例如不要使用 `int` 或 `const` 作为常量名。\n\n## 四、常量的应用场景\n\n### 1. 定义程序中不变的值\n\n常量常用于定义程序中不变的值，例如数学常数、程序配置参数和错误代码。\n\n```cpp\n#include <iostream>\n\n// 定义数学常数\nconstexpr double PI = 3.14159;\nconstexpr double E = 2.71828;\n\n// 定义程序配置参数\nconst int MAX_CONNECTIONS = 100;\n\n// 定义错误代码\nconst int ERROR_CODE_FILE_NOT_FOUND = 404;\n\nint main() {\n    std::cout << \"PI: \" << PI << std::endl;\n    std::cout << \"E: \" << E << std::endl;\n    std::cout << \"Max Connections: \" << MAX_CONNECTIONS << std::endl;\n    std::cout << \"Error Code: \" << ERROR_CODE_FILE_NOT_FOUND << std::endl;\n\n    return 0;\n}\n```\n\n### 2. 提高代码的可读性和可维护性\n\n使用常量可以避免在代码中直接使用魔法数字，从而提高代码的可读性和可维护性。\n\n```cpp\n#include <iostream>\n\n// 使用常量代替魔法数字\nconst int DAYS_IN_WEEK = 7;\n\nint main() {\n    std::cout << \"Days in a week: \" << DAYS_IN_WEEK << std::endl;\n\n    return 0;\n}\n```\n\n### 3. 提高程序的安全性\n\n使用 `const` 关键字可以防止变量被意外修改，从而提高程序的安全性。\n\n```cpp\n#include <iostream>\n\nvoid printValue(const int value) {\n    // value = 10; // 错误：不能修改 const 变量\n    std::cout << \"Value: \" << value << std::endl;\n}\n\nint main() {\n    const int value = 42;\n    printValue(value);\n\n    return 0;\n}\n```\n\n## 五、常量的注意事项\n\n### 1. `#define` 预处理器指令定义的常量没有类型检查\n\n```cpp\n#include <iostream>\n\n#define VALUE 42\n\nint main() {\n    double value = VALUE; // 没有类型检查，可能会导致错误\n    std::cout << \"Value: \" << value << std::endl;\n\n    return 0;\n}\n```\n\n### \n\n### 2. `constexpr` 关键字定义的常量必须能够在编译时求值\n\n```cpp\n#include <iostream>\n\nconstexpr int getValue() {\n    return 42; // 必须在编译时求值\n}\n\nint main() {\n    constexpr int value = getValue();\n    std::cout << \"Value: \" << value << std::endl;\n\n    return 0;\n}\n```\n\n### 3. 避免过度使用常量，影响代码的可读性\n\n```cpp\n#include <iostream>\n\nconst int A = 1;\nconst int B = 2;\nconst int C = 3;\n\nint main() {\n    // 过度使用常量可能会影响代码的可读性\n    int result = A + B + C;\n    std::cout << \"Result: \" << result << std::endl;\n\n    return 0;\n}\n```\n\n## 六、总结\n\n本文详细介绍了 C++ 中常量的定义、使用和应用场景。常量在提高代码质量方面起着重要作用，能够提高代码的可读性、可维护性和安全性。通过合理使用常量，我们可以避免硬编码的数值和字符串，从而使代码更加清晰和易于维护。\n\n## 七、参考资料\n\n- [C++ Primer](https://www.amazon.com/C-Primer-5th-Stanley-Lippman/dp/0321714113)\n- [cppreference.com](https://en.cppreference.com/w/)\n\n## 八、附录\n\n### 常见常量示例代码\n\n```cpp\n#include <iostream>\n\n// 使用 #define 定义常量\n#define MAX_VALUE 100\n\n// 使用 const 定义常量\nconst int MIN_VALUE = 0;\n\n// 使用 constexpr 定义常量\nconstexpr double PI = 3.14159;\n\nint main() {\n    std::cout << \"Max Value: \" << MAX_VALUE << std::endl;\n    std::cout << \"Min Value: \" << MIN_VALUE << std::endl;\n    std::cout << \"PI: \" << PI << std::endl;\n\n    return 0;\n}\n```\n\n### 常量相关的常见问题解答\n\n1. **问：`const` 和 `constexpr` 有什么区别？**\n   - 答：`const` 用于定义运行时常量，而 `constexpr` 用于定义编译时常量，要求在编译时求值。\n\n2. **问：为什么推荐使用 `const` 而不是 `#define`？**\n   - 答：`const` 具有类型检查，更安全且更易于调试，而 `#define` 没有类型检查，容易出错。\n\n3. **问：`constexpr` 函数有什么要求？**\n   - 答：`constexpr` 函数必须在编译时求值，且不能包含复杂的逻辑或运行时才能确定的值。\n\n\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)\n\n","slug":"开发/cpp/C++基础：C++常量详解","published":1,"updated":"2024-12-26T06:37:46.686Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3j000qhghi3wy489mz","content":"<h1 id=\"C-常量详解\"><a href=\"#C-常量详解\" class=\"headerlink\" title=\"C++ 常量详解\"></a>C++ 常量详解</h1><h2 id=\"一、引言\"><a href=\"#一、引言\" class=\"headerlink\" title=\"一、引言\"></a>一、引言</h2><p>在 C++ 编程中，常量是不可或缺的一部分。常量是指在程序运行期间其值不能被改变的量。使用常量可以提高代码的可读性、可维护性和安全性。通过定义常量，我们可以避免在代码中直接使用硬编码的数值或字符串，从而减少错误并使代码更易于理解。</p>\n<h2 id=\"二、常量的定义\"><a href=\"#二、常量的定义\" class=\"headerlink\" title=\"二、常量的定义\"></a>二、常量的定义</h2><h3 id=\"常量的概念\"><a href=\"#常量的概念\" class=\"headerlink\" title=\"常量的概念\"></a>常量的概念</h3><p>常量是指在程序运行期间其值不能被改变的量。与变量不同，常量的值一旦被定义，就不能在程序的其他部分被修改。</p>\n<h3 id=\"常量的类型\"><a href=\"#常量的类型\" class=\"headerlink\" title=\"常量的类型\"></a>常量的类型</h3><p>常量可以分为两大类：字面常量和符号常量。</p>\n<h4 id=\"1-字面常量-Literal-Constants\"><a href=\"#1-字面常量-Literal-Constants\" class=\"headerlink\" title=\"1. 字面常量 (Literal Constants)\"></a>1. 字面常量 (Literal Constants)</h4><p>字面常量是指直接写在代码中的常量值。它们没有名称，直接表示一个固定的值。</p>\n<ul>\n<li>**整型常量 (Integer Constants)**：表示整数值，可以是十进制、八进制或十六进制。</li>\n<li>**浮点型常量 (Floating-point Constants)**：表示浮点数值，可以是小数形式或指数形式。</li>\n<li>**字符常量 (Character Constants)**：表示单个字符，用单引号括起来。</li>\n<li>**字符串常量 (String Constants)**：表示字符序列，用双引号括起来。</li>\n</ul>\n<h4 id=\"2-符号常量-Symbolic-Constants\"><a href=\"#2-符号常量-Symbolic-Constants\" class=\"headerlink\" title=\"2. 符号常量 (Symbolic Constants)\"></a>2. 符号常量 (Symbolic Constants)</h4><p>符号常量是指通过某种方式定义的具有名称的常量。它们有名称，可以在代码中多次使用。</p>\n<ul>\n<li><strong>使用 <code>#define</code> 预处理器指令定义的常量</strong>：通过预处理器指令 <code>#define</code> 定义的常量。</li>\n<li><strong>使用 <code>const</code> 关键字定义的常量</strong>：通过 <code>const</code> 关键字定义的常量，具有类型检查。</li>\n<li><strong>使用 <code>constexpr</code> 关键字定义的常量</strong>：通过 <code>constexpr</code> 关键字定义的常量，要求在编译时求值。</li>\n</ul>\n<h2 id=\"三、常量的使用\"><a href=\"#三、常量的使用\" class=\"headerlink\" title=\"三、常量的使用\"></a>三、常量的使用</h2><h3 id=\"1-字面常量的使用\"><a href=\"#1-字面常量的使用\" class=\"headerlink\" title=\"1. 字面常量的使用\"></a>1. 字面常量的使用</h3><h4 id=\"整型常量的表示方法\"><a href=\"#整型常量的表示方法\" class=\"headerlink\" title=\"整型常量的表示方法\"></a>整型常量的表示方法</h4><p>整型常量可以用十进制、八进制或十六进制表示。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 十进制整型常量</span><br>    <span class=\"hljs-type\">int</span> decimal = <span class=\"hljs-number\">10</span>;<br>    <br>    <span class=\"hljs-comment\">// 八进制整型常量（以0开头）</span><br>    <span class=\"hljs-type\">int</span> octal = <span class=\"hljs-number\">012</span>; <span class=\"hljs-comment\">// 相当于十进制的10</span><br>    <br>    <span class=\"hljs-comment\">// 十六进制整型常量（以0x或0X开头）</span><br>    <span class=\"hljs-type\">int</span> hexadecimal = <span class=\"hljs-number\">0xA</span>; <span class=\"hljs-comment\">// 相当于十进制的10</span><br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Decimal: &quot;</span> &lt;&lt; decimal &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Octal: &quot;</span> &lt;&lt; octal &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Hexadecimal: &quot;</span> &lt;&lt; hexadecimal &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"浮点型常量的表示方法\"><a href=\"#浮点型常量的表示方法\" class=\"headerlink\" title=\"浮点型常量的表示方法\"></a>浮点型常量的表示方法</h4><p>浮点型常量可以用小数形式或指数形式表示。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 小数形式的浮点型常量</span><br>    <span class=\"hljs-type\">double</span> pi = <span class=\"hljs-number\">3.14159</span>;<br>    <br>    <span class=\"hljs-comment\">// 指数形式的浮点型常量</span><br>    <span class=\"hljs-type\">double</span> e = <span class=\"hljs-number\">2.71828e0</span>; <span class=\"hljs-comment\">// 相当于2.71828</span><br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Pi: &quot;</span> &lt;&lt; pi &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;e: &quot;</span> &lt;&lt; e &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"字符常量的表示方法\"><a href=\"#字符常量的表示方法\" class=\"headerlink\" title=\"字符常量的表示方法\"></a>字符常量的表示方法</h4><p>字符常量用单引号括起来。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 字符常量</span><br>    <span class=\"hljs-type\">char</span> ch = <span class=\"hljs-string\">&#x27;A&#x27;</span>;<br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Character: &quot;</span> &lt;&lt; ch &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"字符串常量的表示方法\"><a href=\"#字符串常量的表示方法\" class=\"headerlink\" title=\"字符串常量的表示方法\"></a>字符串常量的表示方法</h4><p>字符串常量用双引号括起来。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 字符串常量</span><br>    std::string str = <span class=\"hljs-string\">&quot;Hello, World!&quot;</span>;<br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;String: &quot;</span> &lt;&lt; str &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"2-符号常量的使用\"><a href=\"#2-符号常量的使用\" class=\"headerlink\" title=\"2. 符号常量的使用\"></a>2. 符号常量的使用</h3><h4 id=\"使用-define-预处理器指令定义的常量\"><a href=\"#使用-define-预处理器指令定义的常量\" class=\"headerlink\" title=\"使用 #define 预处理器指令定义的常量\"></a>使用 <code>#define</code> 预处理器指令定义的常量</h4><p><code>#define</code> 是预处理器指令，用于定义符号常量。它的优点是简单易用，缺点是没有类型检查。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-comment\">// 使用 #define 定义常量</span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">define</span> PI 3.14159</span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;PI: &quot;</span> &lt;&lt; PI &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"使用-const-关键字定义的常量\"><a href=\"#使用-const-关键字定义的常量\" class=\"headerlink\" title=\"使用 const 关键字定义的常量\"></a>使用 <code>const</code> 关键字定义的常量</h4><p><code>const</code> 关键字用于定义常量，具有类型检查，推荐在现代 C++ 中使用。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 使用 const 定义常量</span><br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">double</span> PI = <span class=\"hljs-number\">3.14159</span>;<br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;PI: &quot;</span> &lt;&lt; PI &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"使用-constexpr-关键字定义的常量\"><a href=\"#使用-constexpr-关键字定义的常量\" class=\"headerlink\" title=\"使用 constexpr 关键字定义的常量\"></a>使用 <code>constexpr</code> 关键字定义的常量</h4><p><code>constexpr</code> 关键字用于定义编译时常量，要求在编译时求值。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 使用 constexpr 定义常量</span><br>    <span class=\"hljs-keyword\">constexpr</span> <span class=\"hljs-type\">double</span> PI = <span class=\"hljs-number\">3.14159</span>;<br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;PI: &quot;</span> &lt;&lt; PI &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"3-常量的命名规范\"><a href=\"#3-常量的命名规范\" class=\"headerlink\" title=\"3. 常量的命名规范\"></a>3. 常量的命名规范</h3><p>常量的命名应遵循一定的规范，以提高代码的可读性。</p>\n<ul>\n<li><strong>使用全大写字母和下划线命名常量</strong>：例如 <code>MAX_VALUE</code>。</li>\n<li><strong>避免使用保留字和关键字作为常量名</strong>：例如不要使用 <code>int</code> 或 <code>const</code> 作为常量名。</li>\n</ul>\n<h2 id=\"四、常量的应用场景\"><a href=\"#四、常量的应用场景\" class=\"headerlink\" title=\"四、常量的应用场景\"></a>四、常量的应用场景</h2><h3 id=\"1-定义程序中不变的值\"><a href=\"#1-定义程序中不变的值\" class=\"headerlink\" title=\"1. 定义程序中不变的值\"></a>1. 定义程序中不变的值</h3><p>常量常用于定义程序中不变的值，例如数学常数、程序配置参数和错误代码。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-comment\">// 定义数学常数</span><br><span class=\"hljs-keyword\">constexpr</span> <span class=\"hljs-type\">double</span> PI = <span class=\"hljs-number\">3.14159</span>;<br><span class=\"hljs-keyword\">constexpr</span> <span class=\"hljs-type\">double</span> E = <span class=\"hljs-number\">2.71828</span>;<br><br><span class=\"hljs-comment\">// 定义程序配置参数</span><br><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> MAX_CONNECTIONS = <span class=\"hljs-number\">100</span>;<br><br><span class=\"hljs-comment\">// 定义错误代码</span><br><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> ERROR_CODE_FILE_NOT_FOUND = <span class=\"hljs-number\">404</span>;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;PI: &quot;</span> &lt;&lt; PI &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;E: &quot;</span> &lt;&lt; E &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Max Connections: &quot;</span> &lt;&lt; MAX_CONNECTIONS &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Error Code: &quot;</span> &lt;&lt; ERROR_CODE_FILE_NOT_FOUND &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"2-提高代码的可读性和可维护性\"><a href=\"#2-提高代码的可读性和可维护性\" class=\"headerlink\" title=\"2. 提高代码的可读性和可维护性\"></a>2. 提高代码的可读性和可维护性</h3><p>使用常量可以避免在代码中直接使用魔法数字，从而提高代码的可读性和可维护性。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-comment\">// 使用常量代替魔法数字</span><br><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> DAYS_IN_WEEK = <span class=\"hljs-number\">7</span>;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Days in a week: &quot;</span> &lt;&lt; DAYS_IN_WEEK &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"3-提高程序的安全性\"><a href=\"#3-提高程序的安全性\" class=\"headerlink\" title=\"3. 提高程序的安全性\"></a>3. 提高程序的安全性</h3><p>使用 <code>const</code> 关键字可以防止变量被意外修改，从而提高程序的安全性。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">printValue</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> value)</span> </span>&#123;<br>    <span class=\"hljs-comment\">// value = 10; // 错误：不能修改 const 变量</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Value: &quot;</span> &lt;&lt; value &lt;&lt; std::endl;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> value = <span class=\"hljs-number\">42</span>;<br>    <span class=\"hljs-built_in\">printValue</span>(value);<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"五、常量的注意事项\"><a href=\"#五、常量的注意事项\" class=\"headerlink\" title=\"五、常量的注意事项\"></a>五、常量的注意事项</h2><h3 id=\"1-define-预处理器指令定义的常量没有类型检查\"><a href=\"#1-define-预处理器指令定义的常量没有类型检查\" class=\"headerlink\" title=\"1. #define 预处理器指令定义的常量没有类型检查\"></a>1. <code>#define</code> 预处理器指令定义的常量没有类型检查</h3><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">define</span> VALUE 42</span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">double</span> value = VALUE; <span class=\"hljs-comment\">// 没有类型检查，可能会导致错误</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Value: &quot;</span> &lt;&lt; value &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h3 id=\"2-constexpr-关键字定义的常量必须能够在编译时求值\"><a href=\"#2-constexpr-关键字定义的常量必须能够在编译时求值\" class=\"headerlink\" title=\"2. constexpr 关键字定义的常量必须能够在编译时求值\"></a>2. <code>constexpr</code> 关键字定义的常量必须能够在编译时求值</h3><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">constexpr</span> <span class=\"hljs-type\">int</span> <span class=\"hljs-title\">getValue</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">42</span>; <span class=\"hljs-comment\">// 必须在编译时求值</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-keyword\">constexpr</span> <span class=\"hljs-type\">int</span> value = <span class=\"hljs-built_in\">getValue</span>();<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Value: &quot;</span> &lt;&lt; value &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"3-避免过度使用常量，影响代码的可读性\"><a href=\"#3-避免过度使用常量，影响代码的可读性\" class=\"headerlink\" title=\"3. 避免过度使用常量，影响代码的可读性\"></a>3. 避免过度使用常量，影响代码的可读性</h3><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> A = <span class=\"hljs-number\">1</span>;<br><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> B = <span class=\"hljs-number\">2</span>;<br><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> C = <span class=\"hljs-number\">3</span>;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 过度使用常量可能会影响代码的可读性</span><br>    <span class=\"hljs-type\">int</span> result = A + B + C;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Result: &quot;</span> &lt;&lt; result &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"六、总结\"><a href=\"#六、总结\" class=\"headerlink\" title=\"六、总结\"></a>六、总结</h2><p>本文详细介绍了 C++ 中常量的定义、使用和应用场景。常量在提高代码质量方面起着重要作用，能够提高代码的可读性、可维护性和安全性。通过合理使用常量，我们可以避免硬编码的数值和字符串，从而使代码更加清晰和易于维护。</p>\n<h2 id=\"七、参考资料\"><a href=\"#七、参考资料\" class=\"headerlink\" title=\"七、参考资料\"></a>七、参考资料</h2><ul>\n<li><a href=\"https://www.amazon.com/C-Primer-5th-Stanley-Lippman/dp/0321714113\">C++ Primer</a></li>\n<li><a href=\"https://en.cppreference.com/w/\">cppreference.com</a></li>\n</ul>\n<h2 id=\"八、附录\"><a href=\"#八、附录\" class=\"headerlink\" title=\"八、附录\"></a>八、附录</h2><h3 id=\"常见常量示例代码\"><a href=\"#常见常量示例代码\" class=\"headerlink\" title=\"常见常量示例代码\"></a>常见常量示例代码</h3><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-comment\">// 使用 #define 定义常量</span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">define</span> MAX_VALUE 100</span><br><br><span class=\"hljs-comment\">// 使用 const 定义常量</span><br><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> MIN_VALUE = <span class=\"hljs-number\">0</span>;<br><br><span class=\"hljs-comment\">// 使用 constexpr 定义常量</span><br><span class=\"hljs-keyword\">constexpr</span> <span class=\"hljs-type\">double</span> PI = <span class=\"hljs-number\">3.14159</span>;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Max Value: &quot;</span> &lt;&lt; MAX_VALUE &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Min Value: &quot;</span> &lt;&lt; MIN_VALUE &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;PI: &quot;</span> &lt;&lt; PI &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"常量相关的常见问题解答\"><a href=\"#常量相关的常见问题解答\" class=\"headerlink\" title=\"常量相关的常见问题解答\"></a>常量相关的常见问题解答</h3><ol>\n<li><p><strong>问：<code>const</code> 和 <code>constexpr</code> 有什么区别？</strong></p>\n<ul>\n<li>答：<code>const</code> 用于定义运行时常量，而 <code>constexpr</code> 用于定义编译时常量，要求在编译时求值。</li>\n</ul>\n</li>\n<li><p><strong>问：为什么推荐使用 <code>const</code> 而不是 <code>#define</code>？</strong></p>\n<ul>\n<li>答：<code>const</code> 具有类型检查，更安全且更易于调试，而 <code>#define</code> 没有类型检查，容易出错。</li>\n</ul>\n</li>\n<li><p><strong>问：<code>constexpr</code> 函数有什么要求？</strong></p>\n<ul>\n<li>答：<code>constexpr</code> 函数必须在编译时求值，且不能包含复杂的逻辑或运行时才能确定的值。</li>\n</ul>\n</li>\n</ol>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n","excerpt":"","more":"<h1 id=\"C-常量详解\"><a href=\"#C-常量详解\" class=\"headerlink\" title=\"C++ 常量详解\"></a>C++ 常量详解</h1><h2 id=\"一、引言\"><a href=\"#一、引言\" class=\"headerlink\" title=\"一、引言\"></a>一、引言</h2><p>在 C++ 编程中，常量是不可或缺的一部分。常量是指在程序运行期间其值不能被改变的量。使用常量可以提高代码的可读性、可维护性和安全性。通过定义常量，我们可以避免在代码中直接使用硬编码的数值或字符串，从而减少错误并使代码更易于理解。</p>\n<h2 id=\"二、常量的定义\"><a href=\"#二、常量的定义\" class=\"headerlink\" title=\"二、常量的定义\"></a>二、常量的定义</h2><h3 id=\"常量的概念\"><a href=\"#常量的概念\" class=\"headerlink\" title=\"常量的概念\"></a>常量的概念</h3><p>常量是指在程序运行期间其值不能被改变的量。与变量不同，常量的值一旦被定义，就不能在程序的其他部分被修改。</p>\n<h3 id=\"常量的类型\"><a href=\"#常量的类型\" class=\"headerlink\" title=\"常量的类型\"></a>常量的类型</h3><p>常量可以分为两大类：字面常量和符号常量。</p>\n<h4 id=\"1-字面常量-Literal-Constants\"><a href=\"#1-字面常量-Literal-Constants\" class=\"headerlink\" title=\"1. 字面常量 (Literal Constants)\"></a>1. 字面常量 (Literal Constants)</h4><p>字面常量是指直接写在代码中的常量值。它们没有名称，直接表示一个固定的值。</p>\n<ul>\n<li>**整型常量 (Integer Constants)**：表示整数值，可以是十进制、八进制或十六进制。</li>\n<li>**浮点型常量 (Floating-point Constants)**：表示浮点数值，可以是小数形式或指数形式。</li>\n<li>**字符常量 (Character Constants)**：表示单个字符，用单引号括起来。</li>\n<li>**字符串常量 (String Constants)**：表示字符序列，用双引号括起来。</li>\n</ul>\n<h4 id=\"2-符号常量-Symbolic-Constants\"><a href=\"#2-符号常量-Symbolic-Constants\" class=\"headerlink\" title=\"2. 符号常量 (Symbolic Constants)\"></a>2. 符号常量 (Symbolic Constants)</h4><p>符号常量是指通过某种方式定义的具有名称的常量。它们有名称，可以在代码中多次使用。</p>\n<ul>\n<li><strong>使用 <code>#define</code> 预处理器指令定义的常量</strong>：通过预处理器指令 <code>#define</code> 定义的常量。</li>\n<li><strong>使用 <code>const</code> 关键字定义的常量</strong>：通过 <code>const</code> 关键字定义的常量，具有类型检查。</li>\n<li><strong>使用 <code>constexpr</code> 关键字定义的常量</strong>：通过 <code>constexpr</code> 关键字定义的常量，要求在编译时求值。</li>\n</ul>\n<h2 id=\"三、常量的使用\"><a href=\"#三、常量的使用\" class=\"headerlink\" title=\"三、常量的使用\"></a>三、常量的使用</h2><h3 id=\"1-字面常量的使用\"><a href=\"#1-字面常量的使用\" class=\"headerlink\" title=\"1. 字面常量的使用\"></a>1. 字面常量的使用</h3><h4 id=\"整型常量的表示方法\"><a href=\"#整型常量的表示方法\" class=\"headerlink\" title=\"整型常量的表示方法\"></a>整型常量的表示方法</h4><p>整型常量可以用十进制、八进制或十六进制表示。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 十进制整型常量</span><br>    <span class=\"hljs-type\">int</span> decimal = <span class=\"hljs-number\">10</span>;<br>    <br>    <span class=\"hljs-comment\">// 八进制整型常量（以0开头）</span><br>    <span class=\"hljs-type\">int</span> octal = <span class=\"hljs-number\">012</span>; <span class=\"hljs-comment\">// 相当于十进制的10</span><br>    <br>    <span class=\"hljs-comment\">// 十六进制整型常量（以0x或0X开头）</span><br>    <span class=\"hljs-type\">int</span> hexadecimal = <span class=\"hljs-number\">0xA</span>; <span class=\"hljs-comment\">// 相当于十进制的10</span><br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Decimal: &quot;</span> &lt;&lt; decimal &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Octal: &quot;</span> &lt;&lt; octal &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Hexadecimal: &quot;</span> &lt;&lt; hexadecimal &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"浮点型常量的表示方法\"><a href=\"#浮点型常量的表示方法\" class=\"headerlink\" title=\"浮点型常量的表示方法\"></a>浮点型常量的表示方法</h4><p>浮点型常量可以用小数形式或指数形式表示。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 小数形式的浮点型常量</span><br>    <span class=\"hljs-type\">double</span> pi = <span class=\"hljs-number\">3.14159</span>;<br>    <br>    <span class=\"hljs-comment\">// 指数形式的浮点型常量</span><br>    <span class=\"hljs-type\">double</span> e = <span class=\"hljs-number\">2.71828e0</span>; <span class=\"hljs-comment\">// 相当于2.71828</span><br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Pi: &quot;</span> &lt;&lt; pi &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;e: &quot;</span> &lt;&lt; e &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"字符常量的表示方法\"><a href=\"#字符常量的表示方法\" class=\"headerlink\" title=\"字符常量的表示方法\"></a>字符常量的表示方法</h4><p>字符常量用单引号括起来。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 字符常量</span><br>    <span class=\"hljs-type\">char</span> ch = <span class=\"hljs-string\">&#x27;A&#x27;</span>;<br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Character: &quot;</span> &lt;&lt; ch &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"字符串常量的表示方法\"><a href=\"#字符串常量的表示方法\" class=\"headerlink\" title=\"字符串常量的表示方法\"></a>字符串常量的表示方法</h4><p>字符串常量用双引号括起来。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 字符串常量</span><br>    std::string str = <span class=\"hljs-string\">&quot;Hello, World!&quot;</span>;<br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;String: &quot;</span> &lt;&lt; str &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"2-符号常量的使用\"><a href=\"#2-符号常量的使用\" class=\"headerlink\" title=\"2. 符号常量的使用\"></a>2. 符号常量的使用</h3><h4 id=\"使用-define-预处理器指令定义的常量\"><a href=\"#使用-define-预处理器指令定义的常量\" class=\"headerlink\" title=\"使用 #define 预处理器指令定义的常量\"></a>使用 <code>#define</code> 预处理器指令定义的常量</h4><p><code>#define</code> 是预处理器指令，用于定义符号常量。它的优点是简单易用，缺点是没有类型检查。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-comment\">// 使用 #define 定义常量</span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">define</span> PI 3.14159</span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;PI: &quot;</span> &lt;&lt; PI &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"使用-const-关键字定义的常量\"><a href=\"#使用-const-关键字定义的常量\" class=\"headerlink\" title=\"使用 const 关键字定义的常量\"></a>使用 <code>const</code> 关键字定义的常量</h4><p><code>const</code> 关键字用于定义常量，具有类型检查，推荐在现代 C++ 中使用。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 使用 const 定义常量</span><br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">double</span> PI = <span class=\"hljs-number\">3.14159</span>;<br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;PI: &quot;</span> &lt;&lt; PI &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"使用-constexpr-关键字定义的常量\"><a href=\"#使用-constexpr-关键字定义的常量\" class=\"headerlink\" title=\"使用 constexpr 关键字定义的常量\"></a>使用 <code>constexpr</code> 关键字定义的常量</h4><p><code>constexpr</code> 关键字用于定义编译时常量，要求在编译时求值。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 使用 constexpr 定义常量</span><br>    <span class=\"hljs-keyword\">constexpr</span> <span class=\"hljs-type\">double</span> PI = <span class=\"hljs-number\">3.14159</span>;<br><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;PI: &quot;</span> &lt;&lt; PI &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"3-常量的命名规范\"><a href=\"#3-常量的命名规范\" class=\"headerlink\" title=\"3. 常量的命名规范\"></a>3. 常量的命名规范</h3><p>常量的命名应遵循一定的规范，以提高代码的可读性。</p>\n<ul>\n<li><strong>使用全大写字母和下划线命名常量</strong>：例如 <code>MAX_VALUE</code>。</li>\n<li><strong>避免使用保留字和关键字作为常量名</strong>：例如不要使用 <code>int</code> 或 <code>const</code> 作为常量名。</li>\n</ul>\n<h2 id=\"四、常量的应用场景\"><a href=\"#四、常量的应用场景\" class=\"headerlink\" title=\"四、常量的应用场景\"></a>四、常量的应用场景</h2><h3 id=\"1-定义程序中不变的值\"><a href=\"#1-定义程序中不变的值\" class=\"headerlink\" title=\"1. 定义程序中不变的值\"></a>1. 定义程序中不变的值</h3><p>常量常用于定义程序中不变的值，例如数学常数、程序配置参数和错误代码。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-comment\">// 定义数学常数</span><br><span class=\"hljs-keyword\">constexpr</span> <span class=\"hljs-type\">double</span> PI = <span class=\"hljs-number\">3.14159</span>;<br><span class=\"hljs-keyword\">constexpr</span> <span class=\"hljs-type\">double</span> E = <span class=\"hljs-number\">2.71828</span>;<br><br><span class=\"hljs-comment\">// 定义程序配置参数</span><br><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> MAX_CONNECTIONS = <span class=\"hljs-number\">100</span>;<br><br><span class=\"hljs-comment\">// 定义错误代码</span><br><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> ERROR_CODE_FILE_NOT_FOUND = <span class=\"hljs-number\">404</span>;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;PI: &quot;</span> &lt;&lt; PI &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;E: &quot;</span> &lt;&lt; E &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Max Connections: &quot;</span> &lt;&lt; MAX_CONNECTIONS &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Error Code: &quot;</span> &lt;&lt; ERROR_CODE_FILE_NOT_FOUND &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"2-提高代码的可读性和可维护性\"><a href=\"#2-提高代码的可读性和可维护性\" class=\"headerlink\" title=\"2. 提高代码的可读性和可维护性\"></a>2. 提高代码的可读性和可维护性</h3><p>使用常量可以避免在代码中直接使用魔法数字，从而提高代码的可读性和可维护性。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-comment\">// 使用常量代替魔法数字</span><br><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> DAYS_IN_WEEK = <span class=\"hljs-number\">7</span>;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Days in a week: &quot;</span> &lt;&lt; DAYS_IN_WEEK &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"3-提高程序的安全性\"><a href=\"#3-提高程序的安全性\" class=\"headerlink\" title=\"3. 提高程序的安全性\"></a>3. 提高程序的安全性</h3><p>使用 <code>const</code> 关键字可以防止变量被意外修改，从而提高程序的安全性。</p>\n<figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">void</span> <span class=\"hljs-title\">printValue</span><span class=\"hljs-params\">(<span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> value)</span> </span>&#123;<br>    <span class=\"hljs-comment\">// value = 10; // 错误：不能修改 const 变量</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Value: &quot;</span> &lt;&lt; value &lt;&lt; std::endl;<br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> value = <span class=\"hljs-number\">42</span>;<br>    <span class=\"hljs-built_in\">printValue</span>(value);<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"五、常量的注意事项\"><a href=\"#五、常量的注意事项\" class=\"headerlink\" title=\"五、常量的注意事项\"></a>五、常量的注意事项</h2><h3 id=\"1-define-预处理器指令定义的常量没有类型检查\"><a href=\"#1-define-预处理器指令定义的常量没有类型检查\" class=\"headerlink\" title=\"1. #define 预处理器指令定义的常量没有类型检查\"></a>1. <code>#define</code> 预处理器指令定义的常量没有类型检查</h3><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">define</span> VALUE 42</span><br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-type\">double</span> value = VALUE; <span class=\"hljs-comment\">// 没有类型检查，可能会导致错误</span><br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Value: &quot;</span> &lt;&lt; value &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><h3 id=\"2-constexpr-关键字定义的常量必须能够在编译时求值\"><a href=\"#2-constexpr-关键字定义的常量必须能够在编译时求值\" class=\"headerlink\" title=\"2. constexpr 关键字定义的常量必须能够在编译时求值\"></a>2. <code>constexpr</code> 关键字定义的常量必须能够在编译时求值</h3><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-function\"><span class=\"hljs-keyword\">constexpr</span> <span class=\"hljs-type\">int</span> <span class=\"hljs-title\">getValue</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">42</span>; <span class=\"hljs-comment\">// 必须在编译时求值</span><br>&#125;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-keyword\">constexpr</span> <span class=\"hljs-type\">int</span> value = <span class=\"hljs-built_in\">getValue</span>();<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Value: &quot;</span> &lt;&lt; value &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"3-避免过度使用常量，影响代码的可读性\"><a href=\"#3-避免过度使用常量，影响代码的可读性\" class=\"headerlink\" title=\"3. 避免过度使用常量，影响代码的可读性\"></a>3. 避免过度使用常量，影响代码的可读性</h3><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> A = <span class=\"hljs-number\">1</span>;<br><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> B = <span class=\"hljs-number\">2</span>;<br><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> C = <span class=\"hljs-number\">3</span>;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    <span class=\"hljs-comment\">// 过度使用常量可能会影响代码的可读性</span><br>    <span class=\"hljs-type\">int</span> result = A + B + C;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Result: &quot;</span> &lt;&lt; result &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h2 id=\"六、总结\"><a href=\"#六、总结\" class=\"headerlink\" title=\"六、总结\"></a>六、总结</h2><p>本文详细介绍了 C++ 中常量的定义、使用和应用场景。常量在提高代码质量方面起着重要作用，能够提高代码的可读性、可维护性和安全性。通过合理使用常量，我们可以避免硬编码的数值和字符串，从而使代码更加清晰和易于维护。</p>\n<h2 id=\"七、参考资料\"><a href=\"#七、参考资料\" class=\"headerlink\" title=\"七、参考资料\"></a>七、参考资料</h2><ul>\n<li><a href=\"https://www.amazon.com/C-Primer-5th-Stanley-Lippman/dp/0321714113\">C++ Primer</a></li>\n<li><a href=\"https://en.cppreference.com/w/\">cppreference.com</a></li>\n</ul>\n<h2 id=\"八、附录\"><a href=\"#八、附录\" class=\"headerlink\" title=\"八、附录\"></a>八、附录</h2><h3 id=\"常见常量示例代码\"><a href=\"#常见常量示例代码\" class=\"headerlink\" title=\"常见常量示例代码\"></a>常见常量示例代码</h3><figure class=\"highlight cpp\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs cpp\"><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">include</span> <span class=\"hljs-string\">&lt;iostream&gt;</span></span><br><br><span class=\"hljs-comment\">// 使用 #define 定义常量</span><br><span class=\"hljs-meta\">#<span class=\"hljs-keyword\">define</span> MAX_VALUE 100</span><br><br><span class=\"hljs-comment\">// 使用 const 定义常量</span><br><span class=\"hljs-type\">const</span> <span class=\"hljs-type\">int</span> MIN_VALUE = <span class=\"hljs-number\">0</span>;<br><br><span class=\"hljs-comment\">// 使用 constexpr 定义常量</span><br><span class=\"hljs-keyword\">constexpr</span> <span class=\"hljs-type\">double</span> PI = <span class=\"hljs-number\">3.14159</span>;<br><br><span class=\"hljs-function\"><span class=\"hljs-type\">int</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span> </span>&#123;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Max Value: &quot;</span> &lt;&lt; MAX_VALUE &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;Min Value: &quot;</span> &lt;&lt; MIN_VALUE &lt;&lt; std::endl;<br>    std::cout &lt;&lt; <span class=\"hljs-string\">&quot;PI: &quot;</span> &lt;&lt; PI &lt;&lt; std::endl;<br><br>    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"常量相关的常见问题解答\"><a href=\"#常量相关的常见问题解答\" class=\"headerlink\" title=\"常量相关的常见问题解答\"></a>常量相关的常见问题解答</h3><ol>\n<li><p><strong>问：<code>const</code> 和 <code>constexpr</code> 有什么区别？</strong></p>\n<ul>\n<li>答：<code>const</code> 用于定义运行时常量，而 <code>constexpr</code> 用于定义编译时常量，要求在编译时求值。</li>\n</ul>\n</li>\n<li><p><strong>问：为什么推荐使用 <code>const</code> 而不是 <code>#define</code>？</strong></p>\n<ul>\n<li>答：<code>const</code> 具有类型检查，更安全且更易于调试，而 <code>#define</code> 没有类型检查，容易出错。</li>\n</ul>\n</li>\n<li><p><strong>问：<code>constexpr</code> 函数有什么要求？</strong></p>\n<ul>\n<li>答：<code>constexpr</code> 函数必须在编译时求值，且不能包含复杂的逻辑或运行时才能确定的值。</li>\n</ul>\n</li>\n</ol>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n"},{"title":"HTTP基础03：简单的HTTP协议","date":"2025-01-02T04:00:00.000Z","_content":"\n\n\n## 简单的 HTTP协议\n\n## 1. HTTP协议用于客户端和服务器端之间的通信\n\n![image-20250102104311290](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104311290.png)\n\n- **定义**：HTTP协议用于客户端和服务器之间的通信。\n- **角色**：请求访问资源的一端称为客户端，提供资源响应的一端称为服务器端。\n- **通信线路**：在一条通信线路上，必定有一端是客户端，另一端是服务器端。\n- **角色互换**：在某些情况下，两台计算机可能会互换客户端和服务器端的角色，但在一条通信路线上，角色是确定的。\n\n## 2. 通过请求和响应的交换达成通信\n\n![请求和响应](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104434929.png)\n\n**请求和响应**：HTTP协议规定请求从客户端发出，服务器端响应该请求并返回。\n\n**请求报文**：由请求方法、请求URI、协议版本、可选的请求首部字段和内容实体构成。\n\n- **示例**：`GET /index.htm HTTP/1.1 Host: hackr.jp`\n\n![请求报文](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104508513.png)\n\n**响应报文**：由协议版本、状态码、原因短语、可选的响应首部字段以及实体主体构成。\n\n![image-20250102104617041](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104617041.png)\n\n- **示例**：\n  \n  ```\n  HTTP/1.1 200 OK\n  Date: Tue, 10 Jul 2012 06:50:15 GMT\n  Content-Length: 362\n  Content-Type: text/html\n  ```\n\n## 3. HTTP是不保存状态的协议\n\n![无状态协议](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104640175.png)\n\n- **无状态协议**：HTTP协议自身不对请求和响应之间的通信状态进行保存。\n- **优点**：为了更快地处理大量事务，确保协议的可伸缩性。\n- **缺点**：随着Web的发展，无状态导致业务处理变得棘手。\n- **解决方案**：引入Cookie技术来管理状态。\n\n## 4. 请求URI定位资源\n\n![URI定位资源](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104835594.png)\n\n- **URI功能**：HTTP协议使用URI定位互联网上的资源。\n- **请求URI**：客户端请求访问资源时，URI需要包含在请求报文中。\n  - **完整URI**：`GET http://hackr.jp/index.htm HTTP/1.1`\n  - **Host字段**：`GET /index.htm HTTP/1.1 Host: hackr.jp`\n  - **通配符**：`OPTIONS * HTTP/1.1`\n\n## 5. 告知服务器意图的 HTTP方法\n### 5.1 GET: 获取资源\n- **用途**：用于请求访问已被URI识别的资源。\n- **特点**：请求的资源会被服务器解析后返回响应内容。如果是文本资源，则原样返回；如果是程序（如CGI），则返回执行后的输出结果。\n- **示例请求**：\n  ```\n  GET /index.html HTTP/1.1\n  Host: www.example.com\n  ```\n- **示例响应**：\n  ```\n  HTTP/1.1 200 OK\n  Content-Type: text/html\n  <html>...</html>\n  ```\n\n### 5.2 POST: 传输实体主体\n- **用途**：用于传输实体的主体，通常用于提交表单数据或其他数据。\n- **特点**：虽然GET方法也可以传输数据，但POST方法更适合传输大量数据或敏感信息，因为它不会将数据暴露在URL中。\n- **示例请求**：\n  ```\n  POST /submit.cgi HTTP/1.1\n  Host: www.example.com\n  Content-Length: 1560\n  <form data>\n  ```\n- **示例响应**：\n  ```\n  HTTP/1.1 200 OK\n  Content-Type: text/html\n  <result of form submission>\n  ```\n\n### 5.3 PUT: 传输文件\n- **用途**：用于传输文件，类似于FTP协议的文件上传。\n- **特点**：请求报文的主体中包含文件内容，服务器将其保存到请求URI指定的位置。由于PUT方法不带验证机制，存在安全性问题，一般Web网站不使用该方法。\n- **示例请求**：\n  ```\n  PUT /example.html HTTP/1.1\n  Host: www.example.com\n  Content-Type: text/html\n  Content-Length: 1560\n  <file content>\n  ```\n- **示例响应**：\n  ```\n  HTTP/1.1 204 No Content\n  ```\n\n### 5.4 HEAD: 获得报文首部\n- **用途**：类似于GET方法，但不返回报文主体部分，仅用于确认URI的有效性及资源更新的日期时间等。\n- **特点**：常用于检查资源是否存在或获取资源的元数据。\n- **示例请求**：\n  ```\n  HEAD /index.html HTTP/1.1\n  Host: www.example.com\n  ```\n- **示例响应**：\n  ```\n  HTTP/1.1 200 OK\n  Date: Mon, 27 Jul 2009 12:28:53 GMT\n  Server: Apache/2.2.14 (Win32)\n  Last-Modified: Wed, 22 Jul 2009 19:15:56 GMT\n  Content-Length: 88\n  Content-Type: text/html\n  ```\n\n### 5.5 DELETE: 删除文件\n- **用途**：用于删除文件，是与PUT相反的操作。\n- **特点**：请求URI指定的资源将被删除。由于DELETE方法不带验证机制，存在安全性问题，一般Web网站不使用该方法。\n- **示例请求**：\n  ```\n  DELETE /example.html HTTP/1.1\n  Host: www.example.com\n  ```\n- **示例响应**：\n  ```\n  HTTP/1.1 204 No Content\n  ```\n\n### 5.6 OPTIONS: 询问支持的方法\n- **用途**：用于查询针对请求URI指定的资源支持的方法。\n- **特点**：返回服务器支持的各种HTTP方法。\n- **示例请求**：\n  ```\n  OPTIONS * HTTP/1.1\n  Host: www.example.com\n  ```\n- **示例响应**：\n  ```\n  HTTP/1.1 200 OK\n  Allow: GET, POST, HEAD, OPTIONS\n  ```\n\n### 5.7 TRACE: 追踪路径\n- **用途**：用于让Web服务器端将之前的请求通信环回给客户端。\n- **特点**：通过Max-Forwards首部字段的值递减，最终返回状态码200 OK的响应，包含请求内容。常用于调试和诊断请求路径。\n- **示例请求**：\n  ```\n  TRACE / HTTP/1.1\n  Host: www.example.com\n  Max-Forwards: 2\n  ```\n- **示例响应**：\n  ```\n  HTTP/1.1 200 OK\n  Content-Type: message/http\n  Content-Length: 1024\n  TRACE / HTTP/1.1 Host: www.example.com Max-Forwards: 2\n  ```\n\n### 5.8 CONNECT: 要求用隧道协议连接代理\n- **用途**：用于在与代理服务器通信时建立隧道，实现用隧道协议进行TCP通信，常用于SSL/TLS加密通信。\n- **特点**：主要用于HTTPS请求。\n- **示例请求**：\n  ```\n  CONNECT www.example.com:443 HTTP/1.1\n  Host: www.example.com\n  ```\n- **示例响应**：\n  ```\n  HTTP/1.1 200 Connection Established\n  ```\n\n\n\n## 6. 使用方法下达命令\n- **方法**：向请求URI指定的资源发送请求报文时，采用称为方法的命令。\n- **支持的方法**：GET、POST、HEAD等。\n\n![image-20250102113459101](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113459101.png)\n\n## 7. 持久连接节省通信量\n\n![初始版本](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113558809.png)\n\nHTTP协议的初始版本中，每次HTTP通信都需要断开TCP连接。这在传输小容量文本时问题不大，但随着HTTP的普及，文档中包含大量图片的情况增多，导致每次请求都会造成无谓的TCP连接建立和断开，增加了通信量的开销。\n\n![image-20250102113810021](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113810021.png)\n\n### 7.1 持久连接\n\n![image-20250102113835652](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113835652.png)\n\n为了解决上述TCP连接的问题，HTTP/1.1和一部分HTTP/1.0引入了持久连接（HTTP Persistent Connections，也称为HTTP keep-alive或HTTP connection reuse）的方法。持久连接的特点是，只要任意一端没有明确提出断开连接，则保持TCP连接状态。\n\n**优点**：\n- 减少了TCP连接的重复建立和断开所造成的额外开销。\n- 减轻了服务器端的负载。\n- 减少开销的那部分时间，使HTTP请求和响应能够更早地结束，从而提高了Web页面的显示速度。\n\n在HTTP/1.1中，所有的连接默认都是持久连接，但在HTTP/1.0内并未标准化。虽然有一部分服务器通过非标准的手段实现了持久连接，但服务器端不一定能够支持持久连接。毫无疑问，除了服务器端，客户端也需要支持持久连接。\n\n### 7.2 管线化\n\n![image-20250102113951113](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113951113.png)\n\n持久连接使得多数请求以管线化（pipelining）方式发送成为可能。以前发送请求后需等待并收到响应，才能发送下一个请求。管线化技术出现后，不用等待响应亦可直接发送下一个请求。\n\n**优点**：\n- 能够同时并行发送多个请求，而不需要一个接一个地等待响应。\n- 当请求一个包含多张图片的HTML Web页面时，与挨个连接相比，用持久连接可以让请求更快结束。而管线化技术则比持久连接还要快。请求数越多，时间差就越明显。\n\n通过持久连接和管线化技术，HTTP协议大大提高了通信效率，减少了不必要的开销，提升了用户体验。\n\n## 8. 使用 Cookie的状态管理\nHTTP协议是一种无状态协议，这意味着它不会保存请求和响应之间的通信状态。这种设计简化了协议，使其能够高效地处理大量事务，但也带来了一些挑战，特别是在需要保持用户状态的情况下。例如，用户在登录后访问网站的不同页面时，仍然需要保持登录状态。\n\n![没有Cookie](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102114136299.png)\n\n#### 8.1 无状态协议的缺点\n- **状态管理困难**：由于HTTP不保存状态，服务器无法识别同一用户的多次请求，导致每次请求都需要重新认证。\n- **用户体验不佳**：用户每次访问新页面时可能需要重新登录，影响用户体验。\n\n#### 8.2 Cookie技术的引入\n\n![没有Cookie](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102114244688.png)\n\n![有了Cookie](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102114256778.png)\n\n为了解决无状态协议带来的问题，引入了Cookie技术。Cookie通过在请求和响应报文中写入Cookie信息来控制客户端的状态。\n\n#### 8.3 Cookie的工作原理\n1. **服务器生成Cookie**：服务器在响应报文中添加一个`Set-Cookie`首部字段，通知客户端保存Cookie。\n   ```http\n   HTTP/1.1 200 OK\n   Set-Cookie: session_id=1234567890\n   ```\n\n2. **客户端保存Cookie**：客户端在收到响应后，会自动保存Cookie信息。\n\n3. **客户端发送Cookie**：下次客户端向同一服务器发送请求时，会自动在请求报文中加入Cookie值。\n   ```http\n   GET /page HTTP/1.1\n   Host: example.com\n   Cookie: session_id=1234567890\n   ```\n\n4. **服务器读取Cookie**：服务器端发现客户端发送的Cookie后，会检查并对比服务器上的记录，从而识别出请求的用户。\n\n#### 8.4 Cookie的应用场景\n- **用户认证**：通过Cookie保存用户的登录状态，避免每次请求都需要重新登录。\n- **个性化设置**：保存用户的偏好设置，如主题、语言等。\n- **购物车**：保存用户的购物车内容，方便用户继续购物。\n\n#### 8.5 Cookie的限制\n- **安全性**：Cookie可以被篡改，因此敏感信息不应存储在Cookie中。\n- **隐私**：Cookie可以追踪用户的浏览行为，可能引发隐私问题。\n- **大小限制**：每个域名下的Cookie数量和总大小有限制，通常每个Cookie不超过4KB。\n\n通过Cookie技术，HTTP协议能够在保持其简单高效的同时，实现状态管理功能，提升用户体验。\n\n\n\n\n\n参考：《图解HTTP》第一章\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","source":"_posts/计算机基础/计算机网络/HTTP基础03：简单的 HTTP协议.md","raw":"---\ntitle: 'HTTP基础03：简单的HTTP协议'\ncategories:\n  - [计算机基础,计算机网络]\ntags:\n  - 计算机网络\n  - 计算机基础\n  - HTTP\ndate: 2025-01-02 12:00:00\n---\n\n\n\n## 简单的 HTTP协议\n\n## 1. HTTP协议用于客户端和服务器端之间的通信\n\n![image-20250102104311290](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104311290.png)\n\n- **定义**：HTTP协议用于客户端和服务器之间的通信。\n- **角色**：请求访问资源的一端称为客户端，提供资源响应的一端称为服务器端。\n- **通信线路**：在一条通信线路上，必定有一端是客户端，另一端是服务器端。\n- **角色互换**：在某些情况下，两台计算机可能会互换客户端和服务器端的角色，但在一条通信路线上，角色是确定的。\n\n## 2. 通过请求和响应的交换达成通信\n\n![请求和响应](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104434929.png)\n\n**请求和响应**：HTTP协议规定请求从客户端发出，服务器端响应该请求并返回。\n\n**请求报文**：由请求方法、请求URI、协议版本、可选的请求首部字段和内容实体构成。\n\n- **示例**：`GET /index.htm HTTP/1.1 Host: hackr.jp`\n\n![请求报文](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104508513.png)\n\n**响应报文**：由协议版本、状态码、原因短语、可选的响应首部字段以及实体主体构成。\n\n![image-20250102104617041](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104617041.png)\n\n- **示例**：\n  \n  ```\n  HTTP/1.1 200 OK\n  Date: Tue, 10 Jul 2012 06:50:15 GMT\n  Content-Length: 362\n  Content-Type: text/html\n  ```\n\n## 3. HTTP是不保存状态的协议\n\n![无状态协议](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104640175.png)\n\n- **无状态协议**：HTTP协议自身不对请求和响应之间的通信状态进行保存。\n- **优点**：为了更快地处理大量事务，确保协议的可伸缩性。\n- **缺点**：随着Web的发展，无状态导致业务处理变得棘手。\n- **解决方案**：引入Cookie技术来管理状态。\n\n## 4. 请求URI定位资源\n\n![URI定位资源](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104835594.png)\n\n- **URI功能**：HTTP协议使用URI定位互联网上的资源。\n- **请求URI**：客户端请求访问资源时，URI需要包含在请求报文中。\n  - **完整URI**：`GET http://hackr.jp/index.htm HTTP/1.1`\n  - **Host字段**：`GET /index.htm HTTP/1.1 Host: hackr.jp`\n  - **通配符**：`OPTIONS * HTTP/1.1`\n\n## 5. 告知服务器意图的 HTTP方法\n### 5.1 GET: 获取资源\n- **用途**：用于请求访问已被URI识别的资源。\n- **特点**：请求的资源会被服务器解析后返回响应内容。如果是文本资源，则原样返回；如果是程序（如CGI），则返回执行后的输出结果。\n- **示例请求**：\n  ```\n  GET /index.html HTTP/1.1\n  Host: www.example.com\n  ```\n- **示例响应**：\n  ```\n  HTTP/1.1 200 OK\n  Content-Type: text/html\n  <html>...</html>\n  ```\n\n### 5.2 POST: 传输实体主体\n- **用途**：用于传输实体的主体，通常用于提交表单数据或其他数据。\n- **特点**：虽然GET方法也可以传输数据，但POST方法更适合传输大量数据或敏感信息，因为它不会将数据暴露在URL中。\n- **示例请求**：\n  ```\n  POST /submit.cgi HTTP/1.1\n  Host: www.example.com\n  Content-Length: 1560\n  <form data>\n  ```\n- **示例响应**：\n  ```\n  HTTP/1.1 200 OK\n  Content-Type: text/html\n  <result of form submission>\n  ```\n\n### 5.3 PUT: 传输文件\n- **用途**：用于传输文件，类似于FTP协议的文件上传。\n- **特点**：请求报文的主体中包含文件内容，服务器将其保存到请求URI指定的位置。由于PUT方法不带验证机制，存在安全性问题，一般Web网站不使用该方法。\n- **示例请求**：\n  ```\n  PUT /example.html HTTP/1.1\n  Host: www.example.com\n  Content-Type: text/html\n  Content-Length: 1560\n  <file content>\n  ```\n- **示例响应**：\n  ```\n  HTTP/1.1 204 No Content\n  ```\n\n### 5.4 HEAD: 获得报文首部\n- **用途**：类似于GET方法，但不返回报文主体部分，仅用于确认URI的有效性及资源更新的日期时间等。\n- **特点**：常用于检查资源是否存在或获取资源的元数据。\n- **示例请求**：\n  ```\n  HEAD /index.html HTTP/1.1\n  Host: www.example.com\n  ```\n- **示例响应**：\n  ```\n  HTTP/1.1 200 OK\n  Date: Mon, 27 Jul 2009 12:28:53 GMT\n  Server: Apache/2.2.14 (Win32)\n  Last-Modified: Wed, 22 Jul 2009 19:15:56 GMT\n  Content-Length: 88\n  Content-Type: text/html\n  ```\n\n### 5.5 DELETE: 删除文件\n- **用途**：用于删除文件，是与PUT相反的操作。\n- **特点**：请求URI指定的资源将被删除。由于DELETE方法不带验证机制，存在安全性问题，一般Web网站不使用该方法。\n- **示例请求**：\n  ```\n  DELETE /example.html HTTP/1.1\n  Host: www.example.com\n  ```\n- **示例响应**：\n  ```\n  HTTP/1.1 204 No Content\n  ```\n\n### 5.6 OPTIONS: 询问支持的方法\n- **用途**：用于查询针对请求URI指定的资源支持的方法。\n- **特点**：返回服务器支持的各种HTTP方法。\n- **示例请求**：\n  ```\n  OPTIONS * HTTP/1.1\n  Host: www.example.com\n  ```\n- **示例响应**：\n  ```\n  HTTP/1.1 200 OK\n  Allow: GET, POST, HEAD, OPTIONS\n  ```\n\n### 5.7 TRACE: 追踪路径\n- **用途**：用于让Web服务器端将之前的请求通信环回给客户端。\n- **特点**：通过Max-Forwards首部字段的值递减，最终返回状态码200 OK的响应，包含请求内容。常用于调试和诊断请求路径。\n- **示例请求**：\n  ```\n  TRACE / HTTP/1.1\n  Host: www.example.com\n  Max-Forwards: 2\n  ```\n- **示例响应**：\n  ```\n  HTTP/1.1 200 OK\n  Content-Type: message/http\n  Content-Length: 1024\n  TRACE / HTTP/1.1 Host: www.example.com Max-Forwards: 2\n  ```\n\n### 5.8 CONNECT: 要求用隧道协议连接代理\n- **用途**：用于在与代理服务器通信时建立隧道，实现用隧道协议进行TCP通信，常用于SSL/TLS加密通信。\n- **特点**：主要用于HTTPS请求。\n- **示例请求**：\n  ```\n  CONNECT www.example.com:443 HTTP/1.1\n  Host: www.example.com\n  ```\n- **示例响应**：\n  ```\n  HTTP/1.1 200 Connection Established\n  ```\n\n\n\n## 6. 使用方法下达命令\n- **方法**：向请求URI指定的资源发送请求报文时，采用称为方法的命令。\n- **支持的方法**：GET、POST、HEAD等。\n\n![image-20250102113459101](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113459101.png)\n\n## 7. 持久连接节省通信量\n\n![初始版本](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113558809.png)\n\nHTTP协议的初始版本中，每次HTTP通信都需要断开TCP连接。这在传输小容量文本时问题不大，但随着HTTP的普及，文档中包含大量图片的情况增多，导致每次请求都会造成无谓的TCP连接建立和断开，增加了通信量的开销。\n\n![image-20250102113810021](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113810021.png)\n\n### 7.1 持久连接\n\n![image-20250102113835652](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113835652.png)\n\n为了解决上述TCP连接的问题，HTTP/1.1和一部分HTTP/1.0引入了持久连接（HTTP Persistent Connections，也称为HTTP keep-alive或HTTP connection reuse）的方法。持久连接的特点是，只要任意一端没有明确提出断开连接，则保持TCP连接状态。\n\n**优点**：\n- 减少了TCP连接的重复建立和断开所造成的额外开销。\n- 减轻了服务器端的负载。\n- 减少开销的那部分时间，使HTTP请求和响应能够更早地结束，从而提高了Web页面的显示速度。\n\n在HTTP/1.1中，所有的连接默认都是持久连接，但在HTTP/1.0内并未标准化。虽然有一部分服务器通过非标准的手段实现了持久连接，但服务器端不一定能够支持持久连接。毫无疑问，除了服务器端，客户端也需要支持持久连接。\n\n### 7.2 管线化\n\n![image-20250102113951113](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113951113.png)\n\n持久连接使得多数请求以管线化（pipelining）方式发送成为可能。以前发送请求后需等待并收到响应，才能发送下一个请求。管线化技术出现后，不用等待响应亦可直接发送下一个请求。\n\n**优点**：\n- 能够同时并行发送多个请求，而不需要一个接一个地等待响应。\n- 当请求一个包含多张图片的HTML Web页面时，与挨个连接相比，用持久连接可以让请求更快结束。而管线化技术则比持久连接还要快。请求数越多，时间差就越明显。\n\n通过持久连接和管线化技术，HTTP协议大大提高了通信效率，减少了不必要的开销，提升了用户体验。\n\n## 8. 使用 Cookie的状态管理\nHTTP协议是一种无状态协议，这意味着它不会保存请求和响应之间的通信状态。这种设计简化了协议，使其能够高效地处理大量事务，但也带来了一些挑战，特别是在需要保持用户状态的情况下。例如，用户在登录后访问网站的不同页面时，仍然需要保持登录状态。\n\n![没有Cookie](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102114136299.png)\n\n#### 8.1 无状态协议的缺点\n- **状态管理困难**：由于HTTP不保存状态，服务器无法识别同一用户的多次请求，导致每次请求都需要重新认证。\n- **用户体验不佳**：用户每次访问新页面时可能需要重新登录，影响用户体验。\n\n#### 8.2 Cookie技术的引入\n\n![没有Cookie](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102114244688.png)\n\n![有了Cookie](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102114256778.png)\n\n为了解决无状态协议带来的问题，引入了Cookie技术。Cookie通过在请求和响应报文中写入Cookie信息来控制客户端的状态。\n\n#### 8.3 Cookie的工作原理\n1. **服务器生成Cookie**：服务器在响应报文中添加一个`Set-Cookie`首部字段，通知客户端保存Cookie。\n   ```http\n   HTTP/1.1 200 OK\n   Set-Cookie: session_id=1234567890\n   ```\n\n2. **客户端保存Cookie**：客户端在收到响应后，会自动保存Cookie信息。\n\n3. **客户端发送Cookie**：下次客户端向同一服务器发送请求时，会自动在请求报文中加入Cookie值。\n   ```http\n   GET /page HTTP/1.1\n   Host: example.com\n   Cookie: session_id=1234567890\n   ```\n\n4. **服务器读取Cookie**：服务器端发现客户端发送的Cookie后，会检查并对比服务器上的记录，从而识别出请求的用户。\n\n#### 8.4 Cookie的应用场景\n- **用户认证**：通过Cookie保存用户的登录状态，避免每次请求都需要重新登录。\n- **个性化设置**：保存用户的偏好设置，如主题、语言等。\n- **购物车**：保存用户的购物车内容，方便用户继续购物。\n\n#### 8.5 Cookie的限制\n- **安全性**：Cookie可以被篡改，因此敏感信息不应存储在Cookie中。\n- **隐私**：Cookie可以追踪用户的浏览行为，可能引发隐私问题。\n- **大小限制**：每个域名下的Cookie数量和总大小有限制，通常每个Cookie不超过4KB。\n\n通过Cookie技术，HTTP协议能够在保持其简单高效的同时，实现状态管理功能，提升用户体验。\n\n\n\n\n\n参考：《图解HTTP》第一章\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","slug":"计算机基础/计算机网络/HTTP基础03：简单的 HTTP协议","published":1,"updated":"2025-01-02T03:50:15.821Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3k000thghiecotbrwk","content":"<h2 id=\"简单的-HTTP协议\"><a href=\"#简单的-HTTP协议\" class=\"headerlink\" title=\"简单的 HTTP协议\"></a>简单的 HTTP协议</h2><h2 id=\"1-HTTP协议用于客户端和服务器端之间的通信\"><a href=\"#1-HTTP协议用于客户端和服务器端之间的通信\" class=\"headerlink\" title=\"1. HTTP协议用于客户端和服务器端之间的通信\"></a>1. HTTP协议用于客户端和服务器端之间的通信</h2><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104311290.png\" alt=\"image-20250102104311290\"></p>\n<ul>\n<li><strong>定义</strong>：HTTP协议用于客户端和服务器之间的通信。</li>\n<li><strong>角色</strong>：请求访问资源的一端称为客户端，提供资源响应的一端称为服务器端。</li>\n<li><strong>通信线路</strong>：在一条通信线路上，必定有一端是客户端，另一端是服务器端。</li>\n<li><strong>角色互换</strong>：在某些情况下，两台计算机可能会互换客户端和服务器端的角色，但在一条通信路线上，角色是确定的。</li>\n</ul>\n<h2 id=\"2-通过请求和响应的交换达成通信\"><a href=\"#2-通过请求和响应的交换达成通信\" class=\"headerlink\" title=\"2. 通过请求和响应的交换达成通信\"></a>2. 通过请求和响应的交换达成通信</h2><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104434929.png\" alt=\"请求和响应\"></p>\n<p><strong>请求和响应</strong>：HTTP协议规定请求从客户端发出，服务器端响应该请求并返回。</p>\n<p><strong>请求报文</strong>：由请求方法、请求URI、协议版本、可选的请求首部字段和内容实体构成。</p>\n<ul>\n<li><strong>示例</strong>：<code>GET /index.htm HTTP/1.1 Host: hackr.jp</code></li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104508513.png\" alt=\"请求报文\"></p>\n<p><strong>响应报文</strong>：由协议版本、状态码、原因短语、可选的响应首部字段以及实体主体构成。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104617041.png\" alt=\"image-20250102104617041\"></p>\n<ul>\n<li><p><strong>示例</strong>：</p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">HTTP</span>/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">200</span> OK<br><span class=\"hljs-attribute\">Date</span>: Tue, <span class=\"hljs-number\">10</span> Jul <span class=\"hljs-number\">2012</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">50</span>:<span class=\"hljs-number\">15</span> GMT<br><span class=\"hljs-attribute\">Content</span>-Length: <span class=\"hljs-number\">362</span><br><span class=\"hljs-attribute\">Content</span>-Type: text/html<br></code></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"3-HTTP是不保存状态的协议\"><a href=\"#3-HTTP是不保存状态的协议\" class=\"headerlink\" title=\"3. HTTP是不保存状态的协议\"></a>3. HTTP是不保存状态的协议</h2><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104640175.png\" alt=\"无状态协议\"></p>\n<ul>\n<li><strong>无状态协议</strong>：HTTP协议自身不对请求和响应之间的通信状态进行保存。</li>\n<li><strong>优点</strong>：为了更快地处理大量事务，确保协议的可伸缩性。</li>\n<li><strong>缺点</strong>：随着Web的发展，无状态导致业务处理变得棘手。</li>\n<li><strong>解决方案</strong>：引入Cookie技术来管理状态。</li>\n</ul>\n<h2 id=\"4-请求URI定位资源\"><a href=\"#4-请求URI定位资源\" class=\"headerlink\" title=\"4. 请求URI定位资源\"></a>4. 请求URI定位资源</h2><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104835594.png\" alt=\"URI定位资源\"></p>\n<ul>\n<li><strong>URI功能</strong>：HTTP协议使用URI定位互联网上的资源。</li>\n<li><strong>请求URI</strong>：客户端请求访问资源时，URI需要包含在请求报文中。<ul>\n<li><strong>完整URI</strong>：<code>GET http://hackr.jp/index.htm HTTP/1.1</code></li>\n<li><strong>Host字段</strong>：<code>GET /index.htm HTTP/1.1 Host: hackr.jp</code></li>\n<li><strong>通配符</strong>：<code>OPTIONS * HTTP/1.1</code></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"5-告知服务器意图的-HTTP方法\"><a href=\"#5-告知服务器意图的-HTTP方法\" class=\"headerlink\" title=\"5. 告知服务器意图的 HTTP方法\"></a>5. 告知服务器意图的 HTTP方法</h2><h3 id=\"5-1-GET-获取资源\"><a href=\"#5-1-GET-获取资源\" class=\"headerlink\" title=\"5.1 GET: 获取资源\"></a>5.1 GET: 获取资源</h3><ul>\n<li><strong>用途</strong>：用于请求访问已被URI识别的资源。</li>\n<li><strong>特点</strong>：请求的资源会被服务器解析后返回响应内容。如果是文本资源，则原样返回；如果是程序（如CGI），则返回执行后的输出结果。</li>\n<li><strong>示例请求</strong>：<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-keyword\">GET</span> <span class=\"hljs-string\">/index.html</span> <span class=\"hljs-meta\">HTTP/1.1</span><br><span class=\"hljs-attribute\">Host</span><span class=\"hljs-punctuation\">: </span>www.example.com<br></code></pre></td></tr></table></figure></li>\n<li><strong>示例响应</strong>：<figure class=\"highlight xquery\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xquery\">HTTP/<span class=\"hljs-number\">1.1</span> <span class=\"hljs-number\">200</span> OK<br>Content-Type: <span class=\"hljs-type\">text</span>/html<br><span class=\"language-xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">html</span>&gt;</span>...<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">html</span>&gt;</span></span><br></code></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"5-2-POST-传输实体主体\"><a href=\"#5-2-POST-传输实体主体\" class=\"headerlink\" title=\"5.2 POST: 传输实体主体\"></a>5.2 POST: 传输实体主体</h3><ul>\n<li><strong>用途</strong>：用于传输实体的主体，通常用于提交表单数据或其他数据。</li>\n<li><strong>特点</strong>：虽然GET方法也可以传输数据，但POST方法更适合传输大量数据或敏感信息，因为它不会将数据暴露在URL中。</li>\n<li><strong>示例请求</strong>：<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">POST</span> /submit.cgi HTTP/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span><br><span class=\"hljs-attribute\">Host</span>: www.example.com<br><span class=\"hljs-attribute\">Content</span>-Length: <span class=\"hljs-number\">1560</span><br><span class=\"hljs-section\">&lt;form data&gt;</span><br></code></pre></td></tr></table></figure></li>\n<li><strong>示例响应</strong>：<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">HTTP</span>/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">200</span> OK<br><span class=\"hljs-attribute\">Content</span>-Type: text/html<br><span class=\"hljs-section\">&lt;result of form submission&gt;</span><br></code></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"5-3-PUT-传输文件\"><a href=\"#5-3-PUT-传输文件\" class=\"headerlink\" title=\"5.3 PUT: 传输文件\"></a>5.3 PUT: 传输文件</h3><ul>\n<li><strong>用途</strong>：用于传输文件，类似于FTP协议的文件上传。</li>\n<li><strong>特点</strong>：请求报文的主体中包含文件内容，服务器将其保存到请求URI指定的位置。由于PUT方法不带验证机制，存在安全性问题，一般Web网站不使用该方法。</li>\n<li><strong>示例请求</strong>：<figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stylus\">PUT /example<span class=\"hljs-selector-class\">.html</span> HTTP/<span class=\"hljs-number\">1.1</span><br>Host: www<span class=\"hljs-selector-class\">.example</span><span class=\"hljs-selector-class\">.com</span><br>Content-Type: text/<span class=\"hljs-selector-tag\">html</span><br>Content-Length: <span class=\"hljs-number\">1560</span><br>&lt;file <span class=\"hljs-attribute\">content</span>&gt;<br></code></pre></td></tr></table></figure></li>\n<li><strong>示例响应</strong>：<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">HTTP</span>/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">204</span> No Content<br></code></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"5-4-HEAD-获得报文首部\"><a href=\"#5-4-HEAD-获得报文首部\" class=\"headerlink\" title=\"5.4 HEAD: 获得报文首部\"></a>5.4 HEAD: 获得报文首部</h3><ul>\n<li><strong>用途</strong>：类似于GET方法，但不返回报文主体部分，仅用于确认URI的有效性及资源更新的日期时间等。</li>\n<li><strong>特点</strong>：常用于检查资源是否存在或获取资源的元数据。</li>\n<li><strong>示例请求</strong>：<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-keyword\">HEAD</span> <span class=\"hljs-string\">/index.html</span> <span class=\"hljs-meta\">HTTP/1.1</span><br><span class=\"hljs-attribute\">Host</span><span class=\"hljs-punctuation\">: </span>www.example.com<br></code></pre></td></tr></table></figure></li>\n<li><strong>示例响应</strong>：<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">HTTP</span>/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">200</span> OK<br><span class=\"hljs-attribute\">Date</span>: Mon, <span class=\"hljs-number\">27</span> Jul <span class=\"hljs-number\">2009</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">28</span>:<span class=\"hljs-number\">53</span> GMT<br><span class=\"hljs-attribute\">Server</span>: Apache/<span class=\"hljs-number\">2</span>.<span class=\"hljs-number\">2</span>.<span class=\"hljs-number\">14</span> (Win32)<br><span class=\"hljs-attribute\">Last</span>-Modified: Wed, <span class=\"hljs-number\">22</span> Jul <span class=\"hljs-number\">2009</span> <span class=\"hljs-number\">19</span>:<span class=\"hljs-number\">15</span>:<span class=\"hljs-number\">56</span> GMT<br><span class=\"hljs-attribute\">Content</span>-Length: <span class=\"hljs-number\">88</span><br><span class=\"hljs-attribute\">Content</span>-Type: text/html<br></code></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"5-5-DELETE-删除文件\"><a href=\"#5-5-DELETE-删除文件\" class=\"headerlink\" title=\"5.5 DELETE: 删除文件\"></a>5.5 DELETE: 删除文件</h3><ul>\n<li><strong>用途</strong>：用于删除文件，是与PUT相反的操作。</li>\n<li><strong>特点</strong>：请求URI指定的资源将被删除。由于DELETE方法不带验证机制，存在安全性问题，一般Web网站不使用该方法。</li>\n<li><strong>示例请求</strong>：<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-keyword\">DELETE</span> <span class=\"hljs-string\">/example.html</span> <span class=\"hljs-meta\">HTTP/1.1</span><br><span class=\"hljs-attribute\">Host</span><span class=\"hljs-punctuation\">: </span>www.example.com<br></code></pre></td></tr></table></figure></li>\n<li><strong>示例响应</strong>：<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">HTTP</span>/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">204</span> No Content<br></code></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"5-6-OPTIONS-询问支持的方法\"><a href=\"#5-6-OPTIONS-询问支持的方法\" class=\"headerlink\" title=\"5.6 OPTIONS: 询问支持的方法\"></a>5.6 OPTIONS: 询问支持的方法</h3><ul>\n<li><strong>用途</strong>：用于查询针对请求URI指定的资源支持的方法。</li>\n<li><strong>特点</strong>：返回服务器支持的各种HTTP方法。</li>\n<li><strong>示例请求</strong>：<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-keyword\">OPTIONS</span> <span class=\"hljs-string\">*</span> <span class=\"hljs-meta\">HTTP/1.1</span><br><span class=\"hljs-attribute\">Host</span><span class=\"hljs-punctuation\">: </span>www.example.com<br></code></pre></td></tr></table></figure></li>\n<li><strong>示例响应</strong>：<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-meta\">HTTP/1.1</span> <span class=\"hljs-number\">200</span> OK<br><span class=\"hljs-attribute\">Allow</span><span class=\"hljs-punctuation\">: </span>GET, POST, HEAD, OPTIONS<br></code></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"5-7-TRACE-追踪路径\"><a href=\"#5-7-TRACE-追踪路径\" class=\"headerlink\" title=\"5.7 TRACE: 追踪路径\"></a>5.7 TRACE: 追踪路径</h3><ul>\n<li><strong>用途</strong>：用于让Web服务器端将之前的请求通信环回给客户端。</li>\n<li><strong>特点</strong>：通过Max-Forwards首部字段的值递减，最终返回状态码200 OK的响应，包含请求内容。常用于调试和诊断请求路径。</li>\n<li><strong>示例请求</strong>：<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-keyword\">TRACE</span> <span class=\"hljs-string\">/</span> <span class=\"hljs-meta\">HTTP/1.1</span><br><span class=\"hljs-attribute\">Host</span><span class=\"hljs-punctuation\">: </span>www.example.com<br><span class=\"hljs-attribute\">Max-Forwards</span><span class=\"hljs-punctuation\">: </span>2<br></code></pre></td></tr></table></figure></li>\n<li><strong>示例响应</strong>：<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">HTTP</span>/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">200</span> OK<br><span class=\"hljs-attribute\">Content</span>-Type: message/http<br><span class=\"hljs-attribute\">Content</span>-Length: <span class=\"hljs-number\">1024</span><br><span class=\"hljs-attribute\">TRACE</span> / HTTP/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span> Host: www.example.com Max-Forwards: <span class=\"hljs-number\">2</span><br></code></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"5-8-CONNECT-要求用隧道协议连接代理\"><a href=\"#5-8-CONNECT-要求用隧道协议连接代理\" class=\"headerlink\" title=\"5.8 CONNECT: 要求用隧道协议连接代理\"></a>5.8 CONNECT: 要求用隧道协议连接代理</h3><ul>\n<li><strong>用途</strong>：用于在与代理服务器通信时建立隧道，实现用隧道协议进行TCP通信，常用于SSL&#x2F;TLS加密通信。</li>\n<li><strong>特点</strong>：主要用于HTTPS请求。</li>\n<li><strong>示例请求</strong>：<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-keyword\">CONNECT</span> <span class=\"hljs-string\">www.example.com:443</span> <span class=\"hljs-meta\">HTTP/1.1</span><br><span class=\"hljs-attribute\">Host</span><span class=\"hljs-punctuation\">: </span>www.example.com<br></code></pre></td></tr></table></figure></li>\n<li><strong>示例响应</strong>：<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">HTTP</span>/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">200</span> Connection Established<br></code></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"6-使用方法下达命令\"><a href=\"#6-使用方法下达命令\" class=\"headerlink\" title=\"6. 使用方法下达命令\"></a>6. 使用方法下达命令</h2><ul>\n<li><strong>方法</strong>：向请求URI指定的资源发送请求报文时，采用称为方法的命令。</li>\n<li><strong>支持的方法</strong>：GET、POST、HEAD等。</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113459101.png\" alt=\"image-20250102113459101\"></p>\n<h2 id=\"7-持久连接节省通信量\"><a href=\"#7-持久连接节省通信量\" class=\"headerlink\" title=\"7. 持久连接节省通信量\"></a>7. 持久连接节省通信量</h2><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113558809.png\" alt=\"初始版本\"></p>\n<p>HTTP协议的初始版本中，每次HTTP通信都需要断开TCP连接。这在传输小容量文本时问题不大，但随着HTTP的普及，文档中包含大量图片的情况增多，导致每次请求都会造成无谓的TCP连接建立和断开，增加了通信量的开销。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113810021.png\" alt=\"image-20250102113810021\"></p>\n<h3 id=\"7-1-持久连接\"><a href=\"#7-1-持久连接\" class=\"headerlink\" title=\"7.1 持久连接\"></a>7.1 持久连接</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113835652.png\" alt=\"image-20250102113835652\"></p>\n<p>为了解决上述TCP连接的问题，HTTP&#x2F;1.1和一部分HTTP&#x2F;1.0引入了持久连接（HTTP Persistent Connections，也称为HTTP keep-alive或HTTP connection reuse）的方法。持久连接的特点是，只要任意一端没有明确提出断开连接，则保持TCP连接状态。</p>\n<p><strong>优点</strong>：</p>\n<ul>\n<li>减少了TCP连接的重复建立和断开所造成的额外开销。</li>\n<li>减轻了服务器端的负载。</li>\n<li>减少开销的那部分时间，使HTTP请求和响应能够更早地结束，从而提高了Web页面的显示速度。</li>\n</ul>\n<p>在HTTP&#x2F;1.1中，所有的连接默认都是持久连接，但在HTTP&#x2F;1.0内并未标准化。虽然有一部分服务器通过非标准的手段实现了持久连接，但服务器端不一定能够支持持久连接。毫无疑问，除了服务器端，客户端也需要支持持久连接。</p>\n<h3 id=\"7-2-管线化\"><a href=\"#7-2-管线化\" class=\"headerlink\" title=\"7.2 管线化\"></a>7.2 管线化</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113951113.png\" alt=\"image-20250102113951113\"></p>\n<p>持久连接使得多数请求以管线化（pipelining）方式发送成为可能。以前发送请求后需等待并收到响应，才能发送下一个请求。管线化技术出现后，不用等待响应亦可直接发送下一个请求。</p>\n<p><strong>优点</strong>：</p>\n<ul>\n<li>能够同时并行发送多个请求，而不需要一个接一个地等待响应。</li>\n<li>当请求一个包含多张图片的HTML Web页面时，与挨个连接相比，用持久连接可以让请求更快结束。而管线化技术则比持久连接还要快。请求数越多，时间差就越明显。</li>\n</ul>\n<p>通过持久连接和管线化技术，HTTP协议大大提高了通信效率，减少了不必要的开销，提升了用户体验。</p>\n<h2 id=\"8-使用-Cookie的状态管理\"><a href=\"#8-使用-Cookie的状态管理\" class=\"headerlink\" title=\"8. 使用 Cookie的状态管理\"></a>8. 使用 Cookie的状态管理</h2><p>HTTP协议是一种无状态协议，这意味着它不会保存请求和响应之间的通信状态。这种设计简化了协议，使其能够高效地处理大量事务，但也带来了一些挑战，特别是在需要保持用户状态的情况下。例如，用户在登录后访问网站的不同页面时，仍然需要保持登录状态。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102114136299.png\" alt=\"没有Cookie\"></p>\n<h4 id=\"8-1-无状态协议的缺点\"><a href=\"#8-1-无状态协议的缺点\" class=\"headerlink\" title=\"8.1 无状态协议的缺点\"></a>8.1 无状态协议的缺点</h4><ul>\n<li><strong>状态管理困难</strong>：由于HTTP不保存状态，服务器无法识别同一用户的多次请求，导致每次请求都需要重新认证。</li>\n<li><strong>用户体验不佳</strong>：用户每次访问新页面时可能需要重新登录，影响用户体验。</li>\n</ul>\n<h4 id=\"8-2-Cookie技术的引入\"><a href=\"#8-2-Cookie技术的引入\" class=\"headerlink\" title=\"8.2 Cookie技术的引入\"></a>8.2 Cookie技术的引入</h4><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102114244688.png\" alt=\"没有Cookie\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102114256778.png\" alt=\"有了Cookie\"></p>\n<p>为了解决无状态协议带来的问题，引入了Cookie技术。Cookie通过在请求和响应报文中写入Cookie信息来控制客户端的状态。</p>\n<h4 id=\"8-3-Cookie的工作原理\"><a href=\"#8-3-Cookie的工作原理\" class=\"headerlink\" title=\"8.3 Cookie的工作原理\"></a>8.3 Cookie的工作原理</h4><ol>\n<li><p><strong>服务器生成Cookie</strong>：服务器在响应报文中添加一个<code>Set-Cookie</code>首部字段，通知客户端保存Cookie。</p>\n<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-meta\">HTTP/1.1</span> <span class=\"hljs-number\">200</span> OK<br><span class=\"hljs-attribute\">Set-Cookie</span><span class=\"hljs-punctuation\">: </span>session_id=1234567890<br></code></pre></td></tr></table></figure>\n</li>\n<li><p><strong>客户端保存Cookie</strong>：客户端在收到响应后，会自动保存Cookie信息。</p>\n</li>\n<li><p><strong>客户端发送Cookie</strong>：下次客户端向同一服务器发送请求时，会自动在请求报文中加入Cookie值。</p>\n<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-keyword\">GET</span> <span class=\"hljs-string\">/page</span> <span class=\"hljs-meta\">HTTP/1.1</span><br><span class=\"hljs-attribute\">Host</span><span class=\"hljs-punctuation\">: </span>example.com<br><span class=\"hljs-attribute\">Cookie</span><span class=\"hljs-punctuation\">: </span>session_id=1234567890<br></code></pre></td></tr></table></figure>\n</li>\n<li><p><strong>服务器读取Cookie</strong>：服务器端发现客户端发送的Cookie后，会检查并对比服务器上的记录，从而识别出请求的用户。</p>\n</li>\n</ol>\n<h4 id=\"8-4-Cookie的应用场景\"><a href=\"#8-4-Cookie的应用场景\" class=\"headerlink\" title=\"8.4 Cookie的应用场景\"></a>8.4 Cookie的应用场景</h4><ul>\n<li><strong>用户认证</strong>：通过Cookie保存用户的登录状态，避免每次请求都需要重新登录。</li>\n<li><strong>个性化设置</strong>：保存用户的偏好设置，如主题、语言等。</li>\n<li><strong>购物车</strong>：保存用户的购物车内容，方便用户继续购物。</li>\n</ul>\n<h4 id=\"8-5-Cookie的限制\"><a href=\"#8-5-Cookie的限制\" class=\"headerlink\" title=\"8.5 Cookie的限制\"></a>8.5 Cookie的限制</h4><ul>\n<li><strong>安全性</strong>：Cookie可以被篡改，因此敏感信息不应存储在Cookie中。</li>\n<li><strong>隐私</strong>：Cookie可以追踪用户的浏览行为，可能引发隐私问题。</li>\n<li><strong>大小限制</strong>：每个域名下的Cookie数量和总大小有限制，通常每个Cookie不超过4KB。</li>\n</ul>\n<p>通过Cookie技术，HTTP协议能够在保持其简单高效的同时，实现状态管理功能，提升用户体验。</p>\n<p>参考：《图解HTTP》第一章</p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n","excerpt":"","more":"<h2 id=\"简单的-HTTP协议\"><a href=\"#简单的-HTTP协议\" class=\"headerlink\" title=\"简单的 HTTP协议\"></a>简单的 HTTP协议</h2><h2 id=\"1-HTTP协议用于客户端和服务器端之间的通信\"><a href=\"#1-HTTP协议用于客户端和服务器端之间的通信\" class=\"headerlink\" title=\"1. HTTP协议用于客户端和服务器端之间的通信\"></a>1. HTTP协议用于客户端和服务器端之间的通信</h2><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104311290.png\" alt=\"image-20250102104311290\"></p>\n<ul>\n<li><strong>定义</strong>：HTTP协议用于客户端和服务器之间的通信。</li>\n<li><strong>角色</strong>：请求访问资源的一端称为客户端，提供资源响应的一端称为服务器端。</li>\n<li><strong>通信线路</strong>：在一条通信线路上，必定有一端是客户端，另一端是服务器端。</li>\n<li><strong>角色互换</strong>：在某些情况下，两台计算机可能会互换客户端和服务器端的角色，但在一条通信路线上，角色是确定的。</li>\n</ul>\n<h2 id=\"2-通过请求和响应的交换达成通信\"><a href=\"#2-通过请求和响应的交换达成通信\" class=\"headerlink\" title=\"2. 通过请求和响应的交换达成通信\"></a>2. 通过请求和响应的交换达成通信</h2><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104434929.png\" alt=\"请求和响应\"></p>\n<p><strong>请求和响应</strong>：HTTP协议规定请求从客户端发出，服务器端响应该请求并返回。</p>\n<p><strong>请求报文</strong>：由请求方法、请求URI、协议版本、可选的请求首部字段和内容实体构成。</p>\n<ul>\n<li><strong>示例</strong>：<code>GET /index.htm HTTP/1.1 Host: hackr.jp</code></li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104508513.png\" alt=\"请求报文\"></p>\n<p><strong>响应报文</strong>：由协议版本、状态码、原因短语、可选的响应首部字段以及实体主体构成。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104617041.png\" alt=\"image-20250102104617041\"></p>\n<ul>\n<li><p><strong>示例</strong>：</p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">HTTP</span>/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">200</span> OK<br><span class=\"hljs-attribute\">Date</span>: Tue, <span class=\"hljs-number\">10</span> Jul <span class=\"hljs-number\">2012</span> <span class=\"hljs-number\">06</span>:<span class=\"hljs-number\">50</span>:<span class=\"hljs-number\">15</span> GMT<br><span class=\"hljs-attribute\">Content</span>-Length: <span class=\"hljs-number\">362</span><br><span class=\"hljs-attribute\">Content</span>-Type: text/html<br></code></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"3-HTTP是不保存状态的协议\"><a href=\"#3-HTTP是不保存状态的协议\" class=\"headerlink\" title=\"3. HTTP是不保存状态的协议\"></a>3. HTTP是不保存状态的协议</h2><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104640175.png\" alt=\"无状态协议\"></p>\n<ul>\n<li><strong>无状态协议</strong>：HTTP协议自身不对请求和响应之间的通信状态进行保存。</li>\n<li><strong>优点</strong>：为了更快地处理大量事务，确保协议的可伸缩性。</li>\n<li><strong>缺点</strong>：随着Web的发展，无状态导致业务处理变得棘手。</li>\n<li><strong>解决方案</strong>：引入Cookie技术来管理状态。</li>\n</ul>\n<h2 id=\"4-请求URI定位资源\"><a href=\"#4-请求URI定位资源\" class=\"headerlink\" title=\"4. 请求URI定位资源\"></a>4. 请求URI定位资源</h2><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102104835594.png\" alt=\"URI定位资源\"></p>\n<ul>\n<li><strong>URI功能</strong>：HTTP协议使用URI定位互联网上的资源。</li>\n<li><strong>请求URI</strong>：客户端请求访问资源时，URI需要包含在请求报文中。<ul>\n<li><strong>完整URI</strong>：<code>GET http://hackr.jp/index.htm HTTP/1.1</code></li>\n<li><strong>Host字段</strong>：<code>GET /index.htm HTTP/1.1 Host: hackr.jp</code></li>\n<li><strong>通配符</strong>：<code>OPTIONS * HTTP/1.1</code></li>\n</ul>\n</li>\n</ul>\n<h2 id=\"5-告知服务器意图的-HTTP方法\"><a href=\"#5-告知服务器意图的-HTTP方法\" class=\"headerlink\" title=\"5. 告知服务器意图的 HTTP方法\"></a>5. 告知服务器意图的 HTTP方法</h2><h3 id=\"5-1-GET-获取资源\"><a href=\"#5-1-GET-获取资源\" class=\"headerlink\" title=\"5.1 GET: 获取资源\"></a>5.1 GET: 获取资源</h3><ul>\n<li><strong>用途</strong>：用于请求访问已被URI识别的资源。</li>\n<li><strong>特点</strong>：请求的资源会被服务器解析后返回响应内容。如果是文本资源，则原样返回；如果是程序（如CGI），则返回执行后的输出结果。</li>\n<li><strong>示例请求</strong>：<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-keyword\">GET</span> <span class=\"hljs-string\">/index.html</span> <span class=\"hljs-meta\">HTTP/1.1</span><br><span class=\"hljs-attribute\">Host</span><span class=\"hljs-punctuation\">: </span>www.example.com<br></code></pre></td></tr></table></figure></li>\n<li><strong>示例响应</strong>：<figure class=\"highlight xquery\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xquery\">HTTP/<span class=\"hljs-number\">1.1</span> <span class=\"hljs-number\">200</span> OK<br>Content-Type: <span class=\"hljs-type\">text</span>/html<br><span class=\"language-xml\"><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">html</span>&gt;</span>...<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">html</span>&gt;</span></span><br></code></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"5-2-POST-传输实体主体\"><a href=\"#5-2-POST-传输实体主体\" class=\"headerlink\" title=\"5.2 POST: 传输实体主体\"></a>5.2 POST: 传输实体主体</h3><ul>\n<li><strong>用途</strong>：用于传输实体的主体，通常用于提交表单数据或其他数据。</li>\n<li><strong>特点</strong>：虽然GET方法也可以传输数据，但POST方法更适合传输大量数据或敏感信息，因为它不会将数据暴露在URL中。</li>\n<li><strong>示例请求</strong>：<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">POST</span> /submit.cgi HTTP/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span><br><span class=\"hljs-attribute\">Host</span>: www.example.com<br><span class=\"hljs-attribute\">Content</span>-Length: <span class=\"hljs-number\">1560</span><br><span class=\"hljs-section\">&lt;form data&gt;</span><br></code></pre></td></tr></table></figure></li>\n<li><strong>示例响应</strong>：<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">HTTP</span>/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">200</span> OK<br><span class=\"hljs-attribute\">Content</span>-Type: text/html<br><span class=\"hljs-section\">&lt;result of form submission&gt;</span><br></code></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"5-3-PUT-传输文件\"><a href=\"#5-3-PUT-传输文件\" class=\"headerlink\" title=\"5.3 PUT: 传输文件\"></a>5.3 PUT: 传输文件</h3><ul>\n<li><strong>用途</strong>：用于传输文件，类似于FTP协议的文件上传。</li>\n<li><strong>特点</strong>：请求报文的主体中包含文件内容，服务器将其保存到请求URI指定的位置。由于PUT方法不带验证机制，存在安全性问题，一般Web网站不使用该方法。</li>\n<li><strong>示例请求</strong>：<figure class=\"highlight stylus\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs stylus\">PUT /example<span class=\"hljs-selector-class\">.html</span> HTTP/<span class=\"hljs-number\">1.1</span><br>Host: www<span class=\"hljs-selector-class\">.example</span><span class=\"hljs-selector-class\">.com</span><br>Content-Type: text/<span class=\"hljs-selector-tag\">html</span><br>Content-Length: <span class=\"hljs-number\">1560</span><br>&lt;file <span class=\"hljs-attribute\">content</span>&gt;<br></code></pre></td></tr></table></figure></li>\n<li><strong>示例响应</strong>：<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">HTTP</span>/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">204</span> No Content<br></code></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"5-4-HEAD-获得报文首部\"><a href=\"#5-4-HEAD-获得报文首部\" class=\"headerlink\" title=\"5.4 HEAD: 获得报文首部\"></a>5.4 HEAD: 获得报文首部</h3><ul>\n<li><strong>用途</strong>：类似于GET方法，但不返回报文主体部分，仅用于确认URI的有效性及资源更新的日期时间等。</li>\n<li><strong>特点</strong>：常用于检查资源是否存在或获取资源的元数据。</li>\n<li><strong>示例请求</strong>：<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-keyword\">HEAD</span> <span class=\"hljs-string\">/index.html</span> <span class=\"hljs-meta\">HTTP/1.1</span><br><span class=\"hljs-attribute\">Host</span><span class=\"hljs-punctuation\">: </span>www.example.com<br></code></pre></td></tr></table></figure></li>\n<li><strong>示例响应</strong>：<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">HTTP</span>/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">200</span> OK<br><span class=\"hljs-attribute\">Date</span>: Mon, <span class=\"hljs-number\">27</span> Jul <span class=\"hljs-number\">2009</span> <span class=\"hljs-number\">12</span>:<span class=\"hljs-number\">28</span>:<span class=\"hljs-number\">53</span> GMT<br><span class=\"hljs-attribute\">Server</span>: Apache/<span class=\"hljs-number\">2</span>.<span class=\"hljs-number\">2</span>.<span class=\"hljs-number\">14</span> (Win32)<br><span class=\"hljs-attribute\">Last</span>-Modified: Wed, <span class=\"hljs-number\">22</span> Jul <span class=\"hljs-number\">2009</span> <span class=\"hljs-number\">19</span>:<span class=\"hljs-number\">15</span>:<span class=\"hljs-number\">56</span> GMT<br><span class=\"hljs-attribute\">Content</span>-Length: <span class=\"hljs-number\">88</span><br><span class=\"hljs-attribute\">Content</span>-Type: text/html<br></code></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"5-5-DELETE-删除文件\"><a href=\"#5-5-DELETE-删除文件\" class=\"headerlink\" title=\"5.5 DELETE: 删除文件\"></a>5.5 DELETE: 删除文件</h3><ul>\n<li><strong>用途</strong>：用于删除文件，是与PUT相反的操作。</li>\n<li><strong>特点</strong>：请求URI指定的资源将被删除。由于DELETE方法不带验证机制，存在安全性问题，一般Web网站不使用该方法。</li>\n<li><strong>示例请求</strong>：<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-keyword\">DELETE</span> <span class=\"hljs-string\">/example.html</span> <span class=\"hljs-meta\">HTTP/1.1</span><br><span class=\"hljs-attribute\">Host</span><span class=\"hljs-punctuation\">: </span>www.example.com<br></code></pre></td></tr></table></figure></li>\n<li><strong>示例响应</strong>：<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">HTTP</span>/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">204</span> No Content<br></code></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"5-6-OPTIONS-询问支持的方法\"><a href=\"#5-6-OPTIONS-询问支持的方法\" class=\"headerlink\" title=\"5.6 OPTIONS: 询问支持的方法\"></a>5.6 OPTIONS: 询问支持的方法</h3><ul>\n<li><strong>用途</strong>：用于查询针对请求URI指定的资源支持的方法。</li>\n<li><strong>特点</strong>：返回服务器支持的各种HTTP方法。</li>\n<li><strong>示例请求</strong>：<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-keyword\">OPTIONS</span> <span class=\"hljs-string\">*</span> <span class=\"hljs-meta\">HTTP/1.1</span><br><span class=\"hljs-attribute\">Host</span><span class=\"hljs-punctuation\">: </span>www.example.com<br></code></pre></td></tr></table></figure></li>\n<li><strong>示例响应</strong>：<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-meta\">HTTP/1.1</span> <span class=\"hljs-number\">200</span> OK<br><span class=\"hljs-attribute\">Allow</span><span class=\"hljs-punctuation\">: </span>GET, POST, HEAD, OPTIONS<br></code></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"5-7-TRACE-追踪路径\"><a href=\"#5-7-TRACE-追踪路径\" class=\"headerlink\" title=\"5.7 TRACE: 追踪路径\"></a>5.7 TRACE: 追踪路径</h3><ul>\n<li><strong>用途</strong>：用于让Web服务器端将之前的请求通信环回给客户端。</li>\n<li><strong>特点</strong>：通过Max-Forwards首部字段的值递减，最终返回状态码200 OK的响应，包含请求内容。常用于调试和诊断请求路径。</li>\n<li><strong>示例请求</strong>：<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-keyword\">TRACE</span> <span class=\"hljs-string\">/</span> <span class=\"hljs-meta\">HTTP/1.1</span><br><span class=\"hljs-attribute\">Host</span><span class=\"hljs-punctuation\">: </span>www.example.com<br><span class=\"hljs-attribute\">Max-Forwards</span><span class=\"hljs-punctuation\">: </span>2<br></code></pre></td></tr></table></figure></li>\n<li><strong>示例响应</strong>：<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">HTTP</span>/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">200</span> OK<br><span class=\"hljs-attribute\">Content</span>-Type: message/http<br><span class=\"hljs-attribute\">Content</span>-Length: <span class=\"hljs-number\">1024</span><br><span class=\"hljs-attribute\">TRACE</span> / HTTP/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span> Host: www.example.com Max-Forwards: <span class=\"hljs-number\">2</span><br></code></pre></td></tr></table></figure></li>\n</ul>\n<h3 id=\"5-8-CONNECT-要求用隧道协议连接代理\"><a href=\"#5-8-CONNECT-要求用隧道协议连接代理\" class=\"headerlink\" title=\"5.8 CONNECT: 要求用隧道协议连接代理\"></a>5.8 CONNECT: 要求用隧道协议连接代理</h3><ul>\n<li><strong>用途</strong>：用于在与代理服务器通信时建立隧道，实现用隧道协议进行TCP通信，常用于SSL&#x2F;TLS加密通信。</li>\n<li><strong>特点</strong>：主要用于HTTPS请求。</li>\n<li><strong>示例请求</strong>：<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-keyword\">CONNECT</span> <span class=\"hljs-string\">www.example.com:443</span> <span class=\"hljs-meta\">HTTP/1.1</span><br><span class=\"hljs-attribute\">Host</span><span class=\"hljs-punctuation\">: </span>www.example.com<br></code></pre></td></tr></table></figure></li>\n<li><strong>示例响应</strong>：<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">HTTP</span>/<span class=\"hljs-number\">1</span>.<span class=\"hljs-number\">1</span> <span class=\"hljs-number\">200</span> Connection Established<br></code></pre></td></tr></table></figure></li>\n</ul>\n<h2 id=\"6-使用方法下达命令\"><a href=\"#6-使用方法下达命令\" class=\"headerlink\" title=\"6. 使用方法下达命令\"></a>6. 使用方法下达命令</h2><ul>\n<li><strong>方法</strong>：向请求URI指定的资源发送请求报文时，采用称为方法的命令。</li>\n<li><strong>支持的方法</strong>：GET、POST、HEAD等。</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113459101.png\" alt=\"image-20250102113459101\"></p>\n<h2 id=\"7-持久连接节省通信量\"><a href=\"#7-持久连接节省通信量\" class=\"headerlink\" title=\"7. 持久连接节省通信量\"></a>7. 持久连接节省通信量</h2><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113558809.png\" alt=\"初始版本\"></p>\n<p>HTTP协议的初始版本中，每次HTTP通信都需要断开TCP连接。这在传输小容量文本时问题不大，但随着HTTP的普及，文档中包含大量图片的情况增多，导致每次请求都会造成无谓的TCP连接建立和断开，增加了通信量的开销。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113810021.png\" alt=\"image-20250102113810021\"></p>\n<h3 id=\"7-1-持久连接\"><a href=\"#7-1-持久连接\" class=\"headerlink\" title=\"7.1 持久连接\"></a>7.1 持久连接</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113835652.png\" alt=\"image-20250102113835652\"></p>\n<p>为了解决上述TCP连接的问题，HTTP&#x2F;1.1和一部分HTTP&#x2F;1.0引入了持久连接（HTTP Persistent Connections，也称为HTTP keep-alive或HTTP connection reuse）的方法。持久连接的特点是，只要任意一端没有明确提出断开连接，则保持TCP连接状态。</p>\n<p><strong>优点</strong>：</p>\n<ul>\n<li>减少了TCP连接的重复建立和断开所造成的额外开销。</li>\n<li>减轻了服务器端的负载。</li>\n<li>减少开销的那部分时间，使HTTP请求和响应能够更早地结束，从而提高了Web页面的显示速度。</li>\n</ul>\n<p>在HTTP&#x2F;1.1中，所有的连接默认都是持久连接，但在HTTP&#x2F;1.0内并未标准化。虽然有一部分服务器通过非标准的手段实现了持久连接，但服务器端不一定能够支持持久连接。毫无疑问，除了服务器端，客户端也需要支持持久连接。</p>\n<h3 id=\"7-2-管线化\"><a href=\"#7-2-管线化\" class=\"headerlink\" title=\"7.2 管线化\"></a>7.2 管线化</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102113951113.png\" alt=\"image-20250102113951113\"></p>\n<p>持久连接使得多数请求以管线化（pipelining）方式发送成为可能。以前发送请求后需等待并收到响应，才能发送下一个请求。管线化技术出现后，不用等待响应亦可直接发送下一个请求。</p>\n<p><strong>优点</strong>：</p>\n<ul>\n<li>能够同时并行发送多个请求，而不需要一个接一个地等待响应。</li>\n<li>当请求一个包含多张图片的HTML Web页面时，与挨个连接相比，用持久连接可以让请求更快结束。而管线化技术则比持久连接还要快。请求数越多，时间差就越明显。</li>\n</ul>\n<p>通过持久连接和管线化技术，HTTP协议大大提高了通信效率，减少了不必要的开销，提升了用户体验。</p>\n<h2 id=\"8-使用-Cookie的状态管理\"><a href=\"#8-使用-Cookie的状态管理\" class=\"headerlink\" title=\"8. 使用 Cookie的状态管理\"></a>8. 使用 Cookie的状态管理</h2><p>HTTP协议是一种无状态协议，这意味着它不会保存请求和响应之间的通信状态。这种设计简化了协议，使其能够高效地处理大量事务，但也带来了一些挑战，特别是在需要保持用户状态的情况下。例如，用户在登录后访问网站的不同页面时，仍然需要保持登录状态。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102114136299.png\" alt=\"没有Cookie\"></p>\n<h4 id=\"8-1-无状态协议的缺点\"><a href=\"#8-1-无状态协议的缺点\" class=\"headerlink\" title=\"8.1 无状态协议的缺点\"></a>8.1 无状态协议的缺点</h4><ul>\n<li><strong>状态管理困难</strong>：由于HTTP不保存状态，服务器无法识别同一用户的多次请求，导致每次请求都需要重新认证。</li>\n<li><strong>用户体验不佳</strong>：用户每次访问新页面时可能需要重新登录，影响用户体验。</li>\n</ul>\n<h4 id=\"8-2-Cookie技术的引入\"><a href=\"#8-2-Cookie技术的引入\" class=\"headerlink\" title=\"8.2 Cookie技术的引入\"></a>8.2 Cookie技术的引入</h4><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102114244688.png\" alt=\"没有Cookie\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20250102114256778.png\" alt=\"有了Cookie\"></p>\n<p>为了解决无状态协议带来的问题，引入了Cookie技术。Cookie通过在请求和响应报文中写入Cookie信息来控制客户端的状态。</p>\n<h4 id=\"8-3-Cookie的工作原理\"><a href=\"#8-3-Cookie的工作原理\" class=\"headerlink\" title=\"8.3 Cookie的工作原理\"></a>8.3 Cookie的工作原理</h4><ol>\n<li><p><strong>服务器生成Cookie</strong>：服务器在响应报文中添加一个<code>Set-Cookie</code>首部字段，通知客户端保存Cookie。</p>\n<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-meta\">HTTP/1.1</span> <span class=\"hljs-number\">200</span> OK<br><span class=\"hljs-attribute\">Set-Cookie</span><span class=\"hljs-punctuation\">: </span>session_id=1234567890<br></code></pre></td></tr></table></figure>\n</li>\n<li><p><strong>客户端保存Cookie</strong>：客户端在收到响应后，会自动保存Cookie信息。</p>\n</li>\n<li><p><strong>客户端发送Cookie</strong>：下次客户端向同一服务器发送请求时，会自动在请求报文中加入Cookie值。</p>\n<figure class=\"highlight http\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs http\"><span class=\"hljs-keyword\">GET</span> <span class=\"hljs-string\">/page</span> <span class=\"hljs-meta\">HTTP/1.1</span><br><span class=\"hljs-attribute\">Host</span><span class=\"hljs-punctuation\">: </span>example.com<br><span class=\"hljs-attribute\">Cookie</span><span class=\"hljs-punctuation\">: </span>session_id=1234567890<br></code></pre></td></tr></table></figure>\n</li>\n<li><p><strong>服务器读取Cookie</strong>：服务器端发现客户端发送的Cookie后，会检查并对比服务器上的记录，从而识别出请求的用户。</p>\n</li>\n</ol>\n<h4 id=\"8-4-Cookie的应用场景\"><a href=\"#8-4-Cookie的应用场景\" class=\"headerlink\" title=\"8.4 Cookie的应用场景\"></a>8.4 Cookie的应用场景</h4><ul>\n<li><strong>用户认证</strong>：通过Cookie保存用户的登录状态，避免每次请求都需要重新登录。</li>\n<li><strong>个性化设置</strong>：保存用户的偏好设置，如主题、语言等。</li>\n<li><strong>购物车</strong>：保存用户的购物车内容，方便用户继续购物。</li>\n</ul>\n<h4 id=\"8-5-Cookie的限制\"><a href=\"#8-5-Cookie的限制\" class=\"headerlink\" title=\"8.5 Cookie的限制\"></a>8.5 Cookie的限制</h4><ul>\n<li><strong>安全性</strong>：Cookie可以被篡改，因此敏感信息不应存储在Cookie中。</li>\n<li><strong>隐私</strong>：Cookie可以追踪用户的浏览行为，可能引发隐私问题。</li>\n<li><strong>大小限制</strong>：每个域名下的Cookie数量和总大小有限制，通常每个Cookie不超过4KB。</li>\n</ul>\n<p>通过Cookie技术，HTTP协议能够在保持其简单高效的同时，实现状态管理功能，提升用户体验。</p>\n<p>参考：《图解HTTP》第一章</p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n"},{"title":"HTTP基础02：了解Web及网络基础","date":"2024-12-31T04:00:00.000Z","_content":"\n\n\n## 了解Web及网络基础\n\n### 1. 使用HTTP协议访问Web\n- **URL输入与页面显示**：当用户在浏览器地址栏中输入URL时，浏览器会向指定的Web服务器发送请求，获取相应的资源（如HTML文件、图片等），并将这些资源渲染成用户可见的Web页面。\n\n  ![image-20241231135527092](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231135527092.png)\n\n- **客户端与服务器**：浏览器作为客户端，负责向服务器发送请求并接收响应。服务器则存储资源并响应客户端的请求。这种请求-响应模式是Web通信的基础。\n\n![image-20241231135627239](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231135627239.png)\n\n- **HTTP协议**：HTTP（超文本传输协议）是Web通信的核心协议，定义了客户端和服务器之间的通信规则。它基于请求-响应模型，客户端发送请求，服务器返回响应。HTTP协议是无状态的，意味着每次请求都是独立的，服务器不会保留之前的请求信息。\n\n### 2. HTTP的诞生\n- **背景**：1989年，Tim Berners-Lee在CERN提出了WWW（万维网）的概念，旨在通过互联网实现全球知识共享。他提出了超文本（HyperText）的概念，即文档之间可以通过链接相互关联，形成一个巨大的信息网络。\n- **WWW构建技术**：WWW的构建依赖于三大核心技术：\n  - **HTML**（超文本标记语言）：用于创建和格式化Web页面。\n  - **HTTP**（超文本传输协议）：用于在客户端和服务器之间传输数据。\n  - **URL**（统一资源定位符）：用于定位互联网上的资源。\n- **Web的成长**：1990年，CERN成功研发了世界上第一台Web服务器和Web浏览器。1993年，NCSA Mosaic浏览器问世，它支持内联图像显示，迅速在全球流行。1994年，Netscape Navigator发布，成为当时最流行的浏览器。1995年，微软发布了Internet Explorer，开启了浏览器大战。\n- **HTTP版本**：\n  - **HTTP/0.9**：1990年发布，功能极为简单，仅支持GET请求。\n  - **HTTP/1.0**：1996年发布，引入了更多的请求方法（如POST、HEAD）和头部字段，支持多种内容类型。\n  - **HTTP/1.1**：1997年发布，是目前最广泛使用的版本，支持持久连接、分块传输编码等特性。\n  - **HTTP/2.0**：正在制定中，旨在提高性能，支持多路复用、头部压缩等新特性。\n\n### 3. 网络基础TCP/IP\n- **TCP/IP协议族**：TCP/IP是互联网的基础协议族，定义了计算机如何在网络上进行通信。HTTP协议是TCP/IP协议族的一部分，依赖于TCP/IP进行数据传输。\n\n![image-20241231135723889](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231135723889.png)\n\n- 为什么需要 TCP/IP？\n  - **背景**：互联网是由全球数以亿计的计算机和网络设备组成的复杂网络。为了让这些设备能够相互通信，必须有一套统一的规则和协议。TCP/IP 协议族就是为此而设计的，它定义了计算机和网络设备之间如何通信、如何传输数据、如何寻址等一系列规则。\n  - **跨平台通信**：不同的计算机可能使用不同的硬件、操作系统和网络技术。TCP/IP 协议族提供了一种标准化的通信方式，使得这些异构系统能够无缝地进行数据交换。\n  - **模块化设计**：TCP/IP 协议族采用分层设计，每一层负责特定的功能。这种模块化的设计使得协议族易于扩展和维护，某一层的改动不会影响其他层的功能。\n\n- 分层管理的优点\n\n  - **简化设计**：分层设计将复杂的网络通信问题分解为多个相对简单的子问题，每一层只需关注自己的任务，无需了解其他层的细节。\n\n  - **易于维护和扩展**：如果某一层的协议需要更新或替换，只需修改该层的实现，而不会影响其他层。例如，传输层的 TCP 协议可以独立于应用层的 HTTP 协议进行优化。\n\n  - **灵活性**：分层设计允许不同的协议在同一层中并存。例如，传输层可以使用 TCP 或 UDP，具体选择取决于应用的需求。\n\n  - **标准化接口**：每一层之间通过标准化的接口进行通信，确保了不同厂商的设备能够互操作。\n\n- **分层管理**：TCP/IP协议族分为四层：\n  - **应用层**：提供应用程序之间的通信服务，如HTTP、FTP、DNS等。\n  - **传输层**：负责端到端的数据传输，主要协议有TCP和UDP。\n  - **网络层**：处理在网络上流动的数据包。数据包是网络传输的最小数 据单位。该层规定了通过怎样的路径（所谓的传输路线）到达对方计 算机，并把数据包传送给对方。\n  - **链路层**：硬件部分。包括控制操作系统、硬件的设备驱 动、NIC（Network Interface Card，网络适配器，即网卡），及光纤等 物理可见部分（还包括连接器等一切传输媒介）。硬件上的范畴均在 链路层的作用范围之内。\n- **通信传输流**\n  - 用 HTTP 举例来说明，首先作为发送端的客户端在应用层 （HTTP 协议）发出一个想看某个 Web 页面的 HTTP 请求。 \n  - 接着，为了传输方便，在传输层（TCP 协议）把从应用层处收到的数 据（HTTP 请求报文）进行分割，并在各个报文上打上标记序号及端 口号后转发给网络层。 \n  - 在网络层（IP 协议），增加作为通信目的地的 MAC 地址后转发给链 路层。这样一来，发往网络的通信请求就准备齐全了。 \n  - 接收端的服务器在链路层接收到数据，按序往上层发送，一直到应用 层。\n  - 当传输到应用层，才能算真正接收到由客户端发送过来的 HTTP 请求。\n\n![image-20241231140702101](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231140702101.png)\n\n\n\n![image-20241231140906221](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231140906221.png)\n\n- 发送端在层与层之间传输数据时，每经过一层时必定会被打上一个该 层所属的首部信息。反之，接收端在层与层传输数据时，每经过一层 时会把对应的首部消去。\n\n-  这种把数据信息包装起来的做法称为封装（encapsulate）。\n\n\n\n### 4. 与HTTP关系密切的协议：IP、TCP和DNS\n\n- **IP协议**：IP（网际协议）位于网络层，负责将数据包从源地址传输到目的地址。IP协议依赖于IP地址和MAC地址进行通信。IP地址是逻辑地址，可以变化，而MAC地址是物理地址，通常不变。IP协议使用ARP（地址解析协议）来根据IP地址查找对应的MAC地址。\n- **TCP协议**：TCP（传输控制协议）位于传输层，提供可靠的字节流服务。它将大数据分割成小的报文段进行传输，并通过三次握手确保数据的可靠传输。TCP还提供了流量控制、拥塞控制等机制，确保数据传输的稳定性。\n- **DNS服务**：DNS（域名系统）位于应用层，负责将域名解析为IP地址。用户通常使用域名访问网站，而不是直接使用IP地址，因为域名更易于记忆。DNS服务通过域名查找IP地址，或从IP地址反查域名。\n\n![数据包发送](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231141054269.png)\n\n#### 数据包发送的过程：\n\n1. **发送端准备发送数据包**：\n   - 发送端想要将数据包发送到IP地址为192.0.43.10的目的地。\n   - 发送端使用ARP（地址解析协议）来解析目标IP地址对应的MAC地址。\n\n2. **ARP解析过程**：\n   - 发送端通过ARP协议尝试解析目标IP地址192.0.43.10的MAC地址，但此时还未成功解析到具体的MAC地址。\n\n3. **先将数据包发送给路由器**：\n   - 由于ARP解析未完成，发送端先将数据包发送给一个中间路由器，该路由器的MAC地址为00-XX-C6-6B-XX-XX。\n\n4. **第一次转发**：\n   - 路由器接收到数据包后，进行第一次转发。路由器将数据包转发给下一个路由器，其MAC地址为00-XX-B5-A5-XX-XX。\n\n5. **第二次转发**：\n   - 第二个路由器接收到数据包后，进行第二次转发。此时，路由器已经知道目标IP地址192.0.43.10的具体MAC地址为00-XX-A6-6B-XX-XX。\n   - 路由器将数据包转发给最终的目标接收端。\n\n6. **数据包到达接收端**：\n   - 最终，数据包成功到达接收端，接收端的IP地址为192.0.43.10，MAC地址为00-XX-A6-6B-XX-XX。\n\n总结：\n- 数据包从发送端出发，通过多个路由器的转发，最终到达目标接收端。\n- 在这个过程中，ARP协议用于解析目标IP地址的MAC地址，确保数据包能够正确送达目的地。\n\n![三次握手](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231141211177.png)\n\n字节流服务：TCP 位于传输层，提供可靠的字节流服务。为了方便传输，将大 块数据分割成以报文段（segment）为单位的数据包进行管理。\n\n#### 三次握手\n\n- 发送端首先发送一个带 SYN 标志的数据包给对方。\n- 接收端收到后， 回传一个带有 SYN/ACK 标志的数据包以示传达确认信息。\n- 最后，发 送端再回传一个带 ACK 标志的数据包，代表“握手”结束。\n\n若在握手过程中某个阶段莫名中断，TCP 协议会再次以相同的顺序发 送相同的数据包。\n\n### 5. 负责域名解析的DNS服务\n\n![image-20241231141657984](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231141657984.png)\n\n- **DNS功能**：DNS的主要功能是将人类可读的域名转换为计算机可识别的IP地址。例如，当用户输入`www.example.com`时，DNS会将其解析为对应的IP地址，如`192.0.2.1`，以便浏览器能够与服务器建立连接。\n- **用户习惯**：用户通常使用域名访问网站，因为域名比IP地址更容易记忆。DNS服务使得用户无需记住复杂的IP地址，只需输入简单的域名即可访问资源。\n\n### 6. 各种协议与HTTP协议的关系\n\n![image-20241231141751459](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231141751459.png)\n\n- **HTTP通信过程**：当用户访问一个Web页面时，首先通过DNS解析域名获取IP地址，然后通过IP协议找到目标服务器，接着通过TCP协议建立可靠的连接，最后通过HTTP协议发送请求并接收响应。整个过程涉及多个协议的协同工作。\n- **协议协作**：DNS负责域名解析，IP协议负责寻址，TCP协议确保数据传输的可靠性，HTTP协议则负责生成请求和处理响应。这些协议共同构成了Web通信的基础。\n\n#### 1.7 URI和URL\n- **URI与URL**：URI（统一资源标识符）是用于标识互联网上资源的字符串，而URL（统一资源定位符）是URI的子集，表示资源的具体位置。URL是用户在浏览器中输入的地址，如`http://www.example.com`。\n- **URI格式**：URI的格式包括协议方案、登录信息、服务器地址、端口号、文件路径、查询字符串和片段标识符。例如，`http://user:password@www.example.com:80/path/to/resource?query=string#fragment`。\n- **RFC标准**：HTTP协议通常遵循RFC（Request for Comments）标准，RFC是互联网技术标准文档。虽然大多数应用程序遵循RFC标准，但某些应用程序可能会扩展或偏离标准，导致兼容性问题。\n\n### 7. 总结\n本章详细介绍了Web的基础技术，特别是HTTP协议的诞生、发展及其与TCP/IP协议族的关系。通过了解IP、TCP、DNS等协议，可以更好地理解HTTP在Web通信中的作用。URI和URL的概念及其格式也是Web开发中的重要基础知识。\n\n\n\n参考：《图解HTTP》第一章\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","source":"_posts/计算机基础/计算机网络/HTTP基础02：了解Web及网络基础.md","raw":"---\ntitle: 'HTTP基础02：了解Web及网络基础'\ncategories:\n  - [计算机基础,计算机网络]\ntags:\n  - 计算机网络\n  - 计算机基础\n  - HTTP\ndate: 2024-12-31 12:00:00\n---\n\n\n\n## 了解Web及网络基础\n\n### 1. 使用HTTP协议访问Web\n- **URL输入与页面显示**：当用户在浏览器地址栏中输入URL时，浏览器会向指定的Web服务器发送请求，获取相应的资源（如HTML文件、图片等），并将这些资源渲染成用户可见的Web页面。\n\n  ![image-20241231135527092](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231135527092.png)\n\n- **客户端与服务器**：浏览器作为客户端，负责向服务器发送请求并接收响应。服务器则存储资源并响应客户端的请求。这种请求-响应模式是Web通信的基础。\n\n![image-20241231135627239](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231135627239.png)\n\n- **HTTP协议**：HTTP（超文本传输协议）是Web通信的核心协议，定义了客户端和服务器之间的通信规则。它基于请求-响应模型，客户端发送请求，服务器返回响应。HTTP协议是无状态的，意味着每次请求都是独立的，服务器不会保留之前的请求信息。\n\n### 2. HTTP的诞生\n- **背景**：1989年，Tim Berners-Lee在CERN提出了WWW（万维网）的概念，旨在通过互联网实现全球知识共享。他提出了超文本（HyperText）的概念，即文档之间可以通过链接相互关联，形成一个巨大的信息网络。\n- **WWW构建技术**：WWW的构建依赖于三大核心技术：\n  - **HTML**（超文本标记语言）：用于创建和格式化Web页面。\n  - **HTTP**（超文本传输协议）：用于在客户端和服务器之间传输数据。\n  - **URL**（统一资源定位符）：用于定位互联网上的资源。\n- **Web的成长**：1990年，CERN成功研发了世界上第一台Web服务器和Web浏览器。1993年，NCSA Mosaic浏览器问世，它支持内联图像显示，迅速在全球流行。1994年，Netscape Navigator发布，成为当时最流行的浏览器。1995年，微软发布了Internet Explorer，开启了浏览器大战。\n- **HTTP版本**：\n  - **HTTP/0.9**：1990年发布，功能极为简单，仅支持GET请求。\n  - **HTTP/1.0**：1996年发布，引入了更多的请求方法（如POST、HEAD）和头部字段，支持多种内容类型。\n  - **HTTP/1.1**：1997年发布，是目前最广泛使用的版本，支持持久连接、分块传输编码等特性。\n  - **HTTP/2.0**：正在制定中，旨在提高性能，支持多路复用、头部压缩等新特性。\n\n### 3. 网络基础TCP/IP\n- **TCP/IP协议族**：TCP/IP是互联网的基础协议族，定义了计算机如何在网络上进行通信。HTTP协议是TCP/IP协议族的一部分，依赖于TCP/IP进行数据传输。\n\n![image-20241231135723889](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231135723889.png)\n\n- 为什么需要 TCP/IP？\n  - **背景**：互联网是由全球数以亿计的计算机和网络设备组成的复杂网络。为了让这些设备能够相互通信，必须有一套统一的规则和协议。TCP/IP 协议族就是为此而设计的，它定义了计算机和网络设备之间如何通信、如何传输数据、如何寻址等一系列规则。\n  - **跨平台通信**：不同的计算机可能使用不同的硬件、操作系统和网络技术。TCP/IP 协议族提供了一种标准化的通信方式，使得这些异构系统能够无缝地进行数据交换。\n  - **模块化设计**：TCP/IP 协议族采用分层设计，每一层负责特定的功能。这种模块化的设计使得协议族易于扩展和维护，某一层的改动不会影响其他层的功能。\n\n- 分层管理的优点\n\n  - **简化设计**：分层设计将复杂的网络通信问题分解为多个相对简单的子问题，每一层只需关注自己的任务，无需了解其他层的细节。\n\n  - **易于维护和扩展**：如果某一层的协议需要更新或替换，只需修改该层的实现，而不会影响其他层。例如，传输层的 TCP 协议可以独立于应用层的 HTTP 协议进行优化。\n\n  - **灵活性**：分层设计允许不同的协议在同一层中并存。例如，传输层可以使用 TCP 或 UDP，具体选择取决于应用的需求。\n\n  - **标准化接口**：每一层之间通过标准化的接口进行通信，确保了不同厂商的设备能够互操作。\n\n- **分层管理**：TCP/IP协议族分为四层：\n  - **应用层**：提供应用程序之间的通信服务，如HTTP、FTP、DNS等。\n  - **传输层**：负责端到端的数据传输，主要协议有TCP和UDP。\n  - **网络层**：处理在网络上流动的数据包。数据包是网络传输的最小数 据单位。该层规定了通过怎样的路径（所谓的传输路线）到达对方计 算机，并把数据包传送给对方。\n  - **链路层**：硬件部分。包括控制操作系统、硬件的设备驱 动、NIC（Network Interface Card，网络适配器，即网卡），及光纤等 物理可见部分（还包括连接器等一切传输媒介）。硬件上的范畴均在 链路层的作用范围之内。\n- **通信传输流**\n  - 用 HTTP 举例来说明，首先作为发送端的客户端在应用层 （HTTP 协议）发出一个想看某个 Web 页面的 HTTP 请求。 \n  - 接着，为了传输方便，在传输层（TCP 协议）把从应用层处收到的数 据（HTTP 请求报文）进行分割，并在各个报文上打上标记序号及端 口号后转发给网络层。 \n  - 在网络层（IP 协议），增加作为通信目的地的 MAC 地址后转发给链 路层。这样一来，发往网络的通信请求就准备齐全了。 \n  - 接收端的服务器在链路层接收到数据，按序往上层发送，一直到应用 层。\n  - 当传输到应用层，才能算真正接收到由客户端发送过来的 HTTP 请求。\n\n![image-20241231140702101](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231140702101.png)\n\n\n\n![image-20241231140906221](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231140906221.png)\n\n- 发送端在层与层之间传输数据时，每经过一层时必定会被打上一个该 层所属的首部信息。反之，接收端在层与层传输数据时，每经过一层 时会把对应的首部消去。\n\n-  这种把数据信息包装起来的做法称为封装（encapsulate）。\n\n\n\n### 4. 与HTTP关系密切的协议：IP、TCP和DNS\n\n- **IP协议**：IP（网际协议）位于网络层，负责将数据包从源地址传输到目的地址。IP协议依赖于IP地址和MAC地址进行通信。IP地址是逻辑地址，可以变化，而MAC地址是物理地址，通常不变。IP协议使用ARP（地址解析协议）来根据IP地址查找对应的MAC地址。\n- **TCP协议**：TCP（传输控制协议）位于传输层，提供可靠的字节流服务。它将大数据分割成小的报文段进行传输，并通过三次握手确保数据的可靠传输。TCP还提供了流量控制、拥塞控制等机制，确保数据传输的稳定性。\n- **DNS服务**：DNS（域名系统）位于应用层，负责将域名解析为IP地址。用户通常使用域名访问网站，而不是直接使用IP地址，因为域名更易于记忆。DNS服务通过域名查找IP地址，或从IP地址反查域名。\n\n![数据包发送](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231141054269.png)\n\n#### 数据包发送的过程：\n\n1. **发送端准备发送数据包**：\n   - 发送端想要将数据包发送到IP地址为192.0.43.10的目的地。\n   - 发送端使用ARP（地址解析协议）来解析目标IP地址对应的MAC地址。\n\n2. **ARP解析过程**：\n   - 发送端通过ARP协议尝试解析目标IP地址192.0.43.10的MAC地址，但此时还未成功解析到具体的MAC地址。\n\n3. **先将数据包发送给路由器**：\n   - 由于ARP解析未完成，发送端先将数据包发送给一个中间路由器，该路由器的MAC地址为00-XX-C6-6B-XX-XX。\n\n4. **第一次转发**：\n   - 路由器接收到数据包后，进行第一次转发。路由器将数据包转发给下一个路由器，其MAC地址为00-XX-B5-A5-XX-XX。\n\n5. **第二次转发**：\n   - 第二个路由器接收到数据包后，进行第二次转发。此时，路由器已经知道目标IP地址192.0.43.10的具体MAC地址为00-XX-A6-6B-XX-XX。\n   - 路由器将数据包转发给最终的目标接收端。\n\n6. **数据包到达接收端**：\n   - 最终，数据包成功到达接收端，接收端的IP地址为192.0.43.10，MAC地址为00-XX-A6-6B-XX-XX。\n\n总结：\n- 数据包从发送端出发，通过多个路由器的转发，最终到达目标接收端。\n- 在这个过程中，ARP协议用于解析目标IP地址的MAC地址，确保数据包能够正确送达目的地。\n\n![三次握手](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231141211177.png)\n\n字节流服务：TCP 位于传输层，提供可靠的字节流服务。为了方便传输，将大 块数据分割成以报文段（segment）为单位的数据包进行管理。\n\n#### 三次握手\n\n- 发送端首先发送一个带 SYN 标志的数据包给对方。\n- 接收端收到后， 回传一个带有 SYN/ACK 标志的数据包以示传达确认信息。\n- 最后，发 送端再回传一个带 ACK 标志的数据包，代表“握手”结束。\n\n若在握手过程中某个阶段莫名中断，TCP 协议会再次以相同的顺序发 送相同的数据包。\n\n### 5. 负责域名解析的DNS服务\n\n![image-20241231141657984](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231141657984.png)\n\n- **DNS功能**：DNS的主要功能是将人类可读的域名转换为计算机可识别的IP地址。例如，当用户输入`www.example.com`时，DNS会将其解析为对应的IP地址，如`192.0.2.1`，以便浏览器能够与服务器建立连接。\n- **用户习惯**：用户通常使用域名访问网站，因为域名比IP地址更容易记忆。DNS服务使得用户无需记住复杂的IP地址，只需输入简单的域名即可访问资源。\n\n### 6. 各种协议与HTTP协议的关系\n\n![image-20241231141751459](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231141751459.png)\n\n- **HTTP通信过程**：当用户访问一个Web页面时，首先通过DNS解析域名获取IP地址，然后通过IP协议找到目标服务器，接着通过TCP协议建立可靠的连接，最后通过HTTP协议发送请求并接收响应。整个过程涉及多个协议的协同工作。\n- **协议协作**：DNS负责域名解析，IP协议负责寻址，TCP协议确保数据传输的可靠性，HTTP协议则负责生成请求和处理响应。这些协议共同构成了Web通信的基础。\n\n#### 1.7 URI和URL\n- **URI与URL**：URI（统一资源标识符）是用于标识互联网上资源的字符串，而URL（统一资源定位符）是URI的子集，表示资源的具体位置。URL是用户在浏览器中输入的地址，如`http://www.example.com`。\n- **URI格式**：URI的格式包括协议方案、登录信息、服务器地址、端口号、文件路径、查询字符串和片段标识符。例如，`http://user:password@www.example.com:80/path/to/resource?query=string#fragment`。\n- **RFC标准**：HTTP协议通常遵循RFC（Request for Comments）标准，RFC是互联网技术标准文档。虽然大多数应用程序遵循RFC标准，但某些应用程序可能会扩展或偏离标准，导致兼容性问题。\n\n### 7. 总结\n本章详细介绍了Web的基础技术，特别是HTTP协议的诞生、发展及其与TCP/IP协议族的关系。通过了解IP、TCP、DNS等协议，可以更好地理解HTTP在Web通信中的作用。URI和URL的概念及其格式也是Web开发中的重要基础知识。\n\n\n\n参考：《图解HTTP》第一章\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","slug":"计算机基础/计算机网络/HTTP基础02：了解Web及网络基础","published":1,"updated":"2025-01-02T03:45:49.925Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3k000vhghi61owehuf","content":"<h2 id=\"了解Web及网络基础\"><a href=\"#了解Web及网络基础\" class=\"headerlink\" title=\"了解Web及网络基础\"></a>了解Web及网络基础</h2><h3 id=\"1-使用HTTP协议访问Web\"><a href=\"#1-使用HTTP协议访问Web\" class=\"headerlink\" title=\"1. 使用HTTP协议访问Web\"></a>1. 使用HTTP协议访问Web</h3><ul>\n<li><p><strong>URL输入与页面显示</strong>：当用户在浏览器地址栏中输入URL时，浏览器会向指定的Web服务器发送请求，获取相应的资源（如HTML文件、图片等），并将这些资源渲染成用户可见的Web页面。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231135527092.png\" alt=\"image-20241231135527092\"></p>\n</li>\n<li><p><strong>客户端与服务器</strong>：浏览器作为客户端，负责向服务器发送请求并接收响应。服务器则存储资源并响应客户端的请求。这种请求-响应模式是Web通信的基础。</p>\n</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231135627239.png\" alt=\"image-20241231135627239\"></p>\n<ul>\n<li><strong>HTTP协议</strong>：HTTP（超文本传输协议）是Web通信的核心协议，定义了客户端和服务器之间的通信规则。它基于请求-响应模型，客户端发送请求，服务器返回响应。HTTP协议是无状态的，意味着每次请求都是独立的，服务器不会保留之前的请求信息。</li>\n</ul>\n<h3 id=\"2-HTTP的诞生\"><a href=\"#2-HTTP的诞生\" class=\"headerlink\" title=\"2. HTTP的诞生\"></a>2. HTTP的诞生</h3><ul>\n<li><strong>背景</strong>：1989年，Tim Berners-Lee在CERN提出了WWW（万维网）的概念，旨在通过互联网实现全球知识共享。他提出了超文本（HyperText）的概念，即文档之间可以通过链接相互关联，形成一个巨大的信息网络。</li>\n<li><strong>WWW构建技术</strong>：WWW的构建依赖于三大核心技术：<ul>\n<li><strong>HTML</strong>（超文本标记语言）：用于创建和格式化Web页面。</li>\n<li><strong>HTTP</strong>（超文本传输协议）：用于在客户端和服务器之间传输数据。</li>\n<li><strong>URL</strong>（统一资源定位符）：用于定位互联网上的资源。</li>\n</ul>\n</li>\n<li><strong>Web的成长</strong>：1990年，CERN成功研发了世界上第一台Web服务器和Web浏览器。1993年，NCSA Mosaic浏览器问世，它支持内联图像显示，迅速在全球流行。1994年，Netscape Navigator发布，成为当时最流行的浏览器。1995年，微软发布了Internet Explorer，开启了浏览器大战。</li>\n<li><strong>HTTP版本</strong>：<ul>\n<li><strong>HTTP&#x2F;0.9</strong>：1990年发布，功能极为简单，仅支持GET请求。</li>\n<li><strong>HTTP&#x2F;1.0</strong>：1996年发布，引入了更多的请求方法（如POST、HEAD）和头部字段，支持多种内容类型。</li>\n<li><strong>HTTP&#x2F;1.1</strong>：1997年发布，是目前最广泛使用的版本，支持持久连接、分块传输编码等特性。</li>\n<li><strong>HTTP&#x2F;2.0</strong>：正在制定中，旨在提高性能，支持多路复用、头部压缩等新特性。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"3-网络基础TCP-IP\"><a href=\"#3-网络基础TCP-IP\" class=\"headerlink\" title=\"3. 网络基础TCP&#x2F;IP\"></a>3. 网络基础TCP&#x2F;IP</h3><ul>\n<li><strong>TCP&#x2F;IP协议族</strong>：TCP&#x2F;IP是互联网的基础协议族，定义了计算机如何在网络上进行通信。HTTP协议是TCP&#x2F;IP协议族的一部分，依赖于TCP&#x2F;IP进行数据传输。</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231135723889.png\" alt=\"image-20241231135723889\"></p>\n<ul>\n<li><p>为什么需要 TCP&#x2F;IP？</p>\n<ul>\n<li><strong>背景</strong>：互联网是由全球数以亿计的计算机和网络设备组成的复杂网络。为了让这些设备能够相互通信，必须有一套统一的规则和协议。TCP&#x2F;IP 协议族就是为此而设计的，它定义了计算机和网络设备之间如何通信、如何传输数据、如何寻址等一系列规则。</li>\n<li><strong>跨平台通信</strong>：不同的计算机可能使用不同的硬件、操作系统和网络技术。TCP&#x2F;IP 协议族提供了一种标准化的通信方式，使得这些异构系统能够无缝地进行数据交换。</li>\n<li><strong>模块化设计</strong>：TCP&#x2F;IP 协议族采用分层设计，每一层负责特定的功能。这种模块化的设计使得协议族易于扩展和维护，某一层的改动不会影响其他层的功能。</li>\n</ul>\n</li>\n<li><p>分层管理的优点</p>\n<ul>\n<li><p><strong>简化设计</strong>：分层设计将复杂的网络通信问题分解为多个相对简单的子问题，每一层只需关注自己的任务，无需了解其他层的细节。</p>\n</li>\n<li><p><strong>易于维护和扩展</strong>：如果某一层的协议需要更新或替换，只需修改该层的实现，而不会影响其他层。例如，传输层的 TCP 协议可以独立于应用层的 HTTP 协议进行优化。</p>\n</li>\n<li><p><strong>灵活性</strong>：分层设计允许不同的协议在同一层中并存。例如，传输层可以使用 TCP 或 UDP，具体选择取决于应用的需求。</p>\n</li>\n<li><p><strong>标准化接口</strong>：每一层之间通过标准化的接口进行通信，确保了不同厂商的设备能够互操作。</p>\n</li>\n</ul>\n</li>\n<li><p><strong>分层管理</strong>：TCP&#x2F;IP协议族分为四层：</p>\n<ul>\n<li><strong>应用层</strong>：提供应用程序之间的通信服务，如HTTP、FTP、DNS等。</li>\n<li><strong>传输层</strong>：负责端到端的数据传输，主要协议有TCP和UDP。</li>\n<li><strong>网络层</strong>：处理在网络上流动的数据包。数据包是网络传输的最小数 据单位。该层规定了通过怎样的路径（所谓的传输路线）到达对方计 算机，并把数据包传送给对方。</li>\n<li><strong>链路层</strong>：硬件部分。包括控制操作系统、硬件的设备驱 动、NIC（Network Interface Card，网络适配器，即网卡），及光纤等 物理可见部分（还包括连接器等一切传输媒介）。硬件上的范畴均在 链路层的作用范围之内。</li>\n</ul>\n</li>\n<li><p><strong>通信传输流</strong></p>\n<ul>\n<li>用 HTTP 举例来说明，首先作为发送端的客户端在应用层 （HTTP 协议）发出一个想看某个 Web 页面的 HTTP 请求。 </li>\n<li>接着，为了传输方便，在传输层（TCP 协议）把从应用层处收到的数 据（HTTP 请求报文）进行分割，并在各个报文上打上标记序号及端 口号后转发给网络层。 </li>\n<li>在网络层（IP 协议），增加作为通信目的地的 MAC 地址后转发给链 路层。这样一来，发往网络的通信请求就准备齐全了。 </li>\n<li>接收端的服务器在链路层接收到数据，按序往上层发送，一直到应用 层。</li>\n<li>当传输到应用层，才能算真正接收到由客户端发送过来的 HTTP 请求。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231140702101.png\" alt=\"image-20241231140702101\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231140906221.png\" alt=\"image-20241231140906221\"></p>\n<ul>\n<li><p>发送端在层与层之间传输数据时，每经过一层时必定会被打上一个该 层所属的首部信息。反之，接收端在层与层传输数据时，每经过一层 时会把对应的首部消去。</p>\n</li>\n<li><p>这种把数据信息包装起来的做法称为封装（encapsulate）。</p>\n</li>\n</ul>\n<h3 id=\"4-与HTTP关系密切的协议：IP、TCP和DNS\"><a href=\"#4-与HTTP关系密切的协议：IP、TCP和DNS\" class=\"headerlink\" title=\"4. 与HTTP关系密切的协议：IP、TCP和DNS\"></a>4. 与HTTP关系密切的协议：IP、TCP和DNS</h3><ul>\n<li><strong>IP协议</strong>：IP（网际协议）位于网络层，负责将数据包从源地址传输到目的地址。IP协议依赖于IP地址和MAC地址进行通信。IP地址是逻辑地址，可以变化，而MAC地址是物理地址，通常不变。IP协议使用ARP（地址解析协议）来根据IP地址查找对应的MAC地址。</li>\n<li><strong>TCP协议</strong>：TCP（传输控制协议）位于传输层，提供可靠的字节流服务。它将大数据分割成小的报文段进行传输，并通过三次握手确保数据的可靠传输。TCP还提供了流量控制、拥塞控制等机制，确保数据传输的稳定性。</li>\n<li><strong>DNS服务</strong>：DNS（域名系统）位于应用层，负责将域名解析为IP地址。用户通常使用域名访问网站，而不是直接使用IP地址，因为域名更易于记忆。DNS服务通过域名查找IP地址，或从IP地址反查域名。</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231141054269.png\" alt=\"数据包发送\"></p>\n<h4 id=\"数据包发送的过程：\"><a href=\"#数据包发送的过程：\" class=\"headerlink\" title=\"数据包发送的过程：\"></a>数据包发送的过程：</h4><ol>\n<li><p><strong>发送端准备发送数据包</strong>：</p>\n<ul>\n<li>发送端想要将数据包发送到IP地址为192.0.43.10的目的地。</li>\n<li>发送端使用ARP（地址解析协议）来解析目标IP地址对应的MAC地址。</li>\n</ul>\n</li>\n<li><p><strong>ARP解析过程</strong>：</p>\n<ul>\n<li>发送端通过ARP协议尝试解析目标IP地址192.0.43.10的MAC地址，但此时还未成功解析到具体的MAC地址。</li>\n</ul>\n</li>\n<li><p><strong>先将数据包发送给路由器</strong>：</p>\n<ul>\n<li>由于ARP解析未完成，发送端先将数据包发送给一个中间路由器，该路由器的MAC地址为00-XX-C6-6B-XX-XX。</li>\n</ul>\n</li>\n<li><p><strong>第一次转发</strong>：</p>\n<ul>\n<li>路由器接收到数据包后，进行第一次转发。路由器将数据包转发给下一个路由器，其MAC地址为00-XX-B5-A5-XX-XX。</li>\n</ul>\n</li>\n<li><p><strong>第二次转发</strong>：</p>\n<ul>\n<li>第二个路由器接收到数据包后，进行第二次转发。此时，路由器已经知道目标IP地址192.0.43.10的具体MAC地址为00-XX-A6-6B-XX-XX。</li>\n<li>路由器将数据包转发给最终的目标接收端。</li>\n</ul>\n</li>\n<li><p><strong>数据包到达接收端</strong>：</p>\n<ul>\n<li>最终，数据包成功到达接收端，接收端的IP地址为192.0.43.10，MAC地址为00-XX-A6-6B-XX-XX。</li>\n</ul>\n</li>\n</ol>\n<p>总结：</p>\n<ul>\n<li>数据包从发送端出发，通过多个路由器的转发，最终到达目标接收端。</li>\n<li>在这个过程中，ARP协议用于解析目标IP地址的MAC地址，确保数据包能够正确送达目的地。</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231141211177.png\" alt=\"三次握手\"></p>\n<p>字节流服务：TCP 位于传输层，提供可靠的字节流服务。为了方便传输，将大 块数据分割成以报文段（segment）为单位的数据包进行管理。</p>\n<h4 id=\"三次握手\"><a href=\"#三次握手\" class=\"headerlink\" title=\"三次握手\"></a>三次握手</h4><ul>\n<li>发送端首先发送一个带 SYN 标志的数据包给对方。</li>\n<li>接收端收到后， 回传一个带有 SYN&#x2F;ACK 标志的数据包以示传达确认信息。</li>\n<li>最后，发 送端再回传一个带 ACK 标志的数据包，代表“握手”结束。</li>\n</ul>\n<p>若在握手过程中某个阶段莫名中断，TCP 协议会再次以相同的顺序发 送相同的数据包。</p>\n<h3 id=\"5-负责域名解析的DNS服务\"><a href=\"#5-负责域名解析的DNS服务\" class=\"headerlink\" title=\"5. 负责域名解析的DNS服务\"></a>5. 负责域名解析的DNS服务</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231141657984.png\" alt=\"image-20241231141657984\"></p>\n<ul>\n<li><strong>DNS功能</strong>：DNS的主要功能是将人类可读的域名转换为计算机可识别的IP地址。例如，当用户输入<code>www.example.com</code>时，DNS会将其解析为对应的IP地址，如<code>192.0.2.1</code>，以便浏览器能够与服务器建立连接。</li>\n<li><strong>用户习惯</strong>：用户通常使用域名访问网站，因为域名比IP地址更容易记忆。DNS服务使得用户无需记住复杂的IP地址，只需输入简单的域名即可访问资源。</li>\n</ul>\n<h3 id=\"6-各种协议与HTTP协议的关系\"><a href=\"#6-各种协议与HTTP协议的关系\" class=\"headerlink\" title=\"6. 各种协议与HTTP协议的关系\"></a>6. 各种协议与HTTP协议的关系</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231141751459.png\" alt=\"image-20241231141751459\"></p>\n<ul>\n<li><strong>HTTP通信过程</strong>：当用户访问一个Web页面时，首先通过DNS解析域名获取IP地址，然后通过IP协议找到目标服务器，接着通过TCP协议建立可靠的连接，最后通过HTTP协议发送请求并接收响应。整个过程涉及多个协议的协同工作。</li>\n<li><strong>协议协作</strong>：DNS负责域名解析，IP协议负责寻址，TCP协议确保数据传输的可靠性，HTTP协议则负责生成请求和处理响应。这些协议共同构成了Web通信的基础。</li>\n</ul>\n<h4 id=\"1-7-URI和URL\"><a href=\"#1-7-URI和URL\" class=\"headerlink\" title=\"1.7 URI和URL\"></a>1.7 URI和URL</h4><ul>\n<li><strong>URI与URL</strong>：URI（统一资源标识符）是用于标识互联网上资源的字符串，而URL（统一资源定位符）是URI的子集，表示资源的具体位置。URL是用户在浏览器中输入的地址，如<code>http://www.example.com</code>。</li>\n<li><strong>URI格式</strong>：URI的格式包括协议方案、登录信息、服务器地址、端口号、文件路径、查询字符串和片段标识符。例如，<code>http://user:password@www.example.com:80/path/to/resource?query=string#fragment</code>。</li>\n<li><strong>RFC标准</strong>：HTTP协议通常遵循RFC（Request for Comments）标准，RFC是互联网技术标准文档。虽然大多数应用程序遵循RFC标准，但某些应用程序可能会扩展或偏离标准，导致兼容性问题。</li>\n</ul>\n<h3 id=\"7-总结\"><a href=\"#7-总结\" class=\"headerlink\" title=\"7. 总结\"></a>7. 总结</h3><p>本章详细介绍了Web的基础技术，特别是HTTP协议的诞生、发展及其与TCP&#x2F;IP协议族的关系。通过了解IP、TCP、DNS等协议，可以更好地理解HTTP在Web通信中的作用。URI和URL的概念及其格式也是Web开发中的重要基础知识。</p>\n<p>参考：《图解HTTP》第一章</p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n","excerpt":"","more":"<h2 id=\"了解Web及网络基础\"><a href=\"#了解Web及网络基础\" class=\"headerlink\" title=\"了解Web及网络基础\"></a>了解Web及网络基础</h2><h3 id=\"1-使用HTTP协议访问Web\"><a href=\"#1-使用HTTP协议访问Web\" class=\"headerlink\" title=\"1. 使用HTTP协议访问Web\"></a>1. 使用HTTP协议访问Web</h3><ul>\n<li><p><strong>URL输入与页面显示</strong>：当用户在浏览器地址栏中输入URL时，浏览器会向指定的Web服务器发送请求，获取相应的资源（如HTML文件、图片等），并将这些资源渲染成用户可见的Web页面。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231135527092.png\" alt=\"image-20241231135527092\"></p>\n</li>\n<li><p><strong>客户端与服务器</strong>：浏览器作为客户端，负责向服务器发送请求并接收响应。服务器则存储资源并响应客户端的请求。这种请求-响应模式是Web通信的基础。</p>\n</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231135627239.png\" alt=\"image-20241231135627239\"></p>\n<ul>\n<li><strong>HTTP协议</strong>：HTTP（超文本传输协议）是Web通信的核心协议，定义了客户端和服务器之间的通信规则。它基于请求-响应模型，客户端发送请求，服务器返回响应。HTTP协议是无状态的，意味着每次请求都是独立的，服务器不会保留之前的请求信息。</li>\n</ul>\n<h3 id=\"2-HTTP的诞生\"><a href=\"#2-HTTP的诞生\" class=\"headerlink\" title=\"2. HTTP的诞生\"></a>2. HTTP的诞生</h3><ul>\n<li><strong>背景</strong>：1989年，Tim Berners-Lee在CERN提出了WWW（万维网）的概念，旨在通过互联网实现全球知识共享。他提出了超文本（HyperText）的概念，即文档之间可以通过链接相互关联，形成一个巨大的信息网络。</li>\n<li><strong>WWW构建技术</strong>：WWW的构建依赖于三大核心技术：<ul>\n<li><strong>HTML</strong>（超文本标记语言）：用于创建和格式化Web页面。</li>\n<li><strong>HTTP</strong>（超文本传输协议）：用于在客户端和服务器之间传输数据。</li>\n<li><strong>URL</strong>（统一资源定位符）：用于定位互联网上的资源。</li>\n</ul>\n</li>\n<li><strong>Web的成长</strong>：1990年，CERN成功研发了世界上第一台Web服务器和Web浏览器。1993年，NCSA Mosaic浏览器问世，它支持内联图像显示，迅速在全球流行。1994年，Netscape Navigator发布，成为当时最流行的浏览器。1995年，微软发布了Internet Explorer，开启了浏览器大战。</li>\n<li><strong>HTTP版本</strong>：<ul>\n<li><strong>HTTP&#x2F;0.9</strong>：1990年发布，功能极为简单，仅支持GET请求。</li>\n<li><strong>HTTP&#x2F;1.0</strong>：1996年发布，引入了更多的请求方法（如POST、HEAD）和头部字段，支持多种内容类型。</li>\n<li><strong>HTTP&#x2F;1.1</strong>：1997年发布，是目前最广泛使用的版本，支持持久连接、分块传输编码等特性。</li>\n<li><strong>HTTP&#x2F;2.0</strong>：正在制定中，旨在提高性能，支持多路复用、头部压缩等新特性。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"3-网络基础TCP-IP\"><a href=\"#3-网络基础TCP-IP\" class=\"headerlink\" title=\"3. 网络基础TCP&#x2F;IP\"></a>3. 网络基础TCP&#x2F;IP</h3><ul>\n<li><strong>TCP&#x2F;IP协议族</strong>：TCP&#x2F;IP是互联网的基础协议族，定义了计算机如何在网络上进行通信。HTTP协议是TCP&#x2F;IP协议族的一部分，依赖于TCP&#x2F;IP进行数据传输。</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231135723889.png\" alt=\"image-20241231135723889\"></p>\n<ul>\n<li><p>为什么需要 TCP&#x2F;IP？</p>\n<ul>\n<li><strong>背景</strong>：互联网是由全球数以亿计的计算机和网络设备组成的复杂网络。为了让这些设备能够相互通信，必须有一套统一的规则和协议。TCP&#x2F;IP 协议族就是为此而设计的，它定义了计算机和网络设备之间如何通信、如何传输数据、如何寻址等一系列规则。</li>\n<li><strong>跨平台通信</strong>：不同的计算机可能使用不同的硬件、操作系统和网络技术。TCP&#x2F;IP 协议族提供了一种标准化的通信方式，使得这些异构系统能够无缝地进行数据交换。</li>\n<li><strong>模块化设计</strong>：TCP&#x2F;IP 协议族采用分层设计，每一层负责特定的功能。这种模块化的设计使得协议族易于扩展和维护，某一层的改动不会影响其他层的功能。</li>\n</ul>\n</li>\n<li><p>分层管理的优点</p>\n<ul>\n<li><p><strong>简化设计</strong>：分层设计将复杂的网络通信问题分解为多个相对简单的子问题，每一层只需关注自己的任务，无需了解其他层的细节。</p>\n</li>\n<li><p><strong>易于维护和扩展</strong>：如果某一层的协议需要更新或替换，只需修改该层的实现，而不会影响其他层。例如，传输层的 TCP 协议可以独立于应用层的 HTTP 协议进行优化。</p>\n</li>\n<li><p><strong>灵活性</strong>：分层设计允许不同的协议在同一层中并存。例如，传输层可以使用 TCP 或 UDP，具体选择取决于应用的需求。</p>\n</li>\n<li><p><strong>标准化接口</strong>：每一层之间通过标准化的接口进行通信，确保了不同厂商的设备能够互操作。</p>\n</li>\n</ul>\n</li>\n<li><p><strong>分层管理</strong>：TCP&#x2F;IP协议族分为四层：</p>\n<ul>\n<li><strong>应用层</strong>：提供应用程序之间的通信服务，如HTTP、FTP、DNS等。</li>\n<li><strong>传输层</strong>：负责端到端的数据传输，主要协议有TCP和UDP。</li>\n<li><strong>网络层</strong>：处理在网络上流动的数据包。数据包是网络传输的最小数 据单位。该层规定了通过怎样的路径（所谓的传输路线）到达对方计 算机，并把数据包传送给对方。</li>\n<li><strong>链路层</strong>：硬件部分。包括控制操作系统、硬件的设备驱 动、NIC（Network Interface Card，网络适配器，即网卡），及光纤等 物理可见部分（还包括连接器等一切传输媒介）。硬件上的范畴均在 链路层的作用范围之内。</li>\n</ul>\n</li>\n<li><p><strong>通信传输流</strong></p>\n<ul>\n<li>用 HTTP 举例来说明，首先作为发送端的客户端在应用层 （HTTP 协议）发出一个想看某个 Web 页面的 HTTP 请求。 </li>\n<li>接着，为了传输方便，在传输层（TCP 协议）把从应用层处收到的数 据（HTTP 请求报文）进行分割，并在各个报文上打上标记序号及端 口号后转发给网络层。 </li>\n<li>在网络层（IP 协议），增加作为通信目的地的 MAC 地址后转发给链 路层。这样一来，发往网络的通信请求就准备齐全了。 </li>\n<li>接收端的服务器在链路层接收到数据，按序往上层发送，一直到应用 层。</li>\n<li>当传输到应用层，才能算真正接收到由客户端发送过来的 HTTP 请求。</li>\n</ul>\n</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231140702101.png\" alt=\"image-20241231140702101\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231140906221.png\" alt=\"image-20241231140906221\"></p>\n<ul>\n<li><p>发送端在层与层之间传输数据时，每经过一层时必定会被打上一个该 层所属的首部信息。反之，接收端在层与层传输数据时，每经过一层 时会把对应的首部消去。</p>\n</li>\n<li><p>这种把数据信息包装起来的做法称为封装（encapsulate）。</p>\n</li>\n</ul>\n<h3 id=\"4-与HTTP关系密切的协议：IP、TCP和DNS\"><a href=\"#4-与HTTP关系密切的协议：IP、TCP和DNS\" class=\"headerlink\" title=\"4. 与HTTP关系密切的协议：IP、TCP和DNS\"></a>4. 与HTTP关系密切的协议：IP、TCP和DNS</h3><ul>\n<li><strong>IP协议</strong>：IP（网际协议）位于网络层，负责将数据包从源地址传输到目的地址。IP协议依赖于IP地址和MAC地址进行通信。IP地址是逻辑地址，可以变化，而MAC地址是物理地址，通常不变。IP协议使用ARP（地址解析协议）来根据IP地址查找对应的MAC地址。</li>\n<li><strong>TCP协议</strong>：TCP（传输控制协议）位于传输层，提供可靠的字节流服务。它将大数据分割成小的报文段进行传输，并通过三次握手确保数据的可靠传输。TCP还提供了流量控制、拥塞控制等机制，确保数据传输的稳定性。</li>\n<li><strong>DNS服务</strong>：DNS（域名系统）位于应用层，负责将域名解析为IP地址。用户通常使用域名访问网站，而不是直接使用IP地址，因为域名更易于记忆。DNS服务通过域名查找IP地址，或从IP地址反查域名。</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231141054269.png\" alt=\"数据包发送\"></p>\n<h4 id=\"数据包发送的过程：\"><a href=\"#数据包发送的过程：\" class=\"headerlink\" title=\"数据包发送的过程：\"></a>数据包发送的过程：</h4><ol>\n<li><p><strong>发送端准备发送数据包</strong>：</p>\n<ul>\n<li>发送端想要将数据包发送到IP地址为192.0.43.10的目的地。</li>\n<li>发送端使用ARP（地址解析协议）来解析目标IP地址对应的MAC地址。</li>\n</ul>\n</li>\n<li><p><strong>ARP解析过程</strong>：</p>\n<ul>\n<li>发送端通过ARP协议尝试解析目标IP地址192.0.43.10的MAC地址，但此时还未成功解析到具体的MAC地址。</li>\n</ul>\n</li>\n<li><p><strong>先将数据包发送给路由器</strong>：</p>\n<ul>\n<li>由于ARP解析未完成，发送端先将数据包发送给一个中间路由器，该路由器的MAC地址为00-XX-C6-6B-XX-XX。</li>\n</ul>\n</li>\n<li><p><strong>第一次转发</strong>：</p>\n<ul>\n<li>路由器接收到数据包后，进行第一次转发。路由器将数据包转发给下一个路由器，其MAC地址为00-XX-B5-A5-XX-XX。</li>\n</ul>\n</li>\n<li><p><strong>第二次转发</strong>：</p>\n<ul>\n<li>第二个路由器接收到数据包后，进行第二次转发。此时，路由器已经知道目标IP地址192.0.43.10的具体MAC地址为00-XX-A6-6B-XX-XX。</li>\n<li>路由器将数据包转发给最终的目标接收端。</li>\n</ul>\n</li>\n<li><p><strong>数据包到达接收端</strong>：</p>\n<ul>\n<li>最终，数据包成功到达接收端，接收端的IP地址为192.0.43.10，MAC地址为00-XX-A6-6B-XX-XX。</li>\n</ul>\n</li>\n</ol>\n<p>总结：</p>\n<ul>\n<li>数据包从发送端出发，通过多个路由器的转发，最终到达目标接收端。</li>\n<li>在这个过程中，ARP协议用于解析目标IP地址的MAC地址，确保数据包能够正确送达目的地。</li>\n</ul>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231141211177.png\" alt=\"三次握手\"></p>\n<p>字节流服务：TCP 位于传输层，提供可靠的字节流服务。为了方便传输，将大 块数据分割成以报文段（segment）为单位的数据包进行管理。</p>\n<h4 id=\"三次握手\"><a href=\"#三次握手\" class=\"headerlink\" title=\"三次握手\"></a>三次握手</h4><ul>\n<li>发送端首先发送一个带 SYN 标志的数据包给对方。</li>\n<li>接收端收到后， 回传一个带有 SYN&#x2F;ACK 标志的数据包以示传达确认信息。</li>\n<li>最后，发 送端再回传一个带 ACK 标志的数据包，代表“握手”结束。</li>\n</ul>\n<p>若在握手过程中某个阶段莫名中断，TCP 协议会再次以相同的顺序发 送相同的数据包。</p>\n<h3 id=\"5-负责域名解析的DNS服务\"><a href=\"#5-负责域名解析的DNS服务\" class=\"headerlink\" title=\"5. 负责域名解析的DNS服务\"></a>5. 负责域名解析的DNS服务</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231141657984.png\" alt=\"image-20241231141657984\"></p>\n<ul>\n<li><strong>DNS功能</strong>：DNS的主要功能是将人类可读的域名转换为计算机可识别的IP地址。例如，当用户输入<code>www.example.com</code>时，DNS会将其解析为对应的IP地址，如<code>192.0.2.1</code>，以便浏览器能够与服务器建立连接。</li>\n<li><strong>用户习惯</strong>：用户通常使用域名访问网站，因为域名比IP地址更容易记忆。DNS服务使得用户无需记住复杂的IP地址，只需输入简单的域名即可访问资源。</li>\n</ul>\n<h3 id=\"6-各种协议与HTTP协议的关系\"><a href=\"#6-各种协议与HTTP协议的关系\" class=\"headerlink\" title=\"6. 各种协议与HTTP协议的关系\"></a>6. 各种协议与HTTP协议的关系</h3><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241231141751459.png\" alt=\"image-20241231141751459\"></p>\n<ul>\n<li><strong>HTTP通信过程</strong>：当用户访问一个Web页面时，首先通过DNS解析域名获取IP地址，然后通过IP协议找到目标服务器，接着通过TCP协议建立可靠的连接，最后通过HTTP协议发送请求并接收响应。整个过程涉及多个协议的协同工作。</li>\n<li><strong>协议协作</strong>：DNS负责域名解析，IP协议负责寻址，TCP协议确保数据传输的可靠性，HTTP协议则负责生成请求和处理响应。这些协议共同构成了Web通信的基础。</li>\n</ul>\n<h4 id=\"1-7-URI和URL\"><a href=\"#1-7-URI和URL\" class=\"headerlink\" title=\"1.7 URI和URL\"></a>1.7 URI和URL</h4><ul>\n<li><strong>URI与URL</strong>：URI（统一资源标识符）是用于标识互联网上资源的字符串，而URL（统一资源定位符）是URI的子集，表示资源的具体位置。URL是用户在浏览器中输入的地址，如<code>http://www.example.com</code>。</li>\n<li><strong>URI格式</strong>：URI的格式包括协议方案、登录信息、服务器地址、端口号、文件路径、查询字符串和片段标识符。例如，<code>http://user:password@www.example.com:80/path/to/resource?query=string#fragment</code>。</li>\n<li><strong>RFC标准</strong>：HTTP协议通常遵循RFC（Request for Comments）标准，RFC是互联网技术标准文档。虽然大多数应用程序遵循RFC标准，但某些应用程序可能会扩展或偏离标准，导致兼容性问题。</li>\n</ul>\n<h3 id=\"7-总结\"><a href=\"#7-总结\" class=\"headerlink\" title=\"7. 总结\"></a>7. 总结</h3><p>本章详细介绍了Web的基础技术，特别是HTTP协议的诞生、发展及其与TCP&#x2F;IP协议族的关系。通过了解IP、TCP、DNS等协议，可以更好地理解HTTP在Web通信中的作用。URI和URL的概念及其格式也是Web开发中的重要基础知识。</p>\n<p>参考：《图解HTTP》第一章</p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n"},{"title":"音视频开发08：音视频开发基本步骤和流程","date":"2024-12-11T04:00:00.000Z","category_bar":true,"_content":"\n![image-20241205155843570](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241205155843570.png)\n\n# 音视频开发的基本步骤\n\n音视频开发是一个涉及多个技术领域的复杂过程，其基本步骤涵盖了从数据采集到最终播放展示的各个环节。\n\n### **一、数据采集**\n\n 数据采集是音视频开发的起始点，它解决的是数据从哪里来的问题。这一环节涉及到对声音和图像从现实世界转换为数字信号的操作。\n\n- **设备选择**：首先要选择合适的音视频采集设备。对于音频采集，麦克风是常见的设备；对于视频采集，摄像头则是常用的选择。不同的设备适用于不同的场景，例如在视频会议场景下，可能会选择高清摄像头来确保图像的清晰，而在语音通话场景中，会选用能够有效降低背景噪音的麦克风。\n- **配置采集参数**：针对不同的采集设备和采集场景，需要配置不同的采集参数。对于音频，重要的参数有采样率、位宽、声道数等。采样率指每秒从连续信号中提取并组成离散信号的采样个数，例如人耳能听到的最高频率为20kHz，为了满足人耳的听觉要求，采样率通常为44.1kHz或48kHz；位宽涉及到振幅量化，常见的有8位、16位、32位；声道数有单声道、双声道等。对于视频，图像传输格式、图像格式、传输通道、分辨率、采样频率等是关键参数。分辨率如常见的720P（1280×720）、1080P（1920×1080）等，帧率也是一个重要参数，它代表单位时间内帧的数量，单位是fps，像24/25fps是一般电影的帧率，30/60fps是游戏常见的帧率，30帧可以接受，60帧会感觉更加流畅逼真，85fps以上人眼基本无法察觉出差异，更高帧率在视频里意义不大。\n- **开启采集设备**：通过相应的API或SDK来开启采集设备。例如在Android系统中，视频采集可以使用Camera类，音频采集可以用AudioRecord来开启采集设备。在开启设备后，就可以进行数据的采集了。\n- **采集音频和视频数据**：采集设备获取音频信号并将其转换为数字信号，对于视频则是获取图像的数字信号。在采集过程中，可能会面临一些问题，如音频采集时可能会遇到噪音、回声等干扰，视频采集可能会存在延时敏感、图像质量受环境光影响等问题。同时，采集到的数据可能需要进行一些初步的处理，如音频的降噪、视频的格式转换等，以便后续的操作。例如在音频采集流程中，采集端将音频模拟信号转换为数字信号后，进入音频处理模块，会有音频增益、噪声抑制、混音等操作。\n\n### **二、数据处理** \n\n数据处理是对采集或获取的音视频数据进行加工，以实现特定的应用需求。\n\n- **解码**：如果采集到的数据是经过编码压缩的，那么首先需要进行解码操作，将其转换为原始的音视频信号。例如对于采用H.264编码的视频数据和AAC编码的音频数据，需要对应的解码器将其还原成原始信号，以便进行后续处理。\n- **数据处理操作**：这一步包含多种操作。在音频处理方面，有混音、降噪、声音特效等操作。例如混音可以将多个音频源混合成一个音频流；降噪可以减少环境噪音对音频质量的影响；声音特效则可以为音频添加特殊的效果，如回声、变声等。在视频处理方面，常见的有美颜、水印、自定义滤镜、自定义处理等。美颜操作可以通过磨皮、美白等手段来改善视频中的人物形象，磨皮可以采用均值模糊、高斯模糊和中值滤波等技术，同时可能结合人脸和皮肤检测技术；水印可以是播放器水印或者视频内嵌水印；自定义滤镜则可以根据需求创建各种独特的视觉效果。\n- **编码和压缩**：处理后的音视频数据需要进行编码，以将其转换为压缩的音视频数据流，从而减小数据量，便于存储和传输。对于视频编码，其主要作用是将视频像素数据（如RGB，YUV等）压缩成为视频码流，常见的视频编码标准有H.264、H.265等。H.264具有低码率、高质量、高容错的特点，H.265在码率节省上相比H.264有较大优势，在相同RSNR下分别节省了48.3%和75.8%，但H.264在编码时间上有优势。对于音频编码，常见的编码标准有AAC、MP3等。编码的基本原理包括利用空间冗余（图像相邻像素之间有较强的相关性）、时间冗余（视频序的相邻图像之间内容相似）、编码冗余（不同像素值出现的概率不同）、知识冗余（规性的结构可由先验知识和背景知识得到）等来进行压缩。在编码之后，可能还会进行进一步的压缩操作，以进一步减小数据量，提高传输和存储效率。\n- **重采样和转码**：重采样主要针对音频数据，改变采样率、位深度等参数，以适应不同的应用需求。例如将44100/16/2转成48000/16/2。转码是将音视频数据从一种格式转换为另一种格式，以适应不同的设备和应用环境，如将视频从MKV格式转码为MP4格式，以便在更多设备上播放。\n- **合成操作**：在一些场景下，需要将多个音视频流进行合成，例如将多个音频轨道、视频轨道合并成一个完整的音视频文件。比如在视频编辑软件中，将不同片段的视频和对应的音频合成一个完整的视频作品。\n\n### **三、数据传输**\n\n 数据传输是将采集、处理后的音视频数据流传输到远程设备或服务器的过程。\n\n- **建立连接**：通过网络协议建立连接，常见的网络协议有TCP和UDP等。TCP协议是一种可靠的面向连接的协议，适用于对数据准确性要求较高的场景，如文件传输；UDP协议是一种无连接的协议，传输速度快但可靠性相对较低，适用于对实时性要求较高的场景，如视频直播中的部分数据传输。\n- **数据打包**：将采集、处理后的音视频数据流打包为网络传输的格式，例如RTP、RTMP等协议。RTP（Real - time Transport Protocol）是一种实时传输协议，用于在IP网络上传输实时数据，通常与RTCP（RTP Control Protocol）一起使用，RTCP用于监控服务质量并提供反馈；RTMP（Real - Time Messaging Protocol）是基于TCP的实时消息传输协议，广泛用于直播领域。\n- **压缩（如果需要）**：在传输之前，可能还会对数据流进行压缩，以减小数据量和网络带宽占用。这一步与前面数据处理中的编码压缩类似，但可能会根据传输网络的情况进行进一步的优化，例如根据网络带宽动态调整压缩率。\n- **传输数据**：通过网络将打包和压缩后的数据流传输到远程设备或服务器。在传输过程中，需要考虑网络的稳定性、带宽等因素。如果网络带宽不足，可能会导致视频卡顿、音频中断等问题。\n\n### **四、数据渲染与播放** \n\n这一环节是将音视频数据流转换为可视化的音视频内容并播放的过程。\n\n- **解码（再次解码）**：将接收到的音视频数据流解码为原始的音视频信号。这一步与数据处理中的解码类似，但可能会因为传输过程中的一些情况（如数据丢失、错误等）而需要进行一些特殊的处理，例如纠错、数据恢复等。\n- **帧缓存**：将解码后的视频帧存储到缓存中，以供后续渲染。缓存的大小和管理方式会影响视频播放的流畅性，如果缓存过小，可能会导致视频播放时频繁卡顿；如果缓存过大，可能会增加内存占用和延迟。\n- **视频渲染**：通过OpenGL、DirectX等图形库将视频帧渲染到屏幕上，并可以添加相应的特效和滤镜等处理。这些图形库提供了强大的图形处理功能，可以实现视频的缩放、旋转、添加字幕等操作。\n- **音频渲染**：将音频信号转换为声音，并通过扬声器或耳机播放出来。在播放过程中，需要确保音频的音量、音质等符合要求，并且要与视频保持同步。\n- **同步操作**：将音视频进行同步，以保证音频和视频的时间戳一致，避免出现卡顿、不同步等问题。音视频同步是一个复杂的过程，需要考虑到采集、传输、处理等各个环节可能引入的时间差，通过调整播放速度、缓冲等方式来实现同步。\n\n# 音视频开发流程包含哪些环节\n\n音视频开发流程包含多个环节，这些环节相互协作，共同完成从原始数据到可播放的音视频内容的转换。\n\n### **一、芯片与元件相关环节**\n\n- **主芯片厂商环节**：主芯片厂商，如海思、TI、安霸、联咏等，在音视频开发流程中处于基础地位。他们的核心在于各自的压缩算法，这些算法以SDK的方式开放给开发者使用。这些压缩算法是音视频编码的关键技术支撑，决定了音视频数据在采集、处理和传输过程中的压缩效率和质量。例如，一个好的视频压缩算法可以在保证视频质量的前提下，将视频数据量大大减小，从而节省存储空间和传输带宽。不同的主芯片厂商可能会有不同的技术优势和应用场景，开发者可以根据项目需求选择合适的芯片厂商的SDK进行开发。\n- **传感器与分立元件厂商环节**：传感器（senor）厂商、镜头等分立元件厂商也是重要的一环。传感器用于采集视频的原始数据，如摄像头中的图像传感器，它的性能直接影响到采集到的视频图像的质量，包括分辨率、色彩还原度、低光性能等。镜头则影响着视频的视角、焦距等参数。这些分立元件与主芯片相互配合，为后续的视频采集和处理提供基础的硬件条件。例如，一个高质量的镜头可以提供更清晰、更广阔的视野，与高分辨率的传感器相结合，可以采集到高质量的视频数据。\n\n### **二、模组开发环节** \n\n模组厂商在音视频开发流程中起着承上启下的作用。他们买来芯片、sensor、镜头等进行一些基础的开发，得出一些视频采集的模组，实现视频的采集、编码、传输。在这个环节中，模组厂商会将各种硬件元件集成在一起，并进行软件层面的开发，以实现视频的采集功能。他们需要对采集到的视频数据进行编码，将原始的视频数据转换为适合存储和传输的格式，例如采用H.264或H.265等视频编码标准进行编码。同时，还要实现视频数据的传输功能，确保编码后的视频数据能够在不同的设备之间进行传输。这个环节的开发成果是视频采集模组，它是整个音视频系统的重要组成部分，为后续的视频服务器和上层应用开发提供了基础的视频数据源。\n\n### **三、视频服务器相关环节**\n\n- **视频服务器厂商环节**：视频服务器厂商，如大拿等，在音视频开发流程中负责让编码后的视频能够通过外网传输。他们先将视频推到服务器上，再通过服务器让多个客户端进行多线程的访问。视频服务器需要具备强大的网络处理能力，能够处理大量的视频流数据。在这个环节中，涉及到网络协议的应用，如采用合适的流媒体传输协议（如RTSP、RTMP、HLS等）将视频数据传输到服务器，并在服务器端进行相应的处理，如视频的存储、转发等操作。服务器还需要提供多线程访问的支持，以满足多个客户端同时访问视频数据的需求。\n- **网络传输协议环节**：网络传输协议在视频服务器相关环节中至关重要。不同的协议适用于不同的场景。RTSP（Real Time Streaming Protocol）是一种实时流传输协议，常用于视频监控等场景，它允许客户端对视频流进行暂停、快进等操作；RTMP（Real - Time Messaging Protocol）是基于TCP的实时消息传输协议，广泛应用于直播领域；HLS（HTTP Live Streaming）是由Apple公司定义的基于HTTP的流媒体实时传输协议，可实现流媒体的直播和点播，主要用于iOS系统。这些协议在视频数据的传输过程中，负责将视频数据从服务器传输到客户端，并且要保证视频的流畅播放和数据的准确性。\n\n### **四、上层应用开发环节**\n\n- **面向解决方案的方案开发商环节**：面向解决方案的方案开发商买来模组、视频服务器，进行一些更上层的开发，如app，web管理等。他们会将模组采集到的视频数据和视频服务器提供的视频流进行整合，开发出各种应用。例如，他们可以整合模组与服务器，做出手机app，如将摄像头放在幼儿园中，家长就可以通过app对校园内的环境进行查看；也可以开发人脸识别门禁、打卡方案，将传感器接入人脸识别功能，连接数据库制作一套系统。在这个环节中，开发者需要具备多种技术能力，包括前端开发（如开发手机app的界面）、后端开发（如与数据库进行交互、处理业务逻辑）以及对音视频数据的处理能力（如在app中实现视频的播放、暂停、截图等功能）。\n- **工程商或销售商环节**：工程商或销售商在音视频开发流程中更多地关注项目的实施和销售方面。工程商做工程的，大多不懂技术只懂施工，他们大多关心摄像头装在墙上还是天花板；用什么网线，网线怎么接；多久施工完。例如一个工程商接一个项目，买来解决方案进行某工厂、停车场的监控系统的建设。销售商则将智能家居方案卖给个人或家庭。虽然他们不直接参与音视频技术的开发，但他们在将音视频解决方案推向市场和实际应用场景方面起着重要的作用。\n\n### **五、用户端播放环节** \n\n在用户端播放环节，涉及到将接收到的音视频数据进行解码、渲染和播放的过程。这一环节需要播放器软件或设备来实现。播放器需要支持多种音视频格式和编码标准，例如能够解码H.264编码的视频和AAC编码的音频。在播放过程中，要进行音视频的同步操作，以保证音频和视频的时间戳一致，避免出现卡顿、不同步等问题。同时，用户端设备（如手机、电脑、智能电视等）的性能也会影响播放效果，如设备的处理器速度、内存大小、显卡性能等会影响视频的解码速度和渲染质量。\n\n# 音视频开发的关键步骤有哪些\n\n音视频开发的关键步骤是整个开发流程中的核心部分，它们对最终的开发效果和用户体验有着决定性的影响。\n\n### **一、编码与解码**\n\n- **编码的重要性和原理**：编码是音视频开发中不可或缺的关键步骤。其主要目的是为了压缩数据，节省带宽和传输时间。原始的音视频数据量通常非常大，例如一个1080P30帧，32bit色彩时长为1秒的视频文件，如果按每一帧画面进行存储的话，数据大小将会达到:32bit * 30 * 1080 * 1920≈237MB的空间，通过编码可以大大减小这个数据量。视频编码的主要作用是将视频像素数据（RGB，YUV等）压缩成为视频码流，从而降低视频的数据量。编码的基本原理包括空间冗余（图像相邻像素之间有较强的相关性）、时间冗余（视频序的相邻图像之间内容相似）、编码冗余（不同像素值出现的概率不同）、知识冗余（规性的结构可由先验知识和背景知识得到）等。例如，在背景色全部是黑色的情况下，我们实际上没有必要按照视频大小（1124 * 772）存储黑色，我们可以将存储黑色的像素点抽离出来记录，只存储其他像素点的颜色即可。常见的视频编码标准有H.264、H.265等，H.264具有低码率、高质量、高容错的特点，H.265对H.264在码率节省上有较大的优势，在相同RSNR下分别节省了48.3%和75.8%，但H.264在编码时间上有聚到优势，对比VP9和H.265，H.265是vp9的6倍，vp9是H.264的将近40倍。对于音频编码，常见的编码标准有AAC、MP3等。\n- **解码的作用和实现方式**：解码是编码的逆过程，其作用是将视频/音频压缩编码数据，解码成为非压缩的视频/音频原始数据。在整个音视频系统中，解码是非常重要也是最复杂的一个环节。解码可以使用软解码和硬解码两种方式。软解码就是利用CPU资源去解压缩数据，采用的方式是FFmpeg解码等。硬解码则是利用专门的硬件（如显卡等）来进行解码，对于iOS平台来说，可以使用VideoToolbox.Framework（该框架只能在iOS8.0及以上系统使用）硬解码视频数据。在播放音视频数据时，播放器端需要根据接收到的编码数据类型选择合适的解码方式进行解码，然后才能将解码后的原始数据进行播放。\n\n### **二、数据传输相关步骤**\n\n- **选择合适的流媒体传输协议**：在音视频开发中，选择合适的流媒体传输协议是关键。不同的协议适用于不同的场景和需求。例如RTMP（Real - Time Messaging Protocol）是目前主流的流媒体传输协议，基于TCP，设计用来进行实时数据通信，广泛用于直播领域，市面上绝大多数直播产品都采用了这个协议；HTTP Live Streaming（HLS）是由Apple公司定义的基于HTTP的流媒体实时传输协议，可实现流媒体的直播和点播，主要用于iOS系统，但它的分段推送的特点，决定了HLS的延迟一般会高于普通的流媒体直播协议；WebRTC（webrealtimecommunication）是一个支持网页浏览器进行实时语音或者视频对话的API，适用于网页端的实时音视频通信。在选择协议时，需要考虑到项目的应用场景（如直播、点播、实时通信等）、目标用户群体（如iOS用户、安卓用户、网页用户等）以及对延迟、带宽等方面\n\n\n\n文章合集：https://github.com/chongzicbo/ReadWriteThink\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","source":"_posts/开发/音视频/音视频开发08：音视频开发基本步骤和流程.md","raw":"---\ntitle: '音视频开发08：音视频开发基本步骤和流程'\ncategories:\n  - [开发,音视频,基础]\ntags:\n  - 音视频开发\n  - 音视频基础\ndate: 2024-12-11 12:00:00\ncategory_bar: true\n---\n\n![image-20241205155843570](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241205155843570.png)\n\n# 音视频开发的基本步骤\n\n音视频开发是一个涉及多个技术领域的复杂过程，其基本步骤涵盖了从数据采集到最终播放展示的各个环节。\n\n### **一、数据采集**\n\n 数据采集是音视频开发的起始点，它解决的是数据从哪里来的问题。这一环节涉及到对声音和图像从现实世界转换为数字信号的操作。\n\n- **设备选择**：首先要选择合适的音视频采集设备。对于音频采集，麦克风是常见的设备；对于视频采集，摄像头则是常用的选择。不同的设备适用于不同的场景，例如在视频会议场景下，可能会选择高清摄像头来确保图像的清晰，而在语音通话场景中，会选用能够有效降低背景噪音的麦克风。\n- **配置采集参数**：针对不同的采集设备和采集场景，需要配置不同的采集参数。对于音频，重要的参数有采样率、位宽、声道数等。采样率指每秒从连续信号中提取并组成离散信号的采样个数，例如人耳能听到的最高频率为20kHz，为了满足人耳的听觉要求，采样率通常为44.1kHz或48kHz；位宽涉及到振幅量化，常见的有8位、16位、32位；声道数有单声道、双声道等。对于视频，图像传输格式、图像格式、传输通道、分辨率、采样频率等是关键参数。分辨率如常见的720P（1280×720）、1080P（1920×1080）等，帧率也是一个重要参数，它代表单位时间内帧的数量，单位是fps，像24/25fps是一般电影的帧率，30/60fps是游戏常见的帧率，30帧可以接受，60帧会感觉更加流畅逼真，85fps以上人眼基本无法察觉出差异，更高帧率在视频里意义不大。\n- **开启采集设备**：通过相应的API或SDK来开启采集设备。例如在Android系统中，视频采集可以使用Camera类，音频采集可以用AudioRecord来开启采集设备。在开启设备后，就可以进行数据的采集了。\n- **采集音频和视频数据**：采集设备获取音频信号并将其转换为数字信号，对于视频则是获取图像的数字信号。在采集过程中，可能会面临一些问题，如音频采集时可能会遇到噪音、回声等干扰，视频采集可能会存在延时敏感、图像质量受环境光影响等问题。同时，采集到的数据可能需要进行一些初步的处理，如音频的降噪、视频的格式转换等，以便后续的操作。例如在音频采集流程中，采集端将音频模拟信号转换为数字信号后，进入音频处理模块，会有音频增益、噪声抑制、混音等操作。\n\n### **二、数据处理** \n\n数据处理是对采集或获取的音视频数据进行加工，以实现特定的应用需求。\n\n- **解码**：如果采集到的数据是经过编码压缩的，那么首先需要进行解码操作，将其转换为原始的音视频信号。例如对于采用H.264编码的视频数据和AAC编码的音频数据，需要对应的解码器将其还原成原始信号，以便进行后续处理。\n- **数据处理操作**：这一步包含多种操作。在音频处理方面，有混音、降噪、声音特效等操作。例如混音可以将多个音频源混合成一个音频流；降噪可以减少环境噪音对音频质量的影响；声音特效则可以为音频添加特殊的效果，如回声、变声等。在视频处理方面，常见的有美颜、水印、自定义滤镜、自定义处理等。美颜操作可以通过磨皮、美白等手段来改善视频中的人物形象，磨皮可以采用均值模糊、高斯模糊和中值滤波等技术，同时可能结合人脸和皮肤检测技术；水印可以是播放器水印或者视频内嵌水印；自定义滤镜则可以根据需求创建各种独特的视觉效果。\n- **编码和压缩**：处理后的音视频数据需要进行编码，以将其转换为压缩的音视频数据流，从而减小数据量，便于存储和传输。对于视频编码，其主要作用是将视频像素数据（如RGB，YUV等）压缩成为视频码流，常见的视频编码标准有H.264、H.265等。H.264具有低码率、高质量、高容错的特点，H.265在码率节省上相比H.264有较大优势，在相同RSNR下分别节省了48.3%和75.8%，但H.264在编码时间上有优势。对于音频编码，常见的编码标准有AAC、MP3等。编码的基本原理包括利用空间冗余（图像相邻像素之间有较强的相关性）、时间冗余（视频序的相邻图像之间内容相似）、编码冗余（不同像素值出现的概率不同）、知识冗余（规性的结构可由先验知识和背景知识得到）等来进行压缩。在编码之后，可能还会进行进一步的压缩操作，以进一步减小数据量，提高传输和存储效率。\n- **重采样和转码**：重采样主要针对音频数据，改变采样率、位深度等参数，以适应不同的应用需求。例如将44100/16/2转成48000/16/2。转码是将音视频数据从一种格式转换为另一种格式，以适应不同的设备和应用环境，如将视频从MKV格式转码为MP4格式，以便在更多设备上播放。\n- **合成操作**：在一些场景下，需要将多个音视频流进行合成，例如将多个音频轨道、视频轨道合并成一个完整的音视频文件。比如在视频编辑软件中，将不同片段的视频和对应的音频合成一个完整的视频作品。\n\n### **三、数据传输**\n\n 数据传输是将采集、处理后的音视频数据流传输到远程设备或服务器的过程。\n\n- **建立连接**：通过网络协议建立连接，常见的网络协议有TCP和UDP等。TCP协议是一种可靠的面向连接的协议，适用于对数据准确性要求较高的场景，如文件传输；UDP协议是一种无连接的协议，传输速度快但可靠性相对较低，适用于对实时性要求较高的场景，如视频直播中的部分数据传输。\n- **数据打包**：将采集、处理后的音视频数据流打包为网络传输的格式，例如RTP、RTMP等协议。RTP（Real - time Transport Protocol）是一种实时传输协议，用于在IP网络上传输实时数据，通常与RTCP（RTP Control Protocol）一起使用，RTCP用于监控服务质量并提供反馈；RTMP（Real - Time Messaging Protocol）是基于TCP的实时消息传输协议，广泛用于直播领域。\n- **压缩（如果需要）**：在传输之前，可能还会对数据流进行压缩，以减小数据量和网络带宽占用。这一步与前面数据处理中的编码压缩类似，但可能会根据传输网络的情况进行进一步的优化，例如根据网络带宽动态调整压缩率。\n- **传输数据**：通过网络将打包和压缩后的数据流传输到远程设备或服务器。在传输过程中，需要考虑网络的稳定性、带宽等因素。如果网络带宽不足，可能会导致视频卡顿、音频中断等问题。\n\n### **四、数据渲染与播放** \n\n这一环节是将音视频数据流转换为可视化的音视频内容并播放的过程。\n\n- **解码（再次解码）**：将接收到的音视频数据流解码为原始的音视频信号。这一步与数据处理中的解码类似，但可能会因为传输过程中的一些情况（如数据丢失、错误等）而需要进行一些特殊的处理，例如纠错、数据恢复等。\n- **帧缓存**：将解码后的视频帧存储到缓存中，以供后续渲染。缓存的大小和管理方式会影响视频播放的流畅性，如果缓存过小，可能会导致视频播放时频繁卡顿；如果缓存过大，可能会增加内存占用和延迟。\n- **视频渲染**：通过OpenGL、DirectX等图形库将视频帧渲染到屏幕上，并可以添加相应的特效和滤镜等处理。这些图形库提供了强大的图形处理功能，可以实现视频的缩放、旋转、添加字幕等操作。\n- **音频渲染**：将音频信号转换为声音，并通过扬声器或耳机播放出来。在播放过程中，需要确保音频的音量、音质等符合要求，并且要与视频保持同步。\n- **同步操作**：将音视频进行同步，以保证音频和视频的时间戳一致，避免出现卡顿、不同步等问题。音视频同步是一个复杂的过程，需要考虑到采集、传输、处理等各个环节可能引入的时间差，通过调整播放速度、缓冲等方式来实现同步。\n\n# 音视频开发流程包含哪些环节\n\n音视频开发流程包含多个环节，这些环节相互协作，共同完成从原始数据到可播放的音视频内容的转换。\n\n### **一、芯片与元件相关环节**\n\n- **主芯片厂商环节**：主芯片厂商，如海思、TI、安霸、联咏等，在音视频开发流程中处于基础地位。他们的核心在于各自的压缩算法，这些算法以SDK的方式开放给开发者使用。这些压缩算法是音视频编码的关键技术支撑，决定了音视频数据在采集、处理和传输过程中的压缩效率和质量。例如，一个好的视频压缩算法可以在保证视频质量的前提下，将视频数据量大大减小，从而节省存储空间和传输带宽。不同的主芯片厂商可能会有不同的技术优势和应用场景，开发者可以根据项目需求选择合适的芯片厂商的SDK进行开发。\n- **传感器与分立元件厂商环节**：传感器（senor）厂商、镜头等分立元件厂商也是重要的一环。传感器用于采集视频的原始数据，如摄像头中的图像传感器，它的性能直接影响到采集到的视频图像的质量，包括分辨率、色彩还原度、低光性能等。镜头则影响着视频的视角、焦距等参数。这些分立元件与主芯片相互配合，为后续的视频采集和处理提供基础的硬件条件。例如，一个高质量的镜头可以提供更清晰、更广阔的视野，与高分辨率的传感器相结合，可以采集到高质量的视频数据。\n\n### **二、模组开发环节** \n\n模组厂商在音视频开发流程中起着承上启下的作用。他们买来芯片、sensor、镜头等进行一些基础的开发，得出一些视频采集的模组，实现视频的采集、编码、传输。在这个环节中，模组厂商会将各种硬件元件集成在一起，并进行软件层面的开发，以实现视频的采集功能。他们需要对采集到的视频数据进行编码，将原始的视频数据转换为适合存储和传输的格式，例如采用H.264或H.265等视频编码标准进行编码。同时，还要实现视频数据的传输功能，确保编码后的视频数据能够在不同的设备之间进行传输。这个环节的开发成果是视频采集模组，它是整个音视频系统的重要组成部分，为后续的视频服务器和上层应用开发提供了基础的视频数据源。\n\n### **三、视频服务器相关环节**\n\n- **视频服务器厂商环节**：视频服务器厂商，如大拿等，在音视频开发流程中负责让编码后的视频能够通过外网传输。他们先将视频推到服务器上，再通过服务器让多个客户端进行多线程的访问。视频服务器需要具备强大的网络处理能力，能够处理大量的视频流数据。在这个环节中，涉及到网络协议的应用，如采用合适的流媒体传输协议（如RTSP、RTMP、HLS等）将视频数据传输到服务器，并在服务器端进行相应的处理，如视频的存储、转发等操作。服务器还需要提供多线程访问的支持，以满足多个客户端同时访问视频数据的需求。\n- **网络传输协议环节**：网络传输协议在视频服务器相关环节中至关重要。不同的协议适用于不同的场景。RTSP（Real Time Streaming Protocol）是一种实时流传输协议，常用于视频监控等场景，它允许客户端对视频流进行暂停、快进等操作；RTMP（Real - Time Messaging Protocol）是基于TCP的实时消息传输协议，广泛应用于直播领域；HLS（HTTP Live Streaming）是由Apple公司定义的基于HTTP的流媒体实时传输协议，可实现流媒体的直播和点播，主要用于iOS系统。这些协议在视频数据的传输过程中，负责将视频数据从服务器传输到客户端，并且要保证视频的流畅播放和数据的准确性。\n\n### **四、上层应用开发环节**\n\n- **面向解决方案的方案开发商环节**：面向解决方案的方案开发商买来模组、视频服务器，进行一些更上层的开发，如app，web管理等。他们会将模组采集到的视频数据和视频服务器提供的视频流进行整合，开发出各种应用。例如，他们可以整合模组与服务器，做出手机app，如将摄像头放在幼儿园中，家长就可以通过app对校园内的环境进行查看；也可以开发人脸识别门禁、打卡方案，将传感器接入人脸识别功能，连接数据库制作一套系统。在这个环节中，开发者需要具备多种技术能力，包括前端开发（如开发手机app的界面）、后端开发（如与数据库进行交互、处理业务逻辑）以及对音视频数据的处理能力（如在app中实现视频的播放、暂停、截图等功能）。\n- **工程商或销售商环节**：工程商或销售商在音视频开发流程中更多地关注项目的实施和销售方面。工程商做工程的，大多不懂技术只懂施工，他们大多关心摄像头装在墙上还是天花板；用什么网线，网线怎么接；多久施工完。例如一个工程商接一个项目，买来解决方案进行某工厂、停车场的监控系统的建设。销售商则将智能家居方案卖给个人或家庭。虽然他们不直接参与音视频技术的开发，但他们在将音视频解决方案推向市场和实际应用场景方面起着重要的作用。\n\n### **五、用户端播放环节** \n\n在用户端播放环节，涉及到将接收到的音视频数据进行解码、渲染和播放的过程。这一环节需要播放器软件或设备来实现。播放器需要支持多种音视频格式和编码标准，例如能够解码H.264编码的视频和AAC编码的音频。在播放过程中，要进行音视频的同步操作，以保证音频和视频的时间戳一致，避免出现卡顿、不同步等问题。同时，用户端设备（如手机、电脑、智能电视等）的性能也会影响播放效果，如设备的处理器速度、内存大小、显卡性能等会影响视频的解码速度和渲染质量。\n\n# 音视频开发的关键步骤有哪些\n\n音视频开发的关键步骤是整个开发流程中的核心部分，它们对最终的开发效果和用户体验有着决定性的影响。\n\n### **一、编码与解码**\n\n- **编码的重要性和原理**：编码是音视频开发中不可或缺的关键步骤。其主要目的是为了压缩数据，节省带宽和传输时间。原始的音视频数据量通常非常大，例如一个1080P30帧，32bit色彩时长为1秒的视频文件，如果按每一帧画面进行存储的话，数据大小将会达到:32bit * 30 * 1080 * 1920≈237MB的空间，通过编码可以大大减小这个数据量。视频编码的主要作用是将视频像素数据（RGB，YUV等）压缩成为视频码流，从而降低视频的数据量。编码的基本原理包括空间冗余（图像相邻像素之间有较强的相关性）、时间冗余（视频序的相邻图像之间内容相似）、编码冗余（不同像素值出现的概率不同）、知识冗余（规性的结构可由先验知识和背景知识得到）等。例如，在背景色全部是黑色的情况下，我们实际上没有必要按照视频大小（1124 * 772）存储黑色，我们可以将存储黑色的像素点抽离出来记录，只存储其他像素点的颜色即可。常见的视频编码标准有H.264、H.265等，H.264具有低码率、高质量、高容错的特点，H.265对H.264在码率节省上有较大的优势，在相同RSNR下分别节省了48.3%和75.8%，但H.264在编码时间上有聚到优势，对比VP9和H.265，H.265是vp9的6倍，vp9是H.264的将近40倍。对于音频编码，常见的编码标准有AAC、MP3等。\n- **解码的作用和实现方式**：解码是编码的逆过程，其作用是将视频/音频压缩编码数据，解码成为非压缩的视频/音频原始数据。在整个音视频系统中，解码是非常重要也是最复杂的一个环节。解码可以使用软解码和硬解码两种方式。软解码就是利用CPU资源去解压缩数据，采用的方式是FFmpeg解码等。硬解码则是利用专门的硬件（如显卡等）来进行解码，对于iOS平台来说，可以使用VideoToolbox.Framework（该框架只能在iOS8.0及以上系统使用）硬解码视频数据。在播放音视频数据时，播放器端需要根据接收到的编码数据类型选择合适的解码方式进行解码，然后才能将解码后的原始数据进行播放。\n\n### **二、数据传输相关步骤**\n\n- **选择合适的流媒体传输协议**：在音视频开发中，选择合适的流媒体传输协议是关键。不同的协议适用于不同的场景和需求。例如RTMP（Real - Time Messaging Protocol）是目前主流的流媒体传输协议，基于TCP，设计用来进行实时数据通信，广泛用于直播领域，市面上绝大多数直播产品都采用了这个协议；HTTP Live Streaming（HLS）是由Apple公司定义的基于HTTP的流媒体实时传输协议，可实现流媒体的直播和点播，主要用于iOS系统，但它的分段推送的特点，决定了HLS的延迟一般会高于普通的流媒体直播协议；WebRTC（webrealtimecommunication）是一个支持网页浏览器进行实时语音或者视频对话的API，适用于网页端的实时音视频通信。在选择协议时，需要考虑到项目的应用场景（如直播、点播、实时通信等）、目标用户群体（如iOS用户、安卓用户、网页用户等）以及对延迟、带宽等方面\n\n\n\n文章合集：https://github.com/chongzicbo/ReadWriteThink\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","slug":"开发/音视频/音视频开发08：音视频开发基本步骤和流程","published":1,"updated":"2024-12-26T06:37:15.739Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3l000yhghidw1kfz3z","content":"<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241205155843570.png\" alt=\"image-20241205155843570\"></p>\n<h1 id=\"音视频开发的基本步骤\"><a href=\"#音视频开发的基本步骤\" class=\"headerlink\" title=\"音视频开发的基本步骤\"></a>音视频开发的基本步骤</h1><p>音视频开发是一个涉及多个技术领域的复杂过程，其基本步骤涵盖了从数据采集到最终播放展示的各个环节。</p>\n<h3 id=\"一、数据采集\"><a href=\"#一、数据采集\" class=\"headerlink\" title=\"一、数据采集\"></a><strong>一、数据采集</strong></h3><p> 数据采集是音视频开发的起始点，它解决的是数据从哪里来的问题。这一环节涉及到对声音和图像从现实世界转换为数字信号的操作。</p>\n<ul>\n<li><strong>设备选择</strong>：首先要选择合适的音视频采集设备。对于音频采集，麦克风是常见的设备；对于视频采集，摄像头则是常用的选择。不同的设备适用于不同的场景，例如在视频会议场景下，可能会选择高清摄像头来确保图像的清晰，而在语音通话场景中，会选用能够有效降低背景噪音的麦克风。</li>\n<li><strong>配置采集参数</strong>：针对不同的采集设备和采集场景，需要配置不同的采集参数。对于音频，重要的参数有采样率、位宽、声道数等。采样率指每秒从连续信号中提取并组成离散信号的采样个数，例如人耳能听到的最高频率为20kHz，为了满足人耳的听觉要求，采样率通常为44.1kHz或48kHz；位宽涉及到振幅量化，常见的有8位、16位、32位；声道数有单声道、双声道等。对于视频，图像传输格式、图像格式、传输通道、分辨率、采样频率等是关键参数。分辨率如常见的720P（1280×720）、1080P（1920×1080）等，帧率也是一个重要参数，它代表单位时间内帧的数量，单位是fps，像24&#x2F;25fps是一般电影的帧率，30&#x2F;60fps是游戏常见的帧率，30帧可以接受，60帧会感觉更加流畅逼真，85fps以上人眼基本无法察觉出差异，更高帧率在视频里意义不大。</li>\n<li><strong>开启采集设备</strong>：通过相应的API或SDK来开启采集设备。例如在Android系统中，视频采集可以使用Camera类，音频采集可以用AudioRecord来开启采集设备。在开启设备后，就可以进行数据的采集了。</li>\n<li><strong>采集音频和视频数据</strong>：采集设备获取音频信号并将其转换为数字信号，对于视频则是获取图像的数字信号。在采集过程中，可能会面临一些问题，如音频采集时可能会遇到噪音、回声等干扰，视频采集可能会存在延时敏感、图像质量受环境光影响等问题。同时，采集到的数据可能需要进行一些初步的处理，如音频的降噪、视频的格式转换等，以便后续的操作。例如在音频采集流程中，采集端将音频模拟信号转换为数字信号后，进入音频处理模块，会有音频增益、噪声抑制、混音等操作。</li>\n</ul>\n<h3 id=\"二、数据处理\"><a href=\"#二、数据处理\" class=\"headerlink\" title=\"二、数据处理\"></a><strong>二、数据处理</strong></h3><p>数据处理是对采集或获取的音视频数据进行加工，以实现特定的应用需求。</p>\n<ul>\n<li><strong>解码</strong>：如果采集到的数据是经过编码压缩的，那么首先需要进行解码操作，将其转换为原始的音视频信号。例如对于采用H.264编码的视频数据和AAC编码的音频数据，需要对应的解码器将其还原成原始信号，以便进行后续处理。</li>\n<li><strong>数据处理操作</strong>：这一步包含多种操作。在音频处理方面，有混音、降噪、声音特效等操作。例如混音可以将多个音频源混合成一个音频流；降噪可以减少环境噪音对音频质量的影响；声音特效则可以为音频添加特殊的效果，如回声、变声等。在视频处理方面，常见的有美颜、水印、自定义滤镜、自定义处理等。美颜操作可以通过磨皮、美白等手段来改善视频中的人物形象，磨皮可以采用均值模糊、高斯模糊和中值滤波等技术，同时可能结合人脸和皮肤检测技术；水印可以是播放器水印或者视频内嵌水印；自定义滤镜则可以根据需求创建各种独特的视觉效果。</li>\n<li><strong>编码和压缩</strong>：处理后的音视频数据需要进行编码，以将其转换为压缩的音视频数据流，从而减小数据量，便于存储和传输。对于视频编码，其主要作用是将视频像素数据（如RGB，YUV等）压缩成为视频码流，常见的视频编码标准有H.264、H.265等。H.264具有低码率、高质量、高容错的特点，H.265在码率节省上相比H.264有较大优势，在相同RSNR下分别节省了48.3%和75.8%，但H.264在编码时间上有优势。对于音频编码，常见的编码标准有AAC、MP3等。编码的基本原理包括利用空间冗余（图像相邻像素之间有较强的相关性）、时间冗余（视频序的相邻图像之间内容相似）、编码冗余（不同像素值出现的概率不同）、知识冗余（规性的结构可由先验知识和背景知识得到）等来进行压缩。在编码之后，可能还会进行进一步的压缩操作，以进一步减小数据量，提高传输和存储效率。</li>\n<li><strong>重采样和转码</strong>：重采样主要针对音频数据，改变采样率、位深度等参数，以适应不同的应用需求。例如将44100&#x2F;16&#x2F;2转成48000&#x2F;16&#x2F;2。转码是将音视频数据从一种格式转换为另一种格式，以适应不同的设备和应用环境，如将视频从MKV格式转码为MP4格式，以便在更多设备上播放。</li>\n<li><strong>合成操作</strong>：在一些场景下，需要将多个音视频流进行合成，例如将多个音频轨道、视频轨道合并成一个完整的音视频文件。比如在视频编辑软件中，将不同片段的视频和对应的音频合成一个完整的视频作品。</li>\n</ul>\n<h3 id=\"三、数据传输\"><a href=\"#三、数据传输\" class=\"headerlink\" title=\"三、数据传输\"></a><strong>三、数据传输</strong></h3><p> 数据传输是将采集、处理后的音视频数据流传输到远程设备或服务器的过程。</p>\n<ul>\n<li><strong>建立连接</strong>：通过网络协议建立连接，常见的网络协议有TCP和UDP等。TCP协议是一种可靠的面向连接的协议，适用于对数据准确性要求较高的场景，如文件传输；UDP协议是一种无连接的协议，传输速度快但可靠性相对较低，适用于对实时性要求较高的场景，如视频直播中的部分数据传输。</li>\n<li><strong>数据打包</strong>：将采集、处理后的音视频数据流打包为网络传输的格式，例如RTP、RTMP等协议。RTP（Real - time Transport Protocol）是一种实时传输协议，用于在IP网络上传输实时数据，通常与RTCP（RTP Control Protocol）一起使用，RTCP用于监控服务质量并提供反馈；RTMP（Real - Time Messaging Protocol）是基于TCP的实时消息传输协议，广泛用于直播领域。</li>\n<li><strong>压缩（如果需要）</strong>：在传输之前，可能还会对数据流进行压缩，以减小数据量和网络带宽占用。这一步与前面数据处理中的编码压缩类似，但可能会根据传输网络的情况进行进一步的优化，例如根据网络带宽动态调整压缩率。</li>\n<li><strong>传输数据</strong>：通过网络将打包和压缩后的数据流传输到远程设备或服务器。在传输过程中，需要考虑网络的稳定性、带宽等因素。如果网络带宽不足，可能会导致视频卡顿、音频中断等问题。</li>\n</ul>\n<h3 id=\"四、数据渲染与播放\"><a href=\"#四、数据渲染与播放\" class=\"headerlink\" title=\"四、数据渲染与播放\"></a><strong>四、数据渲染与播放</strong></h3><p>这一环节是将音视频数据流转换为可视化的音视频内容并播放的过程。</p>\n<ul>\n<li><strong>解码（再次解码）</strong>：将接收到的音视频数据流解码为原始的音视频信号。这一步与数据处理中的解码类似，但可能会因为传输过程中的一些情况（如数据丢失、错误等）而需要进行一些特殊的处理，例如纠错、数据恢复等。</li>\n<li><strong>帧缓存</strong>：将解码后的视频帧存储到缓存中，以供后续渲染。缓存的大小和管理方式会影响视频播放的流畅性，如果缓存过小，可能会导致视频播放时频繁卡顿；如果缓存过大，可能会增加内存占用和延迟。</li>\n<li><strong>视频渲染</strong>：通过OpenGL、DirectX等图形库将视频帧渲染到屏幕上，并可以添加相应的特效和滤镜等处理。这些图形库提供了强大的图形处理功能，可以实现视频的缩放、旋转、添加字幕等操作。</li>\n<li><strong>音频渲染</strong>：将音频信号转换为声音，并通过扬声器或耳机播放出来。在播放过程中，需要确保音频的音量、音质等符合要求，并且要与视频保持同步。</li>\n<li><strong>同步操作</strong>：将音视频进行同步，以保证音频和视频的时间戳一致，避免出现卡顿、不同步等问题。音视频同步是一个复杂的过程，需要考虑到采集、传输、处理等各个环节可能引入的时间差，通过调整播放速度、缓冲等方式来实现同步。</li>\n</ul>\n<h1 id=\"音视频开发流程包含哪些环节\"><a href=\"#音视频开发流程包含哪些环节\" class=\"headerlink\" title=\"音视频开发流程包含哪些环节\"></a>音视频开发流程包含哪些环节</h1><p>音视频开发流程包含多个环节，这些环节相互协作，共同完成从原始数据到可播放的音视频内容的转换。</p>\n<h3 id=\"一、芯片与元件相关环节\"><a href=\"#一、芯片与元件相关环节\" class=\"headerlink\" title=\"一、芯片与元件相关环节\"></a><strong>一、芯片与元件相关环节</strong></h3><ul>\n<li><strong>主芯片厂商环节</strong>：主芯片厂商，如海思、TI、安霸、联咏等，在音视频开发流程中处于基础地位。他们的核心在于各自的压缩算法，这些算法以SDK的方式开放给开发者使用。这些压缩算法是音视频编码的关键技术支撑，决定了音视频数据在采集、处理和传输过程中的压缩效率和质量。例如，一个好的视频压缩算法可以在保证视频质量的前提下，将视频数据量大大减小，从而节省存储空间和传输带宽。不同的主芯片厂商可能会有不同的技术优势和应用场景，开发者可以根据项目需求选择合适的芯片厂商的SDK进行开发。</li>\n<li><strong>传感器与分立元件厂商环节</strong>：传感器（senor）厂商、镜头等分立元件厂商也是重要的一环。传感器用于采集视频的原始数据，如摄像头中的图像传感器，它的性能直接影响到采集到的视频图像的质量，包括分辨率、色彩还原度、低光性能等。镜头则影响着视频的视角、焦距等参数。这些分立元件与主芯片相互配合，为后续的视频采集和处理提供基础的硬件条件。例如，一个高质量的镜头可以提供更清晰、更广阔的视野，与高分辨率的传感器相结合，可以采集到高质量的视频数据。</li>\n</ul>\n<h3 id=\"二、模组开发环节\"><a href=\"#二、模组开发环节\" class=\"headerlink\" title=\"二、模组开发环节\"></a><strong>二、模组开发环节</strong></h3><p>模组厂商在音视频开发流程中起着承上启下的作用。他们买来芯片、sensor、镜头等进行一些基础的开发，得出一些视频采集的模组，实现视频的采集、编码、传输。在这个环节中，模组厂商会将各种硬件元件集成在一起，并进行软件层面的开发，以实现视频的采集功能。他们需要对采集到的视频数据进行编码，将原始的视频数据转换为适合存储和传输的格式，例如采用H.264或H.265等视频编码标准进行编码。同时，还要实现视频数据的传输功能，确保编码后的视频数据能够在不同的设备之间进行传输。这个环节的开发成果是视频采集模组，它是整个音视频系统的重要组成部分，为后续的视频服务器和上层应用开发提供了基础的视频数据源。</p>\n<h3 id=\"三、视频服务器相关环节\"><a href=\"#三、视频服务器相关环节\" class=\"headerlink\" title=\"三、视频服务器相关环节\"></a><strong>三、视频服务器相关环节</strong></h3><ul>\n<li><strong>视频服务器厂商环节</strong>：视频服务器厂商，如大拿等，在音视频开发流程中负责让编码后的视频能够通过外网传输。他们先将视频推到服务器上，再通过服务器让多个客户端进行多线程的访问。视频服务器需要具备强大的网络处理能力，能够处理大量的视频流数据。在这个环节中，涉及到网络协议的应用，如采用合适的流媒体传输协议（如RTSP、RTMP、HLS等）将视频数据传输到服务器，并在服务器端进行相应的处理，如视频的存储、转发等操作。服务器还需要提供多线程访问的支持，以满足多个客户端同时访问视频数据的需求。</li>\n<li><strong>网络传输协议环节</strong>：网络传输协议在视频服务器相关环节中至关重要。不同的协议适用于不同的场景。RTSP（Real Time Streaming Protocol）是一种实时流传输协议，常用于视频监控等场景，它允许客户端对视频流进行暂停、快进等操作；RTMP（Real - Time Messaging Protocol）是基于TCP的实时消息传输协议，广泛应用于直播领域；HLS（HTTP Live Streaming）是由Apple公司定义的基于HTTP的流媒体实时传输协议，可实现流媒体的直播和点播，主要用于iOS系统。这些协议在视频数据的传输过程中，负责将视频数据从服务器传输到客户端，并且要保证视频的流畅播放和数据的准确性。</li>\n</ul>\n<h3 id=\"四、上层应用开发环节\"><a href=\"#四、上层应用开发环节\" class=\"headerlink\" title=\"四、上层应用开发环节\"></a><strong>四、上层应用开发环节</strong></h3><ul>\n<li><strong>面向解决方案的方案开发商环节</strong>：面向解决方案的方案开发商买来模组、视频服务器，进行一些更上层的开发，如app，web管理等。他们会将模组采集到的视频数据和视频服务器提供的视频流进行整合，开发出各种应用。例如，他们可以整合模组与服务器，做出手机app，如将摄像头放在幼儿园中，家长就可以通过app对校园内的环境进行查看；也可以开发人脸识别门禁、打卡方案，将传感器接入人脸识别功能，连接数据库制作一套系统。在这个环节中，开发者需要具备多种技术能力，包括前端开发（如开发手机app的界面）、后端开发（如与数据库进行交互、处理业务逻辑）以及对音视频数据的处理能力（如在app中实现视频的播放、暂停、截图等功能）。</li>\n<li><strong>工程商或销售商环节</strong>：工程商或销售商在音视频开发流程中更多地关注项目的实施和销售方面。工程商做工程的，大多不懂技术只懂施工，他们大多关心摄像头装在墙上还是天花板；用什么网线，网线怎么接；多久施工完。例如一个工程商接一个项目，买来解决方案进行某工厂、停车场的监控系统的建设。销售商则将智能家居方案卖给个人或家庭。虽然他们不直接参与音视频技术的开发，但他们在将音视频解决方案推向市场和实际应用场景方面起着重要的作用。</li>\n</ul>\n<h3 id=\"五、用户端播放环节\"><a href=\"#五、用户端播放环节\" class=\"headerlink\" title=\"五、用户端播放环节\"></a><strong>五、用户端播放环节</strong></h3><p>在用户端播放环节，涉及到将接收到的音视频数据进行解码、渲染和播放的过程。这一环节需要播放器软件或设备来实现。播放器需要支持多种音视频格式和编码标准，例如能够解码H.264编码的视频和AAC编码的音频。在播放过程中，要进行音视频的同步操作，以保证音频和视频的时间戳一致，避免出现卡顿、不同步等问题。同时，用户端设备（如手机、电脑、智能电视等）的性能也会影响播放效果，如设备的处理器速度、内存大小、显卡性能等会影响视频的解码速度和渲染质量。</p>\n<h1 id=\"音视频开发的关键步骤有哪些\"><a href=\"#音视频开发的关键步骤有哪些\" class=\"headerlink\" title=\"音视频开发的关键步骤有哪些\"></a>音视频开发的关键步骤有哪些</h1><p>音视频开发的关键步骤是整个开发流程中的核心部分，它们对最终的开发效果和用户体验有着决定性的影响。</p>\n<h3 id=\"一、编码与解码\"><a href=\"#一、编码与解码\" class=\"headerlink\" title=\"一、编码与解码\"></a><strong>一、编码与解码</strong></h3><ul>\n<li><strong>编码的重要性和原理</strong>：编码是音视频开发中不可或缺的关键步骤。其主要目的是为了压缩数据，节省带宽和传输时间。原始的音视频数据量通常非常大，例如一个1080P30帧，32bit色彩时长为1秒的视频文件，如果按每一帧画面进行存储的话，数据大小将会达到:32bit * 30 * 1080 * 1920≈237MB的空间，通过编码可以大大减小这个数据量。视频编码的主要作用是将视频像素数据（RGB，YUV等）压缩成为视频码流，从而降低视频的数据量。编码的基本原理包括空间冗余（图像相邻像素之间有较强的相关性）、时间冗余（视频序的相邻图像之间内容相似）、编码冗余（不同像素值出现的概率不同）、知识冗余（规性的结构可由先验知识和背景知识得到）等。例如，在背景色全部是黑色的情况下，我们实际上没有必要按照视频大小（1124 * 772）存储黑色，我们可以将存储黑色的像素点抽离出来记录，只存储其他像素点的颜色即可。常见的视频编码标准有H.264、H.265等，H.264具有低码率、高质量、高容错的特点，H.265对H.264在码率节省上有较大的优势，在相同RSNR下分别节省了48.3%和75.8%，但H.264在编码时间上有聚到优势，对比VP9和H.265，H.265是vp9的6倍，vp9是H.264的将近40倍。对于音频编码，常见的编码标准有AAC、MP3等。</li>\n<li><strong>解码的作用和实现方式</strong>：解码是编码的逆过程，其作用是将视频&#x2F;音频压缩编码数据，解码成为非压缩的视频&#x2F;音频原始数据。在整个音视频系统中，解码是非常重要也是最复杂的一个环节。解码可以使用软解码和硬解码两种方式。软解码就是利用CPU资源去解压缩数据，采用的方式是FFmpeg解码等。硬解码则是利用专门的硬件（如显卡等）来进行解码，对于iOS平台来说，可以使用VideoToolbox.Framework（该框架只能在iOS8.0及以上系统使用）硬解码视频数据。在播放音视频数据时，播放器端需要根据接收到的编码数据类型选择合适的解码方式进行解码，然后才能将解码后的原始数据进行播放。</li>\n</ul>\n<h3 id=\"二、数据传输相关步骤\"><a href=\"#二、数据传输相关步骤\" class=\"headerlink\" title=\"二、数据传输相关步骤\"></a><strong>二、数据传输相关步骤</strong></h3><ul>\n<li><strong>选择合适的流媒体传输协议</strong>：在音视频开发中，选择合适的流媒体传输协议是关键。不同的协议适用于不同的场景和需求。例如RTMP（Real - Time Messaging Protocol）是目前主流的流媒体传输协议，基于TCP，设计用来进行实时数据通信，广泛用于直播领域，市面上绝大多数直播产品都采用了这个协议；HTTP Live Streaming（HLS）是由Apple公司定义的基于HTTP的流媒体实时传输协议，可实现流媒体的直播和点播，主要用于iOS系统，但它的分段推送的特点，决定了HLS的延迟一般会高于普通的流媒体直播协议；WebRTC（webrealtimecommunication）是一个支持网页浏览器进行实时语音或者视频对话的API，适用于网页端的实时音视频通信。在选择协议时，需要考虑到项目的应用场景（如直播、点播、实时通信等）、目标用户群体（如iOS用户、安卓用户、网页用户等）以及对延迟、带宽等方面</li>\n</ul>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink\">https://github.com/chongzicbo/ReadWriteThink</a></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n","excerpt":"","more":"<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241205155843570.png\" alt=\"image-20241205155843570\"></p>\n<h1 id=\"音视频开发的基本步骤\"><a href=\"#音视频开发的基本步骤\" class=\"headerlink\" title=\"音视频开发的基本步骤\"></a>音视频开发的基本步骤</h1><p>音视频开发是一个涉及多个技术领域的复杂过程，其基本步骤涵盖了从数据采集到最终播放展示的各个环节。</p>\n<h3 id=\"一、数据采集\"><a href=\"#一、数据采集\" class=\"headerlink\" title=\"一、数据采集\"></a><strong>一、数据采集</strong></h3><p> 数据采集是音视频开发的起始点，它解决的是数据从哪里来的问题。这一环节涉及到对声音和图像从现实世界转换为数字信号的操作。</p>\n<ul>\n<li><strong>设备选择</strong>：首先要选择合适的音视频采集设备。对于音频采集，麦克风是常见的设备；对于视频采集，摄像头则是常用的选择。不同的设备适用于不同的场景，例如在视频会议场景下，可能会选择高清摄像头来确保图像的清晰，而在语音通话场景中，会选用能够有效降低背景噪音的麦克风。</li>\n<li><strong>配置采集参数</strong>：针对不同的采集设备和采集场景，需要配置不同的采集参数。对于音频，重要的参数有采样率、位宽、声道数等。采样率指每秒从连续信号中提取并组成离散信号的采样个数，例如人耳能听到的最高频率为20kHz，为了满足人耳的听觉要求，采样率通常为44.1kHz或48kHz；位宽涉及到振幅量化，常见的有8位、16位、32位；声道数有单声道、双声道等。对于视频，图像传输格式、图像格式、传输通道、分辨率、采样频率等是关键参数。分辨率如常见的720P（1280×720）、1080P（1920×1080）等，帧率也是一个重要参数，它代表单位时间内帧的数量，单位是fps，像24&#x2F;25fps是一般电影的帧率，30&#x2F;60fps是游戏常见的帧率，30帧可以接受，60帧会感觉更加流畅逼真，85fps以上人眼基本无法察觉出差异，更高帧率在视频里意义不大。</li>\n<li><strong>开启采集设备</strong>：通过相应的API或SDK来开启采集设备。例如在Android系统中，视频采集可以使用Camera类，音频采集可以用AudioRecord来开启采集设备。在开启设备后，就可以进行数据的采集了。</li>\n<li><strong>采集音频和视频数据</strong>：采集设备获取音频信号并将其转换为数字信号，对于视频则是获取图像的数字信号。在采集过程中，可能会面临一些问题，如音频采集时可能会遇到噪音、回声等干扰，视频采集可能会存在延时敏感、图像质量受环境光影响等问题。同时，采集到的数据可能需要进行一些初步的处理，如音频的降噪、视频的格式转换等，以便后续的操作。例如在音频采集流程中，采集端将音频模拟信号转换为数字信号后，进入音频处理模块，会有音频增益、噪声抑制、混音等操作。</li>\n</ul>\n<h3 id=\"二、数据处理\"><a href=\"#二、数据处理\" class=\"headerlink\" title=\"二、数据处理\"></a><strong>二、数据处理</strong></h3><p>数据处理是对采集或获取的音视频数据进行加工，以实现特定的应用需求。</p>\n<ul>\n<li><strong>解码</strong>：如果采集到的数据是经过编码压缩的，那么首先需要进行解码操作，将其转换为原始的音视频信号。例如对于采用H.264编码的视频数据和AAC编码的音频数据，需要对应的解码器将其还原成原始信号，以便进行后续处理。</li>\n<li><strong>数据处理操作</strong>：这一步包含多种操作。在音频处理方面，有混音、降噪、声音特效等操作。例如混音可以将多个音频源混合成一个音频流；降噪可以减少环境噪音对音频质量的影响；声音特效则可以为音频添加特殊的效果，如回声、变声等。在视频处理方面，常见的有美颜、水印、自定义滤镜、自定义处理等。美颜操作可以通过磨皮、美白等手段来改善视频中的人物形象，磨皮可以采用均值模糊、高斯模糊和中值滤波等技术，同时可能结合人脸和皮肤检测技术；水印可以是播放器水印或者视频内嵌水印；自定义滤镜则可以根据需求创建各种独特的视觉效果。</li>\n<li><strong>编码和压缩</strong>：处理后的音视频数据需要进行编码，以将其转换为压缩的音视频数据流，从而减小数据量，便于存储和传输。对于视频编码，其主要作用是将视频像素数据（如RGB，YUV等）压缩成为视频码流，常见的视频编码标准有H.264、H.265等。H.264具有低码率、高质量、高容错的特点，H.265在码率节省上相比H.264有较大优势，在相同RSNR下分别节省了48.3%和75.8%，但H.264在编码时间上有优势。对于音频编码，常见的编码标准有AAC、MP3等。编码的基本原理包括利用空间冗余（图像相邻像素之间有较强的相关性）、时间冗余（视频序的相邻图像之间内容相似）、编码冗余（不同像素值出现的概率不同）、知识冗余（规性的结构可由先验知识和背景知识得到）等来进行压缩。在编码之后，可能还会进行进一步的压缩操作，以进一步减小数据量，提高传输和存储效率。</li>\n<li><strong>重采样和转码</strong>：重采样主要针对音频数据，改变采样率、位深度等参数，以适应不同的应用需求。例如将44100&#x2F;16&#x2F;2转成48000&#x2F;16&#x2F;2。转码是将音视频数据从一种格式转换为另一种格式，以适应不同的设备和应用环境，如将视频从MKV格式转码为MP4格式，以便在更多设备上播放。</li>\n<li><strong>合成操作</strong>：在一些场景下，需要将多个音视频流进行合成，例如将多个音频轨道、视频轨道合并成一个完整的音视频文件。比如在视频编辑软件中，将不同片段的视频和对应的音频合成一个完整的视频作品。</li>\n</ul>\n<h3 id=\"三、数据传输\"><a href=\"#三、数据传输\" class=\"headerlink\" title=\"三、数据传输\"></a><strong>三、数据传输</strong></h3><p> 数据传输是将采集、处理后的音视频数据流传输到远程设备或服务器的过程。</p>\n<ul>\n<li><strong>建立连接</strong>：通过网络协议建立连接，常见的网络协议有TCP和UDP等。TCP协议是一种可靠的面向连接的协议，适用于对数据准确性要求较高的场景，如文件传输；UDP协议是一种无连接的协议，传输速度快但可靠性相对较低，适用于对实时性要求较高的场景，如视频直播中的部分数据传输。</li>\n<li><strong>数据打包</strong>：将采集、处理后的音视频数据流打包为网络传输的格式，例如RTP、RTMP等协议。RTP（Real - time Transport Protocol）是一种实时传输协议，用于在IP网络上传输实时数据，通常与RTCP（RTP Control Protocol）一起使用，RTCP用于监控服务质量并提供反馈；RTMP（Real - Time Messaging Protocol）是基于TCP的实时消息传输协议，广泛用于直播领域。</li>\n<li><strong>压缩（如果需要）</strong>：在传输之前，可能还会对数据流进行压缩，以减小数据量和网络带宽占用。这一步与前面数据处理中的编码压缩类似，但可能会根据传输网络的情况进行进一步的优化，例如根据网络带宽动态调整压缩率。</li>\n<li><strong>传输数据</strong>：通过网络将打包和压缩后的数据流传输到远程设备或服务器。在传输过程中，需要考虑网络的稳定性、带宽等因素。如果网络带宽不足，可能会导致视频卡顿、音频中断等问题。</li>\n</ul>\n<h3 id=\"四、数据渲染与播放\"><a href=\"#四、数据渲染与播放\" class=\"headerlink\" title=\"四、数据渲染与播放\"></a><strong>四、数据渲染与播放</strong></h3><p>这一环节是将音视频数据流转换为可视化的音视频内容并播放的过程。</p>\n<ul>\n<li><strong>解码（再次解码）</strong>：将接收到的音视频数据流解码为原始的音视频信号。这一步与数据处理中的解码类似，但可能会因为传输过程中的一些情况（如数据丢失、错误等）而需要进行一些特殊的处理，例如纠错、数据恢复等。</li>\n<li><strong>帧缓存</strong>：将解码后的视频帧存储到缓存中，以供后续渲染。缓存的大小和管理方式会影响视频播放的流畅性，如果缓存过小，可能会导致视频播放时频繁卡顿；如果缓存过大，可能会增加内存占用和延迟。</li>\n<li><strong>视频渲染</strong>：通过OpenGL、DirectX等图形库将视频帧渲染到屏幕上，并可以添加相应的特效和滤镜等处理。这些图形库提供了强大的图形处理功能，可以实现视频的缩放、旋转、添加字幕等操作。</li>\n<li><strong>音频渲染</strong>：将音频信号转换为声音，并通过扬声器或耳机播放出来。在播放过程中，需要确保音频的音量、音质等符合要求，并且要与视频保持同步。</li>\n<li><strong>同步操作</strong>：将音视频进行同步，以保证音频和视频的时间戳一致，避免出现卡顿、不同步等问题。音视频同步是一个复杂的过程，需要考虑到采集、传输、处理等各个环节可能引入的时间差，通过调整播放速度、缓冲等方式来实现同步。</li>\n</ul>\n<h1 id=\"音视频开发流程包含哪些环节\"><a href=\"#音视频开发流程包含哪些环节\" class=\"headerlink\" title=\"音视频开发流程包含哪些环节\"></a>音视频开发流程包含哪些环节</h1><p>音视频开发流程包含多个环节，这些环节相互协作，共同完成从原始数据到可播放的音视频内容的转换。</p>\n<h3 id=\"一、芯片与元件相关环节\"><a href=\"#一、芯片与元件相关环节\" class=\"headerlink\" title=\"一、芯片与元件相关环节\"></a><strong>一、芯片与元件相关环节</strong></h3><ul>\n<li><strong>主芯片厂商环节</strong>：主芯片厂商，如海思、TI、安霸、联咏等，在音视频开发流程中处于基础地位。他们的核心在于各自的压缩算法，这些算法以SDK的方式开放给开发者使用。这些压缩算法是音视频编码的关键技术支撑，决定了音视频数据在采集、处理和传输过程中的压缩效率和质量。例如，一个好的视频压缩算法可以在保证视频质量的前提下，将视频数据量大大减小，从而节省存储空间和传输带宽。不同的主芯片厂商可能会有不同的技术优势和应用场景，开发者可以根据项目需求选择合适的芯片厂商的SDK进行开发。</li>\n<li><strong>传感器与分立元件厂商环节</strong>：传感器（senor）厂商、镜头等分立元件厂商也是重要的一环。传感器用于采集视频的原始数据，如摄像头中的图像传感器，它的性能直接影响到采集到的视频图像的质量，包括分辨率、色彩还原度、低光性能等。镜头则影响着视频的视角、焦距等参数。这些分立元件与主芯片相互配合，为后续的视频采集和处理提供基础的硬件条件。例如，一个高质量的镜头可以提供更清晰、更广阔的视野，与高分辨率的传感器相结合，可以采集到高质量的视频数据。</li>\n</ul>\n<h3 id=\"二、模组开发环节\"><a href=\"#二、模组开发环节\" class=\"headerlink\" title=\"二、模组开发环节\"></a><strong>二、模组开发环节</strong></h3><p>模组厂商在音视频开发流程中起着承上启下的作用。他们买来芯片、sensor、镜头等进行一些基础的开发，得出一些视频采集的模组，实现视频的采集、编码、传输。在这个环节中，模组厂商会将各种硬件元件集成在一起，并进行软件层面的开发，以实现视频的采集功能。他们需要对采集到的视频数据进行编码，将原始的视频数据转换为适合存储和传输的格式，例如采用H.264或H.265等视频编码标准进行编码。同时，还要实现视频数据的传输功能，确保编码后的视频数据能够在不同的设备之间进行传输。这个环节的开发成果是视频采集模组，它是整个音视频系统的重要组成部分，为后续的视频服务器和上层应用开发提供了基础的视频数据源。</p>\n<h3 id=\"三、视频服务器相关环节\"><a href=\"#三、视频服务器相关环节\" class=\"headerlink\" title=\"三、视频服务器相关环节\"></a><strong>三、视频服务器相关环节</strong></h3><ul>\n<li><strong>视频服务器厂商环节</strong>：视频服务器厂商，如大拿等，在音视频开发流程中负责让编码后的视频能够通过外网传输。他们先将视频推到服务器上，再通过服务器让多个客户端进行多线程的访问。视频服务器需要具备强大的网络处理能力，能够处理大量的视频流数据。在这个环节中，涉及到网络协议的应用，如采用合适的流媒体传输协议（如RTSP、RTMP、HLS等）将视频数据传输到服务器，并在服务器端进行相应的处理，如视频的存储、转发等操作。服务器还需要提供多线程访问的支持，以满足多个客户端同时访问视频数据的需求。</li>\n<li><strong>网络传输协议环节</strong>：网络传输协议在视频服务器相关环节中至关重要。不同的协议适用于不同的场景。RTSP（Real Time Streaming Protocol）是一种实时流传输协议，常用于视频监控等场景，它允许客户端对视频流进行暂停、快进等操作；RTMP（Real - Time Messaging Protocol）是基于TCP的实时消息传输协议，广泛应用于直播领域；HLS（HTTP Live Streaming）是由Apple公司定义的基于HTTP的流媒体实时传输协议，可实现流媒体的直播和点播，主要用于iOS系统。这些协议在视频数据的传输过程中，负责将视频数据从服务器传输到客户端，并且要保证视频的流畅播放和数据的准确性。</li>\n</ul>\n<h3 id=\"四、上层应用开发环节\"><a href=\"#四、上层应用开发环节\" class=\"headerlink\" title=\"四、上层应用开发环节\"></a><strong>四、上层应用开发环节</strong></h3><ul>\n<li><strong>面向解决方案的方案开发商环节</strong>：面向解决方案的方案开发商买来模组、视频服务器，进行一些更上层的开发，如app，web管理等。他们会将模组采集到的视频数据和视频服务器提供的视频流进行整合，开发出各种应用。例如，他们可以整合模组与服务器，做出手机app，如将摄像头放在幼儿园中，家长就可以通过app对校园内的环境进行查看；也可以开发人脸识别门禁、打卡方案，将传感器接入人脸识别功能，连接数据库制作一套系统。在这个环节中，开发者需要具备多种技术能力，包括前端开发（如开发手机app的界面）、后端开发（如与数据库进行交互、处理业务逻辑）以及对音视频数据的处理能力（如在app中实现视频的播放、暂停、截图等功能）。</li>\n<li><strong>工程商或销售商环节</strong>：工程商或销售商在音视频开发流程中更多地关注项目的实施和销售方面。工程商做工程的，大多不懂技术只懂施工，他们大多关心摄像头装在墙上还是天花板；用什么网线，网线怎么接；多久施工完。例如一个工程商接一个项目，买来解决方案进行某工厂、停车场的监控系统的建设。销售商则将智能家居方案卖给个人或家庭。虽然他们不直接参与音视频技术的开发，但他们在将音视频解决方案推向市场和实际应用场景方面起着重要的作用。</li>\n</ul>\n<h3 id=\"五、用户端播放环节\"><a href=\"#五、用户端播放环节\" class=\"headerlink\" title=\"五、用户端播放环节\"></a><strong>五、用户端播放环节</strong></h3><p>在用户端播放环节，涉及到将接收到的音视频数据进行解码、渲染和播放的过程。这一环节需要播放器软件或设备来实现。播放器需要支持多种音视频格式和编码标准，例如能够解码H.264编码的视频和AAC编码的音频。在播放过程中，要进行音视频的同步操作，以保证音频和视频的时间戳一致，避免出现卡顿、不同步等问题。同时，用户端设备（如手机、电脑、智能电视等）的性能也会影响播放效果，如设备的处理器速度、内存大小、显卡性能等会影响视频的解码速度和渲染质量。</p>\n<h1 id=\"音视频开发的关键步骤有哪些\"><a href=\"#音视频开发的关键步骤有哪些\" class=\"headerlink\" title=\"音视频开发的关键步骤有哪些\"></a>音视频开发的关键步骤有哪些</h1><p>音视频开发的关键步骤是整个开发流程中的核心部分，它们对最终的开发效果和用户体验有着决定性的影响。</p>\n<h3 id=\"一、编码与解码\"><a href=\"#一、编码与解码\" class=\"headerlink\" title=\"一、编码与解码\"></a><strong>一、编码与解码</strong></h3><ul>\n<li><strong>编码的重要性和原理</strong>：编码是音视频开发中不可或缺的关键步骤。其主要目的是为了压缩数据，节省带宽和传输时间。原始的音视频数据量通常非常大，例如一个1080P30帧，32bit色彩时长为1秒的视频文件，如果按每一帧画面进行存储的话，数据大小将会达到:32bit * 30 * 1080 * 1920≈237MB的空间，通过编码可以大大减小这个数据量。视频编码的主要作用是将视频像素数据（RGB，YUV等）压缩成为视频码流，从而降低视频的数据量。编码的基本原理包括空间冗余（图像相邻像素之间有较强的相关性）、时间冗余（视频序的相邻图像之间内容相似）、编码冗余（不同像素值出现的概率不同）、知识冗余（规性的结构可由先验知识和背景知识得到）等。例如，在背景色全部是黑色的情况下，我们实际上没有必要按照视频大小（1124 * 772）存储黑色，我们可以将存储黑色的像素点抽离出来记录，只存储其他像素点的颜色即可。常见的视频编码标准有H.264、H.265等，H.264具有低码率、高质量、高容错的特点，H.265对H.264在码率节省上有较大的优势，在相同RSNR下分别节省了48.3%和75.8%，但H.264在编码时间上有聚到优势，对比VP9和H.265，H.265是vp9的6倍，vp9是H.264的将近40倍。对于音频编码，常见的编码标准有AAC、MP3等。</li>\n<li><strong>解码的作用和实现方式</strong>：解码是编码的逆过程，其作用是将视频&#x2F;音频压缩编码数据，解码成为非压缩的视频&#x2F;音频原始数据。在整个音视频系统中，解码是非常重要也是最复杂的一个环节。解码可以使用软解码和硬解码两种方式。软解码就是利用CPU资源去解压缩数据，采用的方式是FFmpeg解码等。硬解码则是利用专门的硬件（如显卡等）来进行解码，对于iOS平台来说，可以使用VideoToolbox.Framework（该框架只能在iOS8.0及以上系统使用）硬解码视频数据。在播放音视频数据时，播放器端需要根据接收到的编码数据类型选择合适的解码方式进行解码，然后才能将解码后的原始数据进行播放。</li>\n</ul>\n<h3 id=\"二、数据传输相关步骤\"><a href=\"#二、数据传输相关步骤\" class=\"headerlink\" title=\"二、数据传输相关步骤\"></a><strong>二、数据传输相关步骤</strong></h3><ul>\n<li><strong>选择合适的流媒体传输协议</strong>：在音视频开发中，选择合适的流媒体传输协议是关键。不同的协议适用于不同的场景和需求。例如RTMP（Real - Time Messaging Protocol）是目前主流的流媒体传输协议，基于TCP，设计用来进行实时数据通信，广泛用于直播领域，市面上绝大多数直播产品都采用了这个协议；HTTP Live Streaming（HLS）是由Apple公司定义的基于HTTP的流媒体实时传输协议，可实现流媒体的直播和点播，主要用于iOS系统，但它的分段推送的特点，决定了HLS的延迟一般会高于普通的流媒体直播协议；WebRTC（webrealtimecommunication）是一个支持网页浏览器进行实时语音或者视频对话的API，适用于网页端的实时音视频通信。在选择协议时，需要考虑到项目的应用场景（如直播、点播、实时通信等）、目标用户群体（如iOS用户、安卓用户、网页用户等）以及对延迟、带宽等方面</li>\n</ul>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink\">https://github.com/chongzicbo/ReadWriteThink</a></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n"},{"title":"音视频开发01：RGB和YUV颜色模型详解","date":"2024-12-05T03:37:00.000Z","_content":"\n\n\n# 1. RGB颜色模型\n\nRGB（Red, Green, Blue）颜色模型是一种加色模型，通过混合不同强度的红、绿、蓝三种基本颜色来生成各种颜色。RGB模型广泛应用于显示器、电视、摄像机等设备中。\n\n### 1.1 基本概念\n- **红色（Red）**：表示红色光的强度。\n- **绿色（Green）**：表示绿色光的强度。\n- **蓝色（Blue）**：表示蓝色光的强度。\n\n### 1.2 颜色表示\n- 每个颜色通道（R、G、B）通常使用8位（0-255）或16位（0-65535）来表示强度。\n- 例如，纯红色表示为 `(255, 0, 0)`，纯绿色为 `(0, 255, 0)`，纯蓝色为 `(0, 0, 255)`。\n- 白色为 `(255, 255, 255)`，黑色为 `(0, 0, 0)`。\n\n### 1.3 优点\n- **直观**：RGB模型直接对应显示器的发光原理，易于理解和实现。\n- **广泛应用**：适用于大多数显示设备和图像处理软件。\n\n### 1.4 缺点\n- **空间不均匀**：人眼对不同颜色的敏感度不同，RGB模型在颜色空间上不够均匀。\n- **不适合传输**：RGB数据量大，不适合直接用于视频传输和存储。\n\n# 2.YUV颜色模型\n\nYUV颜色模型是一种用于视频压缩和传输的颜色模型，它将亮度（Y）和色度（U、V）分开表示。YUV模型广泛应用于电视广播、视频编码等领域。\n\n### 2.1 基本概念\n- **Y（Luminance）**：表示亮度信息，即图像的灰度值。\n- **U（Chrominance）**：表示蓝色和亮度之间的差异。\n- **V（Chrominance）**：表示红色和亮度之间的差异。\n\n### 2.2  颜色表示\n- YUV模型中，Y通常使用8位（0-255）表示亮度。\n- U和V通常使用8位（-128到127）表示色度。\n- 例如，YUV值 `(128, 0, 0)` 表示中等亮度的灰色，没有颜色偏差。\n\n### 2.3 优点\n- **压缩效率高**：YUV模型将亮度和色度分开，可以进行色度子采样（如4:2:0、4:2:2），减少数据量。\n- **适合传输**：YUV模型适合用于视频压缩和传输，如MPEG、H.264等标准。\n\n### 2.4 缺点\n- **不直观**：YUV模型不如RGB模型直观，需要转换才能在显示器上显示。\n- **转换复杂**：从RGB到YUV的转换涉及复杂的数学运算。\n\n#  3. YUV相比RGB的优势\n\nYUV颜色模型相对于RGB颜色模型具有以下几个显著的优势，特别是在视频处理和传输领域：\n\n### 3.1 压缩效率高\n- **色度子采样**：YUV模型将亮度和色度信息分开表示，可以对色度信息进行子采样（如4:2:0、4:2:2），从而减少数据量。人眼对亮度的变化更为敏感，对色度的变化相对不敏感，因此可以减少色度信息的采样率而不显著影响视觉质量。\n- **数据量减少**：通过色度子采样，YUV模型可以显著减少视频数据的存储和传输需求，提高压缩效率。\n\n### 3.2 适合视频传输\n- **带宽优化**：在视频传输中，YUV模型通过减少色度信息的带宽占用，可以更有效地利用有限的带宽资源。\n- **兼容性**：YUV模型广泛应用于电视广播和视频编码标准（如MPEG、H.264等），具有良好的兼容性和广泛的应用基础。\n\n### 3.3 视觉感知优化\n- **亮度优先**：YUV模型将亮度信息（Y）单独表示，更符合人眼对亮度的敏感性。在视频处理中，可以优先保证亮度信息的准确性，从而提高视觉质量。\n- **色度调整**：通过调整色度信息（U、V），可以在不影响亮度的情况下进行颜色校正和调整，更适合视频后期处理。\n\n### 3.4 历史和标准支持\n- **历史悠久**：YUV模型起源于模拟电视系统（如PAL和NTSC），经过多年的发展和优化，已经成为视频处理和传输的标准模型。\n- **标准支持**：YUV模型被广泛应用于各种视频编码标准和传输协议中，具有强大的标准支持和生态系统。\n\n### 3.5 计算复杂度\n- **转换简单**：虽然从RGB到YUV的转换涉及一定的数学运算，但在视频处理中，这种转换通常是批量进行的，计算复杂度相对可控。\n- **硬件支持**：现代视频处理硬件（如GPU、专用视频处理器）通常支持YUV模型的处理和转换，具有较高的计算效率。\n\n### 3.6 总结\nYUV模型在视频处理和传输中具有显著的优势，特别是在压缩效率、带宽优化、视觉感知优化和标准支持方面。尽管RGB模型在显示器和图像处理中更为直观和直接，但在视频领域，YUV模型因其高效的数据压缩和传输特性而成为主流选择。\n\n# 4. RGB与YUV的转换\n\n### 4.1 RGB到YUV的转换公式\n- **Y** = 0.299R + 0.587G + 0.114B\n- **U** = 0.492(B - Y)\n- **V** = 0.877(R - Y)\n\n### 4.2 YUV到RGB的转换公式\n- **R** = Y + 1.140V\n- **G** = Y - 0.395U - 0.581V\n- **B** = Y + 2.032U\n\n### 4.3 总结\n- **RGB模型**：适用于显示器和图像处理，直观但不适合传输。\n- **YUV模型**：适用于视频压缩和传输，压缩效率高但不够直观。\n\n在实际应用中，通常根据需求选择合适的颜色模型，并在不同模型之间进行转换。\n\n# 5. YUV的采样方式\n\n下面我们通过具体的例子来解释YUV的各种采样方式，以便更好地理解它们的工作原理和效果。\n\n### 5.1  4:4:4 采样\n\n**例子**：假设有一个4x2像素的图像，每个像素的Y、U、V分量都进行采样。\n\n| 像素 | Y    | U    | V    |\n| ---- | ---- | ---- | ---- |\n| 1    | Y1   | U1   | V1   |\n| 2    | Y2   | U2   | V2   |\n| 3    | Y3   | U3   | V3   |\n| 4    | Y4   | U4   | V4   |\n| 5    | Y5   | U5   | V5   |\n| 6    | Y6   | U6   | V6   |\n| 7    | Y7   | U7   | V7   |\n| 8    | Y8   | U8   | V8   |\n\n**解释**：每个像素都有完整的Y、U、V信息，没有进行任何压缩。这种采样方式提供了最高质量的图像，但数据量最大。\n\n### 5.2  4:2:2 采样\n\n**例子**：假设有一个4x2像素的图像，每两个像素共享一个U和V分量。\n\n| 像素 | Y    | U    | V    |\n| ---- | ---- | ---- | ---- |\n| 1    | Y1   | U1   |      |\n| 2    | Y2   |      | V2   |\n| 3    | Y3   | U3   |      |\n| 4    | Y4   |      | V4   |\n| 5    | Y5   | U5   |      |\n| 6    | Y6   |      | V6   |\n| 7    | Y7   | U7   |      |\n| 8    | Y8   |      | V8   |\n\n**解释**：每两个像素中，第一个像素采样Y、U，第二个像素采样Y、V。这种采样方式减少了U和V分量的数据量，但仍然保留了较高的图像质量。\n\n### 5.3  4:2:0 采样\n\n**例子**：假设有一个4x2像素的图像，每四个像素共享一个U和V分量。\n\n| 像素 | Y    | U    | V    |\n| ---- | ---- | ---- | ---- |\n| 1    | Y1   | U1   |      |\n| 2    | Y2   |      |      |\n| 3    | Y3   |      | V3   |\n| 4    | Y4   |      |      |\n| 5    | Y5   | U5   |      |\n| 6    | Y6   |      |      |\n| 7    | Y7   |      | V7   |\n| 8    | Y8   |      |      |\n\n**解释**：每四个像素中，第一个像素采样Y、U，第三个像素采样Y、V，其他像素只采样Y。这种采样方式显著减少了U和V分量的数据量，适用于对数据量要求较高的场景，如数字电视、DVD和流媒体。\n\n### 5.4  4:1:1 采样\n\n**例子**：假设有一个4x2像素的图像，每四个像素共享一个U和V分量。\n\n| 像素 | Y    | U    | V    |\n| ---- | ---- | ---- | ---- |\n| 1    | Y1   | U1   |      |\n| 2    | Y2   |      |      |\n| 3    | Y3   |      | V3   |\n| 4    | Y4   |      |      |\n| 5    | Y5   | U5   |      |\n| 6    | Y6   |      |      |\n| 7    | Y7   |      | V7   |\n| 8    | Y8   |      |      |\n\n**解释**：每四个像素中，第一个像素采样Y、U，第三个像素采样Y、V，其他像素只采样Y。这种采样方式与4:2:0类似，但较少使用，主要在一些旧的视频编码标准中。\n\n### 5.5 总结\n\n通过这些例子，我们可以看到不同YUV采样方式对数据量的影响和图像质量的权衡。4:4:4采样提供最高质量，但数据量最大；4:2:2采样在质量和数据量之间取得平衡；4:2:0采样在保证视觉质量的前提下，最大限度地减少数据量，广泛应用于数字电视、DVD和流媒体等领域。\n\n# 6.举例说明YUV和RGB的存储差异\n\n我们来比较一下RGB和YUV各个采样方式在存储方面的差异。假设我们有一个4x2像素的图像，每个像素的RGB值用8位表示（0-255）。\n\n### 6.1 RGB存储\n\n每个像素有3个分量（R、G、B），每个分量占用8位。\n\n**总存储量**：\n- 每个像素：3字节（24位）\n- 4x2像素图像：4 * 2 * 3 = 24字节\n\n### 6.2 YUV存储\n\n#### 6.2.1 YUV 4:4:4 采样\n\n每个像素有3个分量（Y、U、V），每个分量占用8位。\n\n**总存储量**：\n- 每个像素：3字节（24位）\n- 4x2像素图像：4 * 2 * 3 = 24字节\n\n**比较**：\n- RGB和YUV 4:4:4采样的存储量相同，都是24字节。\n\n#### 6.2.2 YUV 4:2:2 采样\n\n每两个像素共享一个U和V分量。\n\n**总存储量**：\n- Y分量：4 * 2 = 8字节\n- U分量：4 * 2 / 2 = 4字节\n- V分量：4 * 2 / 2 = 4字节\n- 总存储量：8 + 4 + 4 = 16字节\n\n**比较**：\n- YUV 4:2:2采样的存储量比RGB少8字节（16字节 vs 24字节）。\n\n#### 6.2.3 YUV 4:2:0 采样\n\n每四个像素共享一个U和V分量。\n\n**总存储量**：\n- Y分量：4 * 2 = 8字节\n- U分量：4 * 2 / 4 = 2字节\n- V分量：4 * 2 / 4 = 2字节\n- 总存储量：8 + 2 + 2 = 12字节\n\n**比较**：\n- YUV 4:2:0采样的存储量比RGB少12字节（12字节 vs 24字节）。\n\n### 总结\n\n| 采样方式  | 存储量（字节） | 与RGB相比的差异 |\n| --------- | -------------- | --------------- |\n| RGB       | 24             | 0               |\n| YUV 4:4:4 | 24             | 0               |\n| YUV 4:2:2 | 16             | -8              |\n| YUV 4:2:0 | 12             | -12             |\n\n通过这个例子，我们可以清楚地看到YUV采样方式在存储方面的优势。YUV 4:4:4采样与RGB存储量相同，而YUV 4:2:2和YUV 4:2:0采样分别比RGB减少了8字节和12字节的存储量。这种存储量的减少在处理大尺寸图像或视频时尤为显著，有助于提高数据传输和存储的效率。\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","source":"_posts/开发/音视频/音视频开发01：RGB和YUV颜色模型详解.md","raw":"---\ntitle: '音视频开发01：RGB和YUV颜色模型详解'\ncategories:\n  - [开发,音视频,基础]\ntags:\n  - 音视频开发\n  - 音视频基础\ndate: 2024-12-05 11:37:00\n---\n\n\n\n# 1. RGB颜色模型\n\nRGB（Red, Green, Blue）颜色模型是一种加色模型，通过混合不同强度的红、绿、蓝三种基本颜色来生成各种颜色。RGB模型广泛应用于显示器、电视、摄像机等设备中。\n\n### 1.1 基本概念\n- **红色（Red）**：表示红色光的强度。\n- **绿色（Green）**：表示绿色光的强度。\n- **蓝色（Blue）**：表示蓝色光的强度。\n\n### 1.2 颜色表示\n- 每个颜色通道（R、G、B）通常使用8位（0-255）或16位（0-65535）来表示强度。\n- 例如，纯红色表示为 `(255, 0, 0)`，纯绿色为 `(0, 255, 0)`，纯蓝色为 `(0, 0, 255)`。\n- 白色为 `(255, 255, 255)`，黑色为 `(0, 0, 0)`。\n\n### 1.3 优点\n- **直观**：RGB模型直接对应显示器的发光原理，易于理解和实现。\n- **广泛应用**：适用于大多数显示设备和图像处理软件。\n\n### 1.4 缺点\n- **空间不均匀**：人眼对不同颜色的敏感度不同，RGB模型在颜色空间上不够均匀。\n- **不适合传输**：RGB数据量大，不适合直接用于视频传输和存储。\n\n# 2.YUV颜色模型\n\nYUV颜色模型是一种用于视频压缩和传输的颜色模型，它将亮度（Y）和色度（U、V）分开表示。YUV模型广泛应用于电视广播、视频编码等领域。\n\n### 2.1 基本概念\n- **Y（Luminance）**：表示亮度信息，即图像的灰度值。\n- **U（Chrominance）**：表示蓝色和亮度之间的差异。\n- **V（Chrominance）**：表示红色和亮度之间的差异。\n\n### 2.2  颜色表示\n- YUV模型中，Y通常使用8位（0-255）表示亮度。\n- U和V通常使用8位（-128到127）表示色度。\n- 例如，YUV值 `(128, 0, 0)` 表示中等亮度的灰色，没有颜色偏差。\n\n### 2.3 优点\n- **压缩效率高**：YUV模型将亮度和色度分开，可以进行色度子采样（如4:2:0、4:2:2），减少数据量。\n- **适合传输**：YUV模型适合用于视频压缩和传输，如MPEG、H.264等标准。\n\n### 2.4 缺点\n- **不直观**：YUV模型不如RGB模型直观，需要转换才能在显示器上显示。\n- **转换复杂**：从RGB到YUV的转换涉及复杂的数学运算。\n\n#  3. YUV相比RGB的优势\n\nYUV颜色模型相对于RGB颜色模型具有以下几个显著的优势，特别是在视频处理和传输领域：\n\n### 3.1 压缩效率高\n- **色度子采样**：YUV模型将亮度和色度信息分开表示，可以对色度信息进行子采样（如4:2:0、4:2:2），从而减少数据量。人眼对亮度的变化更为敏感，对色度的变化相对不敏感，因此可以减少色度信息的采样率而不显著影响视觉质量。\n- **数据量减少**：通过色度子采样，YUV模型可以显著减少视频数据的存储和传输需求，提高压缩效率。\n\n### 3.2 适合视频传输\n- **带宽优化**：在视频传输中，YUV模型通过减少色度信息的带宽占用，可以更有效地利用有限的带宽资源。\n- **兼容性**：YUV模型广泛应用于电视广播和视频编码标准（如MPEG、H.264等），具有良好的兼容性和广泛的应用基础。\n\n### 3.3 视觉感知优化\n- **亮度优先**：YUV模型将亮度信息（Y）单独表示，更符合人眼对亮度的敏感性。在视频处理中，可以优先保证亮度信息的准确性，从而提高视觉质量。\n- **色度调整**：通过调整色度信息（U、V），可以在不影响亮度的情况下进行颜色校正和调整，更适合视频后期处理。\n\n### 3.4 历史和标准支持\n- **历史悠久**：YUV模型起源于模拟电视系统（如PAL和NTSC），经过多年的发展和优化，已经成为视频处理和传输的标准模型。\n- **标准支持**：YUV模型被广泛应用于各种视频编码标准和传输协议中，具有强大的标准支持和生态系统。\n\n### 3.5 计算复杂度\n- **转换简单**：虽然从RGB到YUV的转换涉及一定的数学运算，但在视频处理中，这种转换通常是批量进行的，计算复杂度相对可控。\n- **硬件支持**：现代视频处理硬件（如GPU、专用视频处理器）通常支持YUV模型的处理和转换，具有较高的计算效率。\n\n### 3.6 总结\nYUV模型在视频处理和传输中具有显著的优势，特别是在压缩效率、带宽优化、视觉感知优化和标准支持方面。尽管RGB模型在显示器和图像处理中更为直观和直接，但在视频领域，YUV模型因其高效的数据压缩和传输特性而成为主流选择。\n\n# 4. RGB与YUV的转换\n\n### 4.1 RGB到YUV的转换公式\n- **Y** = 0.299R + 0.587G + 0.114B\n- **U** = 0.492(B - Y)\n- **V** = 0.877(R - Y)\n\n### 4.2 YUV到RGB的转换公式\n- **R** = Y + 1.140V\n- **G** = Y - 0.395U - 0.581V\n- **B** = Y + 2.032U\n\n### 4.3 总结\n- **RGB模型**：适用于显示器和图像处理，直观但不适合传输。\n- **YUV模型**：适用于视频压缩和传输，压缩效率高但不够直观。\n\n在实际应用中，通常根据需求选择合适的颜色模型，并在不同模型之间进行转换。\n\n# 5. YUV的采样方式\n\n下面我们通过具体的例子来解释YUV的各种采样方式，以便更好地理解它们的工作原理和效果。\n\n### 5.1  4:4:4 采样\n\n**例子**：假设有一个4x2像素的图像，每个像素的Y、U、V分量都进行采样。\n\n| 像素 | Y    | U    | V    |\n| ---- | ---- | ---- | ---- |\n| 1    | Y1   | U1   | V1   |\n| 2    | Y2   | U2   | V2   |\n| 3    | Y3   | U3   | V3   |\n| 4    | Y4   | U4   | V4   |\n| 5    | Y5   | U5   | V5   |\n| 6    | Y6   | U6   | V6   |\n| 7    | Y7   | U7   | V7   |\n| 8    | Y8   | U8   | V8   |\n\n**解释**：每个像素都有完整的Y、U、V信息，没有进行任何压缩。这种采样方式提供了最高质量的图像，但数据量最大。\n\n### 5.2  4:2:2 采样\n\n**例子**：假设有一个4x2像素的图像，每两个像素共享一个U和V分量。\n\n| 像素 | Y    | U    | V    |\n| ---- | ---- | ---- | ---- |\n| 1    | Y1   | U1   |      |\n| 2    | Y2   |      | V2   |\n| 3    | Y3   | U3   |      |\n| 4    | Y4   |      | V4   |\n| 5    | Y5   | U5   |      |\n| 6    | Y6   |      | V6   |\n| 7    | Y7   | U7   |      |\n| 8    | Y8   |      | V8   |\n\n**解释**：每两个像素中，第一个像素采样Y、U，第二个像素采样Y、V。这种采样方式减少了U和V分量的数据量，但仍然保留了较高的图像质量。\n\n### 5.3  4:2:0 采样\n\n**例子**：假设有一个4x2像素的图像，每四个像素共享一个U和V分量。\n\n| 像素 | Y    | U    | V    |\n| ---- | ---- | ---- | ---- |\n| 1    | Y1   | U1   |      |\n| 2    | Y2   |      |      |\n| 3    | Y3   |      | V3   |\n| 4    | Y4   |      |      |\n| 5    | Y5   | U5   |      |\n| 6    | Y6   |      |      |\n| 7    | Y7   |      | V7   |\n| 8    | Y8   |      |      |\n\n**解释**：每四个像素中，第一个像素采样Y、U，第三个像素采样Y、V，其他像素只采样Y。这种采样方式显著减少了U和V分量的数据量，适用于对数据量要求较高的场景，如数字电视、DVD和流媒体。\n\n### 5.4  4:1:1 采样\n\n**例子**：假设有一个4x2像素的图像，每四个像素共享一个U和V分量。\n\n| 像素 | Y    | U    | V    |\n| ---- | ---- | ---- | ---- |\n| 1    | Y1   | U1   |      |\n| 2    | Y2   |      |      |\n| 3    | Y3   |      | V3   |\n| 4    | Y4   |      |      |\n| 5    | Y5   | U5   |      |\n| 6    | Y6   |      |      |\n| 7    | Y7   |      | V7   |\n| 8    | Y8   |      |      |\n\n**解释**：每四个像素中，第一个像素采样Y、U，第三个像素采样Y、V，其他像素只采样Y。这种采样方式与4:2:0类似，但较少使用，主要在一些旧的视频编码标准中。\n\n### 5.5 总结\n\n通过这些例子，我们可以看到不同YUV采样方式对数据量的影响和图像质量的权衡。4:4:4采样提供最高质量，但数据量最大；4:2:2采样在质量和数据量之间取得平衡；4:2:0采样在保证视觉质量的前提下，最大限度地减少数据量，广泛应用于数字电视、DVD和流媒体等领域。\n\n# 6.举例说明YUV和RGB的存储差异\n\n我们来比较一下RGB和YUV各个采样方式在存储方面的差异。假设我们有一个4x2像素的图像，每个像素的RGB值用8位表示（0-255）。\n\n### 6.1 RGB存储\n\n每个像素有3个分量（R、G、B），每个分量占用8位。\n\n**总存储量**：\n- 每个像素：3字节（24位）\n- 4x2像素图像：4 * 2 * 3 = 24字节\n\n### 6.2 YUV存储\n\n#### 6.2.1 YUV 4:4:4 采样\n\n每个像素有3个分量（Y、U、V），每个分量占用8位。\n\n**总存储量**：\n- 每个像素：3字节（24位）\n- 4x2像素图像：4 * 2 * 3 = 24字节\n\n**比较**：\n- RGB和YUV 4:4:4采样的存储量相同，都是24字节。\n\n#### 6.2.2 YUV 4:2:2 采样\n\n每两个像素共享一个U和V分量。\n\n**总存储量**：\n- Y分量：4 * 2 = 8字节\n- U分量：4 * 2 / 2 = 4字节\n- V分量：4 * 2 / 2 = 4字节\n- 总存储量：8 + 4 + 4 = 16字节\n\n**比较**：\n- YUV 4:2:2采样的存储量比RGB少8字节（16字节 vs 24字节）。\n\n#### 6.2.3 YUV 4:2:0 采样\n\n每四个像素共享一个U和V分量。\n\n**总存储量**：\n- Y分量：4 * 2 = 8字节\n- U分量：4 * 2 / 4 = 2字节\n- V分量：4 * 2 / 4 = 2字节\n- 总存储量：8 + 2 + 2 = 12字节\n\n**比较**：\n- YUV 4:2:0采样的存储量比RGB少12字节（12字节 vs 24字节）。\n\n### 总结\n\n| 采样方式  | 存储量（字节） | 与RGB相比的差异 |\n| --------- | -------------- | --------------- |\n| RGB       | 24             | 0               |\n| YUV 4:4:4 | 24             | 0               |\n| YUV 4:2:2 | 16             | -8              |\n| YUV 4:2:0 | 12             | -12             |\n\n通过这个例子，我们可以清楚地看到YUV采样方式在存储方面的优势。YUV 4:4:4采样与RGB存储量相同，而YUV 4:2:2和YUV 4:2:0采样分别比RGB减少了8字节和12字节的存储量。这种存储量的减少在处理大尺寸图像或视频时尤为显著，有助于提高数据传输和存储的效率。\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","slug":"开发/音视频/音视频开发01：RGB和YUV颜色模型详解","published":1,"updated":"2024-12-26T07:41:17.402Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3l0012hghic2ao6wp7","content":"<h1 id=\"1-RGB颜色模型\"><a href=\"#1-RGB颜色模型\" class=\"headerlink\" title=\"1. RGB颜色模型\"></a>1. RGB颜色模型</h1><p>RGB（Red, Green, Blue）颜色模型是一种加色模型，通过混合不同强度的红、绿、蓝三种基本颜色来生成各种颜色。RGB模型广泛应用于显示器、电视、摄像机等设备中。</p>\n<h3 id=\"1-1-基本概念\"><a href=\"#1-1-基本概念\" class=\"headerlink\" title=\"1.1 基本概念\"></a>1.1 基本概念</h3><ul>\n<li><strong>红色（Red）</strong>：表示红色光的强度。</li>\n<li><strong>绿色（Green）</strong>：表示绿色光的强度。</li>\n<li><strong>蓝色（Blue）</strong>：表示蓝色光的强度。</li>\n</ul>\n<h3 id=\"1-2-颜色表示\"><a href=\"#1-2-颜色表示\" class=\"headerlink\" title=\"1.2 颜色表示\"></a>1.2 颜色表示</h3><ul>\n<li>每个颜色通道（R、G、B）通常使用8位（0-255）或16位（0-65535）来表示强度。</li>\n<li>例如，纯红色表示为 <code>(255, 0, 0)</code>，纯绿色为 <code>(0, 255, 0)</code>，纯蓝色为 <code>(0, 0, 255)</code>。</li>\n<li>白色为 <code>(255, 255, 255)</code>，黑色为 <code>(0, 0, 0)</code>。</li>\n</ul>\n<h3 id=\"1-3-优点\"><a href=\"#1-3-优点\" class=\"headerlink\" title=\"1.3 优点\"></a>1.3 优点</h3><ul>\n<li><strong>直观</strong>：RGB模型直接对应显示器的发光原理，易于理解和实现。</li>\n<li><strong>广泛应用</strong>：适用于大多数显示设备和图像处理软件。</li>\n</ul>\n<h3 id=\"1-4-缺点\"><a href=\"#1-4-缺点\" class=\"headerlink\" title=\"1.4 缺点\"></a>1.4 缺点</h3><ul>\n<li><strong>空间不均匀</strong>：人眼对不同颜色的敏感度不同，RGB模型在颜色空间上不够均匀。</li>\n<li><strong>不适合传输</strong>：RGB数据量大，不适合直接用于视频传输和存储。</li>\n</ul>\n<h1 id=\"2-YUV颜色模型\"><a href=\"#2-YUV颜色模型\" class=\"headerlink\" title=\"2.YUV颜色模型\"></a>2.YUV颜色模型</h1><p>YUV颜色模型是一种用于视频压缩和传输的颜色模型，它将亮度（Y）和色度（U、V）分开表示。YUV模型广泛应用于电视广播、视频编码等领域。</p>\n<h3 id=\"2-1-基本概念\"><a href=\"#2-1-基本概念\" class=\"headerlink\" title=\"2.1 基本概念\"></a>2.1 基本概念</h3><ul>\n<li><strong>Y（Luminance）</strong>：表示亮度信息，即图像的灰度值。</li>\n<li><strong>U（Chrominance）</strong>：表示蓝色和亮度之间的差异。</li>\n<li><strong>V（Chrominance）</strong>：表示红色和亮度之间的差异。</li>\n</ul>\n<h3 id=\"2-2-颜色表示\"><a href=\"#2-2-颜色表示\" class=\"headerlink\" title=\"2.2  颜色表示\"></a>2.2  颜色表示</h3><ul>\n<li>YUV模型中，Y通常使用8位（0-255）表示亮度。</li>\n<li>U和V通常使用8位（-128到127）表示色度。</li>\n<li>例如，YUV值 <code>(128, 0, 0)</code> 表示中等亮度的灰色，没有颜色偏差。</li>\n</ul>\n<h3 id=\"2-3-优点\"><a href=\"#2-3-优点\" class=\"headerlink\" title=\"2.3 优点\"></a>2.3 优点</h3><ul>\n<li><strong>压缩效率高</strong>：YUV模型将亮度和色度分开，可以进行色度子采样（如4:2:0、4:2:2），减少数据量。</li>\n<li><strong>适合传输</strong>：YUV模型适合用于视频压缩和传输，如MPEG、H.264等标准。</li>\n</ul>\n<h3 id=\"2-4-缺点\"><a href=\"#2-4-缺点\" class=\"headerlink\" title=\"2.4 缺点\"></a>2.4 缺点</h3><ul>\n<li><strong>不直观</strong>：YUV模型不如RGB模型直观，需要转换才能在显示器上显示。</li>\n<li><strong>转换复杂</strong>：从RGB到YUV的转换涉及复杂的数学运算。</li>\n</ul>\n<h1 id=\"3-YUV相比RGB的优势\"><a href=\"#3-YUV相比RGB的优势\" class=\"headerlink\" title=\"3. YUV相比RGB的优势\"></a>3. YUV相比RGB的优势</h1><p>YUV颜色模型相对于RGB颜色模型具有以下几个显著的优势，特别是在视频处理和传输领域：</p>\n<h3 id=\"3-1-压缩效率高\"><a href=\"#3-1-压缩效率高\" class=\"headerlink\" title=\"3.1 压缩效率高\"></a>3.1 压缩效率高</h3><ul>\n<li><strong>色度子采样</strong>：YUV模型将亮度和色度信息分开表示，可以对色度信息进行子采样（如4:2:0、4:2:2），从而减少数据量。人眼对亮度的变化更为敏感，对色度的变化相对不敏感，因此可以减少色度信息的采样率而不显著影响视觉质量。</li>\n<li><strong>数据量减少</strong>：通过色度子采样，YUV模型可以显著减少视频数据的存储和传输需求，提高压缩效率。</li>\n</ul>\n<h3 id=\"3-2-适合视频传输\"><a href=\"#3-2-适合视频传输\" class=\"headerlink\" title=\"3.2 适合视频传输\"></a>3.2 适合视频传输</h3><ul>\n<li><strong>带宽优化</strong>：在视频传输中，YUV模型通过减少色度信息的带宽占用，可以更有效地利用有限的带宽资源。</li>\n<li><strong>兼容性</strong>：YUV模型广泛应用于电视广播和视频编码标准（如MPEG、H.264等），具有良好的兼容性和广泛的应用基础。</li>\n</ul>\n<h3 id=\"3-3-视觉感知优化\"><a href=\"#3-3-视觉感知优化\" class=\"headerlink\" title=\"3.3 视觉感知优化\"></a>3.3 视觉感知优化</h3><ul>\n<li><strong>亮度优先</strong>：YUV模型将亮度信息（Y）单独表示，更符合人眼对亮度的敏感性。在视频处理中，可以优先保证亮度信息的准确性，从而提高视觉质量。</li>\n<li><strong>色度调整</strong>：通过调整色度信息（U、V），可以在不影响亮度的情况下进行颜色校正和调整，更适合视频后期处理。</li>\n</ul>\n<h3 id=\"3-4-历史和标准支持\"><a href=\"#3-4-历史和标准支持\" class=\"headerlink\" title=\"3.4 历史和标准支持\"></a>3.4 历史和标准支持</h3><ul>\n<li><strong>历史悠久</strong>：YUV模型起源于模拟电视系统（如PAL和NTSC），经过多年的发展和优化，已经成为视频处理和传输的标准模型。</li>\n<li><strong>标准支持</strong>：YUV模型被广泛应用于各种视频编码标准和传输协议中，具有强大的标准支持和生态系统。</li>\n</ul>\n<h3 id=\"3-5-计算复杂度\"><a href=\"#3-5-计算复杂度\" class=\"headerlink\" title=\"3.5 计算复杂度\"></a>3.5 计算复杂度</h3><ul>\n<li><strong>转换简单</strong>：虽然从RGB到YUV的转换涉及一定的数学运算，但在视频处理中，这种转换通常是批量进行的，计算复杂度相对可控。</li>\n<li><strong>硬件支持</strong>：现代视频处理硬件（如GPU、专用视频处理器）通常支持YUV模型的处理和转换，具有较高的计算效率。</li>\n</ul>\n<h3 id=\"3-6-总结\"><a href=\"#3-6-总结\" class=\"headerlink\" title=\"3.6 总结\"></a>3.6 总结</h3><p>YUV模型在视频处理和传输中具有显著的优势，特别是在压缩效率、带宽优化、视觉感知优化和标准支持方面。尽管RGB模型在显示器和图像处理中更为直观和直接，但在视频领域，YUV模型因其高效的数据压缩和传输特性而成为主流选择。</p>\n<h1 id=\"4-RGB与YUV的转换\"><a href=\"#4-RGB与YUV的转换\" class=\"headerlink\" title=\"4. RGB与YUV的转换\"></a>4. RGB与YUV的转换</h1><h3 id=\"4-1-RGB到YUV的转换公式\"><a href=\"#4-1-RGB到YUV的转换公式\" class=\"headerlink\" title=\"4.1 RGB到YUV的转换公式\"></a>4.1 RGB到YUV的转换公式</h3><ul>\n<li><strong>Y</strong> &#x3D; 0.299R + 0.587G + 0.114B</li>\n<li><strong>U</strong> &#x3D; 0.492(B - Y)</li>\n<li><strong>V</strong> &#x3D; 0.877(R - Y)</li>\n</ul>\n<h3 id=\"4-2-YUV到RGB的转换公式\"><a href=\"#4-2-YUV到RGB的转换公式\" class=\"headerlink\" title=\"4.2 YUV到RGB的转换公式\"></a>4.2 YUV到RGB的转换公式</h3><ul>\n<li><strong>R</strong> &#x3D; Y + 1.140V</li>\n<li><strong>G</strong> &#x3D; Y - 0.395U - 0.581V</li>\n<li><strong>B</strong> &#x3D; Y + 2.032U</li>\n</ul>\n<h3 id=\"4-3-总结\"><a href=\"#4-3-总结\" class=\"headerlink\" title=\"4.3 总结\"></a>4.3 总结</h3><ul>\n<li><strong>RGB模型</strong>：适用于显示器和图像处理，直观但不适合传输。</li>\n<li><strong>YUV模型</strong>：适用于视频压缩和传输，压缩效率高但不够直观。</li>\n</ul>\n<p>在实际应用中，通常根据需求选择合适的颜色模型，并在不同模型之间进行转换。</p>\n<h1 id=\"5-YUV的采样方式\"><a href=\"#5-YUV的采样方式\" class=\"headerlink\" title=\"5. YUV的采样方式\"></a>5. YUV的采样方式</h1><p>下面我们通过具体的例子来解释YUV的各种采样方式，以便更好地理解它们的工作原理和效果。</p>\n<h3 id=\"5-1-4-4-4-采样\"><a href=\"#5-1-4-4-4-采样\" class=\"headerlink\" title=\"5.1  4:4:4 采样\"></a>5.1  4:4:4 采样</h3><p><strong>例子</strong>：假设有一个4x2像素的图像，每个像素的Y、U、V分量都进行采样。</p>\n<table>\n<thead>\n<tr>\n<th>像素</th>\n<th>Y</th>\n<th>U</th>\n<th>V</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>Y1</td>\n<td>U1</td>\n<td>V1</td>\n</tr>\n<tr>\n<td>2</td>\n<td>Y2</td>\n<td>U2</td>\n<td>V2</td>\n</tr>\n<tr>\n<td>3</td>\n<td>Y3</td>\n<td>U3</td>\n<td>V3</td>\n</tr>\n<tr>\n<td>4</td>\n<td>Y4</td>\n<td>U4</td>\n<td>V4</td>\n</tr>\n<tr>\n<td>5</td>\n<td>Y5</td>\n<td>U5</td>\n<td>V5</td>\n</tr>\n<tr>\n<td>6</td>\n<td>Y6</td>\n<td>U6</td>\n<td>V6</td>\n</tr>\n<tr>\n<td>7</td>\n<td>Y7</td>\n<td>U7</td>\n<td>V7</td>\n</tr>\n<tr>\n<td>8</td>\n<td>Y8</td>\n<td>U8</td>\n<td>V8</td>\n</tr>\n</tbody></table>\n<p><strong>解释</strong>：每个像素都有完整的Y、U、V信息，没有进行任何压缩。这种采样方式提供了最高质量的图像，但数据量最大。</p>\n<h3 id=\"5-2-4-2-2-采样\"><a href=\"#5-2-4-2-2-采样\" class=\"headerlink\" title=\"5.2  4:2:2 采样\"></a>5.2  4:2:2 采样</h3><p><strong>例子</strong>：假设有一个4x2像素的图像，每两个像素共享一个U和V分量。</p>\n<table>\n<thead>\n<tr>\n<th>像素</th>\n<th>Y</th>\n<th>U</th>\n<th>V</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>Y1</td>\n<td>U1</td>\n<td></td>\n</tr>\n<tr>\n<td>2</td>\n<td>Y2</td>\n<td></td>\n<td>V2</td>\n</tr>\n<tr>\n<td>3</td>\n<td>Y3</td>\n<td>U3</td>\n<td></td>\n</tr>\n<tr>\n<td>4</td>\n<td>Y4</td>\n<td></td>\n<td>V4</td>\n</tr>\n<tr>\n<td>5</td>\n<td>Y5</td>\n<td>U5</td>\n<td></td>\n</tr>\n<tr>\n<td>6</td>\n<td>Y6</td>\n<td></td>\n<td>V6</td>\n</tr>\n<tr>\n<td>7</td>\n<td>Y7</td>\n<td>U7</td>\n<td></td>\n</tr>\n<tr>\n<td>8</td>\n<td>Y8</td>\n<td></td>\n<td>V8</td>\n</tr>\n</tbody></table>\n<p><strong>解释</strong>：每两个像素中，第一个像素采样Y、U，第二个像素采样Y、V。这种采样方式减少了U和V分量的数据量，但仍然保留了较高的图像质量。</p>\n<h3 id=\"5-3-4-2-0-采样\"><a href=\"#5-3-4-2-0-采样\" class=\"headerlink\" title=\"5.3  4:2:0 采样\"></a>5.3  4:2:0 采样</h3><p><strong>例子</strong>：假设有一个4x2像素的图像，每四个像素共享一个U和V分量。</p>\n<table>\n<thead>\n<tr>\n<th>像素</th>\n<th>Y</th>\n<th>U</th>\n<th>V</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>Y1</td>\n<td>U1</td>\n<td></td>\n</tr>\n<tr>\n<td>2</td>\n<td>Y2</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>3</td>\n<td>Y3</td>\n<td></td>\n<td>V3</td>\n</tr>\n<tr>\n<td>4</td>\n<td>Y4</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>5</td>\n<td>Y5</td>\n<td>U5</td>\n<td></td>\n</tr>\n<tr>\n<td>6</td>\n<td>Y6</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>7</td>\n<td>Y7</td>\n<td></td>\n<td>V7</td>\n</tr>\n<tr>\n<td>8</td>\n<td>Y8</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p><strong>解释</strong>：每四个像素中，第一个像素采样Y、U，第三个像素采样Y、V，其他像素只采样Y。这种采样方式显著减少了U和V分量的数据量，适用于对数据量要求较高的场景，如数字电视、DVD和流媒体。</p>\n<h3 id=\"5-4-4-1-1-采样\"><a href=\"#5-4-4-1-1-采样\" class=\"headerlink\" title=\"5.4  4:1:1 采样\"></a>5.4  4:1:1 采样</h3><p><strong>例子</strong>：假设有一个4x2像素的图像，每四个像素共享一个U和V分量。</p>\n<table>\n<thead>\n<tr>\n<th>像素</th>\n<th>Y</th>\n<th>U</th>\n<th>V</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>Y1</td>\n<td>U1</td>\n<td></td>\n</tr>\n<tr>\n<td>2</td>\n<td>Y2</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>3</td>\n<td>Y3</td>\n<td></td>\n<td>V3</td>\n</tr>\n<tr>\n<td>4</td>\n<td>Y4</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>5</td>\n<td>Y5</td>\n<td>U5</td>\n<td></td>\n</tr>\n<tr>\n<td>6</td>\n<td>Y6</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>7</td>\n<td>Y7</td>\n<td></td>\n<td>V7</td>\n</tr>\n<tr>\n<td>8</td>\n<td>Y8</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p><strong>解释</strong>：每四个像素中，第一个像素采样Y、U，第三个像素采样Y、V，其他像素只采样Y。这种采样方式与4:2:0类似，但较少使用，主要在一些旧的视频编码标准中。</p>\n<h3 id=\"5-5-总结\"><a href=\"#5-5-总结\" class=\"headerlink\" title=\"5.5 总结\"></a>5.5 总结</h3><p>通过这些例子，我们可以看到不同YUV采样方式对数据量的影响和图像质量的权衡。4:4:4采样提供最高质量，但数据量最大；4:2:2采样在质量和数据量之间取得平衡；4:2:0采样在保证视觉质量的前提下，最大限度地减少数据量，广泛应用于数字电视、DVD和流媒体等领域。</p>\n<h1 id=\"6-举例说明YUV和RGB的存储差异\"><a href=\"#6-举例说明YUV和RGB的存储差异\" class=\"headerlink\" title=\"6.举例说明YUV和RGB的存储差异\"></a>6.举例说明YUV和RGB的存储差异</h1><p>我们来比较一下RGB和YUV各个采样方式在存储方面的差异。假设我们有一个4x2像素的图像，每个像素的RGB值用8位表示（0-255）。</p>\n<h3 id=\"6-1-RGB存储\"><a href=\"#6-1-RGB存储\" class=\"headerlink\" title=\"6.1 RGB存储\"></a>6.1 RGB存储</h3><p>每个像素有3个分量（R、G、B），每个分量占用8位。</p>\n<p><strong>总存储量</strong>：</p>\n<ul>\n<li>每个像素：3字节（24位）</li>\n<li>4x2像素图像：4 * 2 * 3 &#x3D; 24字节</li>\n</ul>\n<h3 id=\"6-2-YUV存储\"><a href=\"#6-2-YUV存储\" class=\"headerlink\" title=\"6.2 YUV存储\"></a>6.2 YUV存储</h3><h4 id=\"6-2-1-YUV-4-4-4-采样\"><a href=\"#6-2-1-YUV-4-4-4-采样\" class=\"headerlink\" title=\"6.2.1 YUV 4:4:4 采样\"></a>6.2.1 YUV 4:4:4 采样</h4><p>每个像素有3个分量（Y、U、V），每个分量占用8位。</p>\n<p><strong>总存储量</strong>：</p>\n<ul>\n<li>每个像素：3字节（24位）</li>\n<li>4x2像素图像：4 * 2 * 3 &#x3D; 24字节</li>\n</ul>\n<p><strong>比较</strong>：</p>\n<ul>\n<li>RGB和YUV 4:4:4采样的存储量相同，都是24字节。</li>\n</ul>\n<h4 id=\"6-2-2-YUV-4-2-2-采样\"><a href=\"#6-2-2-YUV-4-2-2-采样\" class=\"headerlink\" title=\"6.2.2 YUV 4:2:2 采样\"></a>6.2.2 YUV 4:2:2 采样</h4><p>每两个像素共享一个U和V分量。</p>\n<p><strong>总存储量</strong>：</p>\n<ul>\n<li>Y分量：4 * 2 &#x3D; 8字节</li>\n<li>U分量：4 * 2 &#x2F; 2 &#x3D; 4字节</li>\n<li>V分量：4 * 2 &#x2F; 2 &#x3D; 4字节</li>\n<li>总存储量：8 + 4 + 4 &#x3D; 16字节</li>\n</ul>\n<p><strong>比较</strong>：</p>\n<ul>\n<li>YUV 4:2:2采样的存储量比RGB少8字节（16字节 vs 24字节）。</li>\n</ul>\n<h4 id=\"6-2-3-YUV-4-2-0-采样\"><a href=\"#6-2-3-YUV-4-2-0-采样\" class=\"headerlink\" title=\"6.2.3 YUV 4:2:0 采样\"></a>6.2.3 YUV 4:2:0 采样</h4><p>每四个像素共享一个U和V分量。</p>\n<p><strong>总存储量</strong>：</p>\n<ul>\n<li>Y分量：4 * 2 &#x3D; 8字节</li>\n<li>U分量：4 * 2 &#x2F; 4 &#x3D; 2字节</li>\n<li>V分量：4 * 2 &#x2F; 4 &#x3D; 2字节</li>\n<li>总存储量：8 + 2 + 2 &#x3D; 12字节</li>\n</ul>\n<p><strong>比较</strong>：</p>\n<ul>\n<li>YUV 4:2:0采样的存储量比RGB少12字节（12字节 vs 24字节）。</li>\n</ul>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><table>\n<thead>\n<tr>\n<th>采样方式</th>\n<th>存储量（字节）</th>\n<th>与RGB相比的差异</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>RGB</td>\n<td>24</td>\n<td>0</td>\n</tr>\n<tr>\n<td>YUV 4:4:4</td>\n<td>24</td>\n<td>0</td>\n</tr>\n<tr>\n<td>YUV 4:2:2</td>\n<td>16</td>\n<td>-8</td>\n</tr>\n<tr>\n<td>YUV 4:2:0</td>\n<td>12</td>\n<td>-12</td>\n</tr>\n</tbody></table>\n<p>通过这个例子，我们可以清楚地看到YUV采样方式在存储方面的优势。YUV 4:4:4采样与RGB存储量相同，而YUV 4:2:2和YUV 4:2:0采样分别比RGB减少了8字节和12字节的存储量。这种存储量的减少在处理大尺寸图像或视频时尤为显著，有助于提高数据传输和存储的效率。</p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n","excerpt":"","more":"<h1 id=\"1-RGB颜色模型\"><a href=\"#1-RGB颜色模型\" class=\"headerlink\" title=\"1. RGB颜色模型\"></a>1. RGB颜色模型</h1><p>RGB（Red, Green, Blue）颜色模型是一种加色模型，通过混合不同强度的红、绿、蓝三种基本颜色来生成各种颜色。RGB模型广泛应用于显示器、电视、摄像机等设备中。</p>\n<h3 id=\"1-1-基本概念\"><a href=\"#1-1-基本概念\" class=\"headerlink\" title=\"1.1 基本概念\"></a>1.1 基本概念</h3><ul>\n<li><strong>红色（Red）</strong>：表示红色光的强度。</li>\n<li><strong>绿色（Green）</strong>：表示绿色光的强度。</li>\n<li><strong>蓝色（Blue）</strong>：表示蓝色光的强度。</li>\n</ul>\n<h3 id=\"1-2-颜色表示\"><a href=\"#1-2-颜色表示\" class=\"headerlink\" title=\"1.2 颜色表示\"></a>1.2 颜色表示</h3><ul>\n<li>每个颜色通道（R、G、B）通常使用8位（0-255）或16位（0-65535）来表示强度。</li>\n<li>例如，纯红色表示为 <code>(255, 0, 0)</code>，纯绿色为 <code>(0, 255, 0)</code>，纯蓝色为 <code>(0, 0, 255)</code>。</li>\n<li>白色为 <code>(255, 255, 255)</code>，黑色为 <code>(0, 0, 0)</code>。</li>\n</ul>\n<h3 id=\"1-3-优点\"><a href=\"#1-3-优点\" class=\"headerlink\" title=\"1.3 优点\"></a>1.3 优点</h3><ul>\n<li><strong>直观</strong>：RGB模型直接对应显示器的发光原理，易于理解和实现。</li>\n<li><strong>广泛应用</strong>：适用于大多数显示设备和图像处理软件。</li>\n</ul>\n<h3 id=\"1-4-缺点\"><a href=\"#1-4-缺点\" class=\"headerlink\" title=\"1.4 缺点\"></a>1.4 缺点</h3><ul>\n<li><strong>空间不均匀</strong>：人眼对不同颜色的敏感度不同，RGB模型在颜色空间上不够均匀。</li>\n<li><strong>不适合传输</strong>：RGB数据量大，不适合直接用于视频传输和存储。</li>\n</ul>\n<h1 id=\"2-YUV颜色模型\"><a href=\"#2-YUV颜色模型\" class=\"headerlink\" title=\"2.YUV颜色模型\"></a>2.YUV颜色模型</h1><p>YUV颜色模型是一种用于视频压缩和传输的颜色模型，它将亮度（Y）和色度（U、V）分开表示。YUV模型广泛应用于电视广播、视频编码等领域。</p>\n<h3 id=\"2-1-基本概念\"><a href=\"#2-1-基本概念\" class=\"headerlink\" title=\"2.1 基本概念\"></a>2.1 基本概念</h3><ul>\n<li><strong>Y（Luminance）</strong>：表示亮度信息，即图像的灰度值。</li>\n<li><strong>U（Chrominance）</strong>：表示蓝色和亮度之间的差异。</li>\n<li><strong>V（Chrominance）</strong>：表示红色和亮度之间的差异。</li>\n</ul>\n<h3 id=\"2-2-颜色表示\"><a href=\"#2-2-颜色表示\" class=\"headerlink\" title=\"2.2  颜色表示\"></a>2.2  颜色表示</h3><ul>\n<li>YUV模型中，Y通常使用8位（0-255）表示亮度。</li>\n<li>U和V通常使用8位（-128到127）表示色度。</li>\n<li>例如，YUV值 <code>(128, 0, 0)</code> 表示中等亮度的灰色，没有颜色偏差。</li>\n</ul>\n<h3 id=\"2-3-优点\"><a href=\"#2-3-优点\" class=\"headerlink\" title=\"2.3 优点\"></a>2.3 优点</h3><ul>\n<li><strong>压缩效率高</strong>：YUV模型将亮度和色度分开，可以进行色度子采样（如4:2:0、4:2:2），减少数据量。</li>\n<li><strong>适合传输</strong>：YUV模型适合用于视频压缩和传输，如MPEG、H.264等标准。</li>\n</ul>\n<h3 id=\"2-4-缺点\"><a href=\"#2-4-缺点\" class=\"headerlink\" title=\"2.4 缺点\"></a>2.4 缺点</h3><ul>\n<li><strong>不直观</strong>：YUV模型不如RGB模型直观，需要转换才能在显示器上显示。</li>\n<li><strong>转换复杂</strong>：从RGB到YUV的转换涉及复杂的数学运算。</li>\n</ul>\n<h1 id=\"3-YUV相比RGB的优势\"><a href=\"#3-YUV相比RGB的优势\" class=\"headerlink\" title=\"3. YUV相比RGB的优势\"></a>3. YUV相比RGB的优势</h1><p>YUV颜色模型相对于RGB颜色模型具有以下几个显著的优势，特别是在视频处理和传输领域：</p>\n<h3 id=\"3-1-压缩效率高\"><a href=\"#3-1-压缩效率高\" class=\"headerlink\" title=\"3.1 压缩效率高\"></a>3.1 压缩效率高</h3><ul>\n<li><strong>色度子采样</strong>：YUV模型将亮度和色度信息分开表示，可以对色度信息进行子采样（如4:2:0、4:2:2），从而减少数据量。人眼对亮度的变化更为敏感，对色度的变化相对不敏感，因此可以减少色度信息的采样率而不显著影响视觉质量。</li>\n<li><strong>数据量减少</strong>：通过色度子采样，YUV模型可以显著减少视频数据的存储和传输需求，提高压缩效率。</li>\n</ul>\n<h3 id=\"3-2-适合视频传输\"><a href=\"#3-2-适合视频传输\" class=\"headerlink\" title=\"3.2 适合视频传输\"></a>3.2 适合视频传输</h3><ul>\n<li><strong>带宽优化</strong>：在视频传输中，YUV模型通过减少色度信息的带宽占用，可以更有效地利用有限的带宽资源。</li>\n<li><strong>兼容性</strong>：YUV模型广泛应用于电视广播和视频编码标准（如MPEG、H.264等），具有良好的兼容性和广泛的应用基础。</li>\n</ul>\n<h3 id=\"3-3-视觉感知优化\"><a href=\"#3-3-视觉感知优化\" class=\"headerlink\" title=\"3.3 视觉感知优化\"></a>3.3 视觉感知优化</h3><ul>\n<li><strong>亮度优先</strong>：YUV模型将亮度信息（Y）单独表示，更符合人眼对亮度的敏感性。在视频处理中，可以优先保证亮度信息的准确性，从而提高视觉质量。</li>\n<li><strong>色度调整</strong>：通过调整色度信息（U、V），可以在不影响亮度的情况下进行颜色校正和调整，更适合视频后期处理。</li>\n</ul>\n<h3 id=\"3-4-历史和标准支持\"><a href=\"#3-4-历史和标准支持\" class=\"headerlink\" title=\"3.4 历史和标准支持\"></a>3.4 历史和标准支持</h3><ul>\n<li><strong>历史悠久</strong>：YUV模型起源于模拟电视系统（如PAL和NTSC），经过多年的发展和优化，已经成为视频处理和传输的标准模型。</li>\n<li><strong>标准支持</strong>：YUV模型被广泛应用于各种视频编码标准和传输协议中，具有强大的标准支持和生态系统。</li>\n</ul>\n<h3 id=\"3-5-计算复杂度\"><a href=\"#3-5-计算复杂度\" class=\"headerlink\" title=\"3.5 计算复杂度\"></a>3.5 计算复杂度</h3><ul>\n<li><strong>转换简单</strong>：虽然从RGB到YUV的转换涉及一定的数学运算，但在视频处理中，这种转换通常是批量进行的，计算复杂度相对可控。</li>\n<li><strong>硬件支持</strong>：现代视频处理硬件（如GPU、专用视频处理器）通常支持YUV模型的处理和转换，具有较高的计算效率。</li>\n</ul>\n<h3 id=\"3-6-总结\"><a href=\"#3-6-总结\" class=\"headerlink\" title=\"3.6 总结\"></a>3.6 总结</h3><p>YUV模型在视频处理和传输中具有显著的优势，特别是在压缩效率、带宽优化、视觉感知优化和标准支持方面。尽管RGB模型在显示器和图像处理中更为直观和直接，但在视频领域，YUV模型因其高效的数据压缩和传输特性而成为主流选择。</p>\n<h1 id=\"4-RGB与YUV的转换\"><a href=\"#4-RGB与YUV的转换\" class=\"headerlink\" title=\"4. RGB与YUV的转换\"></a>4. RGB与YUV的转换</h1><h3 id=\"4-1-RGB到YUV的转换公式\"><a href=\"#4-1-RGB到YUV的转换公式\" class=\"headerlink\" title=\"4.1 RGB到YUV的转换公式\"></a>4.1 RGB到YUV的转换公式</h3><ul>\n<li><strong>Y</strong> &#x3D; 0.299R + 0.587G + 0.114B</li>\n<li><strong>U</strong> &#x3D; 0.492(B - Y)</li>\n<li><strong>V</strong> &#x3D; 0.877(R - Y)</li>\n</ul>\n<h3 id=\"4-2-YUV到RGB的转换公式\"><a href=\"#4-2-YUV到RGB的转换公式\" class=\"headerlink\" title=\"4.2 YUV到RGB的转换公式\"></a>4.2 YUV到RGB的转换公式</h3><ul>\n<li><strong>R</strong> &#x3D; Y + 1.140V</li>\n<li><strong>G</strong> &#x3D; Y - 0.395U - 0.581V</li>\n<li><strong>B</strong> &#x3D; Y + 2.032U</li>\n</ul>\n<h3 id=\"4-3-总结\"><a href=\"#4-3-总结\" class=\"headerlink\" title=\"4.3 总结\"></a>4.3 总结</h3><ul>\n<li><strong>RGB模型</strong>：适用于显示器和图像处理，直观但不适合传输。</li>\n<li><strong>YUV模型</strong>：适用于视频压缩和传输，压缩效率高但不够直观。</li>\n</ul>\n<p>在实际应用中，通常根据需求选择合适的颜色模型，并在不同模型之间进行转换。</p>\n<h1 id=\"5-YUV的采样方式\"><a href=\"#5-YUV的采样方式\" class=\"headerlink\" title=\"5. YUV的采样方式\"></a>5. YUV的采样方式</h1><p>下面我们通过具体的例子来解释YUV的各种采样方式，以便更好地理解它们的工作原理和效果。</p>\n<h3 id=\"5-1-4-4-4-采样\"><a href=\"#5-1-4-4-4-采样\" class=\"headerlink\" title=\"5.1  4:4:4 采样\"></a>5.1  4:4:4 采样</h3><p><strong>例子</strong>：假设有一个4x2像素的图像，每个像素的Y、U、V分量都进行采样。</p>\n<table>\n<thead>\n<tr>\n<th>像素</th>\n<th>Y</th>\n<th>U</th>\n<th>V</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>Y1</td>\n<td>U1</td>\n<td>V1</td>\n</tr>\n<tr>\n<td>2</td>\n<td>Y2</td>\n<td>U2</td>\n<td>V2</td>\n</tr>\n<tr>\n<td>3</td>\n<td>Y3</td>\n<td>U3</td>\n<td>V3</td>\n</tr>\n<tr>\n<td>4</td>\n<td>Y4</td>\n<td>U4</td>\n<td>V4</td>\n</tr>\n<tr>\n<td>5</td>\n<td>Y5</td>\n<td>U5</td>\n<td>V5</td>\n</tr>\n<tr>\n<td>6</td>\n<td>Y6</td>\n<td>U6</td>\n<td>V6</td>\n</tr>\n<tr>\n<td>7</td>\n<td>Y7</td>\n<td>U7</td>\n<td>V7</td>\n</tr>\n<tr>\n<td>8</td>\n<td>Y8</td>\n<td>U8</td>\n<td>V8</td>\n</tr>\n</tbody></table>\n<p><strong>解释</strong>：每个像素都有完整的Y、U、V信息，没有进行任何压缩。这种采样方式提供了最高质量的图像，但数据量最大。</p>\n<h3 id=\"5-2-4-2-2-采样\"><a href=\"#5-2-4-2-2-采样\" class=\"headerlink\" title=\"5.2  4:2:2 采样\"></a>5.2  4:2:2 采样</h3><p><strong>例子</strong>：假设有一个4x2像素的图像，每两个像素共享一个U和V分量。</p>\n<table>\n<thead>\n<tr>\n<th>像素</th>\n<th>Y</th>\n<th>U</th>\n<th>V</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>Y1</td>\n<td>U1</td>\n<td></td>\n</tr>\n<tr>\n<td>2</td>\n<td>Y2</td>\n<td></td>\n<td>V2</td>\n</tr>\n<tr>\n<td>3</td>\n<td>Y3</td>\n<td>U3</td>\n<td></td>\n</tr>\n<tr>\n<td>4</td>\n<td>Y4</td>\n<td></td>\n<td>V4</td>\n</tr>\n<tr>\n<td>5</td>\n<td>Y5</td>\n<td>U5</td>\n<td></td>\n</tr>\n<tr>\n<td>6</td>\n<td>Y6</td>\n<td></td>\n<td>V6</td>\n</tr>\n<tr>\n<td>7</td>\n<td>Y7</td>\n<td>U7</td>\n<td></td>\n</tr>\n<tr>\n<td>8</td>\n<td>Y8</td>\n<td></td>\n<td>V8</td>\n</tr>\n</tbody></table>\n<p><strong>解释</strong>：每两个像素中，第一个像素采样Y、U，第二个像素采样Y、V。这种采样方式减少了U和V分量的数据量，但仍然保留了较高的图像质量。</p>\n<h3 id=\"5-3-4-2-0-采样\"><a href=\"#5-3-4-2-0-采样\" class=\"headerlink\" title=\"5.3  4:2:0 采样\"></a>5.3  4:2:0 采样</h3><p><strong>例子</strong>：假设有一个4x2像素的图像，每四个像素共享一个U和V分量。</p>\n<table>\n<thead>\n<tr>\n<th>像素</th>\n<th>Y</th>\n<th>U</th>\n<th>V</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>Y1</td>\n<td>U1</td>\n<td></td>\n</tr>\n<tr>\n<td>2</td>\n<td>Y2</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>3</td>\n<td>Y3</td>\n<td></td>\n<td>V3</td>\n</tr>\n<tr>\n<td>4</td>\n<td>Y4</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>5</td>\n<td>Y5</td>\n<td>U5</td>\n<td></td>\n</tr>\n<tr>\n<td>6</td>\n<td>Y6</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>7</td>\n<td>Y7</td>\n<td></td>\n<td>V7</td>\n</tr>\n<tr>\n<td>8</td>\n<td>Y8</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p><strong>解释</strong>：每四个像素中，第一个像素采样Y、U，第三个像素采样Y、V，其他像素只采样Y。这种采样方式显著减少了U和V分量的数据量，适用于对数据量要求较高的场景，如数字电视、DVD和流媒体。</p>\n<h3 id=\"5-4-4-1-1-采样\"><a href=\"#5-4-4-1-1-采样\" class=\"headerlink\" title=\"5.4  4:1:1 采样\"></a>5.4  4:1:1 采样</h3><p><strong>例子</strong>：假设有一个4x2像素的图像，每四个像素共享一个U和V分量。</p>\n<table>\n<thead>\n<tr>\n<th>像素</th>\n<th>Y</th>\n<th>U</th>\n<th>V</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>1</td>\n<td>Y1</td>\n<td>U1</td>\n<td></td>\n</tr>\n<tr>\n<td>2</td>\n<td>Y2</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>3</td>\n<td>Y3</td>\n<td></td>\n<td>V3</td>\n</tr>\n<tr>\n<td>4</td>\n<td>Y4</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>5</td>\n<td>Y5</td>\n<td>U5</td>\n<td></td>\n</tr>\n<tr>\n<td>6</td>\n<td>Y6</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>7</td>\n<td>Y7</td>\n<td></td>\n<td>V7</td>\n</tr>\n<tr>\n<td>8</td>\n<td>Y8</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<p><strong>解释</strong>：每四个像素中，第一个像素采样Y、U，第三个像素采样Y、V，其他像素只采样Y。这种采样方式与4:2:0类似，但较少使用，主要在一些旧的视频编码标准中。</p>\n<h3 id=\"5-5-总结\"><a href=\"#5-5-总结\" class=\"headerlink\" title=\"5.5 总结\"></a>5.5 总结</h3><p>通过这些例子，我们可以看到不同YUV采样方式对数据量的影响和图像质量的权衡。4:4:4采样提供最高质量，但数据量最大；4:2:2采样在质量和数据量之间取得平衡；4:2:0采样在保证视觉质量的前提下，最大限度地减少数据量，广泛应用于数字电视、DVD和流媒体等领域。</p>\n<h1 id=\"6-举例说明YUV和RGB的存储差异\"><a href=\"#6-举例说明YUV和RGB的存储差异\" class=\"headerlink\" title=\"6.举例说明YUV和RGB的存储差异\"></a>6.举例说明YUV和RGB的存储差异</h1><p>我们来比较一下RGB和YUV各个采样方式在存储方面的差异。假设我们有一个4x2像素的图像，每个像素的RGB值用8位表示（0-255）。</p>\n<h3 id=\"6-1-RGB存储\"><a href=\"#6-1-RGB存储\" class=\"headerlink\" title=\"6.1 RGB存储\"></a>6.1 RGB存储</h3><p>每个像素有3个分量（R、G、B），每个分量占用8位。</p>\n<p><strong>总存储量</strong>：</p>\n<ul>\n<li>每个像素：3字节（24位）</li>\n<li>4x2像素图像：4 * 2 * 3 &#x3D; 24字节</li>\n</ul>\n<h3 id=\"6-2-YUV存储\"><a href=\"#6-2-YUV存储\" class=\"headerlink\" title=\"6.2 YUV存储\"></a>6.2 YUV存储</h3><h4 id=\"6-2-1-YUV-4-4-4-采样\"><a href=\"#6-2-1-YUV-4-4-4-采样\" class=\"headerlink\" title=\"6.2.1 YUV 4:4:4 采样\"></a>6.2.1 YUV 4:4:4 采样</h4><p>每个像素有3个分量（Y、U、V），每个分量占用8位。</p>\n<p><strong>总存储量</strong>：</p>\n<ul>\n<li>每个像素：3字节（24位）</li>\n<li>4x2像素图像：4 * 2 * 3 &#x3D; 24字节</li>\n</ul>\n<p><strong>比较</strong>：</p>\n<ul>\n<li>RGB和YUV 4:4:4采样的存储量相同，都是24字节。</li>\n</ul>\n<h4 id=\"6-2-2-YUV-4-2-2-采样\"><a href=\"#6-2-2-YUV-4-2-2-采样\" class=\"headerlink\" title=\"6.2.2 YUV 4:2:2 采样\"></a>6.2.2 YUV 4:2:2 采样</h4><p>每两个像素共享一个U和V分量。</p>\n<p><strong>总存储量</strong>：</p>\n<ul>\n<li>Y分量：4 * 2 &#x3D; 8字节</li>\n<li>U分量：4 * 2 &#x2F; 2 &#x3D; 4字节</li>\n<li>V分量：4 * 2 &#x2F; 2 &#x3D; 4字节</li>\n<li>总存储量：8 + 4 + 4 &#x3D; 16字节</li>\n</ul>\n<p><strong>比较</strong>：</p>\n<ul>\n<li>YUV 4:2:2采样的存储量比RGB少8字节（16字节 vs 24字节）。</li>\n</ul>\n<h4 id=\"6-2-3-YUV-4-2-0-采样\"><a href=\"#6-2-3-YUV-4-2-0-采样\" class=\"headerlink\" title=\"6.2.3 YUV 4:2:0 采样\"></a>6.2.3 YUV 4:2:0 采样</h4><p>每四个像素共享一个U和V分量。</p>\n<p><strong>总存储量</strong>：</p>\n<ul>\n<li>Y分量：4 * 2 &#x3D; 8字节</li>\n<li>U分量：4 * 2 &#x2F; 4 &#x3D; 2字节</li>\n<li>V分量：4 * 2 &#x2F; 4 &#x3D; 2字节</li>\n<li>总存储量：8 + 2 + 2 &#x3D; 12字节</li>\n</ul>\n<p><strong>比较</strong>：</p>\n<ul>\n<li>YUV 4:2:0采样的存储量比RGB少12字节（12字节 vs 24字节）。</li>\n</ul>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><table>\n<thead>\n<tr>\n<th>采样方式</th>\n<th>存储量（字节）</th>\n<th>与RGB相比的差异</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>RGB</td>\n<td>24</td>\n<td>0</td>\n</tr>\n<tr>\n<td>YUV 4:4:4</td>\n<td>24</td>\n<td>0</td>\n</tr>\n<tr>\n<td>YUV 4:2:2</td>\n<td>16</td>\n<td>-8</td>\n</tr>\n<tr>\n<td>YUV 4:2:0</td>\n<td>12</td>\n<td>-12</td>\n</tr>\n</tbody></table>\n<p>通过这个例子，我们可以清楚地看到YUV采样方式在存储方面的优势。YUV 4:4:4采样与RGB存储量相同，而YUV 4:2:2和YUV 4:2:0采样分别比RGB减少了8字节和12字节的存储量。这种存储量的减少在处理大尺寸图像或视频时尤为显著，有助于提高数据传输和存储的效率。</p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n"},{"title":"音视频开发09：SRT、ASS、SAA、VTT字幕介绍","date":"2024-12-12T04:00:00.000Z","category_bar":true,"_content":"\n![image-20241209171329186](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209171329186.png)\n\n# 1. 定义\n\n音视频的字幕是指以文本形式显示在屏幕上的内容，这些内容通常代表了音频中的对话、叙述以及其他重要的声音元素。字幕不仅有助于提高视频内容的理解度，而且对于那些有听力障碍或是在静音环境中观看视频的人来说尤为重要。此外，字幕还可以用于翻译不同语言的内容，从而扩大视频的受众范围\n\n# 2. 字幕的种类\n\n根据其功能和使用场景，字幕可以分为几种不同类型：\n\n- **开放式字幕（硬编码字幕）**：这类字幕直接嵌入到视频帧中，成为视频的一部分，无法关闭。它们适用于需要永久性地将字幕信息与视频结合的情况。\n- **隐藏式字幕（软字幕/外挂字幕）**：用户可以选择是否开启这类字幕，并且可以根据需要调整样式。它们通常作为独立文件存在，如SRT、ASS等格式，便于管理和更新。\n- **实时字幕**：这种字幕是在直播或其他即时活动中生成的，能够快速响应现场发生的口语交流，为观众提供即时的文字反馈\n\n# 3. 字幕格式\n\n常见的字幕格式包括：\n\n1. **SRT (SubRip Text)**：最常见的字幕格式之一，文本文件，每行包含时间码和字幕内容。\n2. **ASS (Advanced SubStation Alpha)**：功能强大的字幕格式，支持复杂的字幕样式和特效。\n3. **SSA (SubStation Alpha)**：早期的字幕格式，功能不如ASS强大，较少使用。\n4. **VTT (WebVTT)**：用于网页视频的字幕格式，类似于SRT[5](https://blog.csdn.net/AlvinCasper/article/details/113066446)。\n\n### 3.1 SRT字幕\n\nSRT（SubRip Text）字幕格式以其简洁性和广泛的兼容性著称，它由纯文本构成，每个字幕段落包括四个主要部分：序号、时间码、字幕文本以及一个空白行来分隔不同的字幕片段。下面我们将通过具体的例子详细介绍SRT字幕文件的结构和使用方法。\n\n![image-20241209172234191](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209172234191.png)\n\n#### SRT 字幕的基本结构\n\n##### 序号\n\n每个字幕段都有一个唯一的序号，这个数字从1开始递增，表示字幕出现的顺序。虽然序号本身并不直接影响播放时的显示效果，但在实际应用中，它有助于保持字幕的逻辑顺序正确无误。\n\n##### 时间码\n\n紧跟在序号之后的是时间码，它定义了字幕何时出现及消失。时间码遵循`hh:mm:ss,mmm --> hh:mm:ss,mmm`的格式，其中`hh`代表小时，`mm`代表分钟，`ss`代表秒，而`mmm`则表示毫秒。例如：\n\n```\n1\n00:00:29,740 --> 00:00:31,280\n福姬套餐~\n```\n\n在这个例子中，字幕“福姬套餐~”将在视频播放到第29秒740毫秒时出现，并持续到第31秒280毫秒后消失。\n\n##### 字幕文本\n\n接下来是具体的字幕文本，它可以是一行或多行。对于多语言字幕，不同语言的内容可以通过换行分隔开来。例如，在同一时间段内可以先显示英文再显示中文翻译：\n\n```\n2\n00:00:31,400 --> 00:00:32,240\n炒炸酱面\n```\n\n这里，“炒炸酱面”会在指定的时间范围内显示在屏幕上。\n\n##### 空白行\n\n每一组字幕之间必须有一个空行来分隔不同的字幕片段，这标志着上一段字幕的结束和新一段字幕的开始。空白行的存在确保了字幕文件的可读性和结构清晰度。\n\n#### 样式与格式化示例\n\n尽管SRT本质上是一个简单的文本文件，但它也支持一些基本的HTML标签来进行格式化，如粗体（`<b>`）、斜体（`<i>`）、下划线（`<u>`）以及字体颜色（`<font color=\"...\">`）。需要注意的是，并非所有的播放器都支持这些样式标记，因此在实际使用时应该考虑目标平台的支持情况。例如：\n\n```\n3\n00:00:32,360 --> 00:00:33,300\n<b>炒拉面</b>\n```\n\n这段代码会让“炒拉面”以粗体形式显示。\n\n#### 实际应用中的SRT文件示例\n\n以下是一个完整的SRT字幕文件示例，摘自电影《阿凡达》的中英双语字幕：\n\n```\n3\n00:00:39,770 --> 00:00:41,880\n在经历了一场人生巨变之后\nWhen I was lying there in the VA hospital ...\n```\n\n```\n4\n00:00:42,550 --> 00:00:44,690\n我被送进了退伍军人管理局医院 ...\nwith a big hole blown through the middle of my life,\n```\n\n```\n5\n00:00:45,590 --> 00:00:48,120\n那段时间我经常会梦到自己在飞翔 ...\nI started having these dreams of flying.\n```\n\n```\n6\n00:00:49,740 --> 00:00:51,520\n终获自由\nI was free.\n```\n\n在这个例子中，我们可以看到每一段字幕都有其对应的序号、时间码和文本内容，并且通过空白行分隔开各个字幕段。\n\n#### 编码方式\n\nSRT文件默认采用Windows-1252编码，但也可以保存为其他编码格式，如UTF-8或UTF-16，带或不带字节顺序标记（BOM）。为了确保跨平台兼容性，建议尽量使用UTF-8编码。特别是当涉及到非ASCII字符时，正确的编码选择尤为重要，因为错误的编码可能导致乱码问题。\n\n#### 创建与编辑SRT文件\n\n创建SRT文件的过程相对直接，用户可以直接用文本编辑器手动编写，也可以借助专门的字幕编辑软件，如Aegisub、Subtitle Edit等。此外，还有在线服务和移动应用程序可以帮助生成或调整现有的SRT文件。对于批量处理或者需要高精度的时间轴同步，还可以考虑利用语音识别技术自动生成初步的SRT文件，然后进行人工校对和完善。\n\n综上所述，SRT字幕格式凭借其易于理解和操作的特点，成为了视频字幕领域不可或缺的一部分。\n\n### 3.2 ASS字幕\n\nASS（Advanced SubStation Alpha）是一种比SSA更为高级的字幕格式，它不仅支持基本的文本显示，还允许用户添加复杂的样式、特效以及时间轴控制。ASS 文件通常以 `.ass` 作为文件扩展名，并且是纯文本文件，这意味着它们可以用任何文本编辑器手工编辑，但必须注意遵循特定的规则以确保正确解析。\n\n#### ASS 字幕的基本结构\n\n一个典型的 ASS 文件由几个部分组成：`[Script Info]`、`[V4+ Styles]` 和 `[Events]`。每个部分都有其独特的功能和用途。\n\n##### [Script Info]\n\n这部分包含了脚本的头部信息和总体描述。例如：\n\n```\n[Script Info]\n; This is a Sub Station Alpha v4 script.\nTitle: Neon Genesis Evangelion - Episode 26 (neutral Spanish)\nOriginal Script: RoRo\nScript Updated By: version 2.8.01\nScriptType: v4.00+\nCollisions: Normal\nPlayResY: 600\nPlayDepth: 0\nTimer: 100,00\n```\n\n这里定义了诸如标题 (`Title`)、原作者 (`Original Script`) 等元数据，以及一些技术参数如播放分辨率 (`PlayResX`, `PlayResY`) 和颜色深度 (`PlayDepth`)。`Timer` 属性用于调整字幕的时间轴速度，不过现代渲染器通常会忽略这一设置。\n\n##### [V4+ Styles]\n\n这是样式定义的部分，其中每一个被脚本使用的样式都应该在此处定义。格式如下：\n\n```\n[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\nStyle: Default,Arial,20,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,0.5,0,2,10,10,10,1\n```\n\n每一项都对应着不同的视觉属性，比如字体名称 (`Fontname`)、字体大小 (`Fontsize`)、主要颜色 (`PrimaryColour`) 等等。`Alignment` 属性决定了字幕在屏幕上的对齐方式，而 `MarginL`, `MarginR`, `MarginV` 则设定了字幕与屏幕边缘的距离。\n\n##### [Events]\n\n这是最重要的部分之一，因为它包含了所有实际出现在屏幕上的内容。每条事件记录了一个具体的字幕或注释，并指定了它的开始时间和结束时间、所使用的样式以及其他可能的效果。例如：\n\n```\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\nDialogue: 0,0:00:09.07,0:00:13.14,Default,0,0,0,,我的爱从相遇的那一刻起\nDialogue: 0,0:00:13.27,0:00:17.41,Default,0,0,0,,我的生活一切都被你占据\n```\n\n`Layer` 属性控制字幕的叠放顺序；`Start` 和 `End` 分别表示字幕出现和消失的时间点；`Style` 指向之前定义好的样式；`Text` 包含了要显示的具体文字。\n\n#### 样式与格式化示例\n\n除了上述基础元素外，ASS 还提供了丰富的内联标签来实现更加精细的排版和动画效果。例如：\n\n- `\\b1` 开启粗体，`\\b0` 关闭粗体；\n- `\\i1` 开启斜体，`\\i0` 关闭斜体；\n- `\\u1` 开启下划线，`\\u0` 关闭下划线；\n- `\\k<time>` 用于卡拉 OK 效果，指定高亮移动的速度；\n- `\\move(<x1>, <y1>, <x2>, <y2>)` 实现字幕从一个位置移动到另一个位置；\n- `\\fad(<in-time>, <out-time>)` 创建淡入淡出效果。\n\n以下是一个使用这些标签的例子：\n\n```\nDialogue: 0,0:00:00.00,0:00:05.00,Default,,0,0,0,,{\\b1\\u1\\c&HFF0000&}这是一段{\\i1}带{\\i0}有{\\b0\\u0}样式的文本。\nDialogue: 0,0:00:05.00,0:00:10.00,Default,,0,0,0,,{\\move(100,100,500,100)\\fad(1000,1000)}这段文字会从左下角滑动到右下角并伴有淡入淡出。\n```\n\n在这个例子中，第一行应用了粗体和下划线，同时将颜色更改为红色，并且中间有一部分为斜体；第二行则设置了从屏幕左侧到右侧的移动路径，并且加入了1秒的淡入淡出过渡。\n\n#### 实际应用中的ASS文件示例\n\n考虑到ASS的强大功能，它可以用来创建非常复杂且富有创意的字幕效果，尤其是在动漫领域。下面给出一段来自《命运石之门》的日语台词及其对应的ASS代码：\n\n```\nDialogue: 0,0:01:23.45,0:01:27.67,CustomStyle,,0,0,0,,{\\an7\\b1\\c&HFFFF00&\\3c&H0000FF&}OKERU！\nDialogue: 0,0:01:27.67,0:01:31.89,CustomStyle,,0,0,0,,{\\an8\\i1\\k50}我们终于可以一起制作游戏了！\n```\n\n这里，“CustomStyle” 是预先定义好的一种样式，而 `{}` 内的内容则是额外添加的临时样式覆盖。第一句台词位于屏幕顶部中央（`an7`），并且采用了黄色字体配蓝色边框；第二句则位于顶部右侧（`an8`），带有卡拉 OK 式的逐字高亮效果（`\\k50` 表示每个字符高亮持续50毫秒）。\n\n#### 编码方式\n\n与SRT类似，ASS也推荐使用UTF-8编码，特别是当涉及到多语言支持时。正确的编码选择对于避免乱码至关重要。此外，由于ASS支持更多样化的字体和颜色配置，因此还需要确保目标设备上安装了相应的字体文件，或者考虑嵌入所需字体以便于跨平台播放。\n\n### 3.3 SSA字幕\n\n在上面我们介绍了ASS字幕，ASS字幕其实是SSA字幕格式的高级版本，在SSA的基础上增加了一些额外的功能。下面用一个例子介绍下ASS和SSA之间的区别和联系。\n\n假设我们要为一段视频添加带有特效的字幕，这段视频中有一句台词：**“欢迎来到未来世界”。**\n\n#### SSA 字幕文件示例\n\n首先，我们看看如何用 SSA 格式创建这段字幕。\n\n```plaintext\n[Script Info]\n; This is a Sub Station Alpha v4 script.\nTitle: Future World - Episode 1\nOriginal Script: Example Author\nScriptType: v4.00\nCollisions: Normal\nPlayResX: 640\nPlayResY: 480\nTimer: 100,00\n\n[V4 Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, TertiaryColour, BackColour, Bold, Italic, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, AlphaLevel, Encoding\nStyle: Default,Arial,20,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,-1,0,1,2,2,2,10,10,10,0,0\n\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\nDialogue: 0,0:00:05.00,0:00:07.00,Default,,0,0,0,,{\\c&HFF0000&}欢迎{\\c&H00FF00&}来到{\\c&H0000FF&}未来世界！\n```\n\n在这个 SSA 文件中：\n\n- **[Script Info]** 部分定义了脚本的基本信息，如标题、原作者等。\n- **[V4 Styles]** 定义了一种默认样式 `Default`，指定了字体名称、大小、颜色等属性。\n- **[Events]** 包含了一个对话事件，它设置了开始时间和结束时间，并使用了内联标签 `\\c` 来改变文本的颜色，以实现多彩效果。\n\n#### ASS 字幕文件示例\n\n接下来，我们将相同的台词转换成 ASS 格式，同时增加一些额外的功能。\n\n```plaintext\n[Script Info]\n; This is an Advanced Sub Station Alpha v4+ script.\nTitle: Future World - Episode 1\nScriptType: v4.00+\nCollisions: Normal\nPlayResX: 640\nPlayResY: 480\nTimer: 100,00\n\n[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\nStyle: Default,Arial,20,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,1,1,2,10,10,10,1\n\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\nDialogue: 0,0:00:05.00,0:00:07.00,Default,,0,0,0,,{\\an8\\c&HFF0000&\\b1}欢迎{\\c&H00FF00&\\b0}来到{\\c&H0000FF&}未来世界！{\\fad(500,500)}\n```\n\n在这个 ASS 文件中：\n\n- **[Script Info]** 部分同样提供了脚本信息，但指明这是 v4.00+ 版本。\n- **[V4+ Styles]** 中增加了更多样式属性，例如 `ScaleX`, `ScaleY`, `Spacing`, `Angle` 等，允许对文本进行更精细的控制。\n- **[Events]** 部分不仅实现了与 SSA 相同的多彩效果，还加入了粗体切换 (`\\b1`, `\\b0`) 和淡入淡出效果 (`\\fad`)。\n\n#### 区别和联系\n\n##### 区别\n\n1. **版本**：ASS 是基于 SSA v4.00+ 的改进版本，具有更多的功能和支持。\n2. **样式定义**：ASS 在 `[V4+ Styles]` 中引入了额外的样式属性，如 `ScaleX`, `ScaleY`, `Spacing`, `Angle` 等。\n3. **内联标签支持**：ASS 扩展了 SSA 的内联标签功能，新增了如 `\\t` (临时样式覆盖) 等标签，并增强了现有标签的效果，比如卡拉 OK 效果 (`\\k`)。\n4. **高级特效与动画**：ASS 支持更复杂的动画效果，包括路径上的移动 (\\move)，旋转，缩放变换等。\n5. **字符编码**：ASS 设计之初就考虑到了更好的国际化支持，对于非拉丁字符集有更好的处理方式。\n\n##### 联系\n\n- **结构相似**：两者都遵循类似的文件结构，包括 `[Script Info]`, `[V4/V4+ Styles]`, `[Events]` 等部分。\n- **向后兼容**：大多数现代播放器能够解析 SSA 和 ASS 文件，因为 ASS 向后兼容 SSA。\n- **基本功能一致**：在基础功能上，SSA 和 ASS 提供了相同的核心特性，如设置字体、颜色、对齐方式等。\n\n综上所述，尽管 SSA 和 ASS 在细节上有许多不同之处，但它们共享很多共同点，特别是对于普通用户来说，两者都能很好地满足日常字幕制作的需求。然而，如果你需要利用更先进的特效或希望确保最佳的跨平台兼容性，那么选择 ASS 可能会是一个更好的决定。\n\n### 3.4 VTT字幕\n\nWebVTT（Web Video Text Tracks）是一种专门为网络视频设计的字幕格式，它被广泛应用于 HTML5 `<video>` 元素中。WebVTT 文件通常以 `.vtt` 作为扩展名，并且是纯文本文件，易于编辑和解析。与 SSA/ASS 等格式相比，WebVTT 更加简洁，专注于提供基本的字幕功能，如时间戳、文本内容以及简单的样式控制。下面将通过一个具体的例子来详细介绍 WebVTT 的结构和用法。\n\n#### WebVTT 文件的基本结构\n\n每个 WebVTT 文件都必须以 `WEBVTT` 开头，紧接着是一个空行，然后是各个字幕段落。每个段落由以下几部分组成：\n\n1. **标识符（可选）**：可以为每个字幕段落指定一个唯一的标识符。\n2. **时间码**：定义了字幕显示的时间范围，格式为 `HH:MM:SS.mmm --> HH:MM:SS.mmm`，其中 `HH` 表示小时，`MM` 表示分钟，`SS` 表示秒，`mmm` 表示毫秒。\n3. **设置（可选）**：用于指定字幕的位置、对齐方式等属性。\n4. **文本内容**：即实际要显示的字幕文字，可以包含多行。\n\n##### 示例：简单对话场景\n\n假设我们有一段视频，其中一个人说：“欢迎来到未来世界。” 我们可以创建如下的 WebVTT 文件：\n\n```plaintext\nWEBVTT\n\n1\n00:00:05.000 --> 00:00:07.000\n欢迎来到未来世界。\n```\n\n在这个例子中：\n\n- `WEBVTT` 表明这是一个 WebVTT 文件。\n- 数字 `1` 是字幕段落的唯一标识符（可选），有助于管理和引用特定的字幕。\n- 时间码 `00:00:05.000 --> 00:00:07.000` 指定了字幕从第 5 秒开始，在第 7 秒结束。\n- 最后一行是实际要显示的文字内容。\n\n#### 增强样式的使用\n\n虽然 WebVTT 主要关注于提供清晰易读的字幕，但它也允许一定程度上的样式定制。例如，你可以使用 HTML 标签或内联 CSS 来改变字体颜色、大小、样式等。此外，WebVTT 还支持一些特殊的标签来实现更复杂的效果。\n\n##### 示例：带样式的字幕\n\n考虑同样的台词，但我们想让它更引人注目，比如给“欢迎”两个字加上红色高亮，并让整个句子居中显示：\n\n```plaintext\nWEBVTT\n\n1\n00:00:05.000 --> 00:00:07.000 line:50% position:50% align:center\n<c.red>欢迎</c>来到未来世界。\n```\n\n在这个例子中：\n\n- `line:50% position:50% align:center` 设置了字幕在屏幕上的位置和对齐方式，使它位于屏幕中央。\n- `<c.red>` 和 `</c>` 是 WebVTT 特有的标记，用来包裹需要应用样式的文本。这里我们将“欢迎”两个字的颜色设置为红色。\n\n#### 使用 CSS 类进行样式化\n\n对于更复杂的样式需求，可以结合 CSS 类来进行处理。首先，在 WebVTT 文件中定义类名，然后在网页上关联相应的 CSS 样式规则。\n\n##### 示例：使用 CSS 类\n\n继续上面的例子，这次我们将为“欢迎”添加一个自定义的 CSS 类：\n\n```plaintext\nWEBVTT\n\n1\n00:00:05.000 --> 00:00:07.000 line:50% position:50% align:center\n<c.vwelcome>欢迎</c>来到未来世界。\n```\n\n接着，在网页中的 `<style>` 标签或者外部样式表里添加如下 CSS 规则：\n\n```css\n::cue(.vwelcome) {\n    color: red;\n    font-weight: bold;\n}\n```\n\n这样，当播放器渲染这个 WebVTT 文件时，“欢迎”这两个字不仅会变成红色，还会显得更加粗重。\n\n#### WebVTT 的高级特性\n\n除了上述基本功能外，WebVTT 还支持其他类型的文本轨道，如章节列表、描述性音轨等。这些功能使得 WebVTT 成为了一个非常灵活且强大的工具，适用于各种多媒体应用场景。\n\n##### 示例：章节列表\n\n如果想要为视频添加章节导航，可以使用 WebVTT 创建一个章节轨道文件：\n\n```plaintext\nWEBVTT\n\nCHAPTERS\n\n00:00:00.000 --> 00:01:00.000\nIntroduction\n\n00:01:00.000 --> 00:02:30.000\nMain Content\n\n00:02:30.000 --> 00:03:00.000\nConclusion\n```\n\n这段代码定义了一个包含三个章节的列表，用户可以通过点击章节标题快速跳转到相应的时间点。\n\n#### 总结\n\nWebVTT 是一种轻量级但功能丰富的字幕格式，特别适合在网络环境中使用。它的语法简单直观，易于学习和实现，同时提供了足够的灵活性来满足大多数字幕制作的需求。无论是简单的对话字幕还是带有复杂样式的提示信息，WebVTT 都能有效地支持。更重要的是，由于它是 HTML5 标准的一部分，因此可以在所有现代浏览器中无缝工作，确保了良好的兼容性和用户体验。\n\n# 4. 字幕制作\n\n### 4.1 字幕的制作工具\n\n有许多专业的字幕制作软件可以帮助用户轻松制作和编辑字幕，例如：\n\n1. **KBuilderTools (小灰熊字幕制作软件)**：支持MV字幕制作，操作简单。\n2. **Sayatoo卡拉字幕精灵**：支持自定义设置字幕的字体、颜色、布局等参数。\n3. **Srt字幕制作帮手**：专门针对SRT字幕的编辑软件，操作简便。\n4. **字幕大师 (OKVoice)**：采用高精准语音识别技术，支持自动匹配音视频中的语音与字幕。\n5. **Arctime Pro**：专业字幕制作软件，支持多种创新技术，如字幕块绑定、自动分轴等。\n6. **Aegisub**：免费、开源、跨平台的字幕编辑软件，支持多种语言编码。\n\n### 4.2 字幕的制作步骤\n\n1. **导入视频和字幕文件**：使用视频编辑软件导入视频文件和字幕文件，确保字幕文件与视频文件的内容对应。\n2. **调整时间轴**：在视频编辑软件中，调整字幕的出现时间和消失时间，使其与配音的时长和内容一致。\n3. **调整字幕样式**：根据需要，调整字幕的字体、字号、颜色、背景等，以使字幕更加清晰明确。\n4. **预览和调整**：预览整个视频，确保字幕与配音同步显示，并且字幕的内容清晰可读。\n5. **导出视频**：完成字幕的调整后，将视频导出为新的文件，确保字幕和配音同步的效果在最终的视频文件中得以保留。\n\n\n\n\n\n文章合集：https://github.com/chongzicbo/ReadWriteThink\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","source":"_posts/开发/音视频/音视频开发09：字幕介绍.md","raw":"---\ntitle: '音视频开发09：SRT、ASS、SAA、VTT字幕介绍'\ncategories:\n  - [开发,音视频,基础]\ntags:\n  - 音视频开发\n  - 音视频基础\ndate: 2024-12-12 12:00:00\ncategory_bar: true\n---\n\n![image-20241209171329186](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209171329186.png)\n\n# 1. 定义\n\n音视频的字幕是指以文本形式显示在屏幕上的内容，这些内容通常代表了音频中的对话、叙述以及其他重要的声音元素。字幕不仅有助于提高视频内容的理解度，而且对于那些有听力障碍或是在静音环境中观看视频的人来说尤为重要。此外，字幕还可以用于翻译不同语言的内容，从而扩大视频的受众范围\n\n# 2. 字幕的种类\n\n根据其功能和使用场景，字幕可以分为几种不同类型：\n\n- **开放式字幕（硬编码字幕）**：这类字幕直接嵌入到视频帧中，成为视频的一部分，无法关闭。它们适用于需要永久性地将字幕信息与视频结合的情况。\n- **隐藏式字幕（软字幕/外挂字幕）**：用户可以选择是否开启这类字幕，并且可以根据需要调整样式。它们通常作为独立文件存在，如SRT、ASS等格式，便于管理和更新。\n- **实时字幕**：这种字幕是在直播或其他即时活动中生成的，能够快速响应现场发生的口语交流，为观众提供即时的文字反馈\n\n# 3. 字幕格式\n\n常见的字幕格式包括：\n\n1. **SRT (SubRip Text)**：最常见的字幕格式之一，文本文件，每行包含时间码和字幕内容。\n2. **ASS (Advanced SubStation Alpha)**：功能强大的字幕格式，支持复杂的字幕样式和特效。\n3. **SSA (SubStation Alpha)**：早期的字幕格式，功能不如ASS强大，较少使用。\n4. **VTT (WebVTT)**：用于网页视频的字幕格式，类似于SRT[5](https://blog.csdn.net/AlvinCasper/article/details/113066446)。\n\n### 3.1 SRT字幕\n\nSRT（SubRip Text）字幕格式以其简洁性和广泛的兼容性著称，它由纯文本构成，每个字幕段落包括四个主要部分：序号、时间码、字幕文本以及一个空白行来分隔不同的字幕片段。下面我们将通过具体的例子详细介绍SRT字幕文件的结构和使用方法。\n\n![image-20241209172234191](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209172234191.png)\n\n#### SRT 字幕的基本结构\n\n##### 序号\n\n每个字幕段都有一个唯一的序号，这个数字从1开始递增，表示字幕出现的顺序。虽然序号本身并不直接影响播放时的显示效果，但在实际应用中，它有助于保持字幕的逻辑顺序正确无误。\n\n##### 时间码\n\n紧跟在序号之后的是时间码，它定义了字幕何时出现及消失。时间码遵循`hh:mm:ss,mmm --> hh:mm:ss,mmm`的格式，其中`hh`代表小时，`mm`代表分钟，`ss`代表秒，而`mmm`则表示毫秒。例如：\n\n```\n1\n00:00:29,740 --> 00:00:31,280\n福姬套餐~\n```\n\n在这个例子中，字幕“福姬套餐~”将在视频播放到第29秒740毫秒时出现，并持续到第31秒280毫秒后消失。\n\n##### 字幕文本\n\n接下来是具体的字幕文本，它可以是一行或多行。对于多语言字幕，不同语言的内容可以通过换行分隔开来。例如，在同一时间段内可以先显示英文再显示中文翻译：\n\n```\n2\n00:00:31,400 --> 00:00:32,240\n炒炸酱面\n```\n\n这里，“炒炸酱面”会在指定的时间范围内显示在屏幕上。\n\n##### 空白行\n\n每一组字幕之间必须有一个空行来分隔不同的字幕片段，这标志着上一段字幕的结束和新一段字幕的开始。空白行的存在确保了字幕文件的可读性和结构清晰度。\n\n#### 样式与格式化示例\n\n尽管SRT本质上是一个简单的文本文件，但它也支持一些基本的HTML标签来进行格式化，如粗体（`<b>`）、斜体（`<i>`）、下划线（`<u>`）以及字体颜色（`<font color=\"...\">`）。需要注意的是，并非所有的播放器都支持这些样式标记，因此在实际使用时应该考虑目标平台的支持情况。例如：\n\n```\n3\n00:00:32,360 --> 00:00:33,300\n<b>炒拉面</b>\n```\n\n这段代码会让“炒拉面”以粗体形式显示。\n\n#### 实际应用中的SRT文件示例\n\n以下是一个完整的SRT字幕文件示例，摘自电影《阿凡达》的中英双语字幕：\n\n```\n3\n00:00:39,770 --> 00:00:41,880\n在经历了一场人生巨变之后\nWhen I was lying there in the VA hospital ...\n```\n\n```\n4\n00:00:42,550 --> 00:00:44,690\n我被送进了退伍军人管理局医院 ...\nwith a big hole blown through the middle of my life,\n```\n\n```\n5\n00:00:45,590 --> 00:00:48,120\n那段时间我经常会梦到自己在飞翔 ...\nI started having these dreams of flying.\n```\n\n```\n6\n00:00:49,740 --> 00:00:51,520\n终获自由\nI was free.\n```\n\n在这个例子中，我们可以看到每一段字幕都有其对应的序号、时间码和文本内容，并且通过空白行分隔开各个字幕段。\n\n#### 编码方式\n\nSRT文件默认采用Windows-1252编码，但也可以保存为其他编码格式，如UTF-8或UTF-16，带或不带字节顺序标记（BOM）。为了确保跨平台兼容性，建议尽量使用UTF-8编码。特别是当涉及到非ASCII字符时，正确的编码选择尤为重要，因为错误的编码可能导致乱码问题。\n\n#### 创建与编辑SRT文件\n\n创建SRT文件的过程相对直接，用户可以直接用文本编辑器手动编写，也可以借助专门的字幕编辑软件，如Aegisub、Subtitle Edit等。此外，还有在线服务和移动应用程序可以帮助生成或调整现有的SRT文件。对于批量处理或者需要高精度的时间轴同步，还可以考虑利用语音识别技术自动生成初步的SRT文件，然后进行人工校对和完善。\n\n综上所述，SRT字幕格式凭借其易于理解和操作的特点，成为了视频字幕领域不可或缺的一部分。\n\n### 3.2 ASS字幕\n\nASS（Advanced SubStation Alpha）是一种比SSA更为高级的字幕格式，它不仅支持基本的文本显示，还允许用户添加复杂的样式、特效以及时间轴控制。ASS 文件通常以 `.ass` 作为文件扩展名，并且是纯文本文件，这意味着它们可以用任何文本编辑器手工编辑，但必须注意遵循特定的规则以确保正确解析。\n\n#### ASS 字幕的基本结构\n\n一个典型的 ASS 文件由几个部分组成：`[Script Info]`、`[V4+ Styles]` 和 `[Events]`。每个部分都有其独特的功能和用途。\n\n##### [Script Info]\n\n这部分包含了脚本的头部信息和总体描述。例如：\n\n```\n[Script Info]\n; This is a Sub Station Alpha v4 script.\nTitle: Neon Genesis Evangelion - Episode 26 (neutral Spanish)\nOriginal Script: RoRo\nScript Updated By: version 2.8.01\nScriptType: v4.00+\nCollisions: Normal\nPlayResY: 600\nPlayDepth: 0\nTimer: 100,00\n```\n\n这里定义了诸如标题 (`Title`)、原作者 (`Original Script`) 等元数据，以及一些技术参数如播放分辨率 (`PlayResX`, `PlayResY`) 和颜色深度 (`PlayDepth`)。`Timer` 属性用于调整字幕的时间轴速度，不过现代渲染器通常会忽略这一设置。\n\n##### [V4+ Styles]\n\n这是样式定义的部分，其中每一个被脚本使用的样式都应该在此处定义。格式如下：\n\n```\n[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\nStyle: Default,Arial,20,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,0.5,0,2,10,10,10,1\n```\n\n每一项都对应着不同的视觉属性，比如字体名称 (`Fontname`)、字体大小 (`Fontsize`)、主要颜色 (`PrimaryColour`) 等等。`Alignment` 属性决定了字幕在屏幕上的对齐方式，而 `MarginL`, `MarginR`, `MarginV` 则设定了字幕与屏幕边缘的距离。\n\n##### [Events]\n\n这是最重要的部分之一，因为它包含了所有实际出现在屏幕上的内容。每条事件记录了一个具体的字幕或注释，并指定了它的开始时间和结束时间、所使用的样式以及其他可能的效果。例如：\n\n```\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\nDialogue: 0,0:00:09.07,0:00:13.14,Default,0,0,0,,我的爱从相遇的那一刻起\nDialogue: 0,0:00:13.27,0:00:17.41,Default,0,0,0,,我的生活一切都被你占据\n```\n\n`Layer` 属性控制字幕的叠放顺序；`Start` 和 `End` 分别表示字幕出现和消失的时间点；`Style` 指向之前定义好的样式；`Text` 包含了要显示的具体文字。\n\n#### 样式与格式化示例\n\n除了上述基础元素外，ASS 还提供了丰富的内联标签来实现更加精细的排版和动画效果。例如：\n\n- `\\b1` 开启粗体，`\\b0` 关闭粗体；\n- `\\i1` 开启斜体，`\\i0` 关闭斜体；\n- `\\u1` 开启下划线，`\\u0` 关闭下划线；\n- `\\k<time>` 用于卡拉 OK 效果，指定高亮移动的速度；\n- `\\move(<x1>, <y1>, <x2>, <y2>)` 实现字幕从一个位置移动到另一个位置；\n- `\\fad(<in-time>, <out-time>)` 创建淡入淡出效果。\n\n以下是一个使用这些标签的例子：\n\n```\nDialogue: 0,0:00:00.00,0:00:05.00,Default,,0,0,0,,{\\b1\\u1\\c&HFF0000&}这是一段{\\i1}带{\\i0}有{\\b0\\u0}样式的文本。\nDialogue: 0,0:00:05.00,0:00:10.00,Default,,0,0,0,,{\\move(100,100,500,100)\\fad(1000,1000)}这段文字会从左下角滑动到右下角并伴有淡入淡出。\n```\n\n在这个例子中，第一行应用了粗体和下划线，同时将颜色更改为红色，并且中间有一部分为斜体；第二行则设置了从屏幕左侧到右侧的移动路径，并且加入了1秒的淡入淡出过渡。\n\n#### 实际应用中的ASS文件示例\n\n考虑到ASS的强大功能，它可以用来创建非常复杂且富有创意的字幕效果，尤其是在动漫领域。下面给出一段来自《命运石之门》的日语台词及其对应的ASS代码：\n\n```\nDialogue: 0,0:01:23.45,0:01:27.67,CustomStyle,,0,0,0,,{\\an7\\b1\\c&HFFFF00&\\3c&H0000FF&}OKERU！\nDialogue: 0,0:01:27.67,0:01:31.89,CustomStyle,,0,0,0,,{\\an8\\i1\\k50}我们终于可以一起制作游戏了！\n```\n\n这里，“CustomStyle” 是预先定义好的一种样式，而 `{}` 内的内容则是额外添加的临时样式覆盖。第一句台词位于屏幕顶部中央（`an7`），并且采用了黄色字体配蓝色边框；第二句则位于顶部右侧（`an8`），带有卡拉 OK 式的逐字高亮效果（`\\k50` 表示每个字符高亮持续50毫秒）。\n\n#### 编码方式\n\n与SRT类似，ASS也推荐使用UTF-8编码，特别是当涉及到多语言支持时。正确的编码选择对于避免乱码至关重要。此外，由于ASS支持更多样化的字体和颜色配置，因此还需要确保目标设备上安装了相应的字体文件，或者考虑嵌入所需字体以便于跨平台播放。\n\n### 3.3 SSA字幕\n\n在上面我们介绍了ASS字幕，ASS字幕其实是SSA字幕格式的高级版本，在SSA的基础上增加了一些额外的功能。下面用一个例子介绍下ASS和SSA之间的区别和联系。\n\n假设我们要为一段视频添加带有特效的字幕，这段视频中有一句台词：**“欢迎来到未来世界”。**\n\n#### SSA 字幕文件示例\n\n首先，我们看看如何用 SSA 格式创建这段字幕。\n\n```plaintext\n[Script Info]\n; This is a Sub Station Alpha v4 script.\nTitle: Future World - Episode 1\nOriginal Script: Example Author\nScriptType: v4.00\nCollisions: Normal\nPlayResX: 640\nPlayResY: 480\nTimer: 100,00\n\n[V4 Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, TertiaryColour, BackColour, Bold, Italic, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, AlphaLevel, Encoding\nStyle: Default,Arial,20,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,-1,0,1,2,2,2,10,10,10,0,0\n\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\nDialogue: 0,0:00:05.00,0:00:07.00,Default,,0,0,0,,{\\c&HFF0000&}欢迎{\\c&H00FF00&}来到{\\c&H0000FF&}未来世界！\n```\n\n在这个 SSA 文件中：\n\n- **[Script Info]** 部分定义了脚本的基本信息，如标题、原作者等。\n- **[V4 Styles]** 定义了一种默认样式 `Default`，指定了字体名称、大小、颜色等属性。\n- **[Events]** 包含了一个对话事件，它设置了开始时间和结束时间，并使用了内联标签 `\\c` 来改变文本的颜色，以实现多彩效果。\n\n#### ASS 字幕文件示例\n\n接下来，我们将相同的台词转换成 ASS 格式，同时增加一些额外的功能。\n\n```plaintext\n[Script Info]\n; This is an Advanced Sub Station Alpha v4+ script.\nTitle: Future World - Episode 1\nScriptType: v4.00+\nCollisions: Normal\nPlayResX: 640\nPlayResY: 480\nTimer: 100,00\n\n[V4+ Styles]\nFormat: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding\nStyle: Default,Arial,20,&H00FFFFFF,&H000000FF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,1,1,2,10,10,10,1\n\n[Events]\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\nDialogue: 0,0:00:05.00,0:00:07.00,Default,,0,0,0,,{\\an8\\c&HFF0000&\\b1}欢迎{\\c&H00FF00&\\b0}来到{\\c&H0000FF&}未来世界！{\\fad(500,500)}\n```\n\n在这个 ASS 文件中：\n\n- **[Script Info]** 部分同样提供了脚本信息，但指明这是 v4.00+ 版本。\n- **[V4+ Styles]** 中增加了更多样式属性，例如 `ScaleX`, `ScaleY`, `Spacing`, `Angle` 等，允许对文本进行更精细的控制。\n- **[Events]** 部分不仅实现了与 SSA 相同的多彩效果，还加入了粗体切换 (`\\b1`, `\\b0`) 和淡入淡出效果 (`\\fad`)。\n\n#### 区别和联系\n\n##### 区别\n\n1. **版本**：ASS 是基于 SSA v4.00+ 的改进版本，具有更多的功能和支持。\n2. **样式定义**：ASS 在 `[V4+ Styles]` 中引入了额外的样式属性，如 `ScaleX`, `ScaleY`, `Spacing`, `Angle` 等。\n3. **内联标签支持**：ASS 扩展了 SSA 的内联标签功能，新增了如 `\\t` (临时样式覆盖) 等标签，并增强了现有标签的效果，比如卡拉 OK 效果 (`\\k`)。\n4. **高级特效与动画**：ASS 支持更复杂的动画效果，包括路径上的移动 (\\move)，旋转，缩放变换等。\n5. **字符编码**：ASS 设计之初就考虑到了更好的国际化支持，对于非拉丁字符集有更好的处理方式。\n\n##### 联系\n\n- **结构相似**：两者都遵循类似的文件结构，包括 `[Script Info]`, `[V4/V4+ Styles]`, `[Events]` 等部分。\n- **向后兼容**：大多数现代播放器能够解析 SSA 和 ASS 文件，因为 ASS 向后兼容 SSA。\n- **基本功能一致**：在基础功能上，SSA 和 ASS 提供了相同的核心特性，如设置字体、颜色、对齐方式等。\n\n综上所述，尽管 SSA 和 ASS 在细节上有许多不同之处，但它们共享很多共同点，特别是对于普通用户来说，两者都能很好地满足日常字幕制作的需求。然而，如果你需要利用更先进的特效或希望确保最佳的跨平台兼容性，那么选择 ASS 可能会是一个更好的决定。\n\n### 3.4 VTT字幕\n\nWebVTT（Web Video Text Tracks）是一种专门为网络视频设计的字幕格式，它被广泛应用于 HTML5 `<video>` 元素中。WebVTT 文件通常以 `.vtt` 作为扩展名，并且是纯文本文件，易于编辑和解析。与 SSA/ASS 等格式相比，WebVTT 更加简洁，专注于提供基本的字幕功能，如时间戳、文本内容以及简单的样式控制。下面将通过一个具体的例子来详细介绍 WebVTT 的结构和用法。\n\n#### WebVTT 文件的基本结构\n\n每个 WebVTT 文件都必须以 `WEBVTT` 开头，紧接着是一个空行，然后是各个字幕段落。每个段落由以下几部分组成：\n\n1. **标识符（可选）**：可以为每个字幕段落指定一个唯一的标识符。\n2. **时间码**：定义了字幕显示的时间范围，格式为 `HH:MM:SS.mmm --> HH:MM:SS.mmm`，其中 `HH` 表示小时，`MM` 表示分钟，`SS` 表示秒，`mmm` 表示毫秒。\n3. **设置（可选）**：用于指定字幕的位置、对齐方式等属性。\n4. **文本内容**：即实际要显示的字幕文字，可以包含多行。\n\n##### 示例：简单对话场景\n\n假设我们有一段视频，其中一个人说：“欢迎来到未来世界。” 我们可以创建如下的 WebVTT 文件：\n\n```plaintext\nWEBVTT\n\n1\n00:00:05.000 --> 00:00:07.000\n欢迎来到未来世界。\n```\n\n在这个例子中：\n\n- `WEBVTT` 表明这是一个 WebVTT 文件。\n- 数字 `1` 是字幕段落的唯一标识符（可选），有助于管理和引用特定的字幕。\n- 时间码 `00:00:05.000 --> 00:00:07.000` 指定了字幕从第 5 秒开始，在第 7 秒结束。\n- 最后一行是实际要显示的文字内容。\n\n#### 增强样式的使用\n\n虽然 WebVTT 主要关注于提供清晰易读的字幕，但它也允许一定程度上的样式定制。例如，你可以使用 HTML 标签或内联 CSS 来改变字体颜色、大小、样式等。此外，WebVTT 还支持一些特殊的标签来实现更复杂的效果。\n\n##### 示例：带样式的字幕\n\n考虑同样的台词，但我们想让它更引人注目，比如给“欢迎”两个字加上红色高亮，并让整个句子居中显示：\n\n```plaintext\nWEBVTT\n\n1\n00:00:05.000 --> 00:00:07.000 line:50% position:50% align:center\n<c.red>欢迎</c>来到未来世界。\n```\n\n在这个例子中：\n\n- `line:50% position:50% align:center` 设置了字幕在屏幕上的位置和对齐方式，使它位于屏幕中央。\n- `<c.red>` 和 `</c>` 是 WebVTT 特有的标记，用来包裹需要应用样式的文本。这里我们将“欢迎”两个字的颜色设置为红色。\n\n#### 使用 CSS 类进行样式化\n\n对于更复杂的样式需求，可以结合 CSS 类来进行处理。首先，在 WebVTT 文件中定义类名，然后在网页上关联相应的 CSS 样式规则。\n\n##### 示例：使用 CSS 类\n\n继续上面的例子，这次我们将为“欢迎”添加一个自定义的 CSS 类：\n\n```plaintext\nWEBVTT\n\n1\n00:00:05.000 --> 00:00:07.000 line:50% position:50% align:center\n<c.vwelcome>欢迎</c>来到未来世界。\n```\n\n接着，在网页中的 `<style>` 标签或者外部样式表里添加如下 CSS 规则：\n\n```css\n::cue(.vwelcome) {\n    color: red;\n    font-weight: bold;\n}\n```\n\n这样，当播放器渲染这个 WebVTT 文件时，“欢迎”这两个字不仅会变成红色，还会显得更加粗重。\n\n#### WebVTT 的高级特性\n\n除了上述基本功能外，WebVTT 还支持其他类型的文本轨道，如章节列表、描述性音轨等。这些功能使得 WebVTT 成为了一个非常灵活且强大的工具，适用于各种多媒体应用场景。\n\n##### 示例：章节列表\n\n如果想要为视频添加章节导航，可以使用 WebVTT 创建一个章节轨道文件：\n\n```plaintext\nWEBVTT\n\nCHAPTERS\n\n00:00:00.000 --> 00:01:00.000\nIntroduction\n\n00:01:00.000 --> 00:02:30.000\nMain Content\n\n00:02:30.000 --> 00:03:00.000\nConclusion\n```\n\n这段代码定义了一个包含三个章节的列表，用户可以通过点击章节标题快速跳转到相应的时间点。\n\n#### 总结\n\nWebVTT 是一种轻量级但功能丰富的字幕格式，特别适合在网络环境中使用。它的语法简单直观，易于学习和实现，同时提供了足够的灵活性来满足大多数字幕制作的需求。无论是简单的对话字幕还是带有复杂样式的提示信息，WebVTT 都能有效地支持。更重要的是，由于它是 HTML5 标准的一部分，因此可以在所有现代浏览器中无缝工作，确保了良好的兼容性和用户体验。\n\n# 4. 字幕制作\n\n### 4.1 字幕的制作工具\n\n有许多专业的字幕制作软件可以帮助用户轻松制作和编辑字幕，例如：\n\n1. **KBuilderTools (小灰熊字幕制作软件)**：支持MV字幕制作，操作简单。\n2. **Sayatoo卡拉字幕精灵**：支持自定义设置字幕的字体、颜色、布局等参数。\n3. **Srt字幕制作帮手**：专门针对SRT字幕的编辑软件，操作简便。\n4. **字幕大师 (OKVoice)**：采用高精准语音识别技术，支持自动匹配音视频中的语音与字幕。\n5. **Arctime Pro**：专业字幕制作软件，支持多种创新技术，如字幕块绑定、自动分轴等。\n6. **Aegisub**：免费、开源、跨平台的字幕编辑软件，支持多种语言编码。\n\n### 4.2 字幕的制作步骤\n\n1. **导入视频和字幕文件**：使用视频编辑软件导入视频文件和字幕文件，确保字幕文件与视频文件的内容对应。\n2. **调整时间轴**：在视频编辑软件中，调整字幕的出现时间和消失时间，使其与配音的时长和内容一致。\n3. **调整字幕样式**：根据需要，调整字幕的字体、字号、颜色、背景等，以使字幕更加清晰明确。\n4. **预览和调整**：预览整个视频，确保字幕与配音同步显示，并且字幕的内容清晰可读。\n5. **导出视频**：完成字幕的调整后，将视频导出为新的文件，确保字幕和配音同步的效果在最终的视频文件中得以保留。\n\n\n\n\n\n文章合集：https://github.com/chongzicbo/ReadWriteThink\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","slug":"开发/音视频/音视频开发09：字幕介绍","published":1,"updated":"2024-12-26T06:37:11.501Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3m0016hghi4f6t6yyu","content":"<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209171329186.png\" alt=\"image-20241209171329186\"></p>\n<h1 id=\"1-定义\"><a href=\"#1-定义\" class=\"headerlink\" title=\"1. 定义\"></a>1. 定义</h1><p>音视频的字幕是指以文本形式显示在屏幕上的内容，这些内容通常代表了音频中的对话、叙述以及其他重要的声音元素。字幕不仅有助于提高视频内容的理解度，而且对于那些有听力障碍或是在静音环境中观看视频的人来说尤为重要。此外，字幕还可以用于翻译不同语言的内容，从而扩大视频的受众范围</p>\n<h1 id=\"2-字幕的种类\"><a href=\"#2-字幕的种类\" class=\"headerlink\" title=\"2. 字幕的种类\"></a>2. 字幕的种类</h1><p>根据其功能和使用场景，字幕可以分为几种不同类型：</p>\n<ul>\n<li><strong>开放式字幕（硬编码字幕）</strong>：这类字幕直接嵌入到视频帧中，成为视频的一部分，无法关闭。它们适用于需要永久性地将字幕信息与视频结合的情况。</li>\n<li><strong>隐藏式字幕（软字幕&#x2F;外挂字幕）</strong>：用户可以选择是否开启这类字幕，并且可以根据需要调整样式。它们通常作为独立文件存在，如SRT、ASS等格式，便于管理和更新。</li>\n<li><strong>实时字幕</strong>：这种字幕是在直播或其他即时活动中生成的，能够快速响应现场发生的口语交流，为观众提供即时的文字反馈</li>\n</ul>\n<h1 id=\"3-字幕格式\"><a href=\"#3-字幕格式\" class=\"headerlink\" title=\"3. 字幕格式\"></a>3. 字幕格式</h1><p>常见的字幕格式包括：</p>\n<ol>\n<li>**SRT (SubRip Text)**：最常见的字幕格式之一，文本文件，每行包含时间码和字幕内容。</li>\n<li>**ASS (Advanced SubStation Alpha)**：功能强大的字幕格式，支持复杂的字幕样式和特效。</li>\n<li>**SSA (SubStation Alpha)**：早期的字幕格式，功能不如ASS强大，较少使用。</li>\n<li>**VTT (WebVTT)**：用于网页视频的字幕格式，类似于SRT<a href=\"https://blog.csdn.net/AlvinCasper/article/details/113066446\">5</a>。</li>\n</ol>\n<h3 id=\"3-1-SRT字幕\"><a href=\"#3-1-SRT字幕\" class=\"headerlink\" title=\"3.1 SRT字幕\"></a>3.1 SRT字幕</h3><p>SRT（SubRip Text）字幕格式以其简洁性和广泛的兼容性著称，它由纯文本构成，每个字幕段落包括四个主要部分：序号、时间码、字幕文本以及一个空白行来分隔不同的字幕片段。下面我们将通过具体的例子详细介绍SRT字幕文件的结构和使用方法。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209172234191.png\" alt=\"image-20241209172234191\"></p>\n<h4 id=\"SRT-字幕的基本结构\"><a href=\"#SRT-字幕的基本结构\" class=\"headerlink\" title=\"SRT 字幕的基本结构\"></a>SRT 字幕的基本结构</h4><h5 id=\"序号\"><a href=\"#序号\" class=\"headerlink\" title=\"序号\"></a>序号</h5><p>每个字幕段都有一个唯一的序号，这个数字从1开始递增，表示字幕出现的顺序。虽然序号本身并不直接影响播放时的显示效果，但在实际应用中，它有助于保持字幕的逻辑顺序正确无误。</p>\n<h5 id=\"时间码\"><a href=\"#时间码\" class=\"headerlink\" title=\"时间码\"></a>时间码</h5><p>紧跟在序号之后的是时间码，它定义了字幕何时出现及消失。时间码遵循<code>hh:mm:ss,mmm --&gt; hh:mm:ss,mmm</code>的格式，其中<code>hh</code>代表小时，<code>mm</code>代表分钟，<code>ss</code>代表秒，而<code>mmm</code>则表示毫秒。例如：</p>\n<figure class=\"highlight dns\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dns\"><span class=\"hljs-number\">1</span><br><span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00:29,740</span> --&gt; <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00:31,280</span><br>福姬套餐~<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，字幕“福姬套餐~”将在视频播放到第29秒740毫秒时出现，并持续到第31秒280毫秒后消失。</p>\n<h5 id=\"字幕文本\"><a href=\"#字幕文本\" class=\"headerlink\" title=\"字幕文本\"></a>字幕文本</h5><p>接下来是具体的字幕文本，它可以是一行或多行。对于多语言字幕，不同语言的内容可以通过换行分隔开来。例如，在同一时间段内可以先显示英文再显示中文翻译：</p>\n<figure class=\"highlight dns\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dns\"><span class=\"hljs-number\">2</span><br><span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00:31,400</span> --&gt; <span class=\"hljs-number\">00:00:32,240</span><br>炒炸酱面<br></code></pre></td></tr></table></figure>\n\n<p>这里，“炒炸酱面”会在指定的时间范围内显示在屏幕上。</p>\n<h5 id=\"空白行\"><a href=\"#空白行\" class=\"headerlink\" title=\"空白行\"></a>空白行</h5><p>每一组字幕之间必须有一个空行来分隔不同的字幕片段，这标志着上一段字幕的结束和新一段字幕的开始。空白行的存在确保了字幕文件的可读性和结构清晰度。</p>\n<h4 id=\"样式与格式化示例\"><a href=\"#样式与格式化示例\" class=\"headerlink\" title=\"样式与格式化示例\"></a>样式与格式化示例</h4><p>尽管SRT本质上是一个简单的文本文件，但它也支持一些基本的HTML标签来进行格式化，如粗体（<code>&lt;b&gt;</code>）、斜体（<code>&lt;i&gt;</code>）、下划线（<code>&lt;u&gt;</code>）以及字体颜色（<code>&lt;font color=&quot;...&quot;&gt;</code>）。需要注意的是，并非所有的播放器都支持这些样式标记，因此在实际使用时应该考虑目标平台的支持情况。例如：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xml\">3<br>00:00:32,360 --&gt; 00:00:33,300<br><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">b</span>&gt;</span>炒拉面<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">b</span>&gt;</span><br></code></pre></td></tr></table></figure>\n\n<p>这段代码会让“炒拉面”以粗体形式显示。</p>\n<h4 id=\"实际应用中的SRT文件示例\"><a href=\"#实际应用中的SRT文件示例\" class=\"headerlink\" title=\"实际应用中的SRT文件示例\"></a>实际应用中的SRT文件示例</h4><p>以下是一个完整的SRT字幕文件示例，摘自电影《阿凡达》的中英双语字幕：</p>\n<figure class=\"highlight ada\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ada\"><span class=\"hljs-number\">3</span><br><span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">39</span>,<span class=\"hljs-number\">770</span> <span class=\"hljs-comment\">--&gt; 00:00:41,880</span><br>在经历了一场人生巨变之后<br><span class=\"hljs-keyword\">When</span> I was lying there <span class=\"hljs-keyword\">in</span> the VA hospital ...<br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight applescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs applescript\"><span class=\"hljs-number\">4</span><br><span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">42</span>,<span class=\"hljs-number\">550</span> <span class=\"hljs-comment\">--&gt; 00:00:44,690</span><br>我被送进了退伍军人管理局医院 ...<br><span class=\"hljs-keyword\">with</span> a big hole blown <span class=\"hljs-keyword\">through</span> <span class=\"hljs-keyword\">the</span> <span class=\"hljs-keyword\">middle</span> <span class=\"hljs-keyword\">of</span> <span class=\"hljs-keyword\">my</span> life,<br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight dns\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dns\"><span class=\"hljs-number\">5</span><br><span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00:45,590</span> --&gt; <span class=\"hljs-number\">00:00:48,120</span><br>那段时间我经常会梦到自己在飞翔 ...<br>I started having these dreams of flying.<br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight dns\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dns\"><span class=\"hljs-number\">6</span><br><span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00:49,740</span> --&gt; <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00:51,520</span><br>终获自由<br>I was free.<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，我们可以看到每一段字幕都有其对应的序号、时间码和文本内容，并且通过空白行分隔开各个字幕段。</p>\n<h4 id=\"编码方式\"><a href=\"#编码方式\" class=\"headerlink\" title=\"编码方式\"></a>编码方式</h4><p>SRT文件默认采用Windows-1252编码，但也可以保存为其他编码格式，如UTF-8或UTF-16，带或不带字节顺序标记（BOM）。为了确保跨平台兼容性，建议尽量使用UTF-8编码。特别是当涉及到非ASCII字符时，正确的编码选择尤为重要，因为错误的编码可能导致乱码问题。</p>\n<h4 id=\"创建与编辑SRT文件\"><a href=\"#创建与编辑SRT文件\" class=\"headerlink\" title=\"创建与编辑SRT文件\"></a>创建与编辑SRT文件</h4><p>创建SRT文件的过程相对直接，用户可以直接用文本编辑器手动编写，也可以借助专门的字幕编辑软件，如Aegisub、Subtitle Edit等。此外，还有在线服务和移动应用程序可以帮助生成或调整现有的SRT文件。对于批量处理或者需要高精度的时间轴同步，还可以考虑利用语音识别技术自动生成初步的SRT文件，然后进行人工校对和完善。</p>\n<p>综上所述，SRT字幕格式凭借其易于理解和操作的特点，成为了视频字幕领域不可或缺的一部分。</p>\n<h3 id=\"3-2-ASS字幕\"><a href=\"#3-2-ASS字幕\" class=\"headerlink\" title=\"3.2 ASS字幕\"></a>3.2 ASS字幕</h3><p>ASS（Advanced SubStation Alpha）是一种比SSA更为高级的字幕格式，它不仅支持基本的文本显示，还允许用户添加复杂的样式、特效以及时间轴控制。ASS 文件通常以 <code>.ass</code> 作为文件扩展名，并且是纯文本文件，这意味着它们可以用任何文本编辑器手工编辑，但必须注意遵循特定的规则以确保正确解析。</p>\n<h4 id=\"ASS-字幕的基本结构\"><a href=\"#ASS-字幕的基本结构\" class=\"headerlink\" title=\"ASS 字幕的基本结构\"></a>ASS 字幕的基本结构</h4><p>一个典型的 ASS 文件由几个部分组成：<code>[Script Info]</code>、<code>[V4+ Styles]</code> 和 <code>[Events]</code>。每个部分都有其独特的功能和用途。</p>\n<h5 id=\"Script-Info\"><a href=\"#Script-Info\" class=\"headerlink\" title=\"[Script Info]\"></a>[Script Info]</h5><p>这部分包含了脚本的头部信息和总体描述。例如：</p>\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\">[<span class=\"hljs-keyword\">Script </span>Info]<br><span class=\"hljs-comment\">; This is a Sub Station Alpha v4 script.</span><br><span class=\"hljs-symbol\">Title:</span> Neon Genesis Evangelion - Episode <span class=\"hljs-number\">26</span> (neutral Spanish)<br><span class=\"hljs-keyword\">Original </span><span class=\"hljs-keyword\">Script: </span>RoRo<br><span class=\"hljs-keyword\">Script </span>Updated <span class=\"hljs-keyword\">By: </span>version <span class=\"hljs-number\">2</span>.<span class=\"hljs-number\">8</span>.<span class=\"hljs-number\">01</span><br><span class=\"hljs-keyword\">ScriptType: </span>v4.<span class=\"hljs-number\">00</span>+<br><span class=\"hljs-symbol\">Collisions:</span> <span class=\"hljs-keyword\">Normal</span><br><span class=\"hljs-keyword\"></span><span class=\"hljs-symbol\">PlayResY:</span> <span class=\"hljs-number\">600</span><br><span class=\"hljs-symbol\">PlayDepth:</span> <span class=\"hljs-number\">0</span><br><span class=\"hljs-symbol\">Timer:</span> <span class=\"hljs-number\">100</span>,<span class=\"hljs-number\">00</span><br></code></pre></td></tr></table></figure>\n\n<p>这里定义了诸如标题 (<code>Title</code>)、原作者 (<code>Original Script</code>) 等元数据，以及一些技术参数如播放分辨率 (<code>PlayResX</code>, <code>PlayResY</code>) 和颜色深度 (<code>PlayDepth</code>)。<code>Timer</code> 属性用于调整字幕的时间轴速度，不过现代渲染器通常会忽略这一设置。</p>\n<h5 id=\"V4-Styles\"><a href=\"#V4-Styles\" class=\"headerlink\" title=\"[V4+ Styles]\"></a>[V4+ Styles]</h5><p>这是样式定义的部分，其中每一个被脚本使用的样式都应该在此处定义。格式如下：</p>\n<figure class=\"highlight dns\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dns\">[V4+ Styles]<br>Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding<br>Style: Default,Arial,<span class=\"hljs-number\">20</span>,&amp;H00FFFFFF,&amp;H000000FF,&amp;H<span class=\"hljs-number\">00000000</span>,&amp;H<span class=\"hljs-number\">00000000,0</span>,<span class=\"hljs-number\">0,0,0,100</span>,<span class=\"hljs-number\">100,0,0,1</span>,<span class=\"hljs-number\">0.5,0,2</span>,<span class=\"hljs-number\">10,10,10,1</span><br></code></pre></td></tr></table></figure>\n\n<p>每一项都对应着不同的视觉属性，比如字体名称 (<code>Fontname</code>)、字体大小 (<code>Fontsize</code>)、主要颜色 (<code>PrimaryColour</code>) 等等。<code>Alignment</code> 属性决定了字幕在屏幕上的对齐方式，而 <code>MarginL</code>, <code>MarginR</code>, <code>MarginV</code> 则设定了字幕与屏幕边缘的距离。</p>\n<h5 id=\"Events\"><a href=\"#Events\" class=\"headerlink\" title=\"[Events]\"></a>[Events]</h5><p>这是最重要的部分之一，因为它包含了所有实际出现在屏幕上的内容。每条事件记录了一个具体的字幕或注释，并指定了它的开始时间和结束时间、所使用的样式以及其他可能的效果。例如：</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">[Events]<br><span class=\"hljs-keyword\">Format</span>: Layer, <span class=\"hljs-keyword\">Start</span>, <span class=\"hljs-keyword\">End</span>, Style, <span class=\"hljs-type\">Name</span>, MarginL, MarginR, MarginV, Effect, <span class=\"hljs-type\">Text</span><br>Dialogue: <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">09.07</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">13.14</span>,<span class=\"hljs-keyword\">Default</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,,我的爱从相遇的那一刻起<br>Dialogue: <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">13.27</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">17.41</span>,<span class=\"hljs-keyword\">Default</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,,我的生活一切都被你占据<br></code></pre></td></tr></table></figure>\n\n<p><code>Layer</code> 属性控制字幕的叠放顺序；<code>Start</code> 和 <code>End</code> 分别表示字幕出现和消失的时间点；<code>Style</code> 指向之前定义好的样式；<code>Text</code> 包含了要显示的具体文字。</p>\n<h4 id=\"样式与格式化示例-1\"><a href=\"#样式与格式化示例-1\" class=\"headerlink\" title=\"样式与格式化示例\"></a>样式与格式化示例</h4><p>除了上述基础元素外，ASS 还提供了丰富的内联标签来实现更加精细的排版和动画效果。例如：</p>\n<ul>\n<li><code>\\b1</code> 开启粗体，<code>\\b0</code> 关闭粗体；</li>\n<li><code>\\i1</code> 开启斜体，<code>\\i0</code> 关闭斜体；</li>\n<li><code>\\u1</code> 开启下划线，<code>\\u0</code> 关闭下划线；</li>\n<li><code>\\k&lt;time&gt;</code> 用于卡拉 OK 效果，指定高亮移动的速度；</li>\n<li><code>\\move(&lt;x1&gt;, &lt;y1&gt;, &lt;x2&gt;, &lt;y2&gt;)</code> 实现字幕从一个位置移动到另一个位置；</li>\n<li><code>\\fad(&lt;in-time&gt;, &lt;out-time&gt;)</code> 创建淡入淡出效果。</li>\n</ul>\n<p>以下是一个使用这些标签的例子：</p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">Dialogue</span>: <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>.<span class=\"hljs-number\">00</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">05</span>.<span class=\"hljs-number\">00</span>,Default,,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,,&#123;\\b1\\u1\\c&amp;HFF0000&amp;&#125;这是一段&#123;\\i1&#125;带&#123;\\i0&#125;有&#123;\\b0\\u0&#125;样式的文本。<br><span class=\"hljs-attribute\">Dialogue</span>: <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">05</span>.<span class=\"hljs-number\">00</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">10</span>.<span class=\"hljs-number\">00</span>,Default,,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,,&#123;\\move(<span class=\"hljs-number\">100</span>,<span class=\"hljs-number\">100</span>,<span class=\"hljs-number\">500</span>,<span class=\"hljs-number\">100</span>)\\fad(<span class=\"hljs-number\">1000</span>,<span class=\"hljs-number\">1000</span>)&#125;这段文字会从左下角滑动到右下角并伴有淡入淡出。<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，第一行应用了粗体和下划线，同时将颜色更改为红色，并且中间有一部分为斜体；第二行则设置了从屏幕左侧到右侧的移动路径，并且加入了1秒的淡入淡出过渡。</p>\n<h4 id=\"实际应用中的ASS文件示例\"><a href=\"#实际应用中的ASS文件示例\" class=\"headerlink\" title=\"实际应用中的ASS文件示例\"></a>实际应用中的ASS文件示例</h4><p>考虑到ASS的强大功能，它可以用来创建非常复杂且富有创意的字幕效果，尤其是在动漫领域。下面给出一段来自《命运石之门》的日语台词及其对应的ASS代码：</p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">Dialogue</span>: <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">01</span>:<span class=\"hljs-number\">23</span>.<span class=\"hljs-number\">45</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">01</span>:<span class=\"hljs-number\">27</span>.<span class=\"hljs-number\">67</span>,CustomStyle,,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,,&#123;\\an7\\b1\\c&amp;HFFFF00&amp;\\<span class=\"hljs-number\">3</span>c&amp;H0000FF&amp;&#125;OKERU！<br><span class=\"hljs-attribute\">Dialogue</span>: <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">01</span>:<span class=\"hljs-number\">27</span>.<span class=\"hljs-number\">67</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">01</span>:<span class=\"hljs-number\">31</span>.<span class=\"hljs-number\">89</span>,CustomStyle,,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,,&#123;\\an8\\i1\\k50&#125;我们终于可以一起制作游戏了！<br></code></pre></td></tr></table></figure>\n\n<p>这里，“CustomStyle” 是预先定义好的一种样式，而 <code>&#123;&#125;</code> 内的内容则是额外添加的临时样式覆盖。第一句台词位于屏幕顶部中央（<code>an7</code>），并且采用了黄色字体配蓝色边框；第二句则位于顶部右侧（<code>an8</code>），带有卡拉 OK 式的逐字高亮效果（<code>\\k50</code> 表示每个字符高亮持续50毫秒）。</p>\n<h4 id=\"编码方式-1\"><a href=\"#编码方式-1\" class=\"headerlink\" title=\"编码方式\"></a>编码方式</h4><p>与SRT类似，ASS也推荐使用UTF-8编码，特别是当涉及到多语言支持时。正确的编码选择对于避免乱码至关重要。此外，由于ASS支持更多样化的字体和颜色配置，因此还需要确保目标设备上安装了相应的字体文件，或者考虑嵌入所需字体以便于跨平台播放。</p>\n<h3 id=\"3-3-SSA字幕\"><a href=\"#3-3-SSA字幕\" class=\"headerlink\" title=\"3.3 SSA字幕\"></a>3.3 SSA字幕</h3><p>在上面我们介绍了ASS字幕，ASS字幕其实是SSA字幕格式的高级版本，在SSA的基础上增加了一些额外的功能。下面用一个例子介绍下ASS和SSA之间的区别和联系。</p>\n<p>假设我们要为一段视频添加带有特效的字幕，这段视频中有一句台词：<strong>“欢迎来到未来世界”。</strong></p>\n<h4 id=\"SSA-字幕文件示例\"><a href=\"#SSA-字幕文件示例\" class=\"headerlink\" title=\"SSA 字幕文件示例\"></a>SSA 字幕文件示例</h4><p>首先，我们看看如何用 SSA 格式创建这段字幕。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs plaintext\">[Script Info]<br>; This is a Sub Station Alpha v4 script.<br>Title: Future World - Episode 1<br>Original Script: Example Author<br>ScriptType: v4.00<br>Collisions: Normal<br>PlayResX: 640<br>PlayResY: 480<br>Timer: 100,00<br><br>[V4 Styles]<br>Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, TertiaryColour, BackColour, Bold, Italic, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, AlphaLevel, Encoding<br>Style: Default,Arial,20,&amp;H00FFFFFF,&amp;H000000FF,&amp;H00000000,&amp;H00000000,-1,0,1,2,2,2,10,10,10,0,0<br><br>[Events]<br>Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text<br>Dialogue: 0,0:00:05.00,0:00:07.00,Default,,0,0,0,,&#123;\\c&amp;HFF0000&amp;&#125;欢迎&#123;\\c&amp;H00FF00&amp;&#125;来到&#123;\\c&amp;H0000FF&amp;&#125;未来世界！<br></code></pre></td></tr></table></figure>\n\n<p>在这个 SSA 文件中：</p>\n<ul>\n<li><strong>[Script Info]</strong> 部分定义了脚本的基本信息，如标题、原作者等。</li>\n<li><strong>[V4 Styles]</strong> 定义了一种默认样式 <code>Default</code>，指定了字体名称、大小、颜色等属性。</li>\n<li><strong>[Events]</strong> 包含了一个对话事件，它设置了开始时间和结束时间，并使用了内联标签 <code>\\c</code> 来改变文本的颜色，以实现多彩效果。</li>\n</ul>\n<h4 id=\"ASS-字幕文件示例\"><a href=\"#ASS-字幕文件示例\" class=\"headerlink\" title=\"ASS 字幕文件示例\"></a>ASS 字幕文件示例</h4><p>接下来，我们将相同的台词转换成 ASS 格式，同时增加一些额外的功能。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs plaintext\">[Script Info]<br>; This is an Advanced Sub Station Alpha v4+ script.<br>Title: Future World - Episode 1<br>ScriptType: v4.00+<br>Collisions: Normal<br>PlayResX: 640<br>PlayResY: 480<br>Timer: 100,00<br><br>[V4+ Styles]<br>Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding<br>Style: Default,Arial,20,&amp;H00FFFFFF,&amp;H000000FF,&amp;H00000000,&amp;H00000000,0,0,0,0,100,100,0,0,1,1,1,2,10,10,10,1<br><br>[Events]<br>Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text<br>Dialogue: 0,0:00:05.00,0:00:07.00,Default,,0,0,0,,&#123;\\an8\\c&amp;HFF0000&amp;\\b1&#125;欢迎&#123;\\c&amp;H00FF00&amp;\\b0&#125;来到&#123;\\c&amp;H0000FF&amp;&#125;未来世界！&#123;\\fad(500,500)&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在这个 ASS 文件中：</p>\n<ul>\n<li><strong>[Script Info]</strong> 部分同样提供了脚本信息，但指明这是 v4.00+ 版本。</li>\n<li><strong>[V4+ Styles]</strong> 中增加了更多样式属性，例如 <code>ScaleX</code>, <code>ScaleY</code>, <code>Spacing</code>, <code>Angle</code> 等，允许对文本进行更精细的控制。</li>\n<li><strong>[Events]</strong> 部分不仅实现了与 SSA 相同的多彩效果，还加入了粗体切换 (<code>\\b1</code>, <code>\\b0</code>) 和淡入淡出效果 (<code>\\fad</code>)。</li>\n</ul>\n<h4 id=\"区别和联系\"><a href=\"#区别和联系\" class=\"headerlink\" title=\"区别和联系\"></a>区别和联系</h4><h5 id=\"区别\"><a href=\"#区别\" class=\"headerlink\" title=\"区别\"></a>区别</h5><ol>\n<li><strong>版本</strong>：ASS 是基于 SSA v4.00+ 的改进版本，具有更多的功能和支持。</li>\n<li><strong>样式定义</strong>：ASS 在 <code>[V4+ Styles]</code> 中引入了额外的样式属性，如 <code>ScaleX</code>, <code>ScaleY</code>, <code>Spacing</code>, <code>Angle</code> 等。</li>\n<li><strong>内联标签支持</strong>：ASS 扩展了 SSA 的内联标签功能，新增了如 <code>\\t</code> (临时样式覆盖) 等标签，并增强了现有标签的效果，比如卡拉 OK 效果 (<code>\\k</code>)。</li>\n<li><strong>高级特效与动画</strong>：ASS 支持更复杂的动画效果，包括路径上的移动 (\\move)，旋转，缩放变换等。</li>\n<li><strong>字符编码</strong>：ASS 设计之初就考虑到了更好的国际化支持，对于非拉丁字符集有更好的处理方式。</li>\n</ol>\n<h5 id=\"联系\"><a href=\"#联系\" class=\"headerlink\" title=\"联系\"></a>联系</h5><ul>\n<li><strong>结构相似</strong>：两者都遵循类似的文件结构，包括 <code>[Script Info]</code>, <code>[V4/V4+ Styles]</code>, <code>[Events]</code> 等部分。</li>\n<li><strong>向后兼容</strong>：大多数现代播放器能够解析 SSA 和 ASS 文件，因为 ASS 向后兼容 SSA。</li>\n<li><strong>基本功能一致</strong>：在基础功能上，SSA 和 ASS 提供了相同的核心特性，如设置字体、颜色、对齐方式等。</li>\n</ul>\n<p>综上所述，尽管 SSA 和 ASS 在细节上有许多不同之处，但它们共享很多共同点，特别是对于普通用户来说，两者都能很好地满足日常字幕制作的需求。然而，如果你需要利用更先进的特效或希望确保最佳的跨平台兼容性，那么选择 ASS 可能会是一个更好的决定。</p>\n<h3 id=\"3-4-VTT字幕\"><a href=\"#3-4-VTT字幕\" class=\"headerlink\" title=\"3.4 VTT字幕\"></a>3.4 VTT字幕</h3><p>WebVTT（Web Video Text Tracks）是一种专门为网络视频设计的字幕格式，它被广泛应用于 HTML5 <code>&lt;video&gt;</code> 元素中。WebVTT 文件通常以 <code>.vtt</code> 作为扩展名，并且是纯文本文件，易于编辑和解析。与 SSA&#x2F;ASS 等格式相比，WebVTT 更加简洁，专注于提供基本的字幕功能，如时间戳、文本内容以及简单的样式控制。下面将通过一个具体的例子来详细介绍 WebVTT 的结构和用法。</p>\n<h4 id=\"WebVTT-文件的基本结构\"><a href=\"#WebVTT-文件的基本结构\" class=\"headerlink\" title=\"WebVTT 文件的基本结构\"></a>WebVTT 文件的基本结构</h4><p>每个 WebVTT 文件都必须以 <code>WEBVTT</code> 开头，紧接着是一个空行，然后是各个字幕段落。每个段落由以下几部分组成：</p>\n<ol>\n<li><strong>标识符（可选）</strong>：可以为每个字幕段落指定一个唯一的标识符。</li>\n<li><strong>时间码</strong>：定义了字幕显示的时间范围，格式为 <code>HH:MM:SS.mmm --&gt; HH:MM:SS.mmm</code>，其中 <code>HH</code> 表示小时，<code>MM</code> 表示分钟，<code>SS</code> 表示秒，<code>mmm</code> 表示毫秒。</li>\n<li><strong>设置（可选）</strong>：用于指定字幕的位置、对齐方式等属性。</li>\n<li><strong>文本内容</strong>：即实际要显示的字幕文字，可以包含多行。</li>\n</ol>\n<h5 id=\"示例：简单对话场景\"><a href=\"#示例：简单对话场景\" class=\"headerlink\" title=\"示例：简单对话场景\"></a>示例：简单对话场景</h5><p>假设我们有一段视频，其中一个人说：“欢迎来到未来世界。” 我们可以创建如下的 WebVTT 文件：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs plaintext\">WEBVTT<br><br>1<br>00:00:05.000 --&gt; 00:00:07.000<br>欢迎来到未来世界。<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中：</p>\n<ul>\n<li><code>WEBVTT</code> 表明这是一个 WebVTT 文件。</li>\n<li>数字 <code>1</code> 是字幕段落的唯一标识符（可选），有助于管理和引用特定的字幕。</li>\n<li>时间码 <code>00:00:05.000 --&gt; 00:00:07.000</code> 指定了字幕从第 5 秒开始，在第 7 秒结束。</li>\n<li>最后一行是实际要显示的文字内容。</li>\n</ul>\n<h4 id=\"增强样式的使用\"><a href=\"#增强样式的使用\" class=\"headerlink\" title=\"增强样式的使用\"></a>增强样式的使用</h4><p>虽然 WebVTT 主要关注于提供清晰易读的字幕，但它也允许一定程度上的样式定制。例如，你可以使用 HTML 标签或内联 CSS 来改变字体颜色、大小、样式等。此外，WebVTT 还支持一些特殊的标签来实现更复杂的效果。</p>\n<h5 id=\"示例：带样式的字幕\"><a href=\"#示例：带样式的字幕\" class=\"headerlink\" title=\"示例：带样式的字幕\"></a>示例：带样式的字幕</h5><p>考虑同样的台词，但我们想让它更引人注目，比如给“欢迎”两个字加上红色高亮，并让整个句子居中显示：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs plaintext\">WEBVTT<br><br>1<br>00:00:05.000 --&gt; 00:00:07.000 line:50% position:50% align:center<br>&lt;c.red&gt;欢迎&lt;/c&gt;来到未来世界。<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中：</p>\n<ul>\n<li><code>line:50% position:50% align:center</code> 设置了字幕在屏幕上的位置和对齐方式，使它位于屏幕中央。</li>\n<li><code>&lt;c.red&gt;</code> 和 <code>&lt;/c&gt;</code> 是 WebVTT 特有的标记，用来包裹需要应用样式的文本。这里我们将“欢迎”两个字的颜色设置为红色。</li>\n</ul>\n<h4 id=\"使用-CSS-类进行样式化\"><a href=\"#使用-CSS-类进行样式化\" class=\"headerlink\" title=\"使用 CSS 类进行样式化\"></a>使用 CSS 类进行样式化</h4><p>对于更复杂的样式需求，可以结合 CSS 类来进行处理。首先，在 WebVTT 文件中定义类名，然后在网页上关联相应的 CSS 样式规则。</p>\n<h5 id=\"示例：使用-CSS-类\"><a href=\"#示例：使用-CSS-类\" class=\"headerlink\" title=\"示例：使用 CSS 类\"></a>示例：使用 CSS 类</h5><p>继续上面的例子，这次我们将为“欢迎”添加一个自定义的 CSS 类：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs plaintext\">WEBVTT<br><br>1<br>00:00:05.000 --&gt; 00:00:07.000 line:50% position:50% align:center<br>&lt;c.vwelcome&gt;欢迎&lt;/c&gt;来到未来世界。<br></code></pre></td></tr></table></figure>\n\n<p>接着，在网页中的 <code>&lt;style&gt;</code> 标签或者外部样式表里添加如下 CSS 规则：</p>\n<figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\"><span class=\"hljs-selector-pseudo\">::cue</span>(<span class=\"hljs-selector-class\">.vwelcome</span>) &#123;<br>    <span class=\"hljs-attribute\">color</span>: red;<br>    <span class=\"hljs-attribute\">font-weight</span>: bold;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>这样，当播放器渲染这个 WebVTT 文件时，“欢迎”这两个字不仅会变成红色，还会显得更加粗重。</p>\n<h4 id=\"WebVTT-的高级特性\"><a href=\"#WebVTT-的高级特性\" class=\"headerlink\" title=\"WebVTT 的高级特性\"></a>WebVTT 的高级特性</h4><p>除了上述基本功能外，WebVTT 还支持其他类型的文本轨道，如章节列表、描述性音轨等。这些功能使得 WebVTT 成为了一个非常灵活且强大的工具，适用于各种多媒体应用场景。</p>\n<h5 id=\"示例：章节列表\"><a href=\"#示例：章节列表\" class=\"headerlink\" title=\"示例：章节列表\"></a>示例：章节列表</h5><p>如果想要为视频添加章节导航，可以使用 WebVTT 创建一个章节轨道文件：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs plaintext\">WEBVTT<br><br>CHAPTERS<br><br>00:00:00.000 --&gt; 00:01:00.000<br>Introduction<br><br>00:01:00.000 --&gt; 00:02:30.000<br>Main Content<br><br>00:02:30.000 --&gt; 00:03:00.000<br>Conclusion<br></code></pre></td></tr></table></figure>\n\n<p>这段代码定义了一个包含三个章节的列表，用户可以通过点击章节标题快速跳转到相应的时间点。</p>\n<h4 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h4><p>WebVTT 是一种轻量级但功能丰富的字幕格式，特别适合在网络环境中使用。它的语法简单直观，易于学习和实现，同时提供了足够的灵活性来满足大多数字幕制作的需求。无论是简单的对话字幕还是带有复杂样式的提示信息，WebVTT 都能有效地支持。更重要的是，由于它是 HTML5 标准的一部分，因此可以在所有现代浏览器中无缝工作，确保了良好的兼容性和用户体验。</p>\n<h1 id=\"4-字幕制作\"><a href=\"#4-字幕制作\" class=\"headerlink\" title=\"4. 字幕制作\"></a>4. 字幕制作</h1><h3 id=\"4-1-字幕的制作工具\"><a href=\"#4-1-字幕的制作工具\" class=\"headerlink\" title=\"4.1 字幕的制作工具\"></a>4.1 字幕的制作工具</h3><p>有许多专业的字幕制作软件可以帮助用户轻松制作和编辑字幕，例如：</p>\n<ol>\n<li>**KBuilderTools (小灰熊字幕制作软件)**：支持MV字幕制作，操作简单。</li>\n<li><strong>Sayatoo卡拉字幕精灵</strong>：支持自定义设置字幕的字体、颜色、布局等参数。</li>\n<li><strong>Srt字幕制作帮手</strong>：专门针对SRT字幕的编辑软件，操作简便。</li>\n<li>**字幕大师 (OKVoice)**：采用高精准语音识别技术，支持自动匹配音视频中的语音与字幕。</li>\n<li><strong>Arctime Pro</strong>：专业字幕制作软件，支持多种创新技术，如字幕块绑定、自动分轴等。</li>\n<li><strong>Aegisub</strong>：免费、开源、跨平台的字幕编辑软件，支持多种语言编码。</li>\n</ol>\n<h3 id=\"4-2-字幕的制作步骤\"><a href=\"#4-2-字幕的制作步骤\" class=\"headerlink\" title=\"4.2 字幕的制作步骤\"></a>4.2 字幕的制作步骤</h3><ol>\n<li><strong>导入视频和字幕文件</strong>：使用视频编辑软件导入视频文件和字幕文件，确保字幕文件与视频文件的内容对应。</li>\n<li><strong>调整时间轴</strong>：在视频编辑软件中，调整字幕的出现时间和消失时间，使其与配音的时长和内容一致。</li>\n<li><strong>调整字幕样式</strong>：根据需要，调整字幕的字体、字号、颜色、背景等，以使字幕更加清晰明确。</li>\n<li><strong>预览和调整</strong>：预览整个视频，确保字幕与配音同步显示，并且字幕的内容清晰可读。</li>\n<li><strong>导出视频</strong>：完成字幕的调整后，将视频导出为新的文件，确保字幕和配音同步的效果在最终的视频文件中得以保留。</li>\n</ol>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink\">https://github.com/chongzicbo/ReadWriteThink</a></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n","excerpt":"","more":"<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209171329186.png\" alt=\"image-20241209171329186\"></p>\n<h1 id=\"1-定义\"><a href=\"#1-定义\" class=\"headerlink\" title=\"1. 定义\"></a>1. 定义</h1><p>音视频的字幕是指以文本形式显示在屏幕上的内容，这些内容通常代表了音频中的对话、叙述以及其他重要的声音元素。字幕不仅有助于提高视频内容的理解度，而且对于那些有听力障碍或是在静音环境中观看视频的人来说尤为重要。此外，字幕还可以用于翻译不同语言的内容，从而扩大视频的受众范围</p>\n<h1 id=\"2-字幕的种类\"><a href=\"#2-字幕的种类\" class=\"headerlink\" title=\"2. 字幕的种类\"></a>2. 字幕的种类</h1><p>根据其功能和使用场景，字幕可以分为几种不同类型：</p>\n<ul>\n<li><strong>开放式字幕（硬编码字幕）</strong>：这类字幕直接嵌入到视频帧中，成为视频的一部分，无法关闭。它们适用于需要永久性地将字幕信息与视频结合的情况。</li>\n<li><strong>隐藏式字幕（软字幕&#x2F;外挂字幕）</strong>：用户可以选择是否开启这类字幕，并且可以根据需要调整样式。它们通常作为独立文件存在，如SRT、ASS等格式，便于管理和更新。</li>\n<li><strong>实时字幕</strong>：这种字幕是在直播或其他即时活动中生成的，能够快速响应现场发生的口语交流，为观众提供即时的文字反馈</li>\n</ul>\n<h1 id=\"3-字幕格式\"><a href=\"#3-字幕格式\" class=\"headerlink\" title=\"3. 字幕格式\"></a>3. 字幕格式</h1><p>常见的字幕格式包括：</p>\n<ol>\n<li>**SRT (SubRip Text)**：最常见的字幕格式之一，文本文件，每行包含时间码和字幕内容。</li>\n<li>**ASS (Advanced SubStation Alpha)**：功能强大的字幕格式，支持复杂的字幕样式和特效。</li>\n<li>**SSA (SubStation Alpha)**：早期的字幕格式，功能不如ASS强大，较少使用。</li>\n<li>**VTT (WebVTT)**：用于网页视频的字幕格式，类似于SRT<a href=\"https://blog.csdn.net/AlvinCasper/article/details/113066446\">5</a>。</li>\n</ol>\n<h3 id=\"3-1-SRT字幕\"><a href=\"#3-1-SRT字幕\" class=\"headerlink\" title=\"3.1 SRT字幕\"></a>3.1 SRT字幕</h3><p>SRT（SubRip Text）字幕格式以其简洁性和广泛的兼容性著称，它由纯文本构成，每个字幕段落包括四个主要部分：序号、时间码、字幕文本以及一个空白行来分隔不同的字幕片段。下面我们将通过具体的例子详细介绍SRT字幕文件的结构和使用方法。</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209172234191.png\" alt=\"image-20241209172234191\"></p>\n<h4 id=\"SRT-字幕的基本结构\"><a href=\"#SRT-字幕的基本结构\" class=\"headerlink\" title=\"SRT 字幕的基本结构\"></a>SRT 字幕的基本结构</h4><h5 id=\"序号\"><a href=\"#序号\" class=\"headerlink\" title=\"序号\"></a>序号</h5><p>每个字幕段都有一个唯一的序号，这个数字从1开始递增，表示字幕出现的顺序。虽然序号本身并不直接影响播放时的显示效果，但在实际应用中，它有助于保持字幕的逻辑顺序正确无误。</p>\n<h5 id=\"时间码\"><a href=\"#时间码\" class=\"headerlink\" title=\"时间码\"></a>时间码</h5><p>紧跟在序号之后的是时间码，它定义了字幕何时出现及消失。时间码遵循<code>hh:mm:ss,mmm --&gt; hh:mm:ss,mmm</code>的格式，其中<code>hh</code>代表小时，<code>mm</code>代表分钟，<code>ss</code>代表秒，而<code>mmm</code>则表示毫秒。例如：</p>\n<figure class=\"highlight dns\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dns\"><span class=\"hljs-number\">1</span><br><span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00:29,740</span> --&gt; <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00:31,280</span><br>福姬套餐~<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，字幕“福姬套餐~”将在视频播放到第29秒740毫秒时出现，并持续到第31秒280毫秒后消失。</p>\n<h5 id=\"字幕文本\"><a href=\"#字幕文本\" class=\"headerlink\" title=\"字幕文本\"></a>字幕文本</h5><p>接下来是具体的字幕文本，它可以是一行或多行。对于多语言字幕，不同语言的内容可以通过换行分隔开来。例如，在同一时间段内可以先显示英文再显示中文翻译：</p>\n<figure class=\"highlight dns\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dns\"><span class=\"hljs-number\">2</span><br><span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00:31,400</span> --&gt; <span class=\"hljs-number\">00:00:32,240</span><br>炒炸酱面<br></code></pre></td></tr></table></figure>\n\n<p>这里，“炒炸酱面”会在指定的时间范围内显示在屏幕上。</p>\n<h5 id=\"空白行\"><a href=\"#空白行\" class=\"headerlink\" title=\"空白行\"></a>空白行</h5><p>每一组字幕之间必须有一个空行来分隔不同的字幕片段，这标志着上一段字幕的结束和新一段字幕的开始。空白行的存在确保了字幕文件的可读性和结构清晰度。</p>\n<h4 id=\"样式与格式化示例\"><a href=\"#样式与格式化示例\" class=\"headerlink\" title=\"样式与格式化示例\"></a>样式与格式化示例</h4><p>尽管SRT本质上是一个简单的文本文件，但它也支持一些基本的HTML标签来进行格式化，如粗体（<code>&lt;b&gt;</code>）、斜体（<code>&lt;i&gt;</code>）、下划线（<code>&lt;u&gt;</code>）以及字体颜色（<code>&lt;font color=&quot;...&quot;&gt;</code>）。需要注意的是，并非所有的播放器都支持这些样式标记，因此在实际使用时应该考虑目标平台的支持情况。例如：</p>\n<figure class=\"highlight xml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs xml\">3<br>00:00:32,360 --&gt; 00:00:33,300<br><span class=\"hljs-tag\">&lt;<span class=\"hljs-name\">b</span>&gt;</span>炒拉面<span class=\"hljs-tag\">&lt;/<span class=\"hljs-name\">b</span>&gt;</span><br></code></pre></td></tr></table></figure>\n\n<p>这段代码会让“炒拉面”以粗体形式显示。</p>\n<h4 id=\"实际应用中的SRT文件示例\"><a href=\"#实际应用中的SRT文件示例\" class=\"headerlink\" title=\"实际应用中的SRT文件示例\"></a>实际应用中的SRT文件示例</h4><p>以下是一个完整的SRT字幕文件示例，摘自电影《阿凡达》的中英双语字幕：</p>\n<figure class=\"highlight ada\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs ada\"><span class=\"hljs-number\">3</span><br><span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">39</span>,<span class=\"hljs-number\">770</span> <span class=\"hljs-comment\">--&gt; 00:00:41,880</span><br>在经历了一场人生巨变之后<br><span class=\"hljs-keyword\">When</span> I was lying there <span class=\"hljs-keyword\">in</span> the VA hospital ...<br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight applescript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs applescript\"><span class=\"hljs-number\">4</span><br><span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">42</span>,<span class=\"hljs-number\">550</span> <span class=\"hljs-comment\">--&gt; 00:00:44,690</span><br>我被送进了退伍军人管理局医院 ...<br><span class=\"hljs-keyword\">with</span> a big hole blown <span class=\"hljs-keyword\">through</span> <span class=\"hljs-keyword\">the</span> <span class=\"hljs-keyword\">middle</span> <span class=\"hljs-keyword\">of</span> <span class=\"hljs-keyword\">my</span> life,<br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight dns\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dns\"><span class=\"hljs-number\">5</span><br><span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00:45,590</span> --&gt; <span class=\"hljs-number\">00:00:48,120</span><br>那段时间我经常会梦到自己在飞翔 ...<br>I started having these dreams of flying.<br></code></pre></td></tr></table></figure>\n\n<figure class=\"highlight dns\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dns\"><span class=\"hljs-number\">6</span><br><span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00:49,740</span> --&gt; <span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00:51,520</span><br>终获自由<br>I was free.<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，我们可以看到每一段字幕都有其对应的序号、时间码和文本内容，并且通过空白行分隔开各个字幕段。</p>\n<h4 id=\"编码方式\"><a href=\"#编码方式\" class=\"headerlink\" title=\"编码方式\"></a>编码方式</h4><p>SRT文件默认采用Windows-1252编码，但也可以保存为其他编码格式，如UTF-8或UTF-16，带或不带字节顺序标记（BOM）。为了确保跨平台兼容性，建议尽量使用UTF-8编码。特别是当涉及到非ASCII字符时，正确的编码选择尤为重要，因为错误的编码可能导致乱码问题。</p>\n<h4 id=\"创建与编辑SRT文件\"><a href=\"#创建与编辑SRT文件\" class=\"headerlink\" title=\"创建与编辑SRT文件\"></a>创建与编辑SRT文件</h4><p>创建SRT文件的过程相对直接，用户可以直接用文本编辑器手动编写，也可以借助专门的字幕编辑软件，如Aegisub、Subtitle Edit等。此外，还有在线服务和移动应用程序可以帮助生成或调整现有的SRT文件。对于批量处理或者需要高精度的时间轴同步，还可以考虑利用语音识别技术自动生成初步的SRT文件，然后进行人工校对和完善。</p>\n<p>综上所述，SRT字幕格式凭借其易于理解和操作的特点，成为了视频字幕领域不可或缺的一部分。</p>\n<h3 id=\"3-2-ASS字幕\"><a href=\"#3-2-ASS字幕\" class=\"headerlink\" title=\"3.2 ASS字幕\"></a>3.2 ASS字幕</h3><p>ASS（Advanced SubStation Alpha）是一种比SSA更为高级的字幕格式，它不仅支持基本的文本显示，还允许用户添加复杂的样式、特效以及时间轴控制。ASS 文件通常以 <code>.ass</code> 作为文件扩展名，并且是纯文本文件，这意味着它们可以用任何文本编辑器手工编辑，但必须注意遵循特定的规则以确保正确解析。</p>\n<h4 id=\"ASS-字幕的基本结构\"><a href=\"#ASS-字幕的基本结构\" class=\"headerlink\" title=\"ASS 字幕的基本结构\"></a>ASS 字幕的基本结构</h4><p>一个典型的 ASS 文件由几个部分组成：<code>[Script Info]</code>、<code>[V4+ Styles]</code> 和 <code>[Events]</code>。每个部分都有其独特的功能和用途。</p>\n<h5 id=\"Script-Info\"><a href=\"#Script-Info\" class=\"headerlink\" title=\"[Script Info]\"></a>[Script Info]</h5><p>这部分包含了脚本的头部信息和总体描述。例如：</p>\n<figure class=\"highlight mipsasm\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mipsasm\">[<span class=\"hljs-keyword\">Script </span>Info]<br><span class=\"hljs-comment\">; This is a Sub Station Alpha v4 script.</span><br><span class=\"hljs-symbol\">Title:</span> Neon Genesis Evangelion - Episode <span class=\"hljs-number\">26</span> (neutral Spanish)<br><span class=\"hljs-keyword\">Original </span><span class=\"hljs-keyword\">Script: </span>RoRo<br><span class=\"hljs-keyword\">Script </span>Updated <span class=\"hljs-keyword\">By: </span>version <span class=\"hljs-number\">2</span>.<span class=\"hljs-number\">8</span>.<span class=\"hljs-number\">01</span><br><span class=\"hljs-keyword\">ScriptType: </span>v4.<span class=\"hljs-number\">00</span>+<br><span class=\"hljs-symbol\">Collisions:</span> <span class=\"hljs-keyword\">Normal</span><br><span class=\"hljs-keyword\"></span><span class=\"hljs-symbol\">PlayResY:</span> <span class=\"hljs-number\">600</span><br><span class=\"hljs-symbol\">PlayDepth:</span> <span class=\"hljs-number\">0</span><br><span class=\"hljs-symbol\">Timer:</span> <span class=\"hljs-number\">100</span>,<span class=\"hljs-number\">00</span><br></code></pre></td></tr></table></figure>\n\n<p>这里定义了诸如标题 (<code>Title</code>)、原作者 (<code>Original Script</code>) 等元数据，以及一些技术参数如播放分辨率 (<code>PlayResX</code>, <code>PlayResY</code>) 和颜色深度 (<code>PlayDepth</code>)。<code>Timer</code> 属性用于调整字幕的时间轴速度，不过现代渲染器通常会忽略这一设置。</p>\n<h5 id=\"V4-Styles\"><a href=\"#V4-Styles\" class=\"headerlink\" title=\"[V4+ Styles]\"></a>[V4+ Styles]</h5><p>这是样式定义的部分，其中每一个被脚本使用的样式都应该在此处定义。格式如下：</p>\n<figure class=\"highlight dns\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs dns\">[V4+ Styles]<br>Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding<br>Style: Default,Arial,<span class=\"hljs-number\">20</span>,&amp;H00FFFFFF,&amp;H000000FF,&amp;H<span class=\"hljs-number\">00000000</span>,&amp;H<span class=\"hljs-number\">00000000,0</span>,<span class=\"hljs-number\">0,0,0,100</span>,<span class=\"hljs-number\">100,0,0,1</span>,<span class=\"hljs-number\">0.5,0,2</span>,<span class=\"hljs-number\">10,10,10,1</span><br></code></pre></td></tr></table></figure>\n\n<p>每一项都对应着不同的视觉属性，比如字体名称 (<code>Fontname</code>)、字体大小 (<code>Fontsize</code>)、主要颜色 (<code>PrimaryColour</code>) 等等。<code>Alignment</code> 属性决定了字幕在屏幕上的对齐方式，而 <code>MarginL</code>, <code>MarginR</code>, <code>MarginV</code> 则设定了字幕与屏幕边缘的距离。</p>\n<h5 id=\"Events\"><a href=\"#Events\" class=\"headerlink\" title=\"[Events]\"></a>[Events]</h5><p>这是最重要的部分之一，因为它包含了所有实际出现在屏幕上的内容。每条事件记录了一个具体的字幕或注释，并指定了它的开始时间和结束时间、所使用的样式以及其他可能的效果。例如：</p>\n<figure class=\"highlight pgsql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs pgsql\">[Events]<br><span class=\"hljs-keyword\">Format</span>: Layer, <span class=\"hljs-keyword\">Start</span>, <span class=\"hljs-keyword\">End</span>, Style, <span class=\"hljs-type\">Name</span>, MarginL, MarginR, MarginV, Effect, <span class=\"hljs-type\">Text</span><br>Dialogue: <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">09.07</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">13.14</span>,<span class=\"hljs-keyword\">Default</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,,我的爱从相遇的那一刻起<br>Dialogue: <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">13.27</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">17.41</span>,<span class=\"hljs-keyword\">Default</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,,我的生活一切都被你占据<br></code></pre></td></tr></table></figure>\n\n<p><code>Layer</code> 属性控制字幕的叠放顺序；<code>Start</code> 和 <code>End</code> 分别表示字幕出现和消失的时间点；<code>Style</code> 指向之前定义好的样式；<code>Text</code> 包含了要显示的具体文字。</p>\n<h4 id=\"样式与格式化示例-1\"><a href=\"#样式与格式化示例-1\" class=\"headerlink\" title=\"样式与格式化示例\"></a>样式与格式化示例</h4><p>除了上述基础元素外，ASS 还提供了丰富的内联标签来实现更加精细的排版和动画效果。例如：</p>\n<ul>\n<li><code>\\b1</code> 开启粗体，<code>\\b0</code> 关闭粗体；</li>\n<li><code>\\i1</code> 开启斜体，<code>\\i0</code> 关闭斜体；</li>\n<li><code>\\u1</code> 开启下划线，<code>\\u0</code> 关闭下划线；</li>\n<li><code>\\k&lt;time&gt;</code> 用于卡拉 OK 效果，指定高亮移动的速度；</li>\n<li><code>\\move(&lt;x1&gt;, &lt;y1&gt;, &lt;x2&gt;, &lt;y2&gt;)</code> 实现字幕从一个位置移动到另一个位置；</li>\n<li><code>\\fad(&lt;in-time&gt;, &lt;out-time&gt;)</code> 创建淡入淡出效果。</li>\n</ul>\n<p>以下是一个使用这些标签的例子：</p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">Dialogue</span>: <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">00</span>.<span class=\"hljs-number\">00</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">05</span>.<span class=\"hljs-number\">00</span>,Default,,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,,&#123;\\b1\\u1\\c&amp;HFF0000&amp;&#125;这是一段&#123;\\i1&#125;带&#123;\\i0&#125;有&#123;\\b0\\u0&#125;样式的文本。<br><span class=\"hljs-attribute\">Dialogue</span>: <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">05</span>.<span class=\"hljs-number\">00</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">10</span>.<span class=\"hljs-number\">00</span>,Default,,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,,&#123;\\move(<span class=\"hljs-number\">100</span>,<span class=\"hljs-number\">100</span>,<span class=\"hljs-number\">500</span>,<span class=\"hljs-number\">100</span>)\\fad(<span class=\"hljs-number\">1000</span>,<span class=\"hljs-number\">1000</span>)&#125;这段文字会从左下角滑动到右下角并伴有淡入淡出。<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中，第一行应用了粗体和下划线，同时将颜色更改为红色，并且中间有一部分为斜体；第二行则设置了从屏幕左侧到右侧的移动路径，并且加入了1秒的淡入淡出过渡。</p>\n<h4 id=\"实际应用中的ASS文件示例\"><a href=\"#实际应用中的ASS文件示例\" class=\"headerlink\" title=\"实际应用中的ASS文件示例\"></a>实际应用中的ASS文件示例</h4><p>考虑到ASS的强大功能，它可以用来创建非常复杂且富有创意的字幕效果，尤其是在动漫领域。下面给出一段来自《命运石之门》的日语台词及其对应的ASS代码：</p>\n<figure class=\"highlight apache\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs apache\"><span class=\"hljs-attribute\">Dialogue</span>: <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">01</span>:<span class=\"hljs-number\">23</span>.<span class=\"hljs-number\">45</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">01</span>:<span class=\"hljs-number\">27</span>.<span class=\"hljs-number\">67</span>,CustomStyle,,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,,&#123;\\an7\\b1\\c&amp;HFFFF00&amp;\\<span class=\"hljs-number\">3</span>c&amp;H0000FF&amp;&#125;OKERU！<br><span class=\"hljs-attribute\">Dialogue</span>: <span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">01</span>:<span class=\"hljs-number\">27</span>.<span class=\"hljs-number\">67</span>,<span class=\"hljs-number\">0</span>:<span class=\"hljs-number\">01</span>:<span class=\"hljs-number\">31</span>.<span class=\"hljs-number\">89</span>,CustomStyle,,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,<span class=\"hljs-number\">0</span>,,&#123;\\an8\\i1\\k50&#125;我们终于可以一起制作游戏了！<br></code></pre></td></tr></table></figure>\n\n<p>这里，“CustomStyle” 是预先定义好的一种样式，而 <code>&#123;&#125;</code> 内的内容则是额外添加的临时样式覆盖。第一句台词位于屏幕顶部中央（<code>an7</code>），并且采用了黄色字体配蓝色边框；第二句则位于顶部右侧（<code>an8</code>），带有卡拉 OK 式的逐字高亮效果（<code>\\k50</code> 表示每个字符高亮持续50毫秒）。</p>\n<h4 id=\"编码方式-1\"><a href=\"#编码方式-1\" class=\"headerlink\" title=\"编码方式\"></a>编码方式</h4><p>与SRT类似，ASS也推荐使用UTF-8编码，特别是当涉及到多语言支持时。正确的编码选择对于避免乱码至关重要。此外，由于ASS支持更多样化的字体和颜色配置，因此还需要确保目标设备上安装了相应的字体文件，或者考虑嵌入所需字体以便于跨平台播放。</p>\n<h3 id=\"3-3-SSA字幕\"><a href=\"#3-3-SSA字幕\" class=\"headerlink\" title=\"3.3 SSA字幕\"></a>3.3 SSA字幕</h3><p>在上面我们介绍了ASS字幕，ASS字幕其实是SSA字幕格式的高级版本，在SSA的基础上增加了一些额外的功能。下面用一个例子介绍下ASS和SSA之间的区别和联系。</p>\n<p>假设我们要为一段视频添加带有特效的字幕，这段视频中有一句台词：<strong>“欢迎来到未来世界”。</strong></p>\n<h4 id=\"SSA-字幕文件示例\"><a href=\"#SSA-字幕文件示例\" class=\"headerlink\" title=\"SSA 字幕文件示例\"></a>SSA 字幕文件示例</h4><p>首先，我们看看如何用 SSA 格式创建这段字幕。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs plaintext\">[Script Info]<br>; This is a Sub Station Alpha v4 script.<br>Title: Future World - Episode 1<br>Original Script: Example Author<br>ScriptType: v4.00<br>Collisions: Normal<br>PlayResX: 640<br>PlayResY: 480<br>Timer: 100,00<br><br>[V4 Styles]<br>Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, TertiaryColour, BackColour, Bold, Italic, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, AlphaLevel, Encoding<br>Style: Default,Arial,20,&amp;H00FFFFFF,&amp;H000000FF,&amp;H00000000,&amp;H00000000,-1,0,1,2,2,2,10,10,10,0,0<br><br>[Events]<br>Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text<br>Dialogue: 0,0:00:05.00,0:00:07.00,Default,,0,0,0,,&#123;\\c&amp;HFF0000&amp;&#125;欢迎&#123;\\c&amp;H00FF00&amp;&#125;来到&#123;\\c&amp;H0000FF&amp;&#125;未来世界！<br></code></pre></td></tr></table></figure>\n\n<p>在这个 SSA 文件中：</p>\n<ul>\n<li><strong>[Script Info]</strong> 部分定义了脚本的基本信息，如标题、原作者等。</li>\n<li><strong>[V4 Styles]</strong> 定义了一种默认样式 <code>Default</code>，指定了字体名称、大小、颜色等属性。</li>\n<li><strong>[Events]</strong> 包含了一个对话事件，它设置了开始时间和结束时间，并使用了内联标签 <code>\\c</code> 来改变文本的颜色，以实现多彩效果。</li>\n</ul>\n<h4 id=\"ASS-字幕文件示例\"><a href=\"#ASS-字幕文件示例\" class=\"headerlink\" title=\"ASS 字幕文件示例\"></a>ASS 字幕文件示例</h4><p>接下来，我们将相同的台词转换成 ASS 格式，同时增加一些额外的功能。</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs plaintext\">[Script Info]<br>; This is an Advanced Sub Station Alpha v4+ script.<br>Title: Future World - Episode 1<br>ScriptType: v4.00+<br>Collisions: Normal<br>PlayResX: 640<br>PlayResY: 480<br>Timer: 100,00<br><br>[V4+ Styles]<br>Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding<br>Style: Default,Arial,20,&amp;H00FFFFFF,&amp;H000000FF,&amp;H00000000,&amp;H00000000,0,0,0,0,100,100,0,0,1,1,1,2,10,10,10,1<br><br>[Events]<br>Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text<br>Dialogue: 0,0:00:05.00,0:00:07.00,Default,,0,0,0,,&#123;\\an8\\c&amp;HFF0000&amp;\\b1&#125;欢迎&#123;\\c&amp;H00FF00&amp;\\b0&#125;来到&#123;\\c&amp;H0000FF&amp;&#125;未来世界！&#123;\\fad(500,500)&#125;<br></code></pre></td></tr></table></figure>\n\n<p>在这个 ASS 文件中：</p>\n<ul>\n<li><strong>[Script Info]</strong> 部分同样提供了脚本信息，但指明这是 v4.00+ 版本。</li>\n<li><strong>[V4+ Styles]</strong> 中增加了更多样式属性，例如 <code>ScaleX</code>, <code>ScaleY</code>, <code>Spacing</code>, <code>Angle</code> 等，允许对文本进行更精细的控制。</li>\n<li><strong>[Events]</strong> 部分不仅实现了与 SSA 相同的多彩效果，还加入了粗体切换 (<code>\\b1</code>, <code>\\b0</code>) 和淡入淡出效果 (<code>\\fad</code>)。</li>\n</ul>\n<h4 id=\"区别和联系\"><a href=\"#区别和联系\" class=\"headerlink\" title=\"区别和联系\"></a>区别和联系</h4><h5 id=\"区别\"><a href=\"#区别\" class=\"headerlink\" title=\"区别\"></a>区别</h5><ol>\n<li><strong>版本</strong>：ASS 是基于 SSA v4.00+ 的改进版本，具有更多的功能和支持。</li>\n<li><strong>样式定义</strong>：ASS 在 <code>[V4+ Styles]</code> 中引入了额外的样式属性，如 <code>ScaleX</code>, <code>ScaleY</code>, <code>Spacing</code>, <code>Angle</code> 等。</li>\n<li><strong>内联标签支持</strong>：ASS 扩展了 SSA 的内联标签功能，新增了如 <code>\\t</code> (临时样式覆盖) 等标签，并增强了现有标签的效果，比如卡拉 OK 效果 (<code>\\k</code>)。</li>\n<li><strong>高级特效与动画</strong>：ASS 支持更复杂的动画效果，包括路径上的移动 (\\move)，旋转，缩放变换等。</li>\n<li><strong>字符编码</strong>：ASS 设计之初就考虑到了更好的国际化支持，对于非拉丁字符集有更好的处理方式。</li>\n</ol>\n<h5 id=\"联系\"><a href=\"#联系\" class=\"headerlink\" title=\"联系\"></a>联系</h5><ul>\n<li><strong>结构相似</strong>：两者都遵循类似的文件结构，包括 <code>[Script Info]</code>, <code>[V4/V4+ Styles]</code>, <code>[Events]</code> 等部分。</li>\n<li><strong>向后兼容</strong>：大多数现代播放器能够解析 SSA 和 ASS 文件，因为 ASS 向后兼容 SSA。</li>\n<li><strong>基本功能一致</strong>：在基础功能上，SSA 和 ASS 提供了相同的核心特性，如设置字体、颜色、对齐方式等。</li>\n</ul>\n<p>综上所述，尽管 SSA 和 ASS 在细节上有许多不同之处，但它们共享很多共同点，特别是对于普通用户来说，两者都能很好地满足日常字幕制作的需求。然而，如果你需要利用更先进的特效或希望确保最佳的跨平台兼容性，那么选择 ASS 可能会是一个更好的决定。</p>\n<h3 id=\"3-4-VTT字幕\"><a href=\"#3-4-VTT字幕\" class=\"headerlink\" title=\"3.4 VTT字幕\"></a>3.4 VTT字幕</h3><p>WebVTT（Web Video Text Tracks）是一种专门为网络视频设计的字幕格式，它被广泛应用于 HTML5 <code>&lt;video&gt;</code> 元素中。WebVTT 文件通常以 <code>.vtt</code> 作为扩展名，并且是纯文本文件，易于编辑和解析。与 SSA&#x2F;ASS 等格式相比，WebVTT 更加简洁，专注于提供基本的字幕功能，如时间戳、文本内容以及简单的样式控制。下面将通过一个具体的例子来详细介绍 WebVTT 的结构和用法。</p>\n<h4 id=\"WebVTT-文件的基本结构\"><a href=\"#WebVTT-文件的基本结构\" class=\"headerlink\" title=\"WebVTT 文件的基本结构\"></a>WebVTT 文件的基本结构</h4><p>每个 WebVTT 文件都必须以 <code>WEBVTT</code> 开头，紧接着是一个空行，然后是各个字幕段落。每个段落由以下几部分组成：</p>\n<ol>\n<li><strong>标识符（可选）</strong>：可以为每个字幕段落指定一个唯一的标识符。</li>\n<li><strong>时间码</strong>：定义了字幕显示的时间范围，格式为 <code>HH:MM:SS.mmm --&gt; HH:MM:SS.mmm</code>，其中 <code>HH</code> 表示小时，<code>MM</code> 表示分钟，<code>SS</code> 表示秒，<code>mmm</code> 表示毫秒。</li>\n<li><strong>设置（可选）</strong>：用于指定字幕的位置、对齐方式等属性。</li>\n<li><strong>文本内容</strong>：即实际要显示的字幕文字，可以包含多行。</li>\n</ol>\n<h5 id=\"示例：简单对话场景\"><a href=\"#示例：简单对话场景\" class=\"headerlink\" title=\"示例：简单对话场景\"></a>示例：简单对话场景</h5><p>假设我们有一段视频，其中一个人说：“欢迎来到未来世界。” 我们可以创建如下的 WebVTT 文件：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs plaintext\">WEBVTT<br><br>1<br>00:00:05.000 --&gt; 00:00:07.000<br>欢迎来到未来世界。<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中：</p>\n<ul>\n<li><code>WEBVTT</code> 表明这是一个 WebVTT 文件。</li>\n<li>数字 <code>1</code> 是字幕段落的唯一标识符（可选），有助于管理和引用特定的字幕。</li>\n<li>时间码 <code>00:00:05.000 --&gt; 00:00:07.000</code> 指定了字幕从第 5 秒开始，在第 7 秒结束。</li>\n<li>最后一行是实际要显示的文字内容。</li>\n</ul>\n<h4 id=\"增强样式的使用\"><a href=\"#增强样式的使用\" class=\"headerlink\" title=\"增强样式的使用\"></a>增强样式的使用</h4><p>虽然 WebVTT 主要关注于提供清晰易读的字幕，但它也允许一定程度上的样式定制。例如，你可以使用 HTML 标签或内联 CSS 来改变字体颜色、大小、样式等。此外，WebVTT 还支持一些特殊的标签来实现更复杂的效果。</p>\n<h5 id=\"示例：带样式的字幕\"><a href=\"#示例：带样式的字幕\" class=\"headerlink\" title=\"示例：带样式的字幕\"></a>示例：带样式的字幕</h5><p>考虑同样的台词，但我们想让它更引人注目，比如给“欢迎”两个字加上红色高亮，并让整个句子居中显示：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs plaintext\">WEBVTT<br><br>1<br>00:00:05.000 --&gt; 00:00:07.000 line:50% position:50% align:center<br>&lt;c.red&gt;欢迎&lt;/c&gt;来到未来世界。<br></code></pre></td></tr></table></figure>\n\n<p>在这个例子中：</p>\n<ul>\n<li><code>line:50% position:50% align:center</code> 设置了字幕在屏幕上的位置和对齐方式，使它位于屏幕中央。</li>\n<li><code>&lt;c.red&gt;</code> 和 <code>&lt;/c&gt;</code> 是 WebVTT 特有的标记，用来包裹需要应用样式的文本。这里我们将“欢迎”两个字的颜色设置为红色。</li>\n</ul>\n<h4 id=\"使用-CSS-类进行样式化\"><a href=\"#使用-CSS-类进行样式化\" class=\"headerlink\" title=\"使用 CSS 类进行样式化\"></a>使用 CSS 类进行样式化</h4><p>对于更复杂的样式需求，可以结合 CSS 类来进行处理。首先，在 WebVTT 文件中定义类名，然后在网页上关联相应的 CSS 样式规则。</p>\n<h5 id=\"示例：使用-CSS-类\"><a href=\"#示例：使用-CSS-类\" class=\"headerlink\" title=\"示例：使用 CSS 类\"></a>示例：使用 CSS 类</h5><p>继续上面的例子，这次我们将为“欢迎”添加一个自定义的 CSS 类：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs plaintext\">WEBVTT<br><br>1<br>00:00:05.000 --&gt; 00:00:07.000 line:50% position:50% align:center<br>&lt;c.vwelcome&gt;欢迎&lt;/c&gt;来到未来世界。<br></code></pre></td></tr></table></figure>\n\n<p>接着，在网页中的 <code>&lt;style&gt;</code> 标签或者外部样式表里添加如下 CSS 规则：</p>\n<figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs css\"><span class=\"hljs-selector-pseudo\">::cue</span>(<span class=\"hljs-selector-class\">.vwelcome</span>) &#123;<br>    <span class=\"hljs-attribute\">color</span>: red;<br>    <span class=\"hljs-attribute\">font-weight</span>: bold;<br>&#125;<br></code></pre></td></tr></table></figure>\n\n<p>这样，当播放器渲染这个 WebVTT 文件时，“欢迎”这两个字不仅会变成红色，还会显得更加粗重。</p>\n<h4 id=\"WebVTT-的高级特性\"><a href=\"#WebVTT-的高级特性\" class=\"headerlink\" title=\"WebVTT 的高级特性\"></a>WebVTT 的高级特性</h4><p>除了上述基本功能外，WebVTT 还支持其他类型的文本轨道，如章节列表、描述性音轨等。这些功能使得 WebVTT 成为了一个非常灵活且强大的工具，适用于各种多媒体应用场景。</p>\n<h5 id=\"示例：章节列表\"><a href=\"#示例：章节列表\" class=\"headerlink\" title=\"示例：章节列表\"></a>示例：章节列表</h5><p>如果想要为视频添加章节导航，可以使用 WebVTT 创建一个章节轨道文件：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs plaintext\">WEBVTT<br><br>CHAPTERS<br><br>00:00:00.000 --&gt; 00:01:00.000<br>Introduction<br><br>00:01:00.000 --&gt; 00:02:30.000<br>Main Content<br><br>00:02:30.000 --&gt; 00:03:00.000<br>Conclusion<br></code></pre></td></tr></table></figure>\n\n<p>这段代码定义了一个包含三个章节的列表，用户可以通过点击章节标题快速跳转到相应的时间点。</p>\n<h4 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h4><p>WebVTT 是一种轻量级但功能丰富的字幕格式，特别适合在网络环境中使用。它的语法简单直观，易于学习和实现，同时提供了足够的灵活性来满足大多数字幕制作的需求。无论是简单的对话字幕还是带有复杂样式的提示信息，WebVTT 都能有效地支持。更重要的是，由于它是 HTML5 标准的一部分，因此可以在所有现代浏览器中无缝工作，确保了良好的兼容性和用户体验。</p>\n<h1 id=\"4-字幕制作\"><a href=\"#4-字幕制作\" class=\"headerlink\" title=\"4. 字幕制作\"></a>4. 字幕制作</h1><h3 id=\"4-1-字幕的制作工具\"><a href=\"#4-1-字幕的制作工具\" class=\"headerlink\" title=\"4.1 字幕的制作工具\"></a>4.1 字幕的制作工具</h3><p>有许多专业的字幕制作软件可以帮助用户轻松制作和编辑字幕，例如：</p>\n<ol>\n<li>**KBuilderTools (小灰熊字幕制作软件)**：支持MV字幕制作，操作简单。</li>\n<li><strong>Sayatoo卡拉字幕精灵</strong>：支持自定义设置字幕的字体、颜色、布局等参数。</li>\n<li><strong>Srt字幕制作帮手</strong>：专门针对SRT字幕的编辑软件，操作简便。</li>\n<li>**字幕大师 (OKVoice)**：采用高精准语音识别技术，支持自动匹配音视频中的语音与字幕。</li>\n<li><strong>Arctime Pro</strong>：专业字幕制作软件，支持多种创新技术，如字幕块绑定、自动分轴等。</li>\n<li><strong>Aegisub</strong>：免费、开源、跨平台的字幕编辑软件，支持多种语言编码。</li>\n</ol>\n<h3 id=\"4-2-字幕的制作步骤\"><a href=\"#4-2-字幕的制作步骤\" class=\"headerlink\" title=\"4.2 字幕的制作步骤\"></a>4.2 字幕的制作步骤</h3><ol>\n<li><strong>导入视频和字幕文件</strong>：使用视频编辑软件导入视频文件和字幕文件，确保字幕文件与视频文件的内容对应。</li>\n<li><strong>调整时间轴</strong>：在视频编辑软件中，调整字幕的出现时间和消失时间，使其与配音的时长和内容一致。</li>\n<li><strong>调整字幕样式</strong>：根据需要，调整字幕的字体、字号、颜色、背景等，以使字幕更加清晰明确。</li>\n<li><strong>预览和调整</strong>：预览整个视频，确保字幕与配音同步显示，并且字幕的内容清晰可读。</li>\n<li><strong>导出视频</strong>：完成字幕的调整后，将视频导出为新的文件，确保字幕和配音同步的效果在最终的视频文件中得以保留。</li>\n</ol>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink\">https://github.com/chongzicbo/ReadWriteThink</a></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n"},{"title":"llama3源码解析-01：整体代码结构及模块功能","_content":"\n\n\n---\n\n![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/Llama3_Repo.jpeg)\n\nLlama3 是一个基于 Transformer 架构的大规模语言模型，主要用于文本生成和对话任务。以下是 Llama3 项目的整体架构和各个模块的功能总结：\n\n## 1. **项目架构**\nLlama3 项目主要由三个核心文件组成：\n- **generation.py**: 负责模型的加载、文本生成和对话生成的核心逻辑。\n- **model.py**: 定义了 Transformer 模型的结构，包括注意力机制、前馈网络、层归一化等组件。\n- **tokenizer.py**: 负责文本的编码和解码，使用 Tiktoken 作为分词器。\n\n## 2. **模块功能**\n\n### **generation.py**\n- **Llama 类**: 这是 Llama3 的核心类，负责模型的加载、文本生成和对话生成。\n  - **build 方法**: 初始化模型并加载预训练权重。它负责初始化分布式进程组、设置设备、加载模型和分词器。\n  - **generate 方法**: 根据输入的 token 序列生成文本。支持温度调节、top-p 采样、logprobs 计算等功能。\n  - **text_completion 方法**: 对输入的文本提示进行补全，生成文本补全结果。\n  - **chat_completion 方法**: 对输入的对话进行补全，生成助手的回复。\n  - **sample_top_p 函数**: 实现 top-p（nucleus）采样，用于控制生成文本的多样性。\n\n### **model.py**\n- **ModelArgs 类**: 定义了模型的基本参数，如维度、层数、头数、词汇表大小等。\n- **RMSNorm 类**: 实现了 RMS（Root Mean Square）归一化，用于替代传统的 LayerNorm。\n- **precompute_freqs_cis 函数**: 预计算旋转位置编码的频率。\n- **reshape_for_broadcast 函数**: 调整频率张量的形状以进行广播。\n- **apply_rotary_emb 函数**: 应用旋转位置编码到查询和键张量上。\n- **repeat_kv 函数**: 重复键和值张量以匹配头的数量。\n- **Attention 类**: 实现了多头注意力机制，支持键值缓存。\n- **FeedForward 类**: 实现了前馈网络，使用 SwiGLU 激活函数。\n- **TransformerBlock 类**: 组合了注意力机制和前馈网络，构成了 Transformer 的一个基本块。\n- **Transformer 类**: 整个 Transformer 模型，包含多个 TransformerBlock 层，负责前向传播。\n\n### **tokenizer.py**\n- **Tokenizer 类**: 负责文本的编码和解码，使用 Tiktoken 作为分词器。\n  - **encode 方法**: 将字符串编码为 token ID 序列，支持添加 BOS 和 EOS token。\n  - **decode 方法**: 将 token ID 序列解码为字符串。\n  - **_split_whitespaces_or_nonwhitespaces 方法**: 将字符串分割为不超过最大长度的子串。\n- **ChatFormat 类**: 负责对话格式的编码。\n  - **encode_header 方法**: 编码消息头（如角色信息）。\n  - **encode_message 方法**: 编码整个消息，包括消息头和内容。\n  - **encode_dialog_prompt 方法**: 编码整个对话，生成模型输入的 token 序列。\n\n## 3. **核心功能和关键技术**\n\n### 3.1 核心功能\n\n- **模型加载与初始化**: 通过 `Llama.build` 方法加载预训练模型和分词器，初始化分布式训练环境。\n- **文本生成**: 通过 `Llama.generate` 方法实现文本生成，支持温度调节、top-p 采样、logprobs 计算等功能。\n- **对话生成**: 通过 `Llama.chat_completion` 方法生成对话回复，支持多轮对话。\n- **分词与编码**: 通过 `Tokenizer` 类实现文本的编码和解码，支持特殊 token 的处理。\n- **Transformer 模型**: 通过 `Transformer` 类实现 Transformer 模型的前向传播，支持键值缓存和旋转位置编码。\n\n### 3.2 **关键技术**\n\n- **旋转位置编码**: 使用旋转位置编码（Rotary Position Embedding）来增强模型对位置信息的感知。\n- **RMSNorm**: 使用 RMSNorm 替代传统的 LayerNorm，减少计算量。\n- **SwiGLU 激活函数**: 在前馈网络中使用 SwiGLU 激活函数，增强模型的表达能力。\n- **Top-p 采样**: 使用 top-p 采样来控制生成文本的多样性，避免生成过于随机的文本。\n\n## 4. **Llama3 模型中数据从输入到输出的整体过程**\n\nLlama3 模型的数据处理流程从输入文本到生成输出文本，涉及多个步骤和模块的协同工作。以下是数据从输入到输出的整体过程：\n\n### **4.1 输入文本的编码**\n1. **文本输入**: 用户提供文本输入，可以是单句文本（用于文本补全）或多轮对话（用于对话生成）。\n2. **分词与编码**:\n   - **Tokenizer 类**: 使用 `Tokenizer.encode` 方法将输入文本转换为 token ID 序列。该方法会根据配置决定是否添加 BOS（Begin of Sequence）和 EOS（End of Sequence）token。\n   - **特殊 token 处理**: 如果输入文本中包含特殊 token（如对话中的角色标记），Tokenizer 会将其编码为对应的 token ID。\n   - **对话格式编码**: 对于对话任务，`ChatFormat` 类会将对话中的每条消息编码为 token 序列，并添加适当的特殊 token（如 `<|start_header_id|>` 和 `<|end_header_id|>`）。\n\n### **4.2 模型的前向传播**\n1. **输入 token 序列**:\n   - 编码后的 token 序列被转换为 PyTorch 张量，并输入到 Transformer 模型中。\n   - 如果输入序列长度小于模型的最大序列长度，会使用 pad token 进行填充。\n2. **嵌入层**:\n   - **tok_embeddings**: 输入 token 序列通过嵌入层（`VocabParallelEmbedding`）转换为词向量表示。\n   - 每个 token 被映射为一个高维向量（维度由 `ModelArgs.dim` 决定）。\n3. **旋转位置编码**:\n   - **precompute_freqs_cis**: 预计算旋转位置编码的频率。\n   - **apply_rotary_emb**: 将旋转位置编码应用到查询（query）和键（key）张量上，增强模型对位置信息的感知。\n4. **Transformer 层**:\n   - **TransformerBlock**: 模型由多个 TransformerBlock 组成，每个块包含一个多头注意力机制和一个前馈网络。\n     - **Attention**: 多头注意力机制计算查询、键和值之间的注意力分数，生成上下文感知的表示。\n     - **FeedForward**: 前馈网络使用 SwiGLU 激活函数进一步增强表示。\n   - **RMSNorm**: 在每个 TransformerBlock 中，使用 RMSNorm 对输入进行归一化。\n   - **残差连接**: 在每个 TransformerBlock 中，输入和输出通过残差连接进行叠加。\n5. **输出层**:\n   - **norm**: 最后一层 TransformerBlock 的输出通过 RMSNorm 进行归一化。\n   - **output**: 归一化后的输出通过线性层（`ColumnParallelLinear`）映射回词汇表空间，生成每个 token 的 logits（未归一化的概率分布）。\n\n### **4.3 文本生成**\n1. **logits 处理**:\n   - 模型输出的 logits 表示每个 token 的未归一化概率分布。\n   - 根据生成任务的需求，可以选择不同的采样策略（如贪婪采样、top-p 采样等）。\n2. **采样**:\n   - **sample_top_p**: 使用 top-p 采样从 logits 中选择下一个 token。该方法会从累积概率超过阈值 p 的最小 token 集合中进行采样，确保生成的文本既多样又合理。\n   - **温度调节**: 通过调节温度参数（temperature），控制生成文本的随机性。温度越高，生成的文本越随机；温度越低，生成的文本越确定。\n3. **生成 token 序列**:\n   - 根据采样结果，逐步生成 token 序列，直到达到最大生成长度或遇到停止 token（如 EOS token）。\n   - 在生成过程中，模型会不断更新键值缓存（key-value cache），以加速后续 token 的生成。\n\n### **4.4 输出文本的解码**\n1. **token 序列解码**:\n   - 生成的 token 序列通过 `Tokenizer.decode` 方法解码为文本。\n   - 解码过程中会去除特殊 token（如 BOS 和 EOS token），并将 token ID 映射回对应的字符或子词。\n2. **输出文本**:\n   - 解码后的文本作为模型的最终输出，返回给用户。\n   - 对于对话任务，输出文本通常是助手的回复；对于文本补全任务，输出文本是输入提示的补全结果。\n\n### **4.5 整体流程总结**\n1. **输入文本** → **Tokenizer 编码** → **token 序列**\n2. **token 序列** → **嵌入层** → **词向量表示**\n3. **词向量表示** → **旋转位置编码** → **上下文感知表示**\n4. **上下文感知表示** → **Transformer 层** → **logits**\n5. **logits** → **采样策略** → **生成 token 序列**\n6. **生成 token 序列** → **Tokenizer 解码** → **输出文本**\n\n## 5. **总结**\nLlama3 模型的处理流程从输入文本到输出文本，涉及分词、编码、嵌入、Transformer 层的前向传播、采样和解码等多个步骤。每个步骤都通过精心设计的模块（如 Tokenizer、TransformerBlock、Attention 等）实现，确保模型能够高效地生成高质量的文本。通过调节温度、top-p 采样等参数，用户可以控制生成文本的多样性和质量，满足不同任务的需求。\n\nLlama3 是一个功能强大的语言模型，支持文本生成和对话生成任务。其核心架构基于 Transformer，使用了旋转位置编码、RMSNorm、SwiGLU 激活函数等先进技术。通过 `generation.py` 中的 `Llama` 类，用户可以方便地加载模型、生成文本和对话。`model.py` 定义了 Transformer 模型的结构，`tokenizer.py` 负责文本的编码和解码。整体项目架构清晰，模块功能明确，适合大规模语言模型的训练和推理任务。\n\n\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","source":"_posts/人工智能/nlp/llm/源码解析：llama3源码解析-01：整体代码结构及模块功能.md","raw":"---\ntitle: 'llama3源码解析-01：整体代码结构及模块功能'\ncategories:\n  - [人工智能,nlp,llm]\ntags:\n  - nlp\n  - llm\n  - llama\n---\n\n\n\n---\n\n![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/Llama3_Repo.jpeg)\n\nLlama3 是一个基于 Transformer 架构的大规模语言模型，主要用于文本生成和对话任务。以下是 Llama3 项目的整体架构和各个模块的功能总结：\n\n## 1. **项目架构**\nLlama3 项目主要由三个核心文件组成：\n- **generation.py**: 负责模型的加载、文本生成和对话生成的核心逻辑。\n- **model.py**: 定义了 Transformer 模型的结构，包括注意力机制、前馈网络、层归一化等组件。\n- **tokenizer.py**: 负责文本的编码和解码，使用 Tiktoken 作为分词器。\n\n## 2. **模块功能**\n\n### **generation.py**\n- **Llama 类**: 这是 Llama3 的核心类，负责模型的加载、文本生成和对话生成。\n  - **build 方法**: 初始化模型并加载预训练权重。它负责初始化分布式进程组、设置设备、加载模型和分词器。\n  - **generate 方法**: 根据输入的 token 序列生成文本。支持温度调节、top-p 采样、logprobs 计算等功能。\n  - **text_completion 方法**: 对输入的文本提示进行补全，生成文本补全结果。\n  - **chat_completion 方法**: 对输入的对话进行补全，生成助手的回复。\n  - **sample_top_p 函数**: 实现 top-p（nucleus）采样，用于控制生成文本的多样性。\n\n### **model.py**\n- **ModelArgs 类**: 定义了模型的基本参数，如维度、层数、头数、词汇表大小等。\n- **RMSNorm 类**: 实现了 RMS（Root Mean Square）归一化，用于替代传统的 LayerNorm。\n- **precompute_freqs_cis 函数**: 预计算旋转位置编码的频率。\n- **reshape_for_broadcast 函数**: 调整频率张量的形状以进行广播。\n- **apply_rotary_emb 函数**: 应用旋转位置编码到查询和键张量上。\n- **repeat_kv 函数**: 重复键和值张量以匹配头的数量。\n- **Attention 类**: 实现了多头注意力机制，支持键值缓存。\n- **FeedForward 类**: 实现了前馈网络，使用 SwiGLU 激活函数。\n- **TransformerBlock 类**: 组合了注意力机制和前馈网络，构成了 Transformer 的一个基本块。\n- **Transformer 类**: 整个 Transformer 模型，包含多个 TransformerBlock 层，负责前向传播。\n\n### **tokenizer.py**\n- **Tokenizer 类**: 负责文本的编码和解码，使用 Tiktoken 作为分词器。\n  - **encode 方法**: 将字符串编码为 token ID 序列，支持添加 BOS 和 EOS token。\n  - **decode 方法**: 将 token ID 序列解码为字符串。\n  - **_split_whitespaces_or_nonwhitespaces 方法**: 将字符串分割为不超过最大长度的子串。\n- **ChatFormat 类**: 负责对话格式的编码。\n  - **encode_header 方法**: 编码消息头（如角色信息）。\n  - **encode_message 方法**: 编码整个消息，包括消息头和内容。\n  - **encode_dialog_prompt 方法**: 编码整个对话，生成模型输入的 token 序列。\n\n## 3. **核心功能和关键技术**\n\n### 3.1 核心功能\n\n- **模型加载与初始化**: 通过 `Llama.build` 方法加载预训练模型和分词器，初始化分布式训练环境。\n- **文本生成**: 通过 `Llama.generate` 方法实现文本生成，支持温度调节、top-p 采样、logprobs 计算等功能。\n- **对话生成**: 通过 `Llama.chat_completion` 方法生成对话回复，支持多轮对话。\n- **分词与编码**: 通过 `Tokenizer` 类实现文本的编码和解码，支持特殊 token 的处理。\n- **Transformer 模型**: 通过 `Transformer` 类实现 Transformer 模型的前向传播，支持键值缓存和旋转位置编码。\n\n### 3.2 **关键技术**\n\n- **旋转位置编码**: 使用旋转位置编码（Rotary Position Embedding）来增强模型对位置信息的感知。\n- **RMSNorm**: 使用 RMSNorm 替代传统的 LayerNorm，减少计算量。\n- **SwiGLU 激活函数**: 在前馈网络中使用 SwiGLU 激活函数，增强模型的表达能力。\n- **Top-p 采样**: 使用 top-p 采样来控制生成文本的多样性，避免生成过于随机的文本。\n\n## 4. **Llama3 模型中数据从输入到输出的整体过程**\n\nLlama3 模型的数据处理流程从输入文本到生成输出文本，涉及多个步骤和模块的协同工作。以下是数据从输入到输出的整体过程：\n\n### **4.1 输入文本的编码**\n1. **文本输入**: 用户提供文本输入，可以是单句文本（用于文本补全）或多轮对话（用于对话生成）。\n2. **分词与编码**:\n   - **Tokenizer 类**: 使用 `Tokenizer.encode` 方法将输入文本转换为 token ID 序列。该方法会根据配置决定是否添加 BOS（Begin of Sequence）和 EOS（End of Sequence）token。\n   - **特殊 token 处理**: 如果输入文本中包含特殊 token（如对话中的角色标记），Tokenizer 会将其编码为对应的 token ID。\n   - **对话格式编码**: 对于对话任务，`ChatFormat` 类会将对话中的每条消息编码为 token 序列，并添加适当的特殊 token（如 `<|start_header_id|>` 和 `<|end_header_id|>`）。\n\n### **4.2 模型的前向传播**\n1. **输入 token 序列**:\n   - 编码后的 token 序列被转换为 PyTorch 张量，并输入到 Transformer 模型中。\n   - 如果输入序列长度小于模型的最大序列长度，会使用 pad token 进行填充。\n2. **嵌入层**:\n   - **tok_embeddings**: 输入 token 序列通过嵌入层（`VocabParallelEmbedding`）转换为词向量表示。\n   - 每个 token 被映射为一个高维向量（维度由 `ModelArgs.dim` 决定）。\n3. **旋转位置编码**:\n   - **precompute_freqs_cis**: 预计算旋转位置编码的频率。\n   - **apply_rotary_emb**: 将旋转位置编码应用到查询（query）和键（key）张量上，增强模型对位置信息的感知。\n4. **Transformer 层**:\n   - **TransformerBlock**: 模型由多个 TransformerBlock 组成，每个块包含一个多头注意力机制和一个前馈网络。\n     - **Attention**: 多头注意力机制计算查询、键和值之间的注意力分数，生成上下文感知的表示。\n     - **FeedForward**: 前馈网络使用 SwiGLU 激活函数进一步增强表示。\n   - **RMSNorm**: 在每个 TransformerBlock 中，使用 RMSNorm 对输入进行归一化。\n   - **残差连接**: 在每个 TransformerBlock 中，输入和输出通过残差连接进行叠加。\n5. **输出层**:\n   - **norm**: 最后一层 TransformerBlock 的输出通过 RMSNorm 进行归一化。\n   - **output**: 归一化后的输出通过线性层（`ColumnParallelLinear`）映射回词汇表空间，生成每个 token 的 logits（未归一化的概率分布）。\n\n### **4.3 文本生成**\n1. **logits 处理**:\n   - 模型输出的 logits 表示每个 token 的未归一化概率分布。\n   - 根据生成任务的需求，可以选择不同的采样策略（如贪婪采样、top-p 采样等）。\n2. **采样**:\n   - **sample_top_p**: 使用 top-p 采样从 logits 中选择下一个 token。该方法会从累积概率超过阈值 p 的最小 token 集合中进行采样，确保生成的文本既多样又合理。\n   - **温度调节**: 通过调节温度参数（temperature），控制生成文本的随机性。温度越高，生成的文本越随机；温度越低，生成的文本越确定。\n3. **生成 token 序列**:\n   - 根据采样结果，逐步生成 token 序列，直到达到最大生成长度或遇到停止 token（如 EOS token）。\n   - 在生成过程中，模型会不断更新键值缓存（key-value cache），以加速后续 token 的生成。\n\n### **4.4 输出文本的解码**\n1. **token 序列解码**:\n   - 生成的 token 序列通过 `Tokenizer.decode` 方法解码为文本。\n   - 解码过程中会去除特殊 token（如 BOS 和 EOS token），并将 token ID 映射回对应的字符或子词。\n2. **输出文本**:\n   - 解码后的文本作为模型的最终输出，返回给用户。\n   - 对于对话任务，输出文本通常是助手的回复；对于文本补全任务，输出文本是输入提示的补全结果。\n\n### **4.5 整体流程总结**\n1. **输入文本** → **Tokenizer 编码** → **token 序列**\n2. **token 序列** → **嵌入层** → **词向量表示**\n3. **词向量表示** → **旋转位置编码** → **上下文感知表示**\n4. **上下文感知表示** → **Transformer 层** → **logits**\n5. **logits** → **采样策略** → **生成 token 序列**\n6. **生成 token 序列** → **Tokenizer 解码** → **输出文本**\n\n## 5. **总结**\nLlama3 模型的处理流程从输入文本到输出文本，涉及分词、编码、嵌入、Transformer 层的前向传播、采样和解码等多个步骤。每个步骤都通过精心设计的模块（如 Tokenizer、TransformerBlock、Attention 等）实现，确保模型能够高效地生成高质量的文本。通过调节温度、top-p 采样等参数，用户可以控制生成文本的多样性和质量，满足不同任务的需求。\n\nLlama3 是一个功能强大的语言模型，支持文本生成和对话生成任务。其核心架构基于 Transformer，使用了旋转位置编码、RMSNorm、SwiGLU 激活函数等先进技术。通过 `generation.py` 中的 `Llama` 类，用户可以方便地加载模型、生成文本和对话。`model.py` 定义了 Transformer 模型的结构，`tokenizer.py` 负责文本的编码和解码。整体项目架构清晰，模块功能明确，适合大规模语言模型的训练和推理任务。\n\n\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","slug":"人工智能/nlp/llm/源码解析：llama3源码解析-01：整体代码结构及模块功能","published":1,"date":"2024-12-26T04:24:42.760Z","updated":"2024-12-26T04:24:42.760Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3m001ahghi4bvd2opo","content":"<hr>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/Llama3_Repo.jpeg\" alt=\"img\"></p>\n<p>Llama3 是一个基于 Transformer 架构的大规模语言模型，主要用于文本生成和对话任务。以下是 Llama3 项目的整体架构和各个模块的功能总结：</p>\n<h2 id=\"1-项目架构\"><a href=\"#1-项目架构\" class=\"headerlink\" title=\"1. 项目架构\"></a>1. <strong>项目架构</strong></h2><p>Llama3 项目主要由三个核心文件组成：</p>\n<ul>\n<li><strong>generation.py</strong>: 负责模型的加载、文本生成和对话生成的核心逻辑。</li>\n<li><strong>model.py</strong>: 定义了 Transformer 模型的结构，包括注意力机制、前馈网络、层归一化等组件。</li>\n<li><strong>tokenizer.py</strong>: 负责文本的编码和解码，使用 Tiktoken 作为分词器。</li>\n</ul>\n<h2 id=\"2-模块功能\"><a href=\"#2-模块功能\" class=\"headerlink\" title=\"2. 模块功能\"></a>2. <strong>模块功能</strong></h2><h3 id=\"generation-py\"><a href=\"#generation-py\" class=\"headerlink\" title=\"generation.py\"></a><strong>generation.py</strong></h3><ul>\n<li><strong>Llama 类</strong>: 这是 Llama3 的核心类，负责模型的加载、文本生成和对话生成。<ul>\n<li><strong>build 方法</strong>: 初始化模型并加载预训练权重。它负责初始化分布式进程组、设置设备、加载模型和分词器。</li>\n<li><strong>generate 方法</strong>: 根据输入的 token 序列生成文本。支持温度调节、top-p 采样、logprobs 计算等功能。</li>\n<li><strong>text_completion 方法</strong>: 对输入的文本提示进行补全，生成文本补全结果。</li>\n<li><strong>chat_completion 方法</strong>: 对输入的对话进行补全，生成助手的回复。</li>\n<li><strong>sample_top_p 函数</strong>: 实现 top-p（nucleus）采样，用于控制生成文本的多样性。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"model-py\"><a href=\"#model-py\" class=\"headerlink\" title=\"model.py\"></a><strong>model.py</strong></h3><ul>\n<li><strong>ModelArgs 类</strong>: 定义了模型的基本参数，如维度、层数、头数、词汇表大小等。</li>\n<li><strong>RMSNorm 类</strong>: 实现了 RMS（Root Mean Square）归一化，用于替代传统的 LayerNorm。</li>\n<li><strong>precompute_freqs_cis 函数</strong>: 预计算旋转位置编码的频率。</li>\n<li><strong>reshape_for_broadcast 函数</strong>: 调整频率张量的形状以进行广播。</li>\n<li><strong>apply_rotary_emb 函数</strong>: 应用旋转位置编码到查询和键张量上。</li>\n<li><strong>repeat_kv 函数</strong>: 重复键和值张量以匹配头的数量。</li>\n<li><strong>Attention 类</strong>: 实现了多头注意力机制，支持键值缓存。</li>\n<li><strong>FeedForward 类</strong>: 实现了前馈网络，使用 SwiGLU 激活函数。</li>\n<li><strong>TransformerBlock 类</strong>: 组合了注意力机制和前馈网络，构成了 Transformer 的一个基本块。</li>\n<li><strong>Transformer 类</strong>: 整个 Transformer 模型，包含多个 TransformerBlock 层，负责前向传播。</li>\n</ul>\n<h3 id=\"tokenizer-py\"><a href=\"#tokenizer-py\" class=\"headerlink\" title=\"tokenizer.py\"></a><strong>tokenizer.py</strong></h3><ul>\n<li><strong>Tokenizer 类</strong>: 负责文本的编码和解码，使用 Tiktoken 作为分词器。<ul>\n<li><strong>encode 方法</strong>: 将字符串编码为 token ID 序列，支持添加 BOS 和 EOS token。</li>\n<li><strong>decode 方法</strong>: 将 token ID 序列解码为字符串。</li>\n<li><strong>_split_whitespaces_or_nonwhitespaces 方法</strong>: 将字符串分割为不超过最大长度的子串。</li>\n</ul>\n</li>\n<li><strong>ChatFormat 类</strong>: 负责对话格式的编码。<ul>\n<li><strong>encode_header 方法</strong>: 编码消息头（如角色信息）。</li>\n<li><strong>encode_message 方法</strong>: 编码整个消息，包括消息头和内容。</li>\n<li><strong>encode_dialog_prompt 方法</strong>: 编码整个对话，生成模型输入的 token 序列。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-核心功能和关键技术\"><a href=\"#3-核心功能和关键技术\" class=\"headerlink\" title=\"3. 核心功能和关键技术\"></a>3. <strong>核心功能和关键技术</strong></h2><h3 id=\"3-1-核心功能\"><a href=\"#3-1-核心功能\" class=\"headerlink\" title=\"3.1 核心功能\"></a>3.1 核心功能</h3><ul>\n<li><strong>模型加载与初始化</strong>: 通过 <code>Llama.build</code> 方法加载预训练模型和分词器，初始化分布式训练环境。</li>\n<li><strong>文本生成</strong>: 通过 <code>Llama.generate</code> 方法实现文本生成，支持温度调节、top-p 采样、logprobs 计算等功能。</li>\n<li><strong>对话生成</strong>: 通过 <code>Llama.chat_completion</code> 方法生成对话回复，支持多轮对话。</li>\n<li><strong>分词与编码</strong>: 通过 <code>Tokenizer</code> 类实现文本的编码和解码，支持特殊 token 的处理。</li>\n<li><strong>Transformer 模型</strong>: 通过 <code>Transformer</code> 类实现 Transformer 模型的前向传播，支持键值缓存和旋转位置编码。</li>\n</ul>\n<h3 id=\"3-2-关键技术\"><a href=\"#3-2-关键技术\" class=\"headerlink\" title=\"3.2 关键技术\"></a>3.2 <strong>关键技术</strong></h3><ul>\n<li><strong>旋转位置编码</strong>: 使用旋转位置编码（Rotary Position Embedding）来增强模型对位置信息的感知。</li>\n<li><strong>RMSNorm</strong>: 使用 RMSNorm 替代传统的 LayerNorm，减少计算量。</li>\n<li><strong>SwiGLU 激活函数</strong>: 在前馈网络中使用 SwiGLU 激活函数，增强模型的表达能力。</li>\n<li><strong>Top-p 采样</strong>: 使用 top-p 采样来控制生成文本的多样性，避免生成过于随机的文本。</li>\n</ul>\n<h2 id=\"4-Llama3-模型中数据从输入到输出的整体过程\"><a href=\"#4-Llama3-模型中数据从输入到输出的整体过程\" class=\"headerlink\" title=\"4. Llama3 模型中数据从输入到输出的整体过程\"></a>4. <strong>Llama3 模型中数据从输入到输出的整体过程</strong></h2><p>Llama3 模型的数据处理流程从输入文本到生成输出文本，涉及多个步骤和模块的协同工作。以下是数据从输入到输出的整体过程：</p>\n<h3 id=\"4-1-输入文本的编码\"><a href=\"#4-1-输入文本的编码\" class=\"headerlink\" title=\"4.1 输入文本的编码\"></a><strong>4.1 输入文本的编码</strong></h3><ol>\n<li><strong>文本输入</strong>: 用户提供文本输入，可以是单句文本（用于文本补全）或多轮对话（用于对话生成）。</li>\n<li><strong>分词与编码</strong>:<ul>\n<li><strong>Tokenizer 类</strong>: 使用 <code>Tokenizer.encode</code> 方法将输入文本转换为 token ID 序列。该方法会根据配置决定是否添加 BOS（Begin of Sequence）和 EOS（End of Sequence）token。</li>\n<li><strong>特殊 token 处理</strong>: 如果输入文本中包含特殊 token（如对话中的角色标记），Tokenizer 会将其编码为对应的 token ID。</li>\n<li><strong>对话格式编码</strong>: 对于对话任务，<code>ChatFormat</code> 类会将对话中的每条消息编码为 token 序列，并添加适当的特殊 token（如 <code>&lt;|start_header_id|&gt;</code> 和 <code>&lt;|end_header_id|&gt;</code>）。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"4-2-模型的前向传播\"><a href=\"#4-2-模型的前向传播\" class=\"headerlink\" title=\"4.2 模型的前向传播\"></a><strong>4.2 模型的前向传播</strong></h3><ol>\n<li><strong>输入 token 序列</strong>:<ul>\n<li>编码后的 token 序列被转换为 PyTorch 张量，并输入到 Transformer 模型中。</li>\n<li>如果输入序列长度小于模型的最大序列长度，会使用 pad token 进行填充。</li>\n</ul>\n</li>\n<li><strong>嵌入层</strong>:<ul>\n<li><strong>tok_embeddings</strong>: 输入 token 序列通过嵌入层（<code>VocabParallelEmbedding</code>）转换为词向量表示。</li>\n<li>每个 token 被映射为一个高维向量（维度由 <code>ModelArgs.dim</code> 决定）。</li>\n</ul>\n</li>\n<li><strong>旋转位置编码</strong>:<ul>\n<li><strong>precompute_freqs_cis</strong>: 预计算旋转位置编码的频率。</li>\n<li><strong>apply_rotary_emb</strong>: 将旋转位置编码应用到查询（query）和键（key）张量上，增强模型对位置信息的感知。</li>\n</ul>\n</li>\n<li><strong>Transformer 层</strong>:<ul>\n<li><strong>TransformerBlock</strong>: 模型由多个 TransformerBlock 组成，每个块包含一个多头注意力机制和一个前馈网络。<ul>\n<li><strong>Attention</strong>: 多头注意力机制计算查询、键和值之间的注意力分数，生成上下文感知的表示。</li>\n<li><strong>FeedForward</strong>: 前馈网络使用 SwiGLU 激活函数进一步增强表示。</li>\n</ul>\n</li>\n<li><strong>RMSNorm</strong>: 在每个 TransformerBlock 中，使用 RMSNorm 对输入进行归一化。</li>\n<li><strong>残差连接</strong>: 在每个 TransformerBlock 中，输入和输出通过残差连接进行叠加。</li>\n</ul>\n</li>\n<li><strong>输出层</strong>:<ul>\n<li><strong>norm</strong>: 最后一层 TransformerBlock 的输出通过 RMSNorm 进行归一化。</li>\n<li><strong>output</strong>: 归一化后的输出通过线性层（<code>ColumnParallelLinear</code>）映射回词汇表空间，生成每个 token 的 logits（未归一化的概率分布）。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"4-3-文本生成\"><a href=\"#4-3-文本生成\" class=\"headerlink\" title=\"4.3 文本生成\"></a><strong>4.3 文本生成</strong></h3><ol>\n<li><strong>logits 处理</strong>:<ul>\n<li>模型输出的 logits 表示每个 token 的未归一化概率分布。</li>\n<li>根据生成任务的需求，可以选择不同的采样策略（如贪婪采样、top-p 采样等）。</li>\n</ul>\n</li>\n<li><strong>采样</strong>:<ul>\n<li><strong>sample_top_p</strong>: 使用 top-p 采样从 logits 中选择下一个 token。该方法会从累积概率超过阈值 p 的最小 token 集合中进行采样，确保生成的文本既多样又合理。</li>\n<li><strong>温度调节</strong>: 通过调节温度参数（temperature），控制生成文本的随机性。温度越高，生成的文本越随机；温度越低，生成的文本越确定。</li>\n</ul>\n</li>\n<li><strong>生成 token 序列</strong>:<ul>\n<li>根据采样结果，逐步生成 token 序列，直到达到最大生成长度或遇到停止 token（如 EOS token）。</li>\n<li>在生成过程中，模型会不断更新键值缓存（key-value cache），以加速后续 token 的生成。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"4-4-输出文本的解码\"><a href=\"#4-4-输出文本的解码\" class=\"headerlink\" title=\"4.4 输出文本的解码\"></a><strong>4.4 输出文本的解码</strong></h3><ol>\n<li><strong>token 序列解码</strong>:<ul>\n<li>生成的 token 序列通过 <code>Tokenizer.decode</code> 方法解码为文本。</li>\n<li>解码过程中会去除特殊 token（如 BOS 和 EOS token），并将 token ID 映射回对应的字符或子词。</li>\n</ul>\n</li>\n<li><strong>输出文本</strong>:<ul>\n<li>解码后的文本作为模型的最终输出，返回给用户。</li>\n<li>对于对话任务，输出文本通常是助手的回复；对于文本补全任务，输出文本是输入提示的补全结果。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"4-5-整体流程总结\"><a href=\"#4-5-整体流程总结\" class=\"headerlink\" title=\"4.5 整体流程总结\"></a><strong>4.5 整体流程总结</strong></h3><ol>\n<li><strong>输入文本</strong> → <strong>Tokenizer 编码</strong> → <strong>token 序列</strong></li>\n<li><strong>token 序列</strong> → <strong>嵌入层</strong> → <strong>词向量表示</strong></li>\n<li><strong>词向量表示</strong> → <strong>旋转位置编码</strong> → <strong>上下文感知表示</strong></li>\n<li><strong>上下文感知表示</strong> → <strong>Transformer 层</strong> → <strong>logits</strong></li>\n<li><strong>logits</strong> → <strong>采样策略</strong> → <strong>生成 token 序列</strong></li>\n<li><strong>生成 token 序列</strong> → <strong>Tokenizer 解码</strong> → <strong>输出文本</strong></li>\n</ol>\n<h2 id=\"5-总结\"><a href=\"#5-总结\" class=\"headerlink\" title=\"5. 总结\"></a>5. <strong>总结</strong></h2><p>Llama3 模型的处理流程从输入文本到输出文本，涉及分词、编码、嵌入、Transformer 层的前向传播、采样和解码等多个步骤。每个步骤都通过精心设计的模块（如 Tokenizer、TransformerBlock、Attention 等）实现，确保模型能够高效地生成高质量的文本。通过调节温度、top-p 采样等参数，用户可以控制生成文本的多样性和质量，满足不同任务的需求。</p>\n<p>Llama3 是一个功能强大的语言模型，支持文本生成和对话生成任务。其核心架构基于 Transformer，使用了旋转位置编码、RMSNorm、SwiGLU 激活函数等先进技术。通过 <code>generation.py</code> 中的 <code>Llama</code> 类，用户可以方便地加载模型、生成文本和对话。<code>model.py</code> 定义了 Transformer 模型的结构，<code>tokenizer.py</code> 负责文本的编码和解码。整体项目架构清晰，模块功能明确，适合大规模语言模型的训练和推理任务。</p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n","excerpt":"","more":"<hr>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/Llama3_Repo.jpeg\" alt=\"img\"></p>\n<p>Llama3 是一个基于 Transformer 架构的大规模语言模型，主要用于文本生成和对话任务。以下是 Llama3 项目的整体架构和各个模块的功能总结：</p>\n<h2 id=\"1-项目架构\"><a href=\"#1-项目架构\" class=\"headerlink\" title=\"1. 项目架构\"></a>1. <strong>项目架构</strong></h2><p>Llama3 项目主要由三个核心文件组成：</p>\n<ul>\n<li><strong>generation.py</strong>: 负责模型的加载、文本生成和对话生成的核心逻辑。</li>\n<li><strong>model.py</strong>: 定义了 Transformer 模型的结构，包括注意力机制、前馈网络、层归一化等组件。</li>\n<li><strong>tokenizer.py</strong>: 负责文本的编码和解码，使用 Tiktoken 作为分词器。</li>\n</ul>\n<h2 id=\"2-模块功能\"><a href=\"#2-模块功能\" class=\"headerlink\" title=\"2. 模块功能\"></a>2. <strong>模块功能</strong></h2><h3 id=\"generation-py\"><a href=\"#generation-py\" class=\"headerlink\" title=\"generation.py\"></a><strong>generation.py</strong></h3><ul>\n<li><strong>Llama 类</strong>: 这是 Llama3 的核心类，负责模型的加载、文本生成和对话生成。<ul>\n<li><strong>build 方法</strong>: 初始化模型并加载预训练权重。它负责初始化分布式进程组、设置设备、加载模型和分词器。</li>\n<li><strong>generate 方法</strong>: 根据输入的 token 序列生成文本。支持温度调节、top-p 采样、logprobs 计算等功能。</li>\n<li><strong>text_completion 方法</strong>: 对输入的文本提示进行补全，生成文本补全结果。</li>\n<li><strong>chat_completion 方法</strong>: 对输入的对话进行补全，生成助手的回复。</li>\n<li><strong>sample_top_p 函数</strong>: 实现 top-p（nucleus）采样，用于控制生成文本的多样性。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"model-py\"><a href=\"#model-py\" class=\"headerlink\" title=\"model.py\"></a><strong>model.py</strong></h3><ul>\n<li><strong>ModelArgs 类</strong>: 定义了模型的基本参数，如维度、层数、头数、词汇表大小等。</li>\n<li><strong>RMSNorm 类</strong>: 实现了 RMS（Root Mean Square）归一化，用于替代传统的 LayerNorm。</li>\n<li><strong>precompute_freqs_cis 函数</strong>: 预计算旋转位置编码的频率。</li>\n<li><strong>reshape_for_broadcast 函数</strong>: 调整频率张量的形状以进行广播。</li>\n<li><strong>apply_rotary_emb 函数</strong>: 应用旋转位置编码到查询和键张量上。</li>\n<li><strong>repeat_kv 函数</strong>: 重复键和值张量以匹配头的数量。</li>\n<li><strong>Attention 类</strong>: 实现了多头注意力机制，支持键值缓存。</li>\n<li><strong>FeedForward 类</strong>: 实现了前馈网络，使用 SwiGLU 激活函数。</li>\n<li><strong>TransformerBlock 类</strong>: 组合了注意力机制和前馈网络，构成了 Transformer 的一个基本块。</li>\n<li><strong>Transformer 类</strong>: 整个 Transformer 模型，包含多个 TransformerBlock 层，负责前向传播。</li>\n</ul>\n<h3 id=\"tokenizer-py\"><a href=\"#tokenizer-py\" class=\"headerlink\" title=\"tokenizer.py\"></a><strong>tokenizer.py</strong></h3><ul>\n<li><strong>Tokenizer 类</strong>: 负责文本的编码和解码，使用 Tiktoken 作为分词器。<ul>\n<li><strong>encode 方法</strong>: 将字符串编码为 token ID 序列，支持添加 BOS 和 EOS token。</li>\n<li><strong>decode 方法</strong>: 将 token ID 序列解码为字符串。</li>\n<li><strong>_split_whitespaces_or_nonwhitespaces 方法</strong>: 将字符串分割为不超过最大长度的子串。</li>\n</ul>\n</li>\n<li><strong>ChatFormat 类</strong>: 负责对话格式的编码。<ul>\n<li><strong>encode_header 方法</strong>: 编码消息头（如角色信息）。</li>\n<li><strong>encode_message 方法</strong>: 编码整个消息，包括消息头和内容。</li>\n<li><strong>encode_dialog_prompt 方法</strong>: 编码整个对话，生成模型输入的 token 序列。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-核心功能和关键技术\"><a href=\"#3-核心功能和关键技术\" class=\"headerlink\" title=\"3. 核心功能和关键技术\"></a>3. <strong>核心功能和关键技术</strong></h2><h3 id=\"3-1-核心功能\"><a href=\"#3-1-核心功能\" class=\"headerlink\" title=\"3.1 核心功能\"></a>3.1 核心功能</h3><ul>\n<li><strong>模型加载与初始化</strong>: 通过 <code>Llama.build</code> 方法加载预训练模型和分词器，初始化分布式训练环境。</li>\n<li><strong>文本生成</strong>: 通过 <code>Llama.generate</code> 方法实现文本生成，支持温度调节、top-p 采样、logprobs 计算等功能。</li>\n<li><strong>对话生成</strong>: 通过 <code>Llama.chat_completion</code> 方法生成对话回复，支持多轮对话。</li>\n<li><strong>分词与编码</strong>: 通过 <code>Tokenizer</code> 类实现文本的编码和解码，支持特殊 token 的处理。</li>\n<li><strong>Transformer 模型</strong>: 通过 <code>Transformer</code> 类实现 Transformer 模型的前向传播，支持键值缓存和旋转位置编码。</li>\n</ul>\n<h3 id=\"3-2-关键技术\"><a href=\"#3-2-关键技术\" class=\"headerlink\" title=\"3.2 关键技术\"></a>3.2 <strong>关键技术</strong></h3><ul>\n<li><strong>旋转位置编码</strong>: 使用旋转位置编码（Rotary Position Embedding）来增强模型对位置信息的感知。</li>\n<li><strong>RMSNorm</strong>: 使用 RMSNorm 替代传统的 LayerNorm，减少计算量。</li>\n<li><strong>SwiGLU 激活函数</strong>: 在前馈网络中使用 SwiGLU 激活函数，增强模型的表达能力。</li>\n<li><strong>Top-p 采样</strong>: 使用 top-p 采样来控制生成文本的多样性，避免生成过于随机的文本。</li>\n</ul>\n<h2 id=\"4-Llama3-模型中数据从输入到输出的整体过程\"><a href=\"#4-Llama3-模型中数据从输入到输出的整体过程\" class=\"headerlink\" title=\"4. Llama3 模型中数据从输入到输出的整体过程\"></a>4. <strong>Llama3 模型中数据从输入到输出的整体过程</strong></h2><p>Llama3 模型的数据处理流程从输入文本到生成输出文本，涉及多个步骤和模块的协同工作。以下是数据从输入到输出的整体过程：</p>\n<h3 id=\"4-1-输入文本的编码\"><a href=\"#4-1-输入文本的编码\" class=\"headerlink\" title=\"4.1 输入文本的编码\"></a><strong>4.1 输入文本的编码</strong></h3><ol>\n<li><strong>文本输入</strong>: 用户提供文本输入，可以是单句文本（用于文本补全）或多轮对话（用于对话生成）。</li>\n<li><strong>分词与编码</strong>:<ul>\n<li><strong>Tokenizer 类</strong>: 使用 <code>Tokenizer.encode</code> 方法将输入文本转换为 token ID 序列。该方法会根据配置决定是否添加 BOS（Begin of Sequence）和 EOS（End of Sequence）token。</li>\n<li><strong>特殊 token 处理</strong>: 如果输入文本中包含特殊 token（如对话中的角色标记），Tokenizer 会将其编码为对应的 token ID。</li>\n<li><strong>对话格式编码</strong>: 对于对话任务，<code>ChatFormat</code> 类会将对话中的每条消息编码为 token 序列，并添加适当的特殊 token（如 <code>&lt;|start_header_id|&gt;</code> 和 <code>&lt;|end_header_id|&gt;</code>）。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"4-2-模型的前向传播\"><a href=\"#4-2-模型的前向传播\" class=\"headerlink\" title=\"4.2 模型的前向传播\"></a><strong>4.2 模型的前向传播</strong></h3><ol>\n<li><strong>输入 token 序列</strong>:<ul>\n<li>编码后的 token 序列被转换为 PyTorch 张量，并输入到 Transformer 模型中。</li>\n<li>如果输入序列长度小于模型的最大序列长度，会使用 pad token 进行填充。</li>\n</ul>\n</li>\n<li><strong>嵌入层</strong>:<ul>\n<li><strong>tok_embeddings</strong>: 输入 token 序列通过嵌入层（<code>VocabParallelEmbedding</code>）转换为词向量表示。</li>\n<li>每个 token 被映射为一个高维向量（维度由 <code>ModelArgs.dim</code> 决定）。</li>\n</ul>\n</li>\n<li><strong>旋转位置编码</strong>:<ul>\n<li><strong>precompute_freqs_cis</strong>: 预计算旋转位置编码的频率。</li>\n<li><strong>apply_rotary_emb</strong>: 将旋转位置编码应用到查询（query）和键（key）张量上，增强模型对位置信息的感知。</li>\n</ul>\n</li>\n<li><strong>Transformer 层</strong>:<ul>\n<li><strong>TransformerBlock</strong>: 模型由多个 TransformerBlock 组成，每个块包含一个多头注意力机制和一个前馈网络。<ul>\n<li><strong>Attention</strong>: 多头注意力机制计算查询、键和值之间的注意力分数，生成上下文感知的表示。</li>\n<li><strong>FeedForward</strong>: 前馈网络使用 SwiGLU 激活函数进一步增强表示。</li>\n</ul>\n</li>\n<li><strong>RMSNorm</strong>: 在每个 TransformerBlock 中，使用 RMSNorm 对输入进行归一化。</li>\n<li><strong>残差连接</strong>: 在每个 TransformerBlock 中，输入和输出通过残差连接进行叠加。</li>\n</ul>\n</li>\n<li><strong>输出层</strong>:<ul>\n<li><strong>norm</strong>: 最后一层 TransformerBlock 的输出通过 RMSNorm 进行归一化。</li>\n<li><strong>output</strong>: 归一化后的输出通过线性层（<code>ColumnParallelLinear</code>）映射回词汇表空间，生成每个 token 的 logits（未归一化的概率分布）。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"4-3-文本生成\"><a href=\"#4-3-文本生成\" class=\"headerlink\" title=\"4.3 文本生成\"></a><strong>4.3 文本生成</strong></h3><ol>\n<li><strong>logits 处理</strong>:<ul>\n<li>模型输出的 logits 表示每个 token 的未归一化概率分布。</li>\n<li>根据生成任务的需求，可以选择不同的采样策略（如贪婪采样、top-p 采样等）。</li>\n</ul>\n</li>\n<li><strong>采样</strong>:<ul>\n<li><strong>sample_top_p</strong>: 使用 top-p 采样从 logits 中选择下一个 token。该方法会从累积概率超过阈值 p 的最小 token 集合中进行采样，确保生成的文本既多样又合理。</li>\n<li><strong>温度调节</strong>: 通过调节温度参数（temperature），控制生成文本的随机性。温度越高，生成的文本越随机；温度越低，生成的文本越确定。</li>\n</ul>\n</li>\n<li><strong>生成 token 序列</strong>:<ul>\n<li>根据采样结果，逐步生成 token 序列，直到达到最大生成长度或遇到停止 token（如 EOS token）。</li>\n<li>在生成过程中，模型会不断更新键值缓存（key-value cache），以加速后续 token 的生成。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"4-4-输出文本的解码\"><a href=\"#4-4-输出文本的解码\" class=\"headerlink\" title=\"4.4 输出文本的解码\"></a><strong>4.4 输出文本的解码</strong></h3><ol>\n<li><strong>token 序列解码</strong>:<ul>\n<li>生成的 token 序列通过 <code>Tokenizer.decode</code> 方法解码为文本。</li>\n<li>解码过程中会去除特殊 token（如 BOS 和 EOS token），并将 token ID 映射回对应的字符或子词。</li>\n</ul>\n</li>\n<li><strong>输出文本</strong>:<ul>\n<li>解码后的文本作为模型的最终输出，返回给用户。</li>\n<li>对于对话任务，输出文本通常是助手的回复；对于文本补全任务，输出文本是输入提示的补全结果。</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"4-5-整体流程总结\"><a href=\"#4-5-整体流程总结\" class=\"headerlink\" title=\"4.5 整体流程总结\"></a><strong>4.5 整体流程总结</strong></h3><ol>\n<li><strong>输入文本</strong> → <strong>Tokenizer 编码</strong> → <strong>token 序列</strong></li>\n<li><strong>token 序列</strong> → <strong>嵌入层</strong> → <strong>词向量表示</strong></li>\n<li><strong>词向量表示</strong> → <strong>旋转位置编码</strong> → <strong>上下文感知表示</strong></li>\n<li><strong>上下文感知表示</strong> → <strong>Transformer 层</strong> → <strong>logits</strong></li>\n<li><strong>logits</strong> → <strong>采样策略</strong> → <strong>生成 token 序列</strong></li>\n<li><strong>生成 token 序列</strong> → <strong>Tokenizer 解码</strong> → <strong>输出文本</strong></li>\n</ol>\n<h2 id=\"5-总结\"><a href=\"#5-总结\" class=\"headerlink\" title=\"5. 总结\"></a>5. <strong>总结</strong></h2><p>Llama3 模型的处理流程从输入文本到输出文本，涉及分词、编码、嵌入、Transformer 层的前向传播、采样和解码等多个步骤。每个步骤都通过精心设计的模块（如 Tokenizer、TransformerBlock、Attention 等）实现，确保模型能够高效地生成高质量的文本。通过调节温度、top-p 采样等参数，用户可以控制生成文本的多样性和质量，满足不同任务的需求。</p>\n<p>Llama3 是一个功能强大的语言模型，支持文本生成和对话生成任务。其核心架构基于 Transformer，使用了旋转位置编码、RMSNorm、SwiGLU 激活函数等先进技术。通过 <code>generation.py</code> 中的 <code>Llama</code> 类，用户可以方便地加载模型、生成文本和对话。<code>model.py</code> 定义了 Transformer 模型的结构，<code>tokenizer.py</code> 负责文本的编码和解码。整体项目架构清晰，模块功能明确，适合大规模语言模型的训练和推理任务。</p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n"},{"title":"OCR算法、模型综述","date":"2024-12-17T04:00:00.000Z","_content":"\n\n\n# 1. 引言\n\n### 1.1 什么是OCR\n\nOCR俗称光学字符识别，英文全称是Optical Charater Recognition（简称OCR）,它是利用光学技术和计算机技术把印刷在或者写在图纸上的文字以文本形式提取出来，并转换成一种计算机能够接受、人又可以理解的格式。OCR技术是实现文字快速录入的一项关键技术。在信息社会时代，每天会产生大量的票据、表单、证件数据，这些数据要电子化，需要利用OCR技术进行提取录入。在深度学习没有全面推广之前，大部分OCR识别都是基于传统的方法进行检测识别。在背景单一、数据场景简单的情况下，传统OCR一般都能达到好的效果，但在一些场景复杂、干扰多的情况下，识别效果不好，这个时候深度学习OCR就能体现出巨大的优势。\n\n### 1.2 传统OCR与深度学习OCR\n\n传统OCR（Optical Character Recognition，光学字符识别）方法是指在深度学习兴起之前广泛使用的一种将图片中的文字转化为计算机可识别文字的技术手段。它主要通过图像处理和统计机器学习方法来达成这一目的。传统OCR技术能够对纸上打印的字符进行识别，支持多场景、任意版型（如英文、字母、数字等）的文字识别，最初只能将图片中的文字转为纯文本，随着技术发展后来也能识别表格以及将一些固定排版的图片（如证件、票据等）转为结构化的数据 。\n\n从技术实现角度看，传统OCR技术涵盖了多个处理阶段，例如文字区域定位、文字矫正、文字分割、文字识别以及后处理等环节。它利用opencv算法库等工具，运用连通区域分析、MSER（Maximally Stable Extremal Regions，最大稳定极值区域）等技术进行文字区域定位，通过旋转、仿射变换进行文字矫正，采用二值化、过滤噪声来分割文字，再利用逻辑回归、SVM（Support Vector Machine，支持向量机）、Adaboost等分类器识别文字，最后结合规则、语言模型（如HMM - Hidden Markov Model，隐马尔可夫模型）等进行后处理，从而提高识别的准确性和有效性\n\n![image-20241209122335916](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209122335916.png)\n\n深度学习OCR方法可以分为两阶段算法和端到端的算法。两阶段OCR算法分为文本检测和识别算法，文本检测算法从图像中得到文本行的检测框，然后识别算法识别文本框中的内容。\n\n端对端OCR算法使用一个模型同时完成文字检测和文字识别，因此端对端模型更小，速度更快。\n\n相对于传统OCR方法，深度学习OCR方法准确率较高，速度可能慢一点。\n\n#### 传统OCR方法的优缺点\n\n##### （一）优点\n\n1. 处理简单场景效果好\n   - 对于简单场景下的图片，传统OCR已经取得了很好的识别效果。例如在一些格式规范、文字清晰、背景简单的文档识别中，传统OCR能够准确地识别出文字内容。像标准格式的发票识别，发票上的文字排版相对固定，字体规范，传统OCR可以有效地提取出发票号码、金额、日期等关键信息。在这种简单场景下，传统OCR的识别准确率可以达到较高水平，满足基本的业务需求，如财务报销中的发票信息录入等 [8](https://cloud.tencent.com/developer/information/ocr字符识别方法)。\n2. 运行速度较快\n   - 传统OCR技术通常比基于深度学习的OCR（aiOCR）更快，因为它不需要进行大量的训练和学习。在处理一些常规的、规则排列的文字时，传统OCR可以迅速地进行识别。例如在识别大量的、格式统一的表格数据时，传统OCR能够快速地对表格中的文字进行定位、分割和识别，不需要像深度学习模型那样进行复杂的神经网络前向传播和反向传播计算。这使得传统OCR在一些对速度要求较高、数据格式相对简单的应用场景中具有优势，如快递单的信息识别，在快递分拣过程中，需要快速地识别出寄件人和收件人的姓名、地址、电话号码等信息，传统OCR可以在较短的时间内完成识别任务 [16](https://www.11pdf.com/Tag/2192136.html)。\n3. 成本较低\n   - 传统OCR技术通常比较便宜，并且可以在低端硬件上运行。它不需要高端的图形处理单元（GPU）等昂贵的硬件设备来支持计算。对于一些预算有限的企业或个人用户来说，传统OCR技术是一种经济实惠的选择。例如，一些小型企业在进行文档数字化时，如果只是处理一些简单的文档类型，采用传统OCR技术可以在较低的成本下实现文字的识别和转换。而且，传统OCR技术在软件授权方面也相对较为便宜，不需要像一些基于深度学习的OCR软件那样支付高额的软件使用费用 [16](https://www.11pdf.com/Tag/2192136.html)。\n\n##### （二）缺点\n\n1. 对复杂场景适应性差\n   - 传统OCR方法是针对特定场景的图像进行建模的，一旦跳出当前场景，模型就会失效。例如，在处理自然场景中的文字时，如街景中的招牌、车身广告上的文字等，这些文字可能存在字体多样、大小不一、排列不规则、背景复杂（包含各种图案、光影变化等）的情况，传统OCR技术往往难以准确识别。再如手写文字的识别，由于每个人的书写风格差异很大，传统OCR很难对各种手写字体进行准确识别，其识别准确率会大幅下降 [8](https://cloud.tencent.com/developer/information/ocr字符识别方法)。\n2. 识别精度有限\n   - 对于复杂的文本，如包含多种字体、字号、颜色变化以及特殊排版（如艺术字、斜体字与正体字混合排版等）的文本，传统OCR技术可能会出现错误。在处理一些低质量的图像，如模糊、有污渍或者光照不均匀的图像时，传统OCR的识别准确性也会受到严重影响。例如，在识别一张被水浸湿过的纸质文档上的文字时，由于纸张的变形、文字的模糊等原因，传统OCR可能无法正确识别出所有的文字内容 [16](https://www.11pdf.com/Tag/2192136.html)。\n3. 需要专门培训人员\n   - 传统OCR技术需要专门培训人员进行使用和维护。其参数调整、算法优化等操作需要一定的专业知识和经验。例如，在使用传统OCR软件进行特定文档类型的识别时，可能需要根据文档的特点（如字体类型、排版格式等）对识别算法的参数进行调整，这就要求操作人员具备相关的技术知识，而这种专业人才相对较少，增加了企业或组织使用传统OCR技术的人力成本和难度 [16](https://www.11pdf.com/Tag/2192136.html)。\n4. 对格式保留困难\n   - 传统OCR技术在将纸质文档转换为电子文本时，可能无法完全保留原始文档的格式、排版和图表等信息。例如，在识别一份包含表格和图片的文档时，传统OCR可能只能识别出表格中的文字内容，而无法准确还原表格的结构和样式，对于图片更是无法直接转换为电子文档中的可编辑元素，这在一定程度上影响了文档转换的完整性和可用性。\n\n# 2. 传统OCR方法\n\n![传统OCR方法](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1577105446728504.jpeg)\n\n传统OCR方法主要分为文字区域定位、文字图像矫正、行列分割、分类器识别和后处理。按处理方式划分为三个阶段：预处理阶段、识别阶段和后处理阶段。\n\n### 2.1 文字区域定位\n\n- 传统OCR方法在处理图像时，首先要进行文字区域定位。这一过程常采用连通区域分析和MSER算法。连通区域分析是基于图像中像素的连通性，将具有相似特征（如颜色、灰度值等）的像素划分为不同的区域。例如，在一张包含文字和背景的图像中，文字部分的像素与背景像素在灰度或颜色上可能存在差异，通过连通区域分析可以初步找出可能是文字的区域。\n- MSER算法则是通过寻找图像中的极值区域，这些区域在一定的阈值变化范围内是最稳定的。对于文字来说，其字符形状相对稳定，在不同的灰度阈值下，字符所在区域往往表现出极大值或极小值的特性。通过这种方式，可以更精确地定位文字所在的区域\n\n### 2.2 文字图像矫正\n\n- 当图像中的文字存在倾斜或扭曲时，就需要进行文字矫正。这一阶段通常使用旋转和仿射变换。旋转是针对文字整体存在一定角度倾斜的情况，通过计算倾斜角度，将文字区域旋转到水平或垂直方向。例如，在扫描纸质文档时，如果文档放置稍有倾斜，扫描得到的图像中的文字也会倾斜，此时就可以根据文字的边界或者特定的算法来确定倾斜角度并进行旋转操作。\n- 仿射变换则更通用，它可以处理文字的拉伸、压缩以及更复杂的变形情况。它通过对图像中的坐标进行线性变换，将变形后的文字映射回正常的形状，从而为后续的文字分割和识别提供更有利的条件。\n\n### 2.3 行列分割\n\n- 在文字分割阶段，传统OCR采用二值化和过滤噪声等操作。二值化是将图像的像素值转换为只有0和1的二值形式，这样可以突出文字与背景的对比。例如，将文字部分设为1（白色），背景设为0（黑色）或者反之。通过这种方式，可以简化图像的复杂度，使得文字的轮廓更加清晰。\n- 过滤噪声则是去除图像中的干扰因素，如扫描过程中产生的小斑点、划痕等。这些噪声可能会被误识别为文字的一部分，通过滤波算法（如中值滤波、高斯滤波等）可以去除这些不必要的干扰，提高文字分割的准确性。\n\n### 2.4 分类器识别\n\n分类器识别过程是在提取了字符图像之后，对其进行分析和分类，以确定每个字符对应的符号或文字。以下是这一过程的详细说明：\n\n#### 特征提取\n\n在进行分类之前，OCR系统首先需要从图像中提取出字符的特征。这可能包括：\n\n- **几何特征**：如字符的高度、宽度、笔画数量等。\n- **统计特征**：例如像素分布、边缘检测结果等。\n- **拓扑结构**：字符内部的连通性或断开情况。\n- **频域特征**：通过傅里叶变换或其他频域分析方法获得的特征。\n\n这些特征能够描述字符的独特属性，有助于后续的分类工作。\n\n#### 分类器训练\n\n为了实现准确的分类，OCR系统通常会使用机器学习算法来构建分类器。训练阶段涉及以下几个方面：\n\n- **数据准备**：收集大量带有标签的字符图像作为训练样本。每个样本都包含一个字符图像及其对应的正确标签（即该字符的真实值）。\n- **选择模型**：根据任务需求选择合适的分类算法，如支持向量机（SVM）、K近邻（KNN）、神经网络等。\n- **训练过程**：利用训练集中的数据对选定的模型进行训练，调整模型参数，使得模型能够学习到如何基于输入的特征预测正确的字符标签。\n\n#### 分类与决策\n\n一旦分类器被训练好，就可以用于实际的字符识别：\n\n- **输入处理**：当一个新的字符图像输入时，系统首先会提取其特征。\n- **分类预测**：然后使用训练好的分类器对这些特征进行评估，输出最有可能的字符标签。\n- **后处理**：有时还会有一个后处理步骤，比如语言模型的应用，来修正识别结果中的拼写错误或者不符合语法的地方，提高整体准确性。\n\n分类器识别是传统OCR方法的核心部分，它决定了系统能否准确地将图像中的字符转换成文本。通过精心设计的特征提取、有效的分类算法和充足的训练数据，可以显著提高OCR系统的准确性和鲁棒性。\n\n### 2.5 后处理\n\n- 传统OCR的后处理阶段会利用规则和语言模型来提高识别的准确性。规则可以是基于语法、格式等方面的规定。例如，在识别身份证号码时，根据身份证号码的固定格式（18位数字，特定的编码规则等），对识别结果进行校验和修正。\n- 语言模型如HMM也会被应用。HMM是一种统计模型，它基于马尔可夫链假设，对文字的序列进行建模。在文字识别中，它可以根据语言的概率分布来纠正识别结果中的错误。例如，在识别一段英文句子时，如果某个单词被识别为不符合语法规则的形式，HMM可以根据语言的统计规律，推荐最可能的正确单词。\n\n# 3. 深度学习OCR方法\n\n### 3.1 两阶段OCR\n\n#### ![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/68747470733a2f2f61692d73747564696f2d7374617469632d6f6e6c696e652e63646e2e626365626f732e636f6d2f34663465613635353738333834393030393039656666663933643062373338366538366563653134346438633436373762376263393462346630333337636662)\n\n| 文本检测算法模型 | 文字识别算法模型 |      |\n| ---------------- | ---------------- | ---- |\n| CTPN             | CRNN             |      |\n| SegLink          | RARE             |      |\n| EAST             | RAN              |      |\n| PSENet           | ASTER            |      |\n| DBNet            | MORAN            |      |\n| FCENet           | SRN              |      |\n| Texboxes         | STAR-Net         |      |\n| CRAFT            | Rosetta          |      |\n| LOMO             | SAR              |      |\n| SPCNet           | R2AM             |      |\n| PAN              |                  |      |\n| DB               |                  |      |\n\n\n\n### 3.2 端到端OCR\n\n与两阶段OCR不同，端到端OCR不需要先进行文字检测然后再进行文字识别这样明确的分阶段操作。它直接在整个图像上进行操作，将图像中的文字信息直接转换为文本。这样做的好处是避免了由于分阶段处理带来的误差累积问题。例如，在两阶段OCR中，如果文字检测阶段出现错误，那么在识别阶段就会基于错误的检测结果进行操作，而端到端OCR则不存在这种情况，因为它是从图像到文本的直接映射。并且，将检测和识别统一到一个模型里面，就使得图像的feature可以被共享利用。\n\n| OCR算法模型        | Title                                                        |\n| ------------------ | ------------------------------------------------------------ |\n|                    | [Towards End-to-end Text Spotting with Convolution Recurrent Neural Network](https://arxiv.org/pdf/1707.03985.pdf) |\n| FOTS               | [FOTS: Fast Oriented Text Spotting with a Unified Network](https://arxiv.org/pdf/1801.01671.pdf) |\n| Mask TextSpotter   | [Mask TextSpotter: An End-to-End Trainable Neural Network for Spotting Text with Arbitrary Shapes](https://arxiv.org/pdf/1807.02242.pdf) |\n| CharNet            | [Convolutional Character Networks](https://arxiv.org/abs/1910.07954) |\n| Mask TextSpotterV3 | [Mask TextSpotter v3: Segmentation Proposal Network for Robust Scene Text Spotting](https://arxiv.org/abs/2007.09482) |\n| PGNet              | [[2104.05458\\] PGNet: Real-time Arbitrarily-Shaped Text Spotting with Point Gathering Network](https://arxiv.org/abs/2104.05458) |\n| ABCNet             |                                                              |\n| TrOCR              | TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models |\n| SVTRv2             | SVTRv2: CTC Beats Encoder-Decoder Models in Scene Text Recognition |\n| GOT-OCR            | [Ucas-HaoranWei/GOT-OCR2.0: Official code implementation of General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model](https://github.com/Ucas-HaoranWei/GOT-OCR2.0) |\n\n### 3.3 多模态OCR\n\n| 算法模型                                                |                                                              |\n| ------------------------------------------------------- | ------------------------------------------------------------ |\n| Vary                                                    | [[2312.06109\\] Vary: Scaling up the Vision Vocabulary for Large Vision-Language Models](https://arxiv.org/abs/2312.06109) |\n| TextHarmony                                             | [[2407.16364\\] Harmonizing Visual Text Comprehension and Generation](https://arxiv.org/abs/2407.16364) |\n| [GOT-OCR2.0](https://www.aisharenet.com/got-ocr20jiyu/) | [Ucas-HaoranWei/GOT-OCR2.0: Official code implementation of General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model](https://github.com/Ucas-HaoranWei/GOT-OCR2.0) |\n| 其它大部分多模态大模型都支持OCR任务                     | [Yuliang-Liu/MultimodalOCR: On the Hidden Mystery of OCR in Large Multimodal Models (OCRBench)](https://github.com/Yuliang-Liu/MultimodalOCR) |\n\n![多模态OCR方法](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/4b4650c9d035fbd912d56823b451c035.png)\n\n![多模型OCR结果](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209145707320.png)\n\n![多模态OCR结果](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209145800157.png)\n\n![多模态OCR结果](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209145845645.png)\n\n# 4. OCR应用方向\n\n### 4.1 文字识别\n\n- 普通文字识别\n\n- 场景文字识别\n\n- 数学公式识别\n\n  从图片中提取数学公式，转换为markdown或者Latex\n\n  \n\n### 4.2 文档结构化识别（版面分析）\n\n- 页眉\n\n- 页脚\n\n- 数学公式\n\n- 图表的Caption\n\n- 图片\n\n- 表格\n\n- 段落文本\n\n- 段落标题\n\n- 列表\n\n  \n\n### 4.3 关键信息抽取\n\n关键信息提取（Key Information Extraction，KIE）是Document VQA中的一个重要任务，主要从图像中提取所需要的关键信息，如从身份证中提取出姓名和公民身份号码信息，这类信息的种类往往在特定任务下是固定的，但是在不同任务间是不同的。\n\nKIE通常分为两个子任务进行研究：\n\n- SER: 语义实体识别 (Semantic Entity Recognition)，对每一个检测到的文本进行分类，如将其分为姓名，身份证。如下图中的黑色框和红色框。\n- RE: 关系抽取 (Relation Extraction)，对每一个检测到的文本进行分类，如将其分为问题和的答案。然后对每一个问题找到对应的答案。如下图中的红色框和黑色框分别代表问题和答案，黄色线代表问题和答案之间的对应关系。\n\n一般的KIE方法基于命名实体识别(Named Entity Recognition,NER)[4]来研究，但是这类方法只利用了图像中的文本信息，缺少对视觉和结构信息的使用，因此精度不高。在此基础上，近几年的方法都开始将视觉和结构信息与文本信息融合到一起，按照对多模态信息进行融合时所采用的原理可以将这些方法分为下面四种：\n\n- 基于Grid的方法\n- 基于Token的方法\n- 基于GCN的方法\n- 基于End to End 的方法\n\n# 5. OCR相关工具\n\n- PaddleOCR:通用OCR工具\n\n  ![PaddleOCR](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/68747470733a2f2f61692d73747564696f2d7374617469632d6f6e6c696e652e63646e2e626365626f732e636f6d2f65303939323962346133316534346639623565336435343264313234313133333236363964326531613231643435616438386231646439313134326563383663)\n\n- Tesseract: 普通文字识别\n\n- Umi-OCR: 普通文字识别、文档解析\n\n- MinerU:将PDF转换成Markdown和JSON格式\n\n- LaTeX-OCR: 数学公式识别\n\n  \n\n[OCR文字识别方法综述-阿里云开发者社区](https://developer.aliyun.com/article/1054626)\n\n[传统OCR识别综述-云社区-华为云](https://bbs.huaweicloud.com/blogs/140398#H10)\n\n[Dive-into-OCR/notebook_ch/1.introduction/OCR技术导论.ipynb at main · PaddleOCR-Community/Dive-into-OCR](https://github.com/PaddleOCR-Community/Dive-into-OCR/blob/main/notebook_ch/1.introduction/OCR技术导论.ipynb)\n\n[【多模态】29、OCRBench | 为大型多模态模型提供一个 OCR 任务测评基准-CSDN博客](https://blog.csdn.net/jiaoyangwm/article/details/138414709)\n\n\n\n文章合集：https://github.com/chongzicbo/ReadWriteThink\n\n![二维码](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)\n\n","source":"_posts/人工智能/multi-modal/OCR/多模态003：OCR算法、模型综述.md","raw":"---\ntitle: 'OCR算法、模型综述'\ncategories:\n  - [人工智能,multi-modal,OCR]\ntags:\n  - 人工智能\n  - 多模态\n  - OCR\ndate: 2024-12-17 12:00:00\n---\n\n\n\n# 1. 引言\n\n### 1.1 什么是OCR\n\nOCR俗称光学字符识别，英文全称是Optical Charater Recognition（简称OCR）,它是利用光学技术和计算机技术把印刷在或者写在图纸上的文字以文本形式提取出来，并转换成一种计算机能够接受、人又可以理解的格式。OCR技术是实现文字快速录入的一项关键技术。在信息社会时代，每天会产生大量的票据、表单、证件数据，这些数据要电子化，需要利用OCR技术进行提取录入。在深度学习没有全面推广之前，大部分OCR识别都是基于传统的方法进行检测识别。在背景单一、数据场景简单的情况下，传统OCR一般都能达到好的效果，但在一些场景复杂、干扰多的情况下，识别效果不好，这个时候深度学习OCR就能体现出巨大的优势。\n\n### 1.2 传统OCR与深度学习OCR\n\n传统OCR（Optical Character Recognition，光学字符识别）方法是指在深度学习兴起之前广泛使用的一种将图片中的文字转化为计算机可识别文字的技术手段。它主要通过图像处理和统计机器学习方法来达成这一目的。传统OCR技术能够对纸上打印的字符进行识别，支持多场景、任意版型（如英文、字母、数字等）的文字识别，最初只能将图片中的文字转为纯文本，随着技术发展后来也能识别表格以及将一些固定排版的图片（如证件、票据等）转为结构化的数据 。\n\n从技术实现角度看，传统OCR技术涵盖了多个处理阶段，例如文字区域定位、文字矫正、文字分割、文字识别以及后处理等环节。它利用opencv算法库等工具，运用连通区域分析、MSER（Maximally Stable Extremal Regions，最大稳定极值区域）等技术进行文字区域定位，通过旋转、仿射变换进行文字矫正，采用二值化、过滤噪声来分割文字，再利用逻辑回归、SVM（Support Vector Machine，支持向量机）、Adaboost等分类器识别文字，最后结合规则、语言模型（如HMM - Hidden Markov Model，隐马尔可夫模型）等进行后处理，从而提高识别的准确性和有效性\n\n![image-20241209122335916](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209122335916.png)\n\n深度学习OCR方法可以分为两阶段算法和端到端的算法。两阶段OCR算法分为文本检测和识别算法，文本检测算法从图像中得到文本行的检测框，然后识别算法识别文本框中的内容。\n\n端对端OCR算法使用一个模型同时完成文字检测和文字识别，因此端对端模型更小，速度更快。\n\n相对于传统OCR方法，深度学习OCR方法准确率较高，速度可能慢一点。\n\n#### 传统OCR方法的优缺点\n\n##### （一）优点\n\n1. 处理简单场景效果好\n   - 对于简单场景下的图片，传统OCR已经取得了很好的识别效果。例如在一些格式规范、文字清晰、背景简单的文档识别中，传统OCR能够准确地识别出文字内容。像标准格式的发票识别，发票上的文字排版相对固定，字体规范，传统OCR可以有效地提取出发票号码、金额、日期等关键信息。在这种简单场景下，传统OCR的识别准确率可以达到较高水平，满足基本的业务需求，如财务报销中的发票信息录入等 [8](https://cloud.tencent.com/developer/information/ocr字符识别方法)。\n2. 运行速度较快\n   - 传统OCR技术通常比基于深度学习的OCR（aiOCR）更快，因为它不需要进行大量的训练和学习。在处理一些常规的、规则排列的文字时，传统OCR可以迅速地进行识别。例如在识别大量的、格式统一的表格数据时，传统OCR能够快速地对表格中的文字进行定位、分割和识别，不需要像深度学习模型那样进行复杂的神经网络前向传播和反向传播计算。这使得传统OCR在一些对速度要求较高、数据格式相对简单的应用场景中具有优势，如快递单的信息识别，在快递分拣过程中，需要快速地识别出寄件人和收件人的姓名、地址、电话号码等信息，传统OCR可以在较短的时间内完成识别任务 [16](https://www.11pdf.com/Tag/2192136.html)。\n3. 成本较低\n   - 传统OCR技术通常比较便宜，并且可以在低端硬件上运行。它不需要高端的图形处理单元（GPU）等昂贵的硬件设备来支持计算。对于一些预算有限的企业或个人用户来说，传统OCR技术是一种经济实惠的选择。例如，一些小型企业在进行文档数字化时，如果只是处理一些简单的文档类型，采用传统OCR技术可以在较低的成本下实现文字的识别和转换。而且，传统OCR技术在软件授权方面也相对较为便宜，不需要像一些基于深度学习的OCR软件那样支付高额的软件使用费用 [16](https://www.11pdf.com/Tag/2192136.html)。\n\n##### （二）缺点\n\n1. 对复杂场景适应性差\n   - 传统OCR方法是针对特定场景的图像进行建模的，一旦跳出当前场景，模型就会失效。例如，在处理自然场景中的文字时，如街景中的招牌、车身广告上的文字等，这些文字可能存在字体多样、大小不一、排列不规则、背景复杂（包含各种图案、光影变化等）的情况，传统OCR技术往往难以准确识别。再如手写文字的识别，由于每个人的书写风格差异很大，传统OCR很难对各种手写字体进行准确识别，其识别准确率会大幅下降 [8](https://cloud.tencent.com/developer/information/ocr字符识别方法)。\n2. 识别精度有限\n   - 对于复杂的文本，如包含多种字体、字号、颜色变化以及特殊排版（如艺术字、斜体字与正体字混合排版等）的文本，传统OCR技术可能会出现错误。在处理一些低质量的图像，如模糊、有污渍或者光照不均匀的图像时，传统OCR的识别准确性也会受到严重影响。例如，在识别一张被水浸湿过的纸质文档上的文字时，由于纸张的变形、文字的模糊等原因，传统OCR可能无法正确识别出所有的文字内容 [16](https://www.11pdf.com/Tag/2192136.html)。\n3. 需要专门培训人员\n   - 传统OCR技术需要专门培训人员进行使用和维护。其参数调整、算法优化等操作需要一定的专业知识和经验。例如，在使用传统OCR软件进行特定文档类型的识别时，可能需要根据文档的特点（如字体类型、排版格式等）对识别算法的参数进行调整，这就要求操作人员具备相关的技术知识，而这种专业人才相对较少，增加了企业或组织使用传统OCR技术的人力成本和难度 [16](https://www.11pdf.com/Tag/2192136.html)。\n4. 对格式保留困难\n   - 传统OCR技术在将纸质文档转换为电子文本时，可能无法完全保留原始文档的格式、排版和图表等信息。例如，在识别一份包含表格和图片的文档时，传统OCR可能只能识别出表格中的文字内容，而无法准确还原表格的结构和样式，对于图片更是无法直接转换为电子文档中的可编辑元素，这在一定程度上影响了文档转换的完整性和可用性。\n\n# 2. 传统OCR方法\n\n![传统OCR方法](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1577105446728504.jpeg)\n\n传统OCR方法主要分为文字区域定位、文字图像矫正、行列分割、分类器识别和后处理。按处理方式划分为三个阶段：预处理阶段、识别阶段和后处理阶段。\n\n### 2.1 文字区域定位\n\n- 传统OCR方法在处理图像时，首先要进行文字区域定位。这一过程常采用连通区域分析和MSER算法。连通区域分析是基于图像中像素的连通性，将具有相似特征（如颜色、灰度值等）的像素划分为不同的区域。例如，在一张包含文字和背景的图像中，文字部分的像素与背景像素在灰度或颜色上可能存在差异，通过连通区域分析可以初步找出可能是文字的区域。\n- MSER算法则是通过寻找图像中的极值区域，这些区域在一定的阈值变化范围内是最稳定的。对于文字来说，其字符形状相对稳定，在不同的灰度阈值下，字符所在区域往往表现出极大值或极小值的特性。通过这种方式，可以更精确地定位文字所在的区域\n\n### 2.2 文字图像矫正\n\n- 当图像中的文字存在倾斜或扭曲时，就需要进行文字矫正。这一阶段通常使用旋转和仿射变换。旋转是针对文字整体存在一定角度倾斜的情况，通过计算倾斜角度，将文字区域旋转到水平或垂直方向。例如，在扫描纸质文档时，如果文档放置稍有倾斜，扫描得到的图像中的文字也会倾斜，此时就可以根据文字的边界或者特定的算法来确定倾斜角度并进行旋转操作。\n- 仿射变换则更通用，它可以处理文字的拉伸、压缩以及更复杂的变形情况。它通过对图像中的坐标进行线性变换，将变形后的文字映射回正常的形状，从而为后续的文字分割和识别提供更有利的条件。\n\n### 2.3 行列分割\n\n- 在文字分割阶段，传统OCR采用二值化和过滤噪声等操作。二值化是将图像的像素值转换为只有0和1的二值形式，这样可以突出文字与背景的对比。例如，将文字部分设为1（白色），背景设为0（黑色）或者反之。通过这种方式，可以简化图像的复杂度，使得文字的轮廓更加清晰。\n- 过滤噪声则是去除图像中的干扰因素，如扫描过程中产生的小斑点、划痕等。这些噪声可能会被误识别为文字的一部分，通过滤波算法（如中值滤波、高斯滤波等）可以去除这些不必要的干扰，提高文字分割的准确性。\n\n### 2.4 分类器识别\n\n分类器识别过程是在提取了字符图像之后，对其进行分析和分类，以确定每个字符对应的符号或文字。以下是这一过程的详细说明：\n\n#### 特征提取\n\n在进行分类之前，OCR系统首先需要从图像中提取出字符的特征。这可能包括：\n\n- **几何特征**：如字符的高度、宽度、笔画数量等。\n- **统计特征**：例如像素分布、边缘检测结果等。\n- **拓扑结构**：字符内部的连通性或断开情况。\n- **频域特征**：通过傅里叶变换或其他频域分析方法获得的特征。\n\n这些特征能够描述字符的独特属性，有助于后续的分类工作。\n\n#### 分类器训练\n\n为了实现准确的分类，OCR系统通常会使用机器学习算法来构建分类器。训练阶段涉及以下几个方面：\n\n- **数据准备**：收集大量带有标签的字符图像作为训练样本。每个样本都包含一个字符图像及其对应的正确标签（即该字符的真实值）。\n- **选择模型**：根据任务需求选择合适的分类算法，如支持向量机（SVM）、K近邻（KNN）、神经网络等。\n- **训练过程**：利用训练集中的数据对选定的模型进行训练，调整模型参数，使得模型能够学习到如何基于输入的特征预测正确的字符标签。\n\n#### 分类与决策\n\n一旦分类器被训练好，就可以用于实际的字符识别：\n\n- **输入处理**：当一个新的字符图像输入时，系统首先会提取其特征。\n- **分类预测**：然后使用训练好的分类器对这些特征进行评估，输出最有可能的字符标签。\n- **后处理**：有时还会有一个后处理步骤，比如语言模型的应用，来修正识别结果中的拼写错误或者不符合语法的地方，提高整体准确性。\n\n分类器识别是传统OCR方法的核心部分，它决定了系统能否准确地将图像中的字符转换成文本。通过精心设计的特征提取、有效的分类算法和充足的训练数据，可以显著提高OCR系统的准确性和鲁棒性。\n\n### 2.5 后处理\n\n- 传统OCR的后处理阶段会利用规则和语言模型来提高识别的准确性。规则可以是基于语法、格式等方面的规定。例如，在识别身份证号码时，根据身份证号码的固定格式（18位数字，特定的编码规则等），对识别结果进行校验和修正。\n- 语言模型如HMM也会被应用。HMM是一种统计模型，它基于马尔可夫链假设，对文字的序列进行建模。在文字识别中，它可以根据语言的概率分布来纠正识别结果中的错误。例如，在识别一段英文句子时，如果某个单词被识别为不符合语法规则的形式，HMM可以根据语言的统计规律，推荐最可能的正确单词。\n\n# 3. 深度学习OCR方法\n\n### 3.1 两阶段OCR\n\n#### ![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/68747470733a2f2f61692d73747564696f2d7374617469632d6f6e6c696e652e63646e2e626365626f732e636f6d2f34663465613635353738333834393030393039656666663933643062373338366538366563653134346438633436373762376263393462346630333337636662)\n\n| 文本检测算法模型 | 文字识别算法模型 |      |\n| ---------------- | ---------------- | ---- |\n| CTPN             | CRNN             |      |\n| SegLink          | RARE             |      |\n| EAST             | RAN              |      |\n| PSENet           | ASTER            |      |\n| DBNet            | MORAN            |      |\n| FCENet           | SRN              |      |\n| Texboxes         | STAR-Net         |      |\n| CRAFT            | Rosetta          |      |\n| LOMO             | SAR              |      |\n| SPCNet           | R2AM             |      |\n| PAN              |                  |      |\n| DB               |                  |      |\n\n\n\n### 3.2 端到端OCR\n\n与两阶段OCR不同，端到端OCR不需要先进行文字检测然后再进行文字识别这样明确的分阶段操作。它直接在整个图像上进行操作，将图像中的文字信息直接转换为文本。这样做的好处是避免了由于分阶段处理带来的误差累积问题。例如，在两阶段OCR中，如果文字检测阶段出现错误，那么在识别阶段就会基于错误的检测结果进行操作，而端到端OCR则不存在这种情况，因为它是从图像到文本的直接映射。并且，将检测和识别统一到一个模型里面，就使得图像的feature可以被共享利用。\n\n| OCR算法模型        | Title                                                        |\n| ------------------ | ------------------------------------------------------------ |\n|                    | [Towards End-to-end Text Spotting with Convolution Recurrent Neural Network](https://arxiv.org/pdf/1707.03985.pdf) |\n| FOTS               | [FOTS: Fast Oriented Text Spotting with a Unified Network](https://arxiv.org/pdf/1801.01671.pdf) |\n| Mask TextSpotter   | [Mask TextSpotter: An End-to-End Trainable Neural Network for Spotting Text with Arbitrary Shapes](https://arxiv.org/pdf/1807.02242.pdf) |\n| CharNet            | [Convolutional Character Networks](https://arxiv.org/abs/1910.07954) |\n| Mask TextSpotterV3 | [Mask TextSpotter v3: Segmentation Proposal Network for Robust Scene Text Spotting](https://arxiv.org/abs/2007.09482) |\n| PGNet              | [[2104.05458\\] PGNet: Real-time Arbitrarily-Shaped Text Spotting with Point Gathering Network](https://arxiv.org/abs/2104.05458) |\n| ABCNet             |                                                              |\n| TrOCR              | TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models |\n| SVTRv2             | SVTRv2: CTC Beats Encoder-Decoder Models in Scene Text Recognition |\n| GOT-OCR            | [Ucas-HaoranWei/GOT-OCR2.0: Official code implementation of General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model](https://github.com/Ucas-HaoranWei/GOT-OCR2.0) |\n\n### 3.3 多模态OCR\n\n| 算法模型                                                |                                                              |\n| ------------------------------------------------------- | ------------------------------------------------------------ |\n| Vary                                                    | [[2312.06109\\] Vary: Scaling up the Vision Vocabulary for Large Vision-Language Models](https://arxiv.org/abs/2312.06109) |\n| TextHarmony                                             | [[2407.16364\\] Harmonizing Visual Text Comprehension and Generation](https://arxiv.org/abs/2407.16364) |\n| [GOT-OCR2.0](https://www.aisharenet.com/got-ocr20jiyu/) | [Ucas-HaoranWei/GOT-OCR2.0: Official code implementation of General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model](https://github.com/Ucas-HaoranWei/GOT-OCR2.0) |\n| 其它大部分多模态大模型都支持OCR任务                     | [Yuliang-Liu/MultimodalOCR: On the Hidden Mystery of OCR in Large Multimodal Models (OCRBench)](https://github.com/Yuliang-Liu/MultimodalOCR) |\n\n![多模态OCR方法](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/4b4650c9d035fbd912d56823b451c035.png)\n\n![多模型OCR结果](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209145707320.png)\n\n![多模态OCR结果](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209145800157.png)\n\n![多模态OCR结果](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209145845645.png)\n\n# 4. OCR应用方向\n\n### 4.1 文字识别\n\n- 普通文字识别\n\n- 场景文字识别\n\n- 数学公式识别\n\n  从图片中提取数学公式，转换为markdown或者Latex\n\n  \n\n### 4.2 文档结构化识别（版面分析）\n\n- 页眉\n\n- 页脚\n\n- 数学公式\n\n- 图表的Caption\n\n- 图片\n\n- 表格\n\n- 段落文本\n\n- 段落标题\n\n- 列表\n\n  \n\n### 4.3 关键信息抽取\n\n关键信息提取（Key Information Extraction，KIE）是Document VQA中的一个重要任务，主要从图像中提取所需要的关键信息，如从身份证中提取出姓名和公民身份号码信息，这类信息的种类往往在特定任务下是固定的，但是在不同任务间是不同的。\n\nKIE通常分为两个子任务进行研究：\n\n- SER: 语义实体识别 (Semantic Entity Recognition)，对每一个检测到的文本进行分类，如将其分为姓名，身份证。如下图中的黑色框和红色框。\n- RE: 关系抽取 (Relation Extraction)，对每一个检测到的文本进行分类，如将其分为问题和的答案。然后对每一个问题找到对应的答案。如下图中的红色框和黑色框分别代表问题和答案，黄色线代表问题和答案之间的对应关系。\n\n一般的KIE方法基于命名实体识别(Named Entity Recognition,NER)[4]来研究，但是这类方法只利用了图像中的文本信息，缺少对视觉和结构信息的使用，因此精度不高。在此基础上，近几年的方法都开始将视觉和结构信息与文本信息融合到一起，按照对多模态信息进行融合时所采用的原理可以将这些方法分为下面四种：\n\n- 基于Grid的方法\n- 基于Token的方法\n- 基于GCN的方法\n- 基于End to End 的方法\n\n# 5. OCR相关工具\n\n- PaddleOCR:通用OCR工具\n\n  ![PaddleOCR](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/68747470733a2f2f61692d73747564696f2d7374617469632d6f6e6c696e652e63646e2e626365626f732e636f6d2f65303939323962346133316534346639623565336435343264313234313133333236363964326531613231643435616438386231646439313134326563383663)\n\n- Tesseract: 普通文字识别\n\n- Umi-OCR: 普通文字识别、文档解析\n\n- MinerU:将PDF转换成Markdown和JSON格式\n\n- LaTeX-OCR: 数学公式识别\n\n  \n\n[OCR文字识别方法综述-阿里云开发者社区](https://developer.aliyun.com/article/1054626)\n\n[传统OCR识别综述-云社区-华为云](https://bbs.huaweicloud.com/blogs/140398#H10)\n\n[Dive-into-OCR/notebook_ch/1.introduction/OCR技术导论.ipynb at main · PaddleOCR-Community/Dive-into-OCR](https://github.com/PaddleOCR-Community/Dive-into-OCR/blob/main/notebook_ch/1.introduction/OCR技术导论.ipynb)\n\n[【多模态】29、OCRBench | 为大型多模态模型提供一个 OCR 任务测评基准-CSDN博客](https://blog.csdn.net/jiaoyangwm/article/details/138414709)\n\n\n\n文章合集：https://github.com/chongzicbo/ReadWriteThink\n\n![二维码](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)\n\n","slug":"人工智能/multi-modal/OCR/多模态003：OCR算法、模型综述","published":1,"updated":"2024-12-26T06:19:26.722Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3n001ehghi4m3n9u3u","content":"<h1 id=\"1-引言\"><a href=\"#1-引言\" class=\"headerlink\" title=\"1. 引言\"></a>1. 引言</h1><h3 id=\"1-1-什么是OCR\"><a href=\"#1-1-什么是OCR\" class=\"headerlink\" title=\"1.1 什么是OCR\"></a>1.1 什么是OCR</h3><p>OCR俗称光学字符识别，英文全称是Optical Charater Recognition（简称OCR）,它是利用光学技术和计算机技术把印刷在或者写在图纸上的文字以文本形式提取出来，并转换成一种计算机能够接受、人又可以理解的格式。OCR技术是实现文字快速录入的一项关键技术。在信息社会时代，每天会产生大量的票据、表单、证件数据，这些数据要电子化，需要利用OCR技术进行提取录入。在深度学习没有全面推广之前，大部分OCR识别都是基于传统的方法进行检测识别。在背景单一、数据场景简单的情况下，传统OCR一般都能达到好的效果，但在一些场景复杂、干扰多的情况下，识别效果不好，这个时候深度学习OCR就能体现出巨大的优势。</p>\n<h3 id=\"1-2-传统OCR与深度学习OCR\"><a href=\"#1-2-传统OCR与深度学习OCR\" class=\"headerlink\" title=\"1.2 传统OCR与深度学习OCR\"></a>1.2 传统OCR与深度学习OCR</h3><p>传统OCR（Optical Character Recognition，光学字符识别）方法是指在深度学习兴起之前广泛使用的一种将图片中的文字转化为计算机可识别文字的技术手段。它主要通过图像处理和统计机器学习方法来达成这一目的。传统OCR技术能够对纸上打印的字符进行识别，支持多场景、任意版型（如英文、字母、数字等）的文字识别，最初只能将图片中的文字转为纯文本，随着技术发展后来也能识别表格以及将一些固定排版的图片（如证件、票据等）转为结构化的数据 。</p>\n<p>从技术实现角度看，传统OCR技术涵盖了多个处理阶段，例如文字区域定位、文字矫正、文字分割、文字识别以及后处理等环节。它利用opencv算法库等工具，运用连通区域分析、MSER（Maximally Stable Extremal Regions，最大稳定极值区域）等技术进行文字区域定位，通过旋转、仿射变换进行文字矫正，采用二值化、过滤噪声来分割文字，再利用逻辑回归、SVM（Support Vector Machine，支持向量机）、Adaboost等分类器识别文字，最后结合规则、语言模型（如HMM - Hidden Markov Model，隐马尔可夫模型）等进行后处理，从而提高识别的准确性和有效性</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209122335916.png\" alt=\"image-20241209122335916\"></p>\n<p>深度学习OCR方法可以分为两阶段算法和端到端的算法。两阶段OCR算法分为文本检测和识别算法，文本检测算法从图像中得到文本行的检测框，然后识别算法识别文本框中的内容。</p>\n<p>端对端OCR算法使用一个模型同时完成文字检测和文字识别，因此端对端模型更小，速度更快。</p>\n<p>相对于传统OCR方法，深度学习OCR方法准确率较高，速度可能慢一点。</p>\n<h4 id=\"传统OCR方法的优缺点\"><a href=\"#传统OCR方法的优缺点\" class=\"headerlink\" title=\"传统OCR方法的优缺点\"></a>传统OCR方法的优缺点</h4><h5 id=\"（一）优点\"><a href=\"#（一）优点\" class=\"headerlink\" title=\"（一）优点\"></a>（一）优点</h5><ol>\n<li>处理简单场景效果好<ul>\n<li>对于简单场景下的图片，传统OCR已经取得了很好的识别效果。例如在一些格式规范、文字清晰、背景简单的文档识别中，传统OCR能够准确地识别出文字内容。像标准格式的发票识别，发票上的文字排版相对固定，字体规范，传统OCR可以有效地提取出发票号码、金额、日期等关键信息。在这种简单场景下，传统OCR的识别准确率可以达到较高水平，满足基本的业务需求，如财务报销中的发票信息录入等 <a href=\"https://cloud.tencent.com/developer/information/ocr%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95\">8</a>。</li>\n</ul>\n</li>\n<li>运行速度较快<ul>\n<li>传统OCR技术通常比基于深度学习的OCR（aiOCR）更快，因为它不需要进行大量的训练和学习。在处理一些常规的、规则排列的文字时，传统OCR可以迅速地进行识别。例如在识别大量的、格式统一的表格数据时，传统OCR能够快速地对表格中的文字进行定位、分割和识别，不需要像深度学习模型那样进行复杂的神经网络前向传播和反向传播计算。这使得传统OCR在一些对速度要求较高、数据格式相对简单的应用场景中具有优势，如快递单的信息识别，在快递分拣过程中，需要快速地识别出寄件人和收件人的姓名、地址、电话号码等信息，传统OCR可以在较短的时间内完成识别任务 <a href=\"https://www.11pdf.com/Tag/2192136.html\">16</a>。</li>\n</ul>\n</li>\n<li>成本较低<ul>\n<li>传统OCR技术通常比较便宜，并且可以在低端硬件上运行。它不需要高端的图形处理单元（GPU）等昂贵的硬件设备来支持计算。对于一些预算有限的企业或个人用户来说，传统OCR技术是一种经济实惠的选择。例如，一些小型企业在进行文档数字化时，如果只是处理一些简单的文档类型，采用传统OCR技术可以在较低的成本下实现文字的识别和转换。而且，传统OCR技术在软件授权方面也相对较为便宜，不需要像一些基于深度学习的OCR软件那样支付高额的软件使用费用 <a href=\"https://www.11pdf.com/Tag/2192136.html\">16</a>。</li>\n</ul>\n</li>\n</ol>\n<h5 id=\"（二）缺点\"><a href=\"#（二）缺点\" class=\"headerlink\" title=\"（二）缺点\"></a>（二）缺点</h5><ol>\n<li>对复杂场景适应性差<ul>\n<li>传统OCR方法是针对特定场景的图像进行建模的，一旦跳出当前场景，模型就会失效。例如，在处理自然场景中的文字时，如街景中的招牌、车身广告上的文字等，这些文字可能存在字体多样、大小不一、排列不规则、背景复杂（包含各种图案、光影变化等）的情况，传统OCR技术往往难以准确识别。再如手写文字的识别，由于每个人的书写风格差异很大，传统OCR很难对各种手写字体进行准确识别，其识别准确率会大幅下降 <a href=\"https://cloud.tencent.com/developer/information/ocr%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95\">8</a>。</li>\n</ul>\n</li>\n<li>识别精度有限<ul>\n<li>对于复杂的文本，如包含多种字体、字号、颜色变化以及特殊排版（如艺术字、斜体字与正体字混合排版等）的文本，传统OCR技术可能会出现错误。在处理一些低质量的图像，如模糊、有污渍或者光照不均匀的图像时，传统OCR的识别准确性也会受到严重影响。例如，在识别一张被水浸湿过的纸质文档上的文字时，由于纸张的变形、文字的模糊等原因，传统OCR可能无法正确识别出所有的文字内容 <a href=\"https://www.11pdf.com/Tag/2192136.html\">16</a>。</li>\n</ul>\n</li>\n<li>需要专门培训人员<ul>\n<li>传统OCR技术需要专门培训人员进行使用和维护。其参数调整、算法优化等操作需要一定的专业知识和经验。例如，在使用传统OCR软件进行特定文档类型的识别时，可能需要根据文档的特点（如字体类型、排版格式等）对识别算法的参数进行调整，这就要求操作人员具备相关的技术知识，而这种专业人才相对较少，增加了企业或组织使用传统OCR技术的人力成本和难度 <a href=\"https://www.11pdf.com/Tag/2192136.html\">16</a>。</li>\n</ul>\n</li>\n<li>对格式保留困难<ul>\n<li>传统OCR技术在将纸质文档转换为电子文本时，可能无法完全保留原始文档的格式、排版和图表等信息。例如，在识别一份包含表格和图片的文档时，传统OCR可能只能识别出表格中的文字内容，而无法准确还原表格的结构和样式，对于图片更是无法直接转换为电子文档中的可编辑元素，这在一定程度上影响了文档转换的完整性和可用性。</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"2-传统OCR方法\"><a href=\"#2-传统OCR方法\" class=\"headerlink\" title=\"2. 传统OCR方法\"></a>2. 传统OCR方法</h1><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1577105446728504.jpeg\" alt=\"传统OCR方法\"></p>\n<p>传统OCR方法主要分为文字区域定位、文字图像矫正、行列分割、分类器识别和后处理。按处理方式划分为三个阶段：预处理阶段、识别阶段和后处理阶段。</p>\n<h3 id=\"2-1-文字区域定位\"><a href=\"#2-1-文字区域定位\" class=\"headerlink\" title=\"2.1 文字区域定位\"></a>2.1 文字区域定位</h3><ul>\n<li>传统OCR方法在处理图像时，首先要进行文字区域定位。这一过程常采用连通区域分析和MSER算法。连通区域分析是基于图像中像素的连通性，将具有相似特征（如颜色、灰度值等）的像素划分为不同的区域。例如，在一张包含文字和背景的图像中，文字部分的像素与背景像素在灰度或颜色上可能存在差异，通过连通区域分析可以初步找出可能是文字的区域。</li>\n<li>MSER算法则是通过寻找图像中的极值区域，这些区域在一定的阈值变化范围内是最稳定的。对于文字来说，其字符形状相对稳定，在不同的灰度阈值下，字符所在区域往往表现出极大值或极小值的特性。通过这种方式，可以更精确地定位文字所在的区域</li>\n</ul>\n<h3 id=\"2-2-文字图像矫正\"><a href=\"#2-2-文字图像矫正\" class=\"headerlink\" title=\"2.2 文字图像矫正\"></a>2.2 文字图像矫正</h3><ul>\n<li>当图像中的文字存在倾斜或扭曲时，就需要进行文字矫正。这一阶段通常使用旋转和仿射变换。旋转是针对文字整体存在一定角度倾斜的情况，通过计算倾斜角度，将文字区域旋转到水平或垂直方向。例如，在扫描纸质文档时，如果文档放置稍有倾斜，扫描得到的图像中的文字也会倾斜，此时就可以根据文字的边界或者特定的算法来确定倾斜角度并进行旋转操作。</li>\n<li>仿射变换则更通用，它可以处理文字的拉伸、压缩以及更复杂的变形情况。它通过对图像中的坐标进行线性变换，将变形后的文字映射回正常的形状，从而为后续的文字分割和识别提供更有利的条件。</li>\n</ul>\n<h3 id=\"2-3-行列分割\"><a href=\"#2-3-行列分割\" class=\"headerlink\" title=\"2.3 行列分割\"></a>2.3 行列分割</h3><ul>\n<li>在文字分割阶段，传统OCR采用二值化和过滤噪声等操作。二值化是将图像的像素值转换为只有0和1的二值形式，这样可以突出文字与背景的对比。例如，将文字部分设为1（白色），背景设为0（黑色）或者反之。通过这种方式，可以简化图像的复杂度，使得文字的轮廓更加清晰。</li>\n<li>过滤噪声则是去除图像中的干扰因素，如扫描过程中产生的小斑点、划痕等。这些噪声可能会被误识别为文字的一部分，通过滤波算法（如中值滤波、高斯滤波等）可以去除这些不必要的干扰，提高文字分割的准确性。</li>\n</ul>\n<h3 id=\"2-4-分类器识别\"><a href=\"#2-4-分类器识别\" class=\"headerlink\" title=\"2.4 分类器识别\"></a>2.4 分类器识别</h3><p>分类器识别过程是在提取了字符图像之后，对其进行分析和分类，以确定每个字符对应的符号或文字。以下是这一过程的详细说明：</p>\n<h4 id=\"特征提取\"><a href=\"#特征提取\" class=\"headerlink\" title=\"特征提取\"></a>特征提取</h4><p>在进行分类之前，OCR系统首先需要从图像中提取出字符的特征。这可能包括：</p>\n<ul>\n<li><strong>几何特征</strong>：如字符的高度、宽度、笔画数量等。</li>\n<li><strong>统计特征</strong>：例如像素分布、边缘检测结果等。</li>\n<li><strong>拓扑结构</strong>：字符内部的连通性或断开情况。</li>\n<li><strong>频域特征</strong>：通过傅里叶变换或其他频域分析方法获得的特征。</li>\n</ul>\n<p>这些特征能够描述字符的独特属性，有助于后续的分类工作。</p>\n<h4 id=\"分类器训练\"><a href=\"#分类器训练\" class=\"headerlink\" title=\"分类器训练\"></a>分类器训练</h4><p>为了实现准确的分类，OCR系统通常会使用机器学习算法来构建分类器。训练阶段涉及以下几个方面：</p>\n<ul>\n<li><strong>数据准备</strong>：收集大量带有标签的字符图像作为训练样本。每个样本都包含一个字符图像及其对应的正确标签（即该字符的真实值）。</li>\n<li><strong>选择模型</strong>：根据任务需求选择合适的分类算法，如支持向量机（SVM）、K近邻（KNN）、神经网络等。</li>\n<li><strong>训练过程</strong>：利用训练集中的数据对选定的模型进行训练，调整模型参数，使得模型能够学习到如何基于输入的特征预测正确的字符标签。</li>\n</ul>\n<h4 id=\"分类与决策\"><a href=\"#分类与决策\" class=\"headerlink\" title=\"分类与决策\"></a>分类与决策</h4><p>一旦分类器被训练好，就可以用于实际的字符识别：</p>\n<ul>\n<li><strong>输入处理</strong>：当一个新的字符图像输入时，系统首先会提取其特征。</li>\n<li><strong>分类预测</strong>：然后使用训练好的分类器对这些特征进行评估，输出最有可能的字符标签。</li>\n<li><strong>后处理</strong>：有时还会有一个后处理步骤，比如语言模型的应用，来修正识别结果中的拼写错误或者不符合语法的地方，提高整体准确性。</li>\n</ul>\n<p>分类器识别是传统OCR方法的核心部分，它决定了系统能否准确地将图像中的字符转换成文本。通过精心设计的特征提取、有效的分类算法和充足的训练数据，可以显著提高OCR系统的准确性和鲁棒性。</p>\n<h3 id=\"2-5-后处理\"><a href=\"#2-5-后处理\" class=\"headerlink\" title=\"2.5 后处理\"></a>2.5 后处理</h3><ul>\n<li>传统OCR的后处理阶段会利用规则和语言模型来提高识别的准确性。规则可以是基于语法、格式等方面的规定。例如，在识别身份证号码时，根据身份证号码的固定格式（18位数字，特定的编码规则等），对识别结果进行校验和修正。</li>\n<li>语言模型如HMM也会被应用。HMM是一种统计模型，它基于马尔可夫链假设，对文字的序列进行建模。在文字识别中，它可以根据语言的概率分布来纠正识别结果中的错误。例如，在识别一段英文句子时，如果某个单词被识别为不符合语法规则的形式，HMM可以根据语言的统计规律，推荐最可能的正确单词。</li>\n</ul>\n<h1 id=\"3-深度学习OCR方法\"><a href=\"#3-深度学习OCR方法\" class=\"headerlink\" title=\"3. 深度学习OCR方法\"></a>3. 深度学习OCR方法</h1><h3 id=\"3-1-两阶段OCR\"><a href=\"#3-1-两阶段OCR\" class=\"headerlink\" title=\"3.1 两阶段OCR\"></a>3.1 两阶段OCR</h3><h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/68747470733a2f2f61692d73747564696f2d7374617469632d6f6e6c696e652e63646e2e626365626f732e636f6d2f34663465613635353738333834393030393039656666663933643062373338366538366563653134346438633436373762376263393462346630333337636662\" alt=\"img\"></h4><table>\n<thead>\n<tr>\n<th>文本检测算法模型</th>\n<th>文字识别算法模型</th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>CTPN</td>\n<td>CRNN</td>\n<td></td>\n</tr>\n<tr>\n<td>SegLink</td>\n<td>RARE</td>\n<td></td>\n</tr>\n<tr>\n<td>EAST</td>\n<td>RAN</td>\n<td></td>\n</tr>\n<tr>\n<td>PSENet</td>\n<td>ASTER</td>\n<td></td>\n</tr>\n<tr>\n<td>DBNet</td>\n<td>MORAN</td>\n<td></td>\n</tr>\n<tr>\n<td>FCENet</td>\n<td>SRN</td>\n<td></td>\n</tr>\n<tr>\n<td>Texboxes</td>\n<td>STAR-Net</td>\n<td></td>\n</tr>\n<tr>\n<td>CRAFT</td>\n<td>Rosetta</td>\n<td></td>\n</tr>\n<tr>\n<td>LOMO</td>\n<td>SAR</td>\n<td></td>\n</tr>\n<tr>\n<td>SPCNet</td>\n<td>R2AM</td>\n<td></td>\n</tr>\n<tr>\n<td>PAN</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>DB</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<h3 id=\"3-2-端到端OCR\"><a href=\"#3-2-端到端OCR\" class=\"headerlink\" title=\"3.2 端到端OCR\"></a>3.2 端到端OCR</h3><p>与两阶段OCR不同，端到端OCR不需要先进行文字检测然后再进行文字识别这样明确的分阶段操作。它直接在整个图像上进行操作，将图像中的文字信息直接转换为文本。这样做的好处是避免了由于分阶段处理带来的误差累积问题。例如，在两阶段OCR中，如果文字检测阶段出现错误，那么在识别阶段就会基于错误的检测结果进行操作，而端到端OCR则不存在这种情况，因为它是从图像到文本的直接映射。并且，将检测和识别统一到一个模型里面，就使得图像的feature可以被共享利用。</p>\n<table>\n<thead>\n<tr>\n<th>OCR算法模型</th>\n<th>Title</th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n<td><a href=\"https://arxiv.org/pdf/1707.03985.pdf\">Towards End-to-end Text Spotting with Convolution Recurrent Neural Network</a></td>\n</tr>\n<tr>\n<td>FOTS</td>\n<td><a href=\"https://arxiv.org/pdf/1801.01671.pdf\">FOTS: Fast Oriented Text Spotting with a Unified Network</a></td>\n</tr>\n<tr>\n<td>Mask TextSpotter</td>\n<td><a href=\"https://arxiv.org/pdf/1807.02242.pdf\">Mask TextSpotter: An End-to-End Trainable Neural Network for Spotting Text with Arbitrary Shapes</a></td>\n</tr>\n<tr>\n<td>CharNet</td>\n<td><a href=\"https://arxiv.org/abs/1910.07954\">Convolutional Character Networks</a></td>\n</tr>\n<tr>\n<td>Mask TextSpotterV3</td>\n<td><a href=\"https://arxiv.org/abs/2007.09482\">Mask TextSpotter v3: Segmentation Proposal Network for Robust Scene Text Spotting</a></td>\n</tr>\n<tr>\n<td>PGNet</td>\n<td>[<a href=\"https://arxiv.org/abs/2104.05458\">2104.05458] PGNet: Real-time Arbitrarily-Shaped Text Spotting with Point Gathering Network</a></td>\n</tr>\n<tr>\n<td>ABCNet</td>\n<td></td>\n</tr>\n<tr>\n<td>TrOCR</td>\n<td>TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models</td>\n</tr>\n<tr>\n<td>SVTRv2</td>\n<td>SVTRv2: CTC Beats Encoder-Decoder Models in Scene Text Recognition</td>\n</tr>\n<tr>\n<td>GOT-OCR</td>\n<td><a href=\"https://github.com/Ucas-HaoranWei/GOT-OCR2.0\">Ucas-HaoranWei&#x2F;GOT-OCR2.0: Official code implementation of General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model</a></td>\n</tr>\n</tbody></table>\n<h3 id=\"3-3-多模态OCR\"><a href=\"#3-3-多模态OCR\" class=\"headerlink\" title=\"3.3 多模态OCR\"></a>3.3 多模态OCR</h3><table>\n<thead>\n<tr>\n<th>算法模型</th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Vary</td>\n<td>[<a href=\"https://arxiv.org/abs/2312.06109\">2312.06109] Vary: Scaling up the Vision Vocabulary for Large Vision-Language Models</a></td>\n</tr>\n<tr>\n<td>TextHarmony</td>\n<td>[<a href=\"https://arxiv.org/abs/2407.16364\">2407.16364] Harmonizing Visual Text Comprehension and Generation</a></td>\n</tr>\n<tr>\n<td><a href=\"https://www.aisharenet.com/got-ocr20jiyu/\">GOT-OCR2.0</a></td>\n<td><a href=\"https://github.com/Ucas-HaoranWei/GOT-OCR2.0\">Ucas-HaoranWei&#x2F;GOT-OCR2.0: Official code implementation of General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model</a></td>\n</tr>\n<tr>\n<td>其它大部分多模态大模型都支持OCR任务</td>\n<td><a href=\"https://github.com/Yuliang-Liu/MultimodalOCR\">Yuliang-Liu&#x2F;MultimodalOCR: On the Hidden Mystery of OCR in Large Multimodal Models (OCRBench)</a></td>\n</tr>\n</tbody></table>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/4b4650c9d035fbd912d56823b451c035.png\" alt=\"多模态OCR方法\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209145707320.png\" alt=\"多模型OCR结果\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209145800157.png\" alt=\"多模态OCR结果\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209145845645.png\" alt=\"多模态OCR结果\"></p>\n<h1 id=\"4-OCR应用方向\"><a href=\"#4-OCR应用方向\" class=\"headerlink\" title=\"4. OCR应用方向\"></a>4. OCR应用方向</h1><h3 id=\"4-1-文字识别\"><a href=\"#4-1-文字识别\" class=\"headerlink\" title=\"4.1 文字识别\"></a>4.1 文字识别</h3><ul>\n<li><p>普通文字识别</p>\n</li>\n<li><p>场景文字识别</p>\n</li>\n<li><p>数学公式识别</p>\n<p>从图片中提取数学公式，转换为markdown或者Latex</p>\n</li>\n</ul>\n<h3 id=\"4-2-文档结构化识别（版面分析）\"><a href=\"#4-2-文档结构化识别（版面分析）\" class=\"headerlink\" title=\"4.2 文档结构化识别（版面分析）\"></a>4.2 文档结构化识别（版面分析）</h3><ul>\n<li><p>页眉</p>\n</li>\n<li><p>页脚</p>\n</li>\n<li><p>数学公式</p>\n</li>\n<li><p>图表的Caption</p>\n</li>\n<li><p>图片</p>\n</li>\n<li><p>表格</p>\n</li>\n<li><p>段落文本</p>\n</li>\n<li><p>段落标题</p>\n</li>\n<li><p>列表</p>\n</li>\n</ul>\n<h3 id=\"4-3-关键信息抽取\"><a href=\"#4-3-关键信息抽取\" class=\"headerlink\" title=\"4.3 关键信息抽取\"></a>4.3 关键信息抽取</h3><p>关键信息提取（Key Information Extraction，KIE）是Document VQA中的一个重要任务，主要从图像中提取所需要的关键信息，如从身份证中提取出姓名和公民身份号码信息，这类信息的种类往往在特定任务下是固定的，但是在不同任务间是不同的。</p>\n<p>KIE通常分为两个子任务进行研究：</p>\n<ul>\n<li>SER: 语义实体识别 (Semantic Entity Recognition)，对每一个检测到的文本进行分类，如将其分为姓名，身份证。如下图中的黑色框和红色框。</li>\n<li>RE: 关系抽取 (Relation Extraction)，对每一个检测到的文本进行分类，如将其分为问题和的答案。然后对每一个问题找到对应的答案。如下图中的红色框和黑色框分别代表问题和答案，黄色线代表问题和答案之间的对应关系。</li>\n</ul>\n<p>一般的KIE方法基于命名实体识别(Named Entity Recognition,NER)[4]来研究，但是这类方法只利用了图像中的文本信息，缺少对视觉和结构信息的使用，因此精度不高。在此基础上，近几年的方法都开始将视觉和结构信息与文本信息融合到一起，按照对多模态信息进行融合时所采用的原理可以将这些方法分为下面四种：</p>\n<ul>\n<li>基于Grid的方法</li>\n<li>基于Token的方法</li>\n<li>基于GCN的方法</li>\n<li>基于End to End 的方法</li>\n</ul>\n<h1 id=\"5-OCR相关工具\"><a href=\"#5-OCR相关工具\" class=\"headerlink\" title=\"5. OCR相关工具\"></a>5. OCR相关工具</h1><ul>\n<li><p>PaddleOCR:通用OCR工具</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/68747470733a2f2f61692d73747564696f2d7374617469632d6f6e6c696e652e63646e2e626365626f732e636f6d2f65303939323962346133316534346639623565336435343264313234313133333236363964326531613231643435616438386231646439313134326563383663\" alt=\"PaddleOCR\"></p>\n</li>\n<li><p>Tesseract: 普通文字识别</p>\n</li>\n<li><p>Umi-OCR: 普通文字识别、文档解析</p>\n</li>\n<li><p>MinerU:将PDF转换成Markdown和JSON格式</p>\n</li>\n<li><p>LaTeX-OCR: 数学公式识别</p>\n</li>\n</ul>\n<p><a href=\"https://developer.aliyun.com/article/1054626\">OCR文字识别方法综述-阿里云开发者社区</a></p>\n<p><a href=\"https://bbs.huaweicloud.com/blogs/140398#H10\">传统OCR识别综述-云社区-华为云</a></p>\n<p><a href=\"https://github.com/PaddleOCR-Community/Dive-into-OCR/blob/main/notebook_ch/1.introduction/OCR%E6%8A%80%E6%9C%AF%E5%AF%BC%E8%AE%BA.ipynb\">Dive-into-OCR&#x2F;notebook_ch&#x2F;1.introduction&#x2F;OCR技术导论.ipynb at main · PaddleOCR-Community&#x2F;Dive-into-OCR</a></p>\n<p><a href=\"https://blog.csdn.net/jiaoyangwm/article/details/138414709\">【多模态】29、OCRBench | 为大型多模态模型提供一个 OCR 任务测评基准-CSDN博客</a></p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink\">https://github.com/chongzicbo/ReadWriteThink</a></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"二维码\"></p>\n","excerpt":"","more":"<h1 id=\"1-引言\"><a href=\"#1-引言\" class=\"headerlink\" title=\"1. 引言\"></a>1. 引言</h1><h3 id=\"1-1-什么是OCR\"><a href=\"#1-1-什么是OCR\" class=\"headerlink\" title=\"1.1 什么是OCR\"></a>1.1 什么是OCR</h3><p>OCR俗称光学字符识别，英文全称是Optical Charater Recognition（简称OCR）,它是利用光学技术和计算机技术把印刷在或者写在图纸上的文字以文本形式提取出来，并转换成一种计算机能够接受、人又可以理解的格式。OCR技术是实现文字快速录入的一项关键技术。在信息社会时代，每天会产生大量的票据、表单、证件数据，这些数据要电子化，需要利用OCR技术进行提取录入。在深度学习没有全面推广之前，大部分OCR识别都是基于传统的方法进行检测识别。在背景单一、数据场景简单的情况下，传统OCR一般都能达到好的效果，但在一些场景复杂、干扰多的情况下，识别效果不好，这个时候深度学习OCR就能体现出巨大的优势。</p>\n<h3 id=\"1-2-传统OCR与深度学习OCR\"><a href=\"#1-2-传统OCR与深度学习OCR\" class=\"headerlink\" title=\"1.2 传统OCR与深度学习OCR\"></a>1.2 传统OCR与深度学习OCR</h3><p>传统OCR（Optical Character Recognition，光学字符识别）方法是指在深度学习兴起之前广泛使用的一种将图片中的文字转化为计算机可识别文字的技术手段。它主要通过图像处理和统计机器学习方法来达成这一目的。传统OCR技术能够对纸上打印的字符进行识别，支持多场景、任意版型（如英文、字母、数字等）的文字识别，最初只能将图片中的文字转为纯文本，随着技术发展后来也能识别表格以及将一些固定排版的图片（如证件、票据等）转为结构化的数据 。</p>\n<p>从技术实现角度看，传统OCR技术涵盖了多个处理阶段，例如文字区域定位、文字矫正、文字分割、文字识别以及后处理等环节。它利用opencv算法库等工具，运用连通区域分析、MSER（Maximally Stable Extremal Regions，最大稳定极值区域）等技术进行文字区域定位，通过旋转、仿射变换进行文字矫正，采用二值化、过滤噪声来分割文字，再利用逻辑回归、SVM（Support Vector Machine，支持向量机）、Adaboost等分类器识别文字，最后结合规则、语言模型（如HMM - Hidden Markov Model，隐马尔可夫模型）等进行后处理，从而提高识别的准确性和有效性</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209122335916.png\" alt=\"image-20241209122335916\"></p>\n<p>深度学习OCR方法可以分为两阶段算法和端到端的算法。两阶段OCR算法分为文本检测和识别算法，文本检测算法从图像中得到文本行的检测框，然后识别算法识别文本框中的内容。</p>\n<p>端对端OCR算法使用一个模型同时完成文字检测和文字识别，因此端对端模型更小，速度更快。</p>\n<p>相对于传统OCR方法，深度学习OCR方法准确率较高，速度可能慢一点。</p>\n<h4 id=\"传统OCR方法的优缺点\"><a href=\"#传统OCR方法的优缺点\" class=\"headerlink\" title=\"传统OCR方法的优缺点\"></a>传统OCR方法的优缺点</h4><h5 id=\"（一）优点\"><a href=\"#（一）优点\" class=\"headerlink\" title=\"（一）优点\"></a>（一）优点</h5><ol>\n<li>处理简单场景效果好<ul>\n<li>对于简单场景下的图片，传统OCR已经取得了很好的识别效果。例如在一些格式规范、文字清晰、背景简单的文档识别中，传统OCR能够准确地识别出文字内容。像标准格式的发票识别，发票上的文字排版相对固定，字体规范，传统OCR可以有效地提取出发票号码、金额、日期等关键信息。在这种简单场景下，传统OCR的识别准确率可以达到较高水平，满足基本的业务需求，如财务报销中的发票信息录入等 <a href=\"https://cloud.tencent.com/developer/information/ocr%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95\">8</a>。</li>\n</ul>\n</li>\n<li>运行速度较快<ul>\n<li>传统OCR技术通常比基于深度学习的OCR（aiOCR）更快，因为它不需要进行大量的训练和学习。在处理一些常规的、规则排列的文字时，传统OCR可以迅速地进行识别。例如在识别大量的、格式统一的表格数据时，传统OCR能够快速地对表格中的文字进行定位、分割和识别，不需要像深度学习模型那样进行复杂的神经网络前向传播和反向传播计算。这使得传统OCR在一些对速度要求较高、数据格式相对简单的应用场景中具有优势，如快递单的信息识别，在快递分拣过程中，需要快速地识别出寄件人和收件人的姓名、地址、电话号码等信息，传统OCR可以在较短的时间内完成识别任务 <a href=\"https://www.11pdf.com/Tag/2192136.html\">16</a>。</li>\n</ul>\n</li>\n<li>成本较低<ul>\n<li>传统OCR技术通常比较便宜，并且可以在低端硬件上运行。它不需要高端的图形处理单元（GPU）等昂贵的硬件设备来支持计算。对于一些预算有限的企业或个人用户来说，传统OCR技术是一种经济实惠的选择。例如，一些小型企业在进行文档数字化时，如果只是处理一些简单的文档类型，采用传统OCR技术可以在较低的成本下实现文字的识别和转换。而且，传统OCR技术在软件授权方面也相对较为便宜，不需要像一些基于深度学习的OCR软件那样支付高额的软件使用费用 <a href=\"https://www.11pdf.com/Tag/2192136.html\">16</a>。</li>\n</ul>\n</li>\n</ol>\n<h5 id=\"（二）缺点\"><a href=\"#（二）缺点\" class=\"headerlink\" title=\"（二）缺点\"></a>（二）缺点</h5><ol>\n<li>对复杂场景适应性差<ul>\n<li>传统OCR方法是针对特定场景的图像进行建模的，一旦跳出当前场景，模型就会失效。例如，在处理自然场景中的文字时，如街景中的招牌、车身广告上的文字等，这些文字可能存在字体多样、大小不一、排列不规则、背景复杂（包含各种图案、光影变化等）的情况，传统OCR技术往往难以准确识别。再如手写文字的识别，由于每个人的书写风格差异很大，传统OCR很难对各种手写字体进行准确识别，其识别准确率会大幅下降 <a href=\"https://cloud.tencent.com/developer/information/ocr%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB%E6%96%B9%E6%B3%95\">8</a>。</li>\n</ul>\n</li>\n<li>识别精度有限<ul>\n<li>对于复杂的文本，如包含多种字体、字号、颜色变化以及特殊排版（如艺术字、斜体字与正体字混合排版等）的文本，传统OCR技术可能会出现错误。在处理一些低质量的图像，如模糊、有污渍或者光照不均匀的图像时，传统OCR的识别准确性也会受到严重影响。例如，在识别一张被水浸湿过的纸质文档上的文字时，由于纸张的变形、文字的模糊等原因，传统OCR可能无法正确识别出所有的文字内容 <a href=\"https://www.11pdf.com/Tag/2192136.html\">16</a>。</li>\n</ul>\n</li>\n<li>需要专门培训人员<ul>\n<li>传统OCR技术需要专门培训人员进行使用和维护。其参数调整、算法优化等操作需要一定的专业知识和经验。例如，在使用传统OCR软件进行特定文档类型的识别时，可能需要根据文档的特点（如字体类型、排版格式等）对识别算法的参数进行调整，这就要求操作人员具备相关的技术知识，而这种专业人才相对较少，增加了企业或组织使用传统OCR技术的人力成本和难度 <a href=\"https://www.11pdf.com/Tag/2192136.html\">16</a>。</li>\n</ul>\n</li>\n<li>对格式保留困难<ul>\n<li>传统OCR技术在将纸质文档转换为电子文本时，可能无法完全保留原始文档的格式、排版和图表等信息。例如，在识别一份包含表格和图片的文档时，传统OCR可能只能识别出表格中的文字内容，而无法准确还原表格的结构和样式，对于图片更是无法直接转换为电子文档中的可编辑元素，这在一定程度上影响了文档转换的完整性和可用性。</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"2-传统OCR方法\"><a href=\"#2-传统OCR方法\" class=\"headerlink\" title=\"2. 传统OCR方法\"></a>2. 传统OCR方法</h1><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/1577105446728504.jpeg\" alt=\"传统OCR方法\"></p>\n<p>传统OCR方法主要分为文字区域定位、文字图像矫正、行列分割、分类器识别和后处理。按处理方式划分为三个阶段：预处理阶段、识别阶段和后处理阶段。</p>\n<h3 id=\"2-1-文字区域定位\"><a href=\"#2-1-文字区域定位\" class=\"headerlink\" title=\"2.1 文字区域定位\"></a>2.1 文字区域定位</h3><ul>\n<li>传统OCR方法在处理图像时，首先要进行文字区域定位。这一过程常采用连通区域分析和MSER算法。连通区域分析是基于图像中像素的连通性，将具有相似特征（如颜色、灰度值等）的像素划分为不同的区域。例如，在一张包含文字和背景的图像中，文字部分的像素与背景像素在灰度或颜色上可能存在差异，通过连通区域分析可以初步找出可能是文字的区域。</li>\n<li>MSER算法则是通过寻找图像中的极值区域，这些区域在一定的阈值变化范围内是最稳定的。对于文字来说，其字符形状相对稳定，在不同的灰度阈值下，字符所在区域往往表现出极大值或极小值的特性。通过这种方式，可以更精确地定位文字所在的区域</li>\n</ul>\n<h3 id=\"2-2-文字图像矫正\"><a href=\"#2-2-文字图像矫正\" class=\"headerlink\" title=\"2.2 文字图像矫正\"></a>2.2 文字图像矫正</h3><ul>\n<li>当图像中的文字存在倾斜或扭曲时，就需要进行文字矫正。这一阶段通常使用旋转和仿射变换。旋转是针对文字整体存在一定角度倾斜的情况，通过计算倾斜角度，将文字区域旋转到水平或垂直方向。例如，在扫描纸质文档时，如果文档放置稍有倾斜，扫描得到的图像中的文字也会倾斜，此时就可以根据文字的边界或者特定的算法来确定倾斜角度并进行旋转操作。</li>\n<li>仿射变换则更通用，它可以处理文字的拉伸、压缩以及更复杂的变形情况。它通过对图像中的坐标进行线性变换，将变形后的文字映射回正常的形状，从而为后续的文字分割和识别提供更有利的条件。</li>\n</ul>\n<h3 id=\"2-3-行列分割\"><a href=\"#2-3-行列分割\" class=\"headerlink\" title=\"2.3 行列分割\"></a>2.3 行列分割</h3><ul>\n<li>在文字分割阶段，传统OCR采用二值化和过滤噪声等操作。二值化是将图像的像素值转换为只有0和1的二值形式，这样可以突出文字与背景的对比。例如，将文字部分设为1（白色），背景设为0（黑色）或者反之。通过这种方式，可以简化图像的复杂度，使得文字的轮廓更加清晰。</li>\n<li>过滤噪声则是去除图像中的干扰因素，如扫描过程中产生的小斑点、划痕等。这些噪声可能会被误识别为文字的一部分，通过滤波算法（如中值滤波、高斯滤波等）可以去除这些不必要的干扰，提高文字分割的准确性。</li>\n</ul>\n<h3 id=\"2-4-分类器识别\"><a href=\"#2-4-分类器识别\" class=\"headerlink\" title=\"2.4 分类器识别\"></a>2.4 分类器识别</h3><p>分类器识别过程是在提取了字符图像之后，对其进行分析和分类，以确定每个字符对应的符号或文字。以下是这一过程的详细说明：</p>\n<h4 id=\"特征提取\"><a href=\"#特征提取\" class=\"headerlink\" title=\"特征提取\"></a>特征提取</h4><p>在进行分类之前，OCR系统首先需要从图像中提取出字符的特征。这可能包括：</p>\n<ul>\n<li><strong>几何特征</strong>：如字符的高度、宽度、笔画数量等。</li>\n<li><strong>统计特征</strong>：例如像素分布、边缘检测结果等。</li>\n<li><strong>拓扑结构</strong>：字符内部的连通性或断开情况。</li>\n<li><strong>频域特征</strong>：通过傅里叶变换或其他频域分析方法获得的特征。</li>\n</ul>\n<p>这些特征能够描述字符的独特属性，有助于后续的分类工作。</p>\n<h4 id=\"分类器训练\"><a href=\"#分类器训练\" class=\"headerlink\" title=\"分类器训练\"></a>分类器训练</h4><p>为了实现准确的分类，OCR系统通常会使用机器学习算法来构建分类器。训练阶段涉及以下几个方面：</p>\n<ul>\n<li><strong>数据准备</strong>：收集大量带有标签的字符图像作为训练样本。每个样本都包含一个字符图像及其对应的正确标签（即该字符的真实值）。</li>\n<li><strong>选择模型</strong>：根据任务需求选择合适的分类算法，如支持向量机（SVM）、K近邻（KNN）、神经网络等。</li>\n<li><strong>训练过程</strong>：利用训练集中的数据对选定的模型进行训练，调整模型参数，使得模型能够学习到如何基于输入的特征预测正确的字符标签。</li>\n</ul>\n<h4 id=\"分类与决策\"><a href=\"#分类与决策\" class=\"headerlink\" title=\"分类与决策\"></a>分类与决策</h4><p>一旦分类器被训练好，就可以用于实际的字符识别：</p>\n<ul>\n<li><strong>输入处理</strong>：当一个新的字符图像输入时，系统首先会提取其特征。</li>\n<li><strong>分类预测</strong>：然后使用训练好的分类器对这些特征进行评估，输出最有可能的字符标签。</li>\n<li><strong>后处理</strong>：有时还会有一个后处理步骤，比如语言模型的应用，来修正识别结果中的拼写错误或者不符合语法的地方，提高整体准确性。</li>\n</ul>\n<p>分类器识别是传统OCR方法的核心部分，它决定了系统能否准确地将图像中的字符转换成文本。通过精心设计的特征提取、有效的分类算法和充足的训练数据，可以显著提高OCR系统的准确性和鲁棒性。</p>\n<h3 id=\"2-5-后处理\"><a href=\"#2-5-后处理\" class=\"headerlink\" title=\"2.5 后处理\"></a>2.5 后处理</h3><ul>\n<li>传统OCR的后处理阶段会利用规则和语言模型来提高识别的准确性。规则可以是基于语法、格式等方面的规定。例如，在识别身份证号码时，根据身份证号码的固定格式（18位数字，特定的编码规则等），对识别结果进行校验和修正。</li>\n<li>语言模型如HMM也会被应用。HMM是一种统计模型，它基于马尔可夫链假设，对文字的序列进行建模。在文字识别中，它可以根据语言的概率分布来纠正识别结果中的错误。例如，在识别一段英文句子时，如果某个单词被识别为不符合语法规则的形式，HMM可以根据语言的统计规律，推荐最可能的正确单词。</li>\n</ul>\n<h1 id=\"3-深度学习OCR方法\"><a href=\"#3-深度学习OCR方法\" class=\"headerlink\" title=\"3. 深度学习OCR方法\"></a>3. 深度学习OCR方法</h1><h3 id=\"3-1-两阶段OCR\"><a href=\"#3-1-两阶段OCR\" class=\"headerlink\" title=\"3.1 两阶段OCR\"></a>3.1 两阶段OCR</h3><h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/68747470733a2f2f61692d73747564696f2d7374617469632d6f6e6c696e652e63646e2e626365626f732e636f6d2f34663465613635353738333834393030393039656666663933643062373338366538366563653134346438633436373762376263393462346630333337636662\" alt=\"img\"></h4><table>\n<thead>\n<tr>\n<th>文本检测算法模型</th>\n<th>文字识别算法模型</th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>CTPN</td>\n<td>CRNN</td>\n<td></td>\n</tr>\n<tr>\n<td>SegLink</td>\n<td>RARE</td>\n<td></td>\n</tr>\n<tr>\n<td>EAST</td>\n<td>RAN</td>\n<td></td>\n</tr>\n<tr>\n<td>PSENet</td>\n<td>ASTER</td>\n<td></td>\n</tr>\n<tr>\n<td>DBNet</td>\n<td>MORAN</td>\n<td></td>\n</tr>\n<tr>\n<td>FCENet</td>\n<td>SRN</td>\n<td></td>\n</tr>\n<tr>\n<td>Texboxes</td>\n<td>STAR-Net</td>\n<td></td>\n</tr>\n<tr>\n<td>CRAFT</td>\n<td>Rosetta</td>\n<td></td>\n</tr>\n<tr>\n<td>LOMO</td>\n<td>SAR</td>\n<td></td>\n</tr>\n<tr>\n<td>SPCNet</td>\n<td>R2AM</td>\n<td></td>\n</tr>\n<tr>\n<td>PAN</td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>DB</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<h3 id=\"3-2-端到端OCR\"><a href=\"#3-2-端到端OCR\" class=\"headerlink\" title=\"3.2 端到端OCR\"></a>3.2 端到端OCR</h3><p>与两阶段OCR不同，端到端OCR不需要先进行文字检测然后再进行文字识别这样明确的分阶段操作。它直接在整个图像上进行操作，将图像中的文字信息直接转换为文本。这样做的好处是避免了由于分阶段处理带来的误差累积问题。例如，在两阶段OCR中，如果文字检测阶段出现错误，那么在识别阶段就会基于错误的检测结果进行操作，而端到端OCR则不存在这种情况，因为它是从图像到文本的直接映射。并且，将检测和识别统一到一个模型里面，就使得图像的feature可以被共享利用。</p>\n<table>\n<thead>\n<tr>\n<th>OCR算法模型</th>\n<th>Title</th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n<td><a href=\"https://arxiv.org/pdf/1707.03985.pdf\">Towards End-to-end Text Spotting with Convolution Recurrent Neural Network</a></td>\n</tr>\n<tr>\n<td>FOTS</td>\n<td><a href=\"https://arxiv.org/pdf/1801.01671.pdf\">FOTS: Fast Oriented Text Spotting with a Unified Network</a></td>\n</tr>\n<tr>\n<td>Mask TextSpotter</td>\n<td><a href=\"https://arxiv.org/pdf/1807.02242.pdf\">Mask TextSpotter: An End-to-End Trainable Neural Network for Spotting Text with Arbitrary Shapes</a></td>\n</tr>\n<tr>\n<td>CharNet</td>\n<td><a href=\"https://arxiv.org/abs/1910.07954\">Convolutional Character Networks</a></td>\n</tr>\n<tr>\n<td>Mask TextSpotterV3</td>\n<td><a href=\"https://arxiv.org/abs/2007.09482\">Mask TextSpotter v3: Segmentation Proposal Network for Robust Scene Text Spotting</a></td>\n</tr>\n<tr>\n<td>PGNet</td>\n<td>[<a href=\"https://arxiv.org/abs/2104.05458\">2104.05458] PGNet: Real-time Arbitrarily-Shaped Text Spotting with Point Gathering Network</a></td>\n</tr>\n<tr>\n<td>ABCNet</td>\n<td></td>\n</tr>\n<tr>\n<td>TrOCR</td>\n<td>TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models</td>\n</tr>\n<tr>\n<td>SVTRv2</td>\n<td>SVTRv2: CTC Beats Encoder-Decoder Models in Scene Text Recognition</td>\n</tr>\n<tr>\n<td>GOT-OCR</td>\n<td><a href=\"https://github.com/Ucas-HaoranWei/GOT-OCR2.0\">Ucas-HaoranWei&#x2F;GOT-OCR2.0: Official code implementation of General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model</a></td>\n</tr>\n</tbody></table>\n<h3 id=\"3-3-多模态OCR\"><a href=\"#3-3-多模态OCR\" class=\"headerlink\" title=\"3.3 多模态OCR\"></a>3.3 多模态OCR</h3><table>\n<thead>\n<tr>\n<th>算法模型</th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Vary</td>\n<td>[<a href=\"https://arxiv.org/abs/2312.06109\">2312.06109] Vary: Scaling up the Vision Vocabulary for Large Vision-Language Models</a></td>\n</tr>\n<tr>\n<td>TextHarmony</td>\n<td>[<a href=\"https://arxiv.org/abs/2407.16364\">2407.16364] Harmonizing Visual Text Comprehension and Generation</a></td>\n</tr>\n<tr>\n<td><a href=\"https://www.aisharenet.com/got-ocr20jiyu/\">GOT-OCR2.0</a></td>\n<td><a href=\"https://github.com/Ucas-HaoranWei/GOT-OCR2.0\">Ucas-HaoranWei&#x2F;GOT-OCR2.0: Official code implementation of General OCR Theory: Towards OCR-2.0 via a Unified End-to-end Model</a></td>\n</tr>\n<tr>\n<td>其它大部分多模态大模型都支持OCR任务</td>\n<td><a href=\"https://github.com/Yuliang-Liu/MultimodalOCR\">Yuliang-Liu&#x2F;MultimodalOCR: On the Hidden Mystery of OCR in Large Multimodal Models (OCRBench)</a></td>\n</tr>\n</tbody></table>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/4b4650c9d035fbd912d56823b451c035.png\" alt=\"多模态OCR方法\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209145707320.png\" alt=\"多模型OCR结果\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209145800157.png\" alt=\"多模态OCR结果\"></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241209145845645.png\" alt=\"多模态OCR结果\"></p>\n<h1 id=\"4-OCR应用方向\"><a href=\"#4-OCR应用方向\" class=\"headerlink\" title=\"4. OCR应用方向\"></a>4. OCR应用方向</h1><h3 id=\"4-1-文字识别\"><a href=\"#4-1-文字识别\" class=\"headerlink\" title=\"4.1 文字识别\"></a>4.1 文字识别</h3><ul>\n<li><p>普通文字识别</p>\n</li>\n<li><p>场景文字识别</p>\n</li>\n<li><p>数学公式识别</p>\n<p>从图片中提取数学公式，转换为markdown或者Latex</p>\n</li>\n</ul>\n<h3 id=\"4-2-文档结构化识别（版面分析）\"><a href=\"#4-2-文档结构化识别（版面分析）\" class=\"headerlink\" title=\"4.2 文档结构化识别（版面分析）\"></a>4.2 文档结构化识别（版面分析）</h3><ul>\n<li><p>页眉</p>\n</li>\n<li><p>页脚</p>\n</li>\n<li><p>数学公式</p>\n</li>\n<li><p>图表的Caption</p>\n</li>\n<li><p>图片</p>\n</li>\n<li><p>表格</p>\n</li>\n<li><p>段落文本</p>\n</li>\n<li><p>段落标题</p>\n</li>\n<li><p>列表</p>\n</li>\n</ul>\n<h3 id=\"4-3-关键信息抽取\"><a href=\"#4-3-关键信息抽取\" class=\"headerlink\" title=\"4.3 关键信息抽取\"></a>4.3 关键信息抽取</h3><p>关键信息提取（Key Information Extraction，KIE）是Document VQA中的一个重要任务，主要从图像中提取所需要的关键信息，如从身份证中提取出姓名和公民身份号码信息，这类信息的种类往往在特定任务下是固定的，但是在不同任务间是不同的。</p>\n<p>KIE通常分为两个子任务进行研究：</p>\n<ul>\n<li>SER: 语义实体识别 (Semantic Entity Recognition)，对每一个检测到的文本进行分类，如将其分为姓名，身份证。如下图中的黑色框和红色框。</li>\n<li>RE: 关系抽取 (Relation Extraction)，对每一个检测到的文本进行分类，如将其分为问题和的答案。然后对每一个问题找到对应的答案。如下图中的红色框和黑色框分别代表问题和答案，黄色线代表问题和答案之间的对应关系。</li>\n</ul>\n<p>一般的KIE方法基于命名实体识别(Named Entity Recognition,NER)[4]来研究，但是这类方法只利用了图像中的文本信息，缺少对视觉和结构信息的使用，因此精度不高。在此基础上，近几年的方法都开始将视觉和结构信息与文本信息融合到一起，按照对多模态信息进行融合时所采用的原理可以将这些方法分为下面四种：</p>\n<ul>\n<li>基于Grid的方法</li>\n<li>基于Token的方法</li>\n<li>基于GCN的方法</li>\n<li>基于End to End 的方法</li>\n</ul>\n<h1 id=\"5-OCR相关工具\"><a href=\"#5-OCR相关工具\" class=\"headerlink\" title=\"5. OCR相关工具\"></a>5. OCR相关工具</h1><ul>\n<li><p>PaddleOCR:通用OCR工具</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/68747470733a2f2f61692d73747564696f2d7374617469632d6f6e6c696e652e63646e2e626365626f732e636f6d2f65303939323962346133316534346639623565336435343264313234313133333236363964326531613231643435616438386231646439313134326563383663\" alt=\"PaddleOCR\"></p>\n</li>\n<li><p>Tesseract: 普通文字识别</p>\n</li>\n<li><p>Umi-OCR: 普通文字识别、文档解析</p>\n</li>\n<li><p>MinerU:将PDF转换成Markdown和JSON格式</p>\n</li>\n<li><p>LaTeX-OCR: 数学公式识别</p>\n</li>\n</ul>\n<p><a href=\"https://developer.aliyun.com/article/1054626\">OCR文字识别方法综述-阿里云开发者社区</a></p>\n<p><a href=\"https://bbs.huaweicloud.com/blogs/140398#H10\">传统OCR识别综述-云社区-华为云</a></p>\n<p><a href=\"https://github.com/PaddleOCR-Community/Dive-into-OCR/blob/main/notebook_ch/1.introduction/OCR%E6%8A%80%E6%9C%AF%E5%AF%BC%E8%AE%BA.ipynb\">Dive-into-OCR&#x2F;notebook_ch&#x2F;1.introduction&#x2F;OCR技术导论.ipynb at main · PaddleOCR-Community&#x2F;Dive-into-OCR</a></p>\n<p><a href=\"https://blog.csdn.net/jiaoyangwm/article/details/138414709\">【多模态】29、OCRBench | 为大型多模态模型提供一个 OCR 任务测评基准-CSDN博客</a></p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink\">https://github.com/chongzicbo/ReadWriteThink</a></p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"二维码\"></p>\n"},{"title":"llama3源码解析-02：tokenizer模块解析","_content":"\n![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/Llama3_Repo.jpeg)\n\n## Tokenizer类\n\n以下是 `tokenizer.py` 中 `Tokenizer` 类的逐行详细解释：\n\n```python\nclass Tokenizer:\n    \"\"\"\n    Tokenizing and encoding/decoding text using the Tiktoken tokenizer.\n    \"\"\"\n    # 特殊 token 的字典，用于存储特殊 token 及其对应的 token ID\n    special_tokens: Dict[str, int]\n\n    # 保留的特殊 token 数量，默认为 256\n    num_reserved_special_tokens = 256\n\n    # 正则表达式模式，用于匹配文本中的子词和特殊字符\n    pat_str = r\"(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\\r\\n\\p{L}\\p{N}]?\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]+[\\r\\n]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+\"  # noqa: E501\n\n    def __init__(self, model_path: str):\n        \"\"\"\n        Initializes the Tokenizer with a Tiktoken model.\n\n        Args:\n            model_path (str): The path to the Tiktoken model file.\n        \"\"\"\n        # 检查模型文件是否存在\n        assert os.path.isfile(model_path), model_path\n\n        # 加载 Tiktoken 模型的 BPE（Byte Pair Encoding）合并表\n        mergeable_ranks = load_tiktoken_bpe(model_path)\n        # 获取基础 token 的数量\n        num_base_tokens = len(mergeable_ranks)\n        # 定义特殊 token 列表\n        special_tokens = [\n            \"<|begin_of_text|>\",\n            \"<|end_of_text|>\",\n            \"<|reserved_special_token_0|>\",\n            \"<|reserved_special_token_1|>\",\n            \"<|reserved_special_token_2|>\",\n            \"<|reserved_special_token_3|>\",\n            \"<|start_header_id|>\",\n            \"<|end_header_id|>\",\n            \"<|reserved_special_token_4|>\",\n            \"<|eot_id|>\",  # end of turn\n        ] + [\n            # 生成剩余的保留特殊 token\n            f\"<|reserved_special_token_{i}|>\"\n            for i in range(5, self.num_reserved_special_tokens - 5)\n        ]\n        # 将特殊 token 映射到 token ID，ID 从基础 token 数量开始递增\n        self.special_tokens = {\n            token: num_base_tokens + i for i, token in enumerate(special_tokens)\n        }\n        # 初始化 Tiktoken 的 Encoding 对象\n        self.model = tiktoken.Encoding(\n            name=Path(model_path).name,\n            pat_str=self.pat_str,\n            mergeable_ranks=mergeable_ranks,\n            special_tokens=self.special_tokens,\n        )\n        # 记录日志，表示模型已加载\n        logger.info(f\"Reloaded tiktoken model from {model_path}\")\n\n        # 获取词汇表大小\n        self.n_words: int = self.model.n_vocab\n        # 获取 BOS（Begin of Sequence）token 的 ID\n        self.bos_id: int = self.special_tokens[\"<|begin_of_text|>\"]\n        # 获取 EOS（End of Sequence）token 的 ID\n        self.eos_id: int = self.special_tokens[\"<|end_of_text|>\"]\n        # 设置 pad token 的 ID，默认为 -1\n        self.pad_id: int = -1\n        # 定义停止 token 集合，包含 EOS 和 EOT（End of Turn）token\n        self.stop_tokens = {\n            self.special_tokens[\"<|end_of_text|>\"],\n            self.special_tokens[\"<|eot_id|>\"],\n        }\n        # 记录词汇表大小、BOS ID 和 EOS ID\n        logger.info(\n            f\"#words: {self.n_words} - BOS ID: {self.bos_id} - EOS ID: {self.eos_id}\"\n        )\n\n    def encode(\n        self,\n        s: str,\n        *,\n        bos: bool,\n        eos: bool,\n        allowed_special: Union[Literal[\"all\"], AbstractSet[str]] = set(),\n        disallowed_special: Union[Literal[\"all\"], Collection[str]] = (),\n    ) -> List[int]:\n        \"\"\"\n        Encodes a string into a list of token IDs.\n\n        Args:\n            s (str): The input string to be encoded.\n            bos (bool): Whether to prepend the beginning-of-sequence token.\n            eos (bool): Whether to append the end-of-sequence token.\n            allowed_tokens (\"all\"|set[str]): allowed special tokens in string\n            disallowed_tokens (\"all\"|set[str]): special tokens that raise an error when in string\n\n        Returns:\n            list[int]: A list of token IDs.\n        \"\"\"\n        # 确保输入是字符串\n        assert type(s) is str\n\n        # Tiktoken 分词器单次编码的最大字符数\n        TIKTOKEN_MAX_ENCODE_CHARS = 400_000\n\n        # 最大连续非空格或空格字符数\n        MAX_NO_WHITESPACES_CHARS = 25_000\n\n        # 将输入字符串分割为子串，确保每个子串不超过最大字符数\n        substrs = (\n            substr\n            for i in range(0, len(s), TIKTOKEN_MAX_ENCODE_CHARS)\n            for substr in self._split_whitespaces_or_nonwhitespaces(\n                s[i : i + TIKTOKEN_MAX_ENCODE_CHARS], MAX_NO_WHITESPACES_CHARS\n            )\n        )\n        # 初始化 token ID 列表\n        t: List[int] = []\n        # 对每个子串进行编码\n        for substr in substrs:\n            t.extend(\n                self.model.encode(\n                    substr,\n                    allowed_special=allowed_special,\n                    disallowed_special=disallowed_special,\n                )\n            )\n        # 如果需要，在开头添加 BOS token\n        if bos:\n            t.insert(0, self.bos_id)\n        # 如果需要，在结尾添加 EOS token\n        if eos:\n            t.append(self.eos_id)\n        # 返回编码后的 token ID 列表\n        return t\n\n    def decode(self, t: Sequence[int]) -> str:\n        \"\"\"\n        Decodes a list of token IDs into a string.\n\n        Args:\n            t (List[int]): The list of token IDs to be decoded.\n\n        Returns:\n            str: The decoded string.\n        \"\"\"\n        # 将 token ID 序列解码为字符串\n        return self.model.decode(cast(List[int], t))\n\n    @staticmethod\n    def _split_whitespaces_or_nonwhitespaces(\n        s: str, max_consecutive_slice_len: int\n    ) -> Iterator[str]:\n        \"\"\"\n        Splits the string `s` so that each substring contains no more than `max_consecutive_slice_len`\n        consecutive whitespaces or consecutive non-whitespaces.\n        \"\"\"\n        # 初始化当前子串的长度和类型\n        current_slice_len = 0\n        current_slice_is_space = s[0].isspace() if len(s) > 0 else False\n        slice_start = 0\n\n        # 遍历字符串，按空格或非空格进行分割\n        for i in range(len(s)):\n            is_now_space = s[i].isspace()\n\n            if current_slice_is_space ^ is_now_space:\n                current_slice_len = 1\n                current_slice_is_space = is_now_space\n            else:\n                current_slice_len += 1\n                if current_slice_len > max_consecutive_slice_len:\n                    yield s[slice_start:i]\n                    slice_start = i\n                    current_slice_len = 1\n        yield s[slice_start:]\n```\n\n### 逐行解释总结\n1. **特殊 token 处理**:\n   - `special_tokens` 字典存储特殊 token 及其对应的 token ID。\n   - `num_reserved_special_tokens` 定义了保留的特殊 token 数量。\n   - `pat_str` 是正则表达式模式，用于匹配文本中的子词和特殊字符。\n\n2. **初始化方法 (`__init__`)**:\n   - 加载 Tiktoken 模型的 BPE 合并表，并初始化特殊 token。\n   - 设置 BOS、EOS 和 pad token 的 ID，并定义停止 token 集合。\n   - 初始化 Tiktoken 的 `Encoding` 对象，用于实际的编码和解码操作。\n\n3. **编码方法 (`encode`)**:\n   - 将输入字符串分割为子串，确保每个子串不超过最大字符数。\n   - 对每个子串进行编码，并根据参数决定是否添加 BOS 和 EOS token。\n   - 返回编码后的 token ID 列表。\n\n4. **解码方法 (`decode`)**:\n   - 将 token ID 序列解码为字符串。\n\n5. **子串分割方法 (`_split_whitespaces_or_nonwhitespaces`)**:\n   - 将字符串按空格或非空格进行分割，确保每个子串不超过最大连续字符数。\n   \n   - ### **什么保留空格？**\n   \n     1. **语义完整性**:\n        - 空格在文本中用于分隔单词、标点符号等，是文本结构的重要组成部分。\n        - 如果丢弃空格，分词结果可能会将多个单词合并，导致语义错误。例如：\n          - 输入: `\"Hello, how are you?\"`\n          - 丢弃空格: `\"Hello,howareyou?\"`（分词结果错误）\n          - 保留空格: `\"Hello, how are you?\"`（分词结果正确）\n     2. **特殊 token 处理**:\n        - 某些特殊 token（如 `<|end_of_text|>`）可能被空格包围，保留空格可以确保这些特殊 token 被正确识别和处理。\n     3. **模型输入格式**:\n        - 许多语言模型（如 GPT）的输入需要保留空格，以确保生成的文本格式正确。\n\n### 对输入字符串进行tokenize的详细流程\n\n结合一个具体的字符串示例，详细说明 `Tokenizer` 如何处理输入字符串。假设我们已经有一个 Tiktoken 模型文件，并且输入字符串为：\n\n```\n\"Hello, how are you? <|end_of_text|>\"\n```\n\n我们将逐步分析 `Tokenizer` 如何处理这个字符串。\n\n---\n\n#### **1. 输入字符串**\n```python\ns = \"Hello, how are you? <|end_of_text|>\"\n```\n\n---\n\n#### **2. 参数设置**\n假设调用 `encode` 方法时，参数如下：\n```python\nbos = True  # 添加 BOS token\neos = False  # 不添加 EOS token\nallowed_special = {\"<|end_of_text|>\"}  # 允许的特殊 token\ndisallowed_special = ()  # 不允许的特殊 token（为空）\n```\n\n---\n\n#### **3. 输入验证**\n- **类型检查**:\n  ```python\n  assert type(s) is str\n  ```\n  输入是一个字符串，检查通过。\n\n---\n\n#### **4. 字符串分割**\n由于输入字符串较短（远小于 `TIKTOKEN_MAX_ENCODE_CHARS = 400_000`），不需要按字符数分割。但为了演示，我们假设字符串较长，需要按空格和非空格进行分割。\n\n##### **分割逻辑**\n- 输入字符串: `\"Hello, how are you? <|end_of_text|>\"`\n- 按空格和非空格分割：\n  - `\"Hello,\"`（非空格）\n  - `\" how \"`（空格）\n  - `\"are\"`（非空格）\n  - `\" you? \"`（空格）\n  - `\"<|end_of_text|>\"`（非空格）\n\n##### **分割结果**\n```python\nsubstrs = [\"Hello,\", \" how \", \"are\", \" you? \", \"<|end_of_text|>\"]\n```\n\n---\n\n#### **5. 子串编码**\n对每个子串进行编码，生成 token ID 序列。\n\n##### **假设的 Tiktoken 模型**\n假设 Tiktoken 模型的词汇表和编码规则如下：\n- `\"Hello\"` → `[15496]`\n- `\",\"` → `[11]`\n- `\" how\"` → `[703]`\n- `\"are\"` → `[527]`\n- `\" you\"` → `[366]`\n- `\"?\"` → `[30]`\n- `\"<|end_of_text|>\"` → `[50256]`（特殊 token）\n\n##### **编码过程**\n1. **子串 `\"Hello,\"`**:\n   - 编码为 `[15496, 11]`。\n2. **子串 `\" how \"`**:\n   - 编码为 `[703]`。\n3. **子串 `\"are\"`**:\n   - 编码为 `[527]`。\n4. **子串 `\" you? \"`**:\n   - 编码为 `[366, 30]`。\n5. **子串 `\"<|end_of_text|>\"`**:\n   - 这是一个特殊 token，编码为 `[50256]`。\n\n##### **编码结果**\n```python\nt = [15496, 11, 703, 527, 366, 30, 50256]\n```\n\n---\n\n#### **6. 添加特殊 token**\n根据参数设置，需要在开头添加 BOS token，不添加 EOS token。\n\n##### **BOS token**\n假设 BOS token 的 ID 为 `50257`：\n```python\nif bos:\n    t.insert(0, 50257)\n```\n\n##### **更新后的 token 序列**\n```python\nt = [50257, 15496, 11, 703, 527, 366, 30, 50256]\n```\n\n---\n\n#### **7. 返回编码结果**\n最终的 token ID 序列为：\n```python\n[50257, 15496, 11, 703, 527, 366, 30, 50256]\n```\n\n---\n\n#### **8. 解码过程**\n如果需要将 token ID 序列解码回字符串，可以使用 `decode` 方法。\n\n##### **解码逻辑**\n- 将每个 token ID 映射回对应的子词或字符。\n- 特殊 token（如 `<|end_of_text|>`）会被解码为原始字符串。\n\n##### **解码结果**\n```python\ndecoded_str = \"<|begin_of_text|>Hello, how are you? <|end_of_text|>\"\n```\n\n---\n\n#### **9. 总结**\n结合具体示例，`Tokenizer` 处理输入字符串的详细流程如下：\n1. **输入字符串**: `\"Hello, how are you? <|end_of_text|>\"`\n2. **分割字符串**: 按空格和非空格分割为 `[\"Hello,\", \" how \", \"are\", \" you? \", \"<|end_of_text|>\"]`。\n3. **编码子串**: 将每个子串编码为 token ID 序列 `[15496, 11, 703, 527, 366, 30, 50256]`。\n4. **添加 BOS token**: 在开头插入 BOS token，得到 `[50257, 15496, 11, 703, 527, 366, 30, 50256]`。\n5. **返回结果**: 返回最终的 token ID 序列。\n6. **解码**: 将 token ID 序列解码回原始字符串 `\"<|begin_of_text|>Hello, how are you? <|end_of_text|>\"`。\n\n通过这种分步骤的处理方式，`Tokenizer` 能够高效地将输入字符串转换为模型可处理的 token ID 序列，并支持特殊 token 的灵活处理。\n\n### 总结\n\n`Tokenizer` 类负责文本的编码和解码，使用 Tiktoken 作为底层分词器。它支持特殊 token 的处理，并提供了灵活的编码和解码接口。通过 `encode` 方法，可以将文本转换为 token ID 序列；通过 `decode` 方法，可以将 token ID 序列转换回文本。此外，`Tokenizer` 还提供了对长文本的分割功能，确保编码过程不会因输入过长而失败。\n\n\n\n## ChatFormat类\n\n`ChatFormat` 类的主要功能是将对话消息（`Message`）编码为模型可以理解的 token 序列，特别适用于对话生成任务。\n\n---\n\n### **代码注释**\n\n```python\nclass ChatFormat:\n    def __init__(self, tokenizer: Tokenizer):\n        \"\"\"\n        初始化 ChatFormat 类。\n\n        Args:\n            tokenizer (Tokenizer): 用于编码和解码的 Tokenizer 实例。\n        \"\"\"\n        self.tokenizer = tokenizer\n```\n\n- **功能**: 初始化 `ChatFormat` 类，绑定一个 `Tokenizer` 实例，用于后续的编码操作。\n- **参数**:\n  - `tokenizer`: 一个 `Tokenizer` 对象，用于将文本转换为 token ID 序列。\n\n---\n\n```python\n    def encode_header(self, message: Message) -> List[int]:\n        \"\"\"\n        编码消息头，包括角色信息和分隔符。\n\n        Args:\n            message (Message): 包含角色和内容的消息字典。\n\n        Returns:\n            List[int]: 编码后的 token ID 序列。\n        \"\"\"\n        tokens = []\n        # 添加消息头开始标记\n        tokens.append(self.tokenizer.special_tokens[\"<|start_header_id|>\"])\n        # 编码角色信息（如 \"user\" 或 \"assistant\"）\n        tokens.extend(self.tokenizer.encode(message[\"role\"], bos=False, eos=False))\n        # 添加消息头结束标记\n        tokens.append(self.tokenizer.special_tokens[\"<|end_header_id|>\"])\n        # 添加换行符（两个换行符，用于分隔消息头和内容）\n        tokens.extend(self.tokenizer.encode(\"\\n\\n\", bos=False, eos=False))\n        return tokens\n```\n\n- **功能**: 编码消息头，包括角色信息和分隔符。\n- **参数**:\n  - `message`: 一个 `Message` 字典，包含 `role`（角色）和 `content`（内容）。\n- **返回值**: 编码后的 token ID 序列。\n- **详细步骤**:\n  1. 添加消息头开始标记 `<|start_header_id|>`。\n  2. 编码角色信息（如 `\"user\"` 或 `\"assistant\"`）。\n  3. 添加消息头结束标记 `<|end_header_id|>`。\n  4. 添加两个换行符 `\\n\\n`，用于分隔消息头和内容。\n\n---\n\n```python\n    def encode_message(self, message: Message) -> List[int]:\n        \"\"\"\n        编码整个消息，包括消息头和内容。\n\n        Args:\n            message (Message): 包含角色和内容的消息字典。\n\n        Returns:\n            List[int]: 编码后的 token ID 序列。\n        \"\"\"\n        # 编码消息头\n        tokens = self.encode_header(message)\n        # 编码消息内容，并去除首尾空白字符\n        tokens.extend(\n            self.tokenizer.encode(message[\"content\"].strip(), bos=False, eos=False)\n        )\n        # 添加消息结束标记 <|eot_id|>\n        tokens.append(self.tokenizer.special_tokens[\"<|eot_id|>\"])\n        return tokens\n```\n\n- **功能**: 编码整个消息，包括消息头和内容。\n- **参数**:\n  - `message`: 一个 `Message` 字典，包含 `role`（角色）和 `content`（内容）。\n- **返回值**: 编码后的 token ID 序列。\n- **详细步骤**:\n  1. 调用 `encode_header` 方法，编码消息头。\n  2. 编码消息内容，并去除首尾空白字符。\n  3. 添加消息结束标记 `<|eot_id|>`，表示当前消息的结束。\n\n---\n\n```python\n    def encode_dialog_prompt(self, dialog: Dialog) -> List[int]:\n        \"\"\"\n        编码整个对话，生成模型输入的 token 序列。\n\n        Args:\n            dialog (Dialog): 对话列表，包含多条消息。\n\n        Returns:\n            List[int]: 编码后的 token ID 序列。\n        \"\"\"\n        tokens = []\n        # 添加对话开始标记 <|begin_of_text|>\n        tokens.append(self.tokenizer.special_tokens[\"<|begin_of_text|>\"])\n        # 编码每条消息\n        for message in dialog:\n            tokens.extend(self.encode_message(message))\n        # 添加助手消息的开始标记，供模型生成回复\n        tokens.extend(self.encode_header({\"role\": \"assistant\", \"content\": \"\"}))\n        return tokens\n```\n\n- **功能**: 编码整个对话，生成模型输入的 token 序列。\n- **参数**:\n  - `dialog`: 一个 `Dialog` 列表，包含多条消息。\n- **返回值**: 编码后的 token ID 序列。\n- **详细步骤**:\n  1. 添加对话开始标记 `<|begin_of_text|>`。\n  2. 遍历对话中的每条消息，调用 `encode_message` 方法进行编码。\n  3. 添加助手消息的开始标记（包括角色信息和分隔符），供模型生成回复。\n\n---\n\n### **总结**\n\n#### **功能**\n`ChatFormat` 类的主要功能是将对话消息（`Message`）编码为模型可以理解的 token 序列。它特别适用于对话生成任务，能够处理多轮对话，并生成符合模型输入格式的 token 序列。\n\n#### **核心方法**\n1. **`encode_header`**:\n   - 编码消息头，包括角色信息和分隔符。\n   - 用于标识每条消息的角色（如 `\"user\"` 或 `\"assistant\"`）。\n\n2. **`encode_message`**:\n   - 编码整个消息，包括消息头和内容。\n   - 在消息末尾添加结束标记 `<|eot_id|>`，表示当前消息的结束。\n\n3. **`encode_dialog_prompt`**:\n   - 编码整个对话，生成模型输入的 token 序列。\n   - 在对话末尾添加助手消息的开始标记，供模型生成回复。\n\n#### **特殊 token**\n- `<|begin_of_text|>`: 对话开始标记。\n- `<|start_header_id|>`: 消息头开始标记。\n- `<|end_header_id|>`: 消息头结束标记。\n- `<|eot_id|>`: 消息结束标记。\n\n#### **适用场景**\n- **对话生成**: 将多轮对话编码为模型输入，生成助手的回复。\n- **消息格式化**: 确保每条消息的格式符合模型的要求，包括角色信息和内容分隔符。\n\n#### **示例**\n假设有以下对话：\n```python\ndialog = [\n    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n    {\"role\": \"assistant\", \"content\": \"I'm fine, thank you!\"},\n]\n```\n调用 `encode_dialog_prompt(dialog)` 后，生成的 token 序列可能如下：\n```python\n[\n    <|begin_of_text|>,\n    <|start_header_id|>, \"user\", <|end_header_id|>, \"\\n\\n\", \"Hello, how are you?\", <|eot_id|>,\n    <|start_header_id|>, \"assistant\", <|end_header_id|>, \"\\n\\n\", \"I'm fine, thank you!\", <|eot_id|>,\n    <|start_header_id|>, \"assistant\", <|end_header_id|>, \"\\n\\n\"\n]\n```\n\n#### **总结**\n`ChatFormat` 类通过定义清晰的对话格式和特殊 token，确保对话消息能够被模型正确理解和处理。它是对话生成任务中不可或缺的一部分，能够有效提升模型生成回复的准确性和连贯性。\n\n## **Message** 实例解析\n\n结合实际的 `Message` 输入，详细说明 `Tokenizer` 和 `ChatFormat` 两个类如何协同工作，从 `Message` 输入到输出的完整流程。我们将重点关注 `encode_message`、`decode_message` 和 `encode_dialog_prompt` 方法，并明确区分 `encode_message` 和 `encode_dialog_prompt` 的输入和输出。\n\n---\n\n### **1. 输入数据**\n假设我们有以下 `Message` 和 `Dialog` 输入：\n\n#### **单个消息（Message）**\n```python\nmessage = {\n    \"role\": \"user\",\n    \"content\": \"Hello, how are you?\"\n}\n```\n\n#### **多轮对话（Dialog）**\n```python\ndialog = [\n    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n    {\"role\": \"assistant\", \"content\": \"I'm fine, thank you!\"},\n]\n```\n\n---\n\n### **2. Tokenizer 和 ChatFormat 初始化**\n首先，我们需要初始化 `Tokenizer` 和 `ChatFormat` 类。\n\n```python\n# 假设模型文件路径为 \"tiktoken_model.model\"\ntokenizer = Tokenizer(model_path=\"tiktoken_model.model\")\nchat_format = ChatFormat(tokenizer)\n```\n\n---\n\n### **3. encode_message 的流程**\n`encode_message` 方法用于编码单个消息，包括消息头和内容。\n\n#### **输入**\n```python\nmessage = {\n    \"role\": \"user\",\n    \"content\": \"Hello, how are you?\"\n}\n```\n\n#### **步骤**\n1. **编码消息头**:\n   - 调用 `encode_header` 方法，生成消息头的 token 序列。\n   - 假设 `encode_header` 返回的 token 序列为：\n     ```python\n     [50258, 366, 50259, 11, 11]  # <|start_header_id|>, \"user\", <|end_header_id|>, \"\\n\\n\"\n     ```\n\n2. **编码消息内容**:\n   - 调用 `Tokenizer.encode` 方法，编码消息内容 `\"Hello, how are you?\"`。\n   - 假设返回的 token 序列为：\n     ```python\n     [15496, 11, 703, 527, 366, 30]  # \"Hello, how are you?\"\n     ```\n\n3. **添加消息结束标记**:\n   - 添加 `<|eot_id|>` 标记，假设其 ID 为 `50256`。\n   - 最终的 token 序列为：\n     ```python\n     [50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256]\n     ```\n\n#### **输出**\n```python\nencoded_message = chat_format.encode_message(message)\n# encoded_message = [50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256]\n```\n\n---\n\n### **4. decode_message 的流程**\n`decode_message` 方法用于将 token 序列解码回原始消息。\n\n#### **输入**\n```python\nencoded_message = [50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256]\n```\n\n#### **步骤**\n1. **解码 token 序列**:\n   - 调用 `Tokenizer.decode` 方法，将 token 序列解码为字符串。\n   - 假设解码结果为：\n     ```python\n     \"<|start_header_id|>user<|end_header_id|>\\n\\nHello, how are you?<|eot_id|>\"\n     ```\n\n2. **提取消息内容**:\n   - 从解码结果中提取消息内容 `\"Hello, how are you?\"`。\n\n#### **输出**\n```python\ndecoded_message = tokenizer.decode(encoded_message)\n# decoded_message = \"<|start_header_id|>user<|end_header_id|>\\n\\nHello, how are you?<|eot_id|>\"\n```\n\n---\n\n### **5. encode_dialog_prompt 的流程**\n`encode_dialog_prompt` 方法用于编码整个对话，生成模型输入的 token 序列。\n\n#### **输入**\n```python\ndialog = [\n    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n    {\"role\": \"assistant\", \"content\": \"I'm fine, thank you!\"},\n]\n```\n\n#### **步骤**\n1. **添加对话开始标记**:\n   - 添加 `<|begin_of_text|>` 标记，假设其 ID 为 `50257`。\n   - 当前的 token 序列为：\n     ```python\n     [50257]\n     ```\n\n2. **编码每条消息**:\n   - 对每条消息调用 `encode_message` 方法，生成 token 序列。\n   - 假设第一条消息的 token 序列为：\n     ```python\n     [50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256]\n     ```\n   - 假设第二条消息的 token 序列为：\n     ```python\n     [50258, 527, 50259, 11, 11, 366, 30, 703, 527, 366, 30, 50256]\n     ```\n   - 将两条消息的 token 序列合并：\n     ```python\n     [50257, 50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256, 50258, 527, 50259, 11, 11, 366, 30, 703, 527, 366, 30, 50256]\n     ```\n\n3. **添加助手消息的开始标记**:\n   - 添加助手消息的开始标记（包括角色信息和分隔符），供模型生成回复。\n   - 假设生成的 token 序列为：\n     ```python\n     [50258, 527, 50259, 11, 11]\n     ```\n   - 最终的 token 序列为：\n     ```python\n     [50257, 50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256, 50258, 527, 50259, 11, 11, 366, 30, 703, 527, 366, 30, 50256, 50258, 527, 50259, 11, 11]\n     ```\n\n#### **输出**\n```python\nencoded_dialog = chat_format.encode_dialog_prompt(dialog)\n# encoded_dialog = [50257, 50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256, 50258, 527, 50259, 11, 11, 366, 30, 703, 527, 366, 30, 50256, 50258, 527, 50259, 11, 11]\n```\n\n---\n\n### **6. 区分 encode_message 和 encode_dialog_prompt**\n#### **encode_message**\n- **输入**: 单个 `Message` 字典。\n- **输出**: 编码后的 token 序列，包含消息头、内容和结束标记。\n- **用途**: 用于编码单条消息。\n\n#### **encode_dialog_prompt**\n- **输入**: 一个 `Dialog` 列表，包含多条消息。\n- **输出**: 编码后的 token 序列，包含对话开始标记、所有消息的编码以及助手消息的开始标记。\n- **用途**: 用于编码整个对话，生成模型输入的 token 序列。\n\n---\n\n### **7. 总结**\n通过 `Tokenizer` 和 `ChatFormat` 两个类的协同工作，我们可以将 `Message` 和 `Dialog` 编码为模型可以理解的 token 序列，并能够将 token 序列解码回原始文本。以下是完整的流程总结：\n\n1. **单个消息编码**:\n   - 使用 `encode_message` 方法，将 `Message` 编码为 token 序列。\n   - 输出包含消息头、内容和结束标记。\n\n2. **对话编码**:\n   - 使用 `encode_dialog_prompt` 方法，将 `Dialog` 编码为 token 序列。\n   - 输出包含对话开始标记、所有消息的编码以及助手消息的开始标记。\n\n3. **解码**:\n   - 使用 `Tokenizer.decode` 方法，将 token 序列解码回原始文本。\n\n通过这种方式，`Tokenizer` 和 `ChatFormat` 能够高效地处理对话数据，为语言模型提供格式化的输入。\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","source":"_posts/人工智能/nlp/llm/源码解析：llama3源码解析-02：tokenizer模块解析.md","raw":"---\ntitle: 'llama3源码解析-02：tokenizer模块解析'\ncategories:\n  - [人工智能,nlp,llm]\ntags:\n  - nlp\n  - llm\n  - llama\n---\n\n![img](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/Llama3_Repo.jpeg)\n\n## Tokenizer类\n\n以下是 `tokenizer.py` 中 `Tokenizer` 类的逐行详细解释：\n\n```python\nclass Tokenizer:\n    \"\"\"\n    Tokenizing and encoding/decoding text using the Tiktoken tokenizer.\n    \"\"\"\n    # 特殊 token 的字典，用于存储特殊 token 及其对应的 token ID\n    special_tokens: Dict[str, int]\n\n    # 保留的特殊 token 数量，默认为 256\n    num_reserved_special_tokens = 256\n\n    # 正则表达式模式，用于匹配文本中的子词和特殊字符\n    pat_str = r\"(?i:'s|'t|'re|'ve|'m|'ll|'d)|[^\\r\\n\\p{L}\\p{N}]?\\p{L}+|\\p{N}{1,3}| ?[^\\s\\p{L}\\p{N}]+[\\r\\n]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+\"  # noqa: E501\n\n    def __init__(self, model_path: str):\n        \"\"\"\n        Initializes the Tokenizer with a Tiktoken model.\n\n        Args:\n            model_path (str): The path to the Tiktoken model file.\n        \"\"\"\n        # 检查模型文件是否存在\n        assert os.path.isfile(model_path), model_path\n\n        # 加载 Tiktoken 模型的 BPE（Byte Pair Encoding）合并表\n        mergeable_ranks = load_tiktoken_bpe(model_path)\n        # 获取基础 token 的数量\n        num_base_tokens = len(mergeable_ranks)\n        # 定义特殊 token 列表\n        special_tokens = [\n            \"<|begin_of_text|>\",\n            \"<|end_of_text|>\",\n            \"<|reserved_special_token_0|>\",\n            \"<|reserved_special_token_1|>\",\n            \"<|reserved_special_token_2|>\",\n            \"<|reserved_special_token_3|>\",\n            \"<|start_header_id|>\",\n            \"<|end_header_id|>\",\n            \"<|reserved_special_token_4|>\",\n            \"<|eot_id|>\",  # end of turn\n        ] + [\n            # 生成剩余的保留特殊 token\n            f\"<|reserved_special_token_{i}|>\"\n            for i in range(5, self.num_reserved_special_tokens - 5)\n        ]\n        # 将特殊 token 映射到 token ID，ID 从基础 token 数量开始递增\n        self.special_tokens = {\n            token: num_base_tokens + i for i, token in enumerate(special_tokens)\n        }\n        # 初始化 Tiktoken 的 Encoding 对象\n        self.model = tiktoken.Encoding(\n            name=Path(model_path).name,\n            pat_str=self.pat_str,\n            mergeable_ranks=mergeable_ranks,\n            special_tokens=self.special_tokens,\n        )\n        # 记录日志，表示模型已加载\n        logger.info(f\"Reloaded tiktoken model from {model_path}\")\n\n        # 获取词汇表大小\n        self.n_words: int = self.model.n_vocab\n        # 获取 BOS（Begin of Sequence）token 的 ID\n        self.bos_id: int = self.special_tokens[\"<|begin_of_text|>\"]\n        # 获取 EOS（End of Sequence）token 的 ID\n        self.eos_id: int = self.special_tokens[\"<|end_of_text|>\"]\n        # 设置 pad token 的 ID，默认为 -1\n        self.pad_id: int = -1\n        # 定义停止 token 集合，包含 EOS 和 EOT（End of Turn）token\n        self.stop_tokens = {\n            self.special_tokens[\"<|end_of_text|>\"],\n            self.special_tokens[\"<|eot_id|>\"],\n        }\n        # 记录词汇表大小、BOS ID 和 EOS ID\n        logger.info(\n            f\"#words: {self.n_words} - BOS ID: {self.bos_id} - EOS ID: {self.eos_id}\"\n        )\n\n    def encode(\n        self,\n        s: str,\n        *,\n        bos: bool,\n        eos: bool,\n        allowed_special: Union[Literal[\"all\"], AbstractSet[str]] = set(),\n        disallowed_special: Union[Literal[\"all\"], Collection[str]] = (),\n    ) -> List[int]:\n        \"\"\"\n        Encodes a string into a list of token IDs.\n\n        Args:\n            s (str): The input string to be encoded.\n            bos (bool): Whether to prepend the beginning-of-sequence token.\n            eos (bool): Whether to append the end-of-sequence token.\n            allowed_tokens (\"all\"|set[str]): allowed special tokens in string\n            disallowed_tokens (\"all\"|set[str]): special tokens that raise an error when in string\n\n        Returns:\n            list[int]: A list of token IDs.\n        \"\"\"\n        # 确保输入是字符串\n        assert type(s) is str\n\n        # Tiktoken 分词器单次编码的最大字符数\n        TIKTOKEN_MAX_ENCODE_CHARS = 400_000\n\n        # 最大连续非空格或空格字符数\n        MAX_NO_WHITESPACES_CHARS = 25_000\n\n        # 将输入字符串分割为子串，确保每个子串不超过最大字符数\n        substrs = (\n            substr\n            for i in range(0, len(s), TIKTOKEN_MAX_ENCODE_CHARS)\n            for substr in self._split_whitespaces_or_nonwhitespaces(\n                s[i : i + TIKTOKEN_MAX_ENCODE_CHARS], MAX_NO_WHITESPACES_CHARS\n            )\n        )\n        # 初始化 token ID 列表\n        t: List[int] = []\n        # 对每个子串进行编码\n        for substr in substrs:\n            t.extend(\n                self.model.encode(\n                    substr,\n                    allowed_special=allowed_special,\n                    disallowed_special=disallowed_special,\n                )\n            )\n        # 如果需要，在开头添加 BOS token\n        if bos:\n            t.insert(0, self.bos_id)\n        # 如果需要，在结尾添加 EOS token\n        if eos:\n            t.append(self.eos_id)\n        # 返回编码后的 token ID 列表\n        return t\n\n    def decode(self, t: Sequence[int]) -> str:\n        \"\"\"\n        Decodes a list of token IDs into a string.\n\n        Args:\n            t (List[int]): The list of token IDs to be decoded.\n\n        Returns:\n            str: The decoded string.\n        \"\"\"\n        # 将 token ID 序列解码为字符串\n        return self.model.decode(cast(List[int], t))\n\n    @staticmethod\n    def _split_whitespaces_or_nonwhitespaces(\n        s: str, max_consecutive_slice_len: int\n    ) -> Iterator[str]:\n        \"\"\"\n        Splits the string `s` so that each substring contains no more than `max_consecutive_slice_len`\n        consecutive whitespaces or consecutive non-whitespaces.\n        \"\"\"\n        # 初始化当前子串的长度和类型\n        current_slice_len = 0\n        current_slice_is_space = s[0].isspace() if len(s) > 0 else False\n        slice_start = 0\n\n        # 遍历字符串，按空格或非空格进行分割\n        for i in range(len(s)):\n            is_now_space = s[i].isspace()\n\n            if current_slice_is_space ^ is_now_space:\n                current_slice_len = 1\n                current_slice_is_space = is_now_space\n            else:\n                current_slice_len += 1\n                if current_slice_len > max_consecutive_slice_len:\n                    yield s[slice_start:i]\n                    slice_start = i\n                    current_slice_len = 1\n        yield s[slice_start:]\n```\n\n### 逐行解释总结\n1. **特殊 token 处理**:\n   - `special_tokens` 字典存储特殊 token 及其对应的 token ID。\n   - `num_reserved_special_tokens` 定义了保留的特殊 token 数量。\n   - `pat_str` 是正则表达式模式，用于匹配文本中的子词和特殊字符。\n\n2. **初始化方法 (`__init__`)**:\n   - 加载 Tiktoken 模型的 BPE 合并表，并初始化特殊 token。\n   - 设置 BOS、EOS 和 pad token 的 ID，并定义停止 token 集合。\n   - 初始化 Tiktoken 的 `Encoding` 对象，用于实际的编码和解码操作。\n\n3. **编码方法 (`encode`)**:\n   - 将输入字符串分割为子串，确保每个子串不超过最大字符数。\n   - 对每个子串进行编码，并根据参数决定是否添加 BOS 和 EOS token。\n   - 返回编码后的 token ID 列表。\n\n4. **解码方法 (`decode`)**:\n   - 将 token ID 序列解码为字符串。\n\n5. **子串分割方法 (`_split_whitespaces_or_nonwhitespaces`)**:\n   - 将字符串按空格或非空格进行分割，确保每个子串不超过最大连续字符数。\n   \n   - ### **什么保留空格？**\n   \n     1. **语义完整性**:\n        - 空格在文本中用于分隔单词、标点符号等，是文本结构的重要组成部分。\n        - 如果丢弃空格，分词结果可能会将多个单词合并，导致语义错误。例如：\n          - 输入: `\"Hello, how are you?\"`\n          - 丢弃空格: `\"Hello,howareyou?\"`（分词结果错误）\n          - 保留空格: `\"Hello, how are you?\"`（分词结果正确）\n     2. **特殊 token 处理**:\n        - 某些特殊 token（如 `<|end_of_text|>`）可能被空格包围，保留空格可以确保这些特殊 token 被正确识别和处理。\n     3. **模型输入格式**:\n        - 许多语言模型（如 GPT）的输入需要保留空格，以确保生成的文本格式正确。\n\n### 对输入字符串进行tokenize的详细流程\n\n结合一个具体的字符串示例，详细说明 `Tokenizer` 如何处理输入字符串。假设我们已经有一个 Tiktoken 模型文件，并且输入字符串为：\n\n```\n\"Hello, how are you? <|end_of_text|>\"\n```\n\n我们将逐步分析 `Tokenizer` 如何处理这个字符串。\n\n---\n\n#### **1. 输入字符串**\n```python\ns = \"Hello, how are you? <|end_of_text|>\"\n```\n\n---\n\n#### **2. 参数设置**\n假设调用 `encode` 方法时，参数如下：\n```python\nbos = True  # 添加 BOS token\neos = False  # 不添加 EOS token\nallowed_special = {\"<|end_of_text|>\"}  # 允许的特殊 token\ndisallowed_special = ()  # 不允许的特殊 token（为空）\n```\n\n---\n\n#### **3. 输入验证**\n- **类型检查**:\n  ```python\n  assert type(s) is str\n  ```\n  输入是一个字符串，检查通过。\n\n---\n\n#### **4. 字符串分割**\n由于输入字符串较短（远小于 `TIKTOKEN_MAX_ENCODE_CHARS = 400_000`），不需要按字符数分割。但为了演示，我们假设字符串较长，需要按空格和非空格进行分割。\n\n##### **分割逻辑**\n- 输入字符串: `\"Hello, how are you? <|end_of_text|>\"`\n- 按空格和非空格分割：\n  - `\"Hello,\"`（非空格）\n  - `\" how \"`（空格）\n  - `\"are\"`（非空格）\n  - `\" you? \"`（空格）\n  - `\"<|end_of_text|>\"`（非空格）\n\n##### **分割结果**\n```python\nsubstrs = [\"Hello,\", \" how \", \"are\", \" you? \", \"<|end_of_text|>\"]\n```\n\n---\n\n#### **5. 子串编码**\n对每个子串进行编码，生成 token ID 序列。\n\n##### **假设的 Tiktoken 模型**\n假设 Tiktoken 模型的词汇表和编码规则如下：\n- `\"Hello\"` → `[15496]`\n- `\",\"` → `[11]`\n- `\" how\"` → `[703]`\n- `\"are\"` → `[527]`\n- `\" you\"` → `[366]`\n- `\"?\"` → `[30]`\n- `\"<|end_of_text|>\"` → `[50256]`（特殊 token）\n\n##### **编码过程**\n1. **子串 `\"Hello,\"`**:\n   - 编码为 `[15496, 11]`。\n2. **子串 `\" how \"`**:\n   - 编码为 `[703]`。\n3. **子串 `\"are\"`**:\n   - 编码为 `[527]`。\n4. **子串 `\" you? \"`**:\n   - 编码为 `[366, 30]`。\n5. **子串 `\"<|end_of_text|>\"`**:\n   - 这是一个特殊 token，编码为 `[50256]`。\n\n##### **编码结果**\n```python\nt = [15496, 11, 703, 527, 366, 30, 50256]\n```\n\n---\n\n#### **6. 添加特殊 token**\n根据参数设置，需要在开头添加 BOS token，不添加 EOS token。\n\n##### **BOS token**\n假设 BOS token 的 ID 为 `50257`：\n```python\nif bos:\n    t.insert(0, 50257)\n```\n\n##### **更新后的 token 序列**\n```python\nt = [50257, 15496, 11, 703, 527, 366, 30, 50256]\n```\n\n---\n\n#### **7. 返回编码结果**\n最终的 token ID 序列为：\n```python\n[50257, 15496, 11, 703, 527, 366, 30, 50256]\n```\n\n---\n\n#### **8. 解码过程**\n如果需要将 token ID 序列解码回字符串，可以使用 `decode` 方法。\n\n##### **解码逻辑**\n- 将每个 token ID 映射回对应的子词或字符。\n- 特殊 token（如 `<|end_of_text|>`）会被解码为原始字符串。\n\n##### **解码结果**\n```python\ndecoded_str = \"<|begin_of_text|>Hello, how are you? <|end_of_text|>\"\n```\n\n---\n\n#### **9. 总结**\n结合具体示例，`Tokenizer` 处理输入字符串的详细流程如下：\n1. **输入字符串**: `\"Hello, how are you? <|end_of_text|>\"`\n2. **分割字符串**: 按空格和非空格分割为 `[\"Hello,\", \" how \", \"are\", \" you? \", \"<|end_of_text|>\"]`。\n3. **编码子串**: 将每个子串编码为 token ID 序列 `[15496, 11, 703, 527, 366, 30, 50256]`。\n4. **添加 BOS token**: 在开头插入 BOS token，得到 `[50257, 15496, 11, 703, 527, 366, 30, 50256]`。\n5. **返回结果**: 返回最终的 token ID 序列。\n6. **解码**: 将 token ID 序列解码回原始字符串 `\"<|begin_of_text|>Hello, how are you? <|end_of_text|>\"`。\n\n通过这种分步骤的处理方式，`Tokenizer` 能够高效地将输入字符串转换为模型可处理的 token ID 序列，并支持特殊 token 的灵活处理。\n\n### 总结\n\n`Tokenizer` 类负责文本的编码和解码，使用 Tiktoken 作为底层分词器。它支持特殊 token 的处理，并提供了灵活的编码和解码接口。通过 `encode` 方法，可以将文本转换为 token ID 序列；通过 `decode` 方法，可以将 token ID 序列转换回文本。此外，`Tokenizer` 还提供了对长文本的分割功能，确保编码过程不会因输入过长而失败。\n\n\n\n## ChatFormat类\n\n`ChatFormat` 类的主要功能是将对话消息（`Message`）编码为模型可以理解的 token 序列，特别适用于对话生成任务。\n\n---\n\n### **代码注释**\n\n```python\nclass ChatFormat:\n    def __init__(self, tokenizer: Tokenizer):\n        \"\"\"\n        初始化 ChatFormat 类。\n\n        Args:\n            tokenizer (Tokenizer): 用于编码和解码的 Tokenizer 实例。\n        \"\"\"\n        self.tokenizer = tokenizer\n```\n\n- **功能**: 初始化 `ChatFormat` 类，绑定一个 `Tokenizer` 实例，用于后续的编码操作。\n- **参数**:\n  - `tokenizer`: 一个 `Tokenizer` 对象，用于将文本转换为 token ID 序列。\n\n---\n\n```python\n    def encode_header(self, message: Message) -> List[int]:\n        \"\"\"\n        编码消息头，包括角色信息和分隔符。\n\n        Args:\n            message (Message): 包含角色和内容的消息字典。\n\n        Returns:\n            List[int]: 编码后的 token ID 序列。\n        \"\"\"\n        tokens = []\n        # 添加消息头开始标记\n        tokens.append(self.tokenizer.special_tokens[\"<|start_header_id|>\"])\n        # 编码角色信息（如 \"user\" 或 \"assistant\"）\n        tokens.extend(self.tokenizer.encode(message[\"role\"], bos=False, eos=False))\n        # 添加消息头结束标记\n        tokens.append(self.tokenizer.special_tokens[\"<|end_header_id|>\"])\n        # 添加换行符（两个换行符，用于分隔消息头和内容）\n        tokens.extend(self.tokenizer.encode(\"\\n\\n\", bos=False, eos=False))\n        return tokens\n```\n\n- **功能**: 编码消息头，包括角色信息和分隔符。\n- **参数**:\n  - `message`: 一个 `Message` 字典，包含 `role`（角色）和 `content`（内容）。\n- **返回值**: 编码后的 token ID 序列。\n- **详细步骤**:\n  1. 添加消息头开始标记 `<|start_header_id|>`。\n  2. 编码角色信息（如 `\"user\"` 或 `\"assistant\"`）。\n  3. 添加消息头结束标记 `<|end_header_id|>`。\n  4. 添加两个换行符 `\\n\\n`，用于分隔消息头和内容。\n\n---\n\n```python\n    def encode_message(self, message: Message) -> List[int]:\n        \"\"\"\n        编码整个消息，包括消息头和内容。\n\n        Args:\n            message (Message): 包含角色和内容的消息字典。\n\n        Returns:\n            List[int]: 编码后的 token ID 序列。\n        \"\"\"\n        # 编码消息头\n        tokens = self.encode_header(message)\n        # 编码消息内容，并去除首尾空白字符\n        tokens.extend(\n            self.tokenizer.encode(message[\"content\"].strip(), bos=False, eos=False)\n        )\n        # 添加消息结束标记 <|eot_id|>\n        tokens.append(self.tokenizer.special_tokens[\"<|eot_id|>\"])\n        return tokens\n```\n\n- **功能**: 编码整个消息，包括消息头和内容。\n- **参数**:\n  - `message`: 一个 `Message` 字典，包含 `role`（角色）和 `content`（内容）。\n- **返回值**: 编码后的 token ID 序列。\n- **详细步骤**:\n  1. 调用 `encode_header` 方法，编码消息头。\n  2. 编码消息内容，并去除首尾空白字符。\n  3. 添加消息结束标记 `<|eot_id|>`，表示当前消息的结束。\n\n---\n\n```python\n    def encode_dialog_prompt(self, dialog: Dialog) -> List[int]:\n        \"\"\"\n        编码整个对话，生成模型输入的 token 序列。\n\n        Args:\n            dialog (Dialog): 对话列表，包含多条消息。\n\n        Returns:\n            List[int]: 编码后的 token ID 序列。\n        \"\"\"\n        tokens = []\n        # 添加对话开始标记 <|begin_of_text|>\n        tokens.append(self.tokenizer.special_tokens[\"<|begin_of_text|>\"])\n        # 编码每条消息\n        for message in dialog:\n            tokens.extend(self.encode_message(message))\n        # 添加助手消息的开始标记，供模型生成回复\n        tokens.extend(self.encode_header({\"role\": \"assistant\", \"content\": \"\"}))\n        return tokens\n```\n\n- **功能**: 编码整个对话，生成模型输入的 token 序列。\n- **参数**:\n  - `dialog`: 一个 `Dialog` 列表，包含多条消息。\n- **返回值**: 编码后的 token ID 序列。\n- **详细步骤**:\n  1. 添加对话开始标记 `<|begin_of_text|>`。\n  2. 遍历对话中的每条消息，调用 `encode_message` 方法进行编码。\n  3. 添加助手消息的开始标记（包括角色信息和分隔符），供模型生成回复。\n\n---\n\n### **总结**\n\n#### **功能**\n`ChatFormat` 类的主要功能是将对话消息（`Message`）编码为模型可以理解的 token 序列。它特别适用于对话生成任务，能够处理多轮对话，并生成符合模型输入格式的 token 序列。\n\n#### **核心方法**\n1. **`encode_header`**:\n   - 编码消息头，包括角色信息和分隔符。\n   - 用于标识每条消息的角色（如 `\"user\"` 或 `\"assistant\"`）。\n\n2. **`encode_message`**:\n   - 编码整个消息，包括消息头和内容。\n   - 在消息末尾添加结束标记 `<|eot_id|>`，表示当前消息的结束。\n\n3. **`encode_dialog_prompt`**:\n   - 编码整个对话，生成模型输入的 token 序列。\n   - 在对话末尾添加助手消息的开始标记，供模型生成回复。\n\n#### **特殊 token**\n- `<|begin_of_text|>`: 对话开始标记。\n- `<|start_header_id|>`: 消息头开始标记。\n- `<|end_header_id|>`: 消息头结束标记。\n- `<|eot_id|>`: 消息结束标记。\n\n#### **适用场景**\n- **对话生成**: 将多轮对话编码为模型输入，生成助手的回复。\n- **消息格式化**: 确保每条消息的格式符合模型的要求，包括角色信息和内容分隔符。\n\n#### **示例**\n假设有以下对话：\n```python\ndialog = [\n    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n    {\"role\": \"assistant\", \"content\": \"I'm fine, thank you!\"},\n]\n```\n调用 `encode_dialog_prompt(dialog)` 后，生成的 token 序列可能如下：\n```python\n[\n    <|begin_of_text|>,\n    <|start_header_id|>, \"user\", <|end_header_id|>, \"\\n\\n\", \"Hello, how are you?\", <|eot_id|>,\n    <|start_header_id|>, \"assistant\", <|end_header_id|>, \"\\n\\n\", \"I'm fine, thank you!\", <|eot_id|>,\n    <|start_header_id|>, \"assistant\", <|end_header_id|>, \"\\n\\n\"\n]\n```\n\n#### **总结**\n`ChatFormat` 类通过定义清晰的对话格式和特殊 token，确保对话消息能够被模型正确理解和处理。它是对话生成任务中不可或缺的一部分，能够有效提升模型生成回复的准确性和连贯性。\n\n## **Message** 实例解析\n\n结合实际的 `Message` 输入，详细说明 `Tokenizer` 和 `ChatFormat` 两个类如何协同工作，从 `Message` 输入到输出的完整流程。我们将重点关注 `encode_message`、`decode_message` 和 `encode_dialog_prompt` 方法，并明确区分 `encode_message` 和 `encode_dialog_prompt` 的输入和输出。\n\n---\n\n### **1. 输入数据**\n假设我们有以下 `Message` 和 `Dialog` 输入：\n\n#### **单个消息（Message）**\n```python\nmessage = {\n    \"role\": \"user\",\n    \"content\": \"Hello, how are you?\"\n}\n```\n\n#### **多轮对话（Dialog）**\n```python\ndialog = [\n    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n    {\"role\": \"assistant\", \"content\": \"I'm fine, thank you!\"},\n]\n```\n\n---\n\n### **2. Tokenizer 和 ChatFormat 初始化**\n首先，我们需要初始化 `Tokenizer` 和 `ChatFormat` 类。\n\n```python\n# 假设模型文件路径为 \"tiktoken_model.model\"\ntokenizer = Tokenizer(model_path=\"tiktoken_model.model\")\nchat_format = ChatFormat(tokenizer)\n```\n\n---\n\n### **3. encode_message 的流程**\n`encode_message` 方法用于编码单个消息，包括消息头和内容。\n\n#### **输入**\n```python\nmessage = {\n    \"role\": \"user\",\n    \"content\": \"Hello, how are you?\"\n}\n```\n\n#### **步骤**\n1. **编码消息头**:\n   - 调用 `encode_header` 方法，生成消息头的 token 序列。\n   - 假设 `encode_header` 返回的 token 序列为：\n     ```python\n     [50258, 366, 50259, 11, 11]  # <|start_header_id|>, \"user\", <|end_header_id|>, \"\\n\\n\"\n     ```\n\n2. **编码消息内容**:\n   - 调用 `Tokenizer.encode` 方法，编码消息内容 `\"Hello, how are you?\"`。\n   - 假设返回的 token 序列为：\n     ```python\n     [15496, 11, 703, 527, 366, 30]  # \"Hello, how are you?\"\n     ```\n\n3. **添加消息结束标记**:\n   - 添加 `<|eot_id|>` 标记，假设其 ID 为 `50256`。\n   - 最终的 token 序列为：\n     ```python\n     [50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256]\n     ```\n\n#### **输出**\n```python\nencoded_message = chat_format.encode_message(message)\n# encoded_message = [50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256]\n```\n\n---\n\n### **4. decode_message 的流程**\n`decode_message` 方法用于将 token 序列解码回原始消息。\n\n#### **输入**\n```python\nencoded_message = [50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256]\n```\n\n#### **步骤**\n1. **解码 token 序列**:\n   - 调用 `Tokenizer.decode` 方法，将 token 序列解码为字符串。\n   - 假设解码结果为：\n     ```python\n     \"<|start_header_id|>user<|end_header_id|>\\n\\nHello, how are you?<|eot_id|>\"\n     ```\n\n2. **提取消息内容**:\n   - 从解码结果中提取消息内容 `\"Hello, how are you?\"`。\n\n#### **输出**\n```python\ndecoded_message = tokenizer.decode(encoded_message)\n# decoded_message = \"<|start_header_id|>user<|end_header_id|>\\n\\nHello, how are you?<|eot_id|>\"\n```\n\n---\n\n### **5. encode_dialog_prompt 的流程**\n`encode_dialog_prompt` 方法用于编码整个对话，生成模型输入的 token 序列。\n\n#### **输入**\n```python\ndialog = [\n    {\"role\": \"user\", \"content\": \"Hello, how are you?\"},\n    {\"role\": \"assistant\", \"content\": \"I'm fine, thank you!\"},\n]\n```\n\n#### **步骤**\n1. **添加对话开始标记**:\n   - 添加 `<|begin_of_text|>` 标记，假设其 ID 为 `50257`。\n   - 当前的 token 序列为：\n     ```python\n     [50257]\n     ```\n\n2. **编码每条消息**:\n   - 对每条消息调用 `encode_message` 方法，生成 token 序列。\n   - 假设第一条消息的 token 序列为：\n     ```python\n     [50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256]\n     ```\n   - 假设第二条消息的 token 序列为：\n     ```python\n     [50258, 527, 50259, 11, 11, 366, 30, 703, 527, 366, 30, 50256]\n     ```\n   - 将两条消息的 token 序列合并：\n     ```python\n     [50257, 50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256, 50258, 527, 50259, 11, 11, 366, 30, 703, 527, 366, 30, 50256]\n     ```\n\n3. **添加助手消息的开始标记**:\n   - 添加助手消息的开始标记（包括角色信息和分隔符），供模型生成回复。\n   - 假设生成的 token 序列为：\n     ```python\n     [50258, 527, 50259, 11, 11]\n     ```\n   - 最终的 token 序列为：\n     ```python\n     [50257, 50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256, 50258, 527, 50259, 11, 11, 366, 30, 703, 527, 366, 30, 50256, 50258, 527, 50259, 11, 11]\n     ```\n\n#### **输出**\n```python\nencoded_dialog = chat_format.encode_dialog_prompt(dialog)\n# encoded_dialog = [50257, 50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256, 50258, 527, 50259, 11, 11, 366, 30, 703, 527, 366, 30, 50256, 50258, 527, 50259, 11, 11]\n```\n\n---\n\n### **6. 区分 encode_message 和 encode_dialog_prompt**\n#### **encode_message**\n- **输入**: 单个 `Message` 字典。\n- **输出**: 编码后的 token 序列，包含消息头、内容和结束标记。\n- **用途**: 用于编码单条消息。\n\n#### **encode_dialog_prompt**\n- **输入**: 一个 `Dialog` 列表，包含多条消息。\n- **输出**: 编码后的 token 序列，包含对话开始标记、所有消息的编码以及助手消息的开始标记。\n- **用途**: 用于编码整个对话，生成模型输入的 token 序列。\n\n---\n\n### **7. 总结**\n通过 `Tokenizer` 和 `ChatFormat` 两个类的协同工作，我们可以将 `Message` 和 `Dialog` 编码为模型可以理解的 token 序列，并能够将 token 序列解码回原始文本。以下是完整的流程总结：\n\n1. **单个消息编码**:\n   - 使用 `encode_message` 方法，将 `Message` 编码为 token 序列。\n   - 输出包含消息头、内容和结束标记。\n\n2. **对话编码**:\n   - 使用 `encode_dialog_prompt` 方法，将 `Dialog` 编码为 token 序列。\n   - 输出包含对话开始标记、所有消息的编码以及助手消息的开始标记。\n\n3. **解码**:\n   - 使用 `Tokenizer.decode` 方法，将 token 序列解码回原始文本。\n\n通过这种方式，`Tokenizer` 和 `ChatFormat` 能够高效地处理对话数据，为语言模型提供格式化的输入。\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","slug":"人工智能/nlp/llm/源码解析：llama3源码解析-02：tokenizer模块解析","published":1,"date":"2024-12-26T04:24:42.760Z","updated":"2024-12-26T04:24:42.760Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3n001ghghi2u8fdsj2","content":"<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/Llama3_Repo.jpeg\" alt=\"img\"></p>\n<h2 id=\"Tokenizer类\"><a href=\"#Tokenizer类\" class=\"headerlink\" title=\"Tokenizer类\"></a>Tokenizer类</h2><p>以下是 <code>tokenizer.py</code> 中 <code>Tokenizer</code> 类的逐行详细解释：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Tokenizer</span>:<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    Tokenizing and encoding/decoding text using the Tiktoken tokenizer.</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 特殊 token 的字典，用于存储特殊 token 及其对应的 token ID</span><br>    special_tokens: <span class=\"hljs-type\">Dict</span>[<span class=\"hljs-built_in\">str</span>, <span class=\"hljs-built_in\">int</span>]<br><br>    <span class=\"hljs-comment\"># 保留的特殊 token 数量，默认为 256</span><br>    num_reserved_special_tokens = <span class=\"hljs-number\">256</span><br><br>    <span class=\"hljs-comment\"># 正则表达式模式，用于匹配文本中的子词和特殊字符</span><br>    pat_str = <span class=\"hljs-string\">r&quot;(?i:&#x27;s|&#x27;t|&#x27;re|&#x27;ve|&#x27;m|&#x27;ll|&#x27;d)|[^\\r\\n\\p&#123;L&#125;\\p&#123;N&#125;]?\\p&#123;L&#125;+|\\p&#123;N&#125;&#123;1,3&#125;| ?[^\\s\\p&#123;L&#125;\\p&#123;N&#125;]+[\\r\\n]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+&quot;</span>  <span class=\"hljs-comment\"># noqa: E501</span><br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, model_path: <span class=\"hljs-built_in\">str</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">        Initializes the Tokenizer with a Tiktoken model.</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">        Args:</span><br><span class=\"hljs-string\">            model_path (str): The path to the Tiktoken model file.</span><br><span class=\"hljs-string\">        &quot;&quot;&quot;</span><br>        <span class=\"hljs-comment\"># 检查模型文件是否存在</span><br>        <span class=\"hljs-keyword\">assert</span> os.path.isfile(model_path), model_path<br><br>        <span class=\"hljs-comment\"># 加载 Tiktoken 模型的 BPE（Byte Pair Encoding）合并表</span><br>        mergeable_ranks = load_tiktoken_bpe(model_path)<br>        <span class=\"hljs-comment\"># 获取基础 token 的数量</span><br>        num_base_tokens = <span class=\"hljs-built_in\">len</span>(mergeable_ranks)<br>        <span class=\"hljs-comment\"># 定义特殊 token 列表</span><br>        special_tokens = [<br>            <span class=\"hljs-string\">&quot;&lt;|begin_of_text|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|end_of_text|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|reserved_special_token_0|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|reserved_special_token_1|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|reserved_special_token_2|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|reserved_special_token_3|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|start_header_id|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|end_header_id|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|reserved_special_token_4|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|eot_id|&gt;&quot;</span>,  <span class=\"hljs-comment\"># end of turn</span><br>        ] + [<br>            <span class=\"hljs-comment\"># 生成剩余的保留特殊 token</span><br>            <span class=\"hljs-string\">f&quot;&lt;|reserved_special_token_<span class=\"hljs-subst\">&#123;i&#125;</span>|&gt;&quot;</span><br>            <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">5</span>, <span class=\"hljs-variable language_\">self</span>.num_reserved_special_tokens - <span class=\"hljs-number\">5</span>)<br>        ]<br>        <span class=\"hljs-comment\"># 将特殊 token 映射到 token ID，ID 从基础 token 数量开始递增</span><br>        <span class=\"hljs-variable language_\">self</span>.special_tokens = &#123;<br>            token: num_base_tokens + i <span class=\"hljs-keyword\">for</span> i, token <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(special_tokens)<br>        &#125;<br>        <span class=\"hljs-comment\"># 初始化 Tiktoken 的 Encoding 对象</span><br>        <span class=\"hljs-variable language_\">self</span>.model = tiktoken.Encoding(<br>            name=Path(model_path).name,<br>            pat_str=<span class=\"hljs-variable language_\">self</span>.pat_str,<br>            mergeable_ranks=mergeable_ranks,<br>            special_tokens=<span class=\"hljs-variable language_\">self</span>.special_tokens,<br>        )<br>        <span class=\"hljs-comment\"># 记录日志，表示模型已加载</span><br>        logger.info(<span class=\"hljs-string\">f&quot;Reloaded tiktoken model from <span class=\"hljs-subst\">&#123;model_path&#125;</span>&quot;</span>)<br><br>        <span class=\"hljs-comment\"># 获取词汇表大小</span><br>        <span class=\"hljs-variable language_\">self</span>.n_words: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-variable language_\">self</span>.model.n_vocab<br>        <span class=\"hljs-comment\"># 获取 BOS（Begin of Sequence）token 的 ID</span><br>        <span class=\"hljs-variable language_\">self</span>.bos_id: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-variable language_\">self</span>.special_tokens[<span class=\"hljs-string\">&quot;&lt;|begin_of_text|&gt;&quot;</span>]<br>        <span class=\"hljs-comment\"># 获取 EOS（End of Sequence）token 的 ID</span><br>        <span class=\"hljs-variable language_\">self</span>.eos_id: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-variable language_\">self</span>.special_tokens[<span class=\"hljs-string\">&quot;&lt;|end_of_text|&gt;&quot;</span>]<br>        <span class=\"hljs-comment\"># 设置 pad token 的 ID，默认为 -1</span><br>        <span class=\"hljs-variable language_\">self</span>.pad_id: <span class=\"hljs-built_in\">int</span> = -<span class=\"hljs-number\">1</span><br>        <span class=\"hljs-comment\"># 定义停止 token 集合，包含 EOS 和 EOT（End of Turn）token</span><br>        <span class=\"hljs-variable language_\">self</span>.stop_tokens = &#123;<br>            <span class=\"hljs-variable language_\">self</span>.special_tokens[<span class=\"hljs-string\">&quot;&lt;|end_of_text|&gt;&quot;</span>],<br>            <span class=\"hljs-variable language_\">self</span>.special_tokens[<span class=\"hljs-string\">&quot;&lt;|eot_id|&gt;&quot;</span>],<br>        &#125;<br>        <span class=\"hljs-comment\"># 记录词汇表大小、BOS ID 和 EOS ID</span><br>        logger.info(<br>            <span class=\"hljs-string\">f&quot;#words: <span class=\"hljs-subst\">&#123;self.n_words&#125;</span> - BOS ID: <span class=\"hljs-subst\">&#123;self.bos_id&#125;</span> - EOS ID: <span class=\"hljs-subst\">&#123;self.eos_id&#125;</span>&quot;</span><br>        )<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">encode</span>(<span class=\"hljs-params\"></span><br><span class=\"hljs-params\">        self,</span><br><span class=\"hljs-params\">        s: <span class=\"hljs-built_in\">str</span>,</span><br><span class=\"hljs-params\">        *,</span><br><span class=\"hljs-params\">        bos: <span class=\"hljs-built_in\">bool</span>,</span><br><span class=\"hljs-params\">        eos: <span class=\"hljs-built_in\">bool</span>,</span><br><span class=\"hljs-params\">        allowed_special: <span class=\"hljs-type\">Union</span>[<span class=\"hljs-type\">Literal</span>[<span class=\"hljs-string\">&quot;all&quot;</span>], AbstractSet[<span class=\"hljs-built_in\">str</span>]] = <span class=\"hljs-built_in\">set</span>(<span class=\"hljs-params\"></span>),</span><br><span class=\"hljs-params\">        disallowed_special: <span class=\"hljs-type\">Union</span>[<span class=\"hljs-type\">Literal</span>[<span class=\"hljs-string\">&quot;all&quot;</span>], Collection[<span class=\"hljs-built_in\">str</span>]] = (<span class=\"hljs-params\"></span>),</span><br><span class=\"hljs-params\">    </span>) -&gt; <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]:<br>        <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">        Encodes a string into a list of token IDs.</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">        Args:</span><br><span class=\"hljs-string\">            s (str): The input string to be encoded.</span><br><span class=\"hljs-string\">            bos (bool): Whether to prepend the beginning-of-sequence token.</span><br><span class=\"hljs-string\">            eos (bool): Whether to append the end-of-sequence token.</span><br><span class=\"hljs-string\">            allowed_tokens (&quot;all&quot;|set[str]): allowed special tokens in string</span><br><span class=\"hljs-string\">            disallowed_tokens (&quot;all&quot;|set[str]): special tokens that raise an error when in string</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">        Returns:</span><br><span class=\"hljs-string\">            list[int]: A list of token IDs.</span><br><span class=\"hljs-string\">        &quot;&quot;&quot;</span><br>        <span class=\"hljs-comment\"># 确保输入是字符串</span><br>        <span class=\"hljs-keyword\">assert</span> <span class=\"hljs-built_in\">type</span>(s) <span class=\"hljs-keyword\">is</span> <span class=\"hljs-built_in\">str</span><br><br>        <span class=\"hljs-comment\"># Tiktoken 分词器单次编码的最大字符数</span><br>        TIKTOKEN_MAX_ENCODE_CHARS = <span class=\"hljs-number\">400_000</span><br><br>        <span class=\"hljs-comment\"># 最大连续非空格或空格字符数</span><br>        MAX_NO_WHITESPACES_CHARS = <span class=\"hljs-number\">25_000</span><br><br>        <span class=\"hljs-comment\"># 将输入字符串分割为子串，确保每个子串不超过最大字符数</span><br>        substrs = (<br>            substr<br>            <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-built_in\">len</span>(s), TIKTOKEN_MAX_ENCODE_CHARS)<br>            <span class=\"hljs-keyword\">for</span> substr <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>._split_whitespaces_or_nonwhitespaces(<br>                s[i : i + TIKTOKEN_MAX_ENCODE_CHARS], MAX_NO_WHITESPACES_CHARS<br>            )<br>        )<br>        <span class=\"hljs-comment\"># 初始化 token ID 列表</span><br>        t: <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>] = []<br>        <span class=\"hljs-comment\"># 对每个子串进行编码</span><br>        <span class=\"hljs-keyword\">for</span> substr <span class=\"hljs-keyword\">in</span> substrs:<br>            t.extend(<br>                <span class=\"hljs-variable language_\">self</span>.model.encode(<br>                    substr,<br>                    allowed_special=allowed_special,<br>                    disallowed_special=disallowed_special,<br>                )<br>            )<br>        <span class=\"hljs-comment\"># 如果需要，在开头添加 BOS token</span><br>        <span class=\"hljs-keyword\">if</span> bos:<br>            t.insert(<span class=\"hljs-number\">0</span>, <span class=\"hljs-variable language_\">self</span>.bos_id)<br>        <span class=\"hljs-comment\"># 如果需要，在结尾添加 EOS token</span><br>        <span class=\"hljs-keyword\">if</span> eos:<br>            t.append(<span class=\"hljs-variable language_\">self</span>.eos_id)<br>        <span class=\"hljs-comment\"># 返回编码后的 token ID 列表</span><br>        <span class=\"hljs-keyword\">return</span> t<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">decode</span>(<span class=\"hljs-params\">self, t: <span class=\"hljs-type\">Sequence</span>[<span class=\"hljs-built_in\">int</span>]</span>) -&gt; <span class=\"hljs-built_in\">str</span>:<br>        <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">        Decodes a list of token IDs into a string.</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">        Args:</span><br><span class=\"hljs-string\">            t (List[int]): The list of token IDs to be decoded.</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">        Returns:</span><br><span class=\"hljs-string\">            str: The decoded string.</span><br><span class=\"hljs-string\">        &quot;&quot;&quot;</span><br>        <span class=\"hljs-comment\"># 将 token ID 序列解码为字符串</span><br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>.model.decode(cast(<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>], t))<br><br><span class=\"hljs-meta\">    @staticmethod</span><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">_split_whitespaces_or_nonwhitespaces</span>(<span class=\"hljs-params\"></span><br><span class=\"hljs-params\">        s: <span class=\"hljs-built_in\">str</span>, max_consecutive_slice_len: <span class=\"hljs-built_in\">int</span></span><br><span class=\"hljs-params\">    </span>) -&gt; Iterator[<span class=\"hljs-built_in\">str</span>]:<br>        <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">        Splits the string `s` so that each substring contains no more than `max_consecutive_slice_len`</span><br><span class=\"hljs-string\">        consecutive whitespaces or consecutive non-whitespaces.</span><br><span class=\"hljs-string\">        &quot;&quot;&quot;</span><br>        <span class=\"hljs-comment\"># 初始化当前子串的长度和类型</span><br>        current_slice_len = <span class=\"hljs-number\">0</span><br>        current_slice_is_space = s[<span class=\"hljs-number\">0</span>].isspace() <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(s) &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">False</span><br>        slice_start = <span class=\"hljs-number\">0</span><br><br>        <span class=\"hljs-comment\"># 遍历字符串，按空格或非空格进行分割</span><br>        <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(s)):<br>            is_now_space = s[i].isspace()<br><br>            <span class=\"hljs-keyword\">if</span> current_slice_is_space ^ is_now_space:<br>                current_slice_len = <span class=\"hljs-number\">1</span><br>                current_slice_is_space = is_now_space<br>            <span class=\"hljs-keyword\">else</span>:<br>                current_slice_len += <span class=\"hljs-number\">1</span><br>                <span class=\"hljs-keyword\">if</span> current_slice_len &gt; max_consecutive_slice_len:<br>                    <span class=\"hljs-keyword\">yield</span> s[slice_start:i]<br>                    slice_start = i<br>                    current_slice_len = <span class=\"hljs-number\">1</span><br>        <span class=\"hljs-keyword\">yield</span> s[slice_start:]<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"逐行解释总结\"><a href=\"#逐行解释总结\" class=\"headerlink\" title=\"逐行解释总结\"></a>逐行解释总结</h3><ol>\n<li><p><strong>特殊 token 处理</strong>:</p>\n<ul>\n<li><code>special_tokens</code> 字典存储特殊 token 及其对应的 token ID。</li>\n<li><code>num_reserved_special_tokens</code> 定义了保留的特殊 token 数量。</li>\n<li><code>pat_str</code> 是正则表达式模式，用于匹配文本中的子词和特殊字符。</li>\n</ul>\n</li>\n<li><p><strong>初始化方法 (<code>__init__</code>)</strong>:</p>\n<ul>\n<li>加载 Tiktoken 模型的 BPE 合并表，并初始化特殊 token。</li>\n<li>设置 BOS、EOS 和 pad token 的 ID，并定义停止 token 集合。</li>\n<li>初始化 Tiktoken 的 <code>Encoding</code> 对象，用于实际的编码和解码操作。</li>\n</ul>\n</li>\n<li><p><strong>编码方法 (<code>encode</code>)</strong>:</p>\n<ul>\n<li>将输入字符串分割为子串，确保每个子串不超过最大字符数。</li>\n<li>对每个子串进行编码，并根据参数决定是否添加 BOS 和 EOS token。</li>\n<li>返回编码后的 token ID 列表。</li>\n</ul>\n</li>\n<li><p><strong>解码方法 (<code>decode</code>)</strong>:</p>\n<ul>\n<li>将 token ID 序列解码为字符串。</li>\n</ul>\n</li>\n<li><p><strong>子串分割方法 (<code>_split_whitespaces_or_nonwhitespaces</code>)</strong>:</p>\n<ul>\n<li><p>将字符串按空格或非空格进行分割，确保每个子串不超过最大连续字符数。</p>\n</li>\n<li><h3 id=\"什么保留空格？\"><a href=\"#什么保留空格？\" class=\"headerlink\" title=\"什么保留空格？\"></a><strong>什么保留空格？</strong></h3><ol>\n<li><strong>语义完整性</strong>:<ul>\n<li>空格在文本中用于分隔单词、标点符号等，是文本结构的重要组成部分。</li>\n<li>如果丢弃空格，分词结果可能会将多个单词合并，导致语义错误。例如：<ul>\n<li>输入: <code>&quot;Hello, how are you?&quot;</code></li>\n<li>丢弃空格: <code>&quot;Hello,howareyou?&quot;</code>（分词结果错误）</li>\n<li>保留空格: <code>&quot;Hello, how are you?&quot;</code>（分词结果正确）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>特殊 token 处理</strong>:<ul>\n<li>某些特殊 token（如 <code>&lt;|end_of_text|&gt;</code>）可能被空格包围，保留空格可以确保这些特殊 token 被正确识别和处理。</li>\n</ul>\n</li>\n<li><strong>模型输入格式</strong>:<ul>\n<li>许多语言模型（如 GPT）的输入需要保留空格，以确保生成的文本格式正确。</li>\n</ul>\n</li>\n</ol>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"对输入字符串进行tokenize的详细流程\"><a href=\"#对输入字符串进行tokenize的详细流程\" class=\"headerlink\" title=\"对输入字符串进行tokenize的详细流程\"></a>对输入字符串进行tokenize的详细流程</h3><p>结合一个具体的字符串示例，详细说明 <code>Tokenizer</code> 如何处理输入字符串。假设我们已经有一个 Tiktoken 模型文件，并且输入字符串为：</p>\n<figure class=\"highlight 1c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs 1c\"><span class=\"hljs-string\">&quot;Hello, how are you? &lt;|end_of_text|&gt;&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>我们将逐步分析 <code>Tokenizer</code> 如何处理这个字符串。</p>\n<hr>\n<h4 id=\"1-输入字符串\"><a href=\"#1-输入字符串\" class=\"headerlink\" title=\"1. 输入字符串\"></a><strong>1. 输入字符串</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">s = <span class=\"hljs-string\">&quot;Hello, how are you? &lt;|end_of_text|&gt;&quot;</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"2-参数设置\"><a href=\"#2-参数设置\" class=\"headerlink\" title=\"2. 参数设置\"></a><strong>2. 参数设置</strong></h4><p>假设调用 <code>encode</code> 方法时，参数如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">bos = <span class=\"hljs-literal\">True</span>  <span class=\"hljs-comment\"># 添加 BOS token</span><br>eos = <span class=\"hljs-literal\">False</span>  <span class=\"hljs-comment\"># 不添加 EOS token</span><br>allowed_special = &#123;<span class=\"hljs-string\">&quot;&lt;|end_of_text|&gt;&quot;</span>&#125;  <span class=\"hljs-comment\"># 允许的特殊 token</span><br>disallowed_special = ()  <span class=\"hljs-comment\"># 不允许的特殊 token（为空）</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"3-输入验证\"><a href=\"#3-输入验证\" class=\"headerlink\" title=\"3. 输入验证\"></a><strong>3. 输入验证</strong></h4><ul>\n<li><strong>类型检查</strong>:<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">assert</span> <span class=\"hljs-built_in\">type</span>(s) <span class=\"hljs-keyword\">is</span> <span class=\"hljs-built_in\">str</span><br></code></pre></td></tr></table></figure>\n输入是一个字符串，检查通过。</li>\n</ul>\n<hr>\n<h4 id=\"4-字符串分割\"><a href=\"#4-字符串分割\" class=\"headerlink\" title=\"4. 字符串分割\"></a><strong>4. 字符串分割</strong></h4><p>由于输入字符串较短（远小于 <code>TIKTOKEN_MAX_ENCODE_CHARS = 400_000</code>），不需要按字符数分割。但为了演示，我们假设字符串较长，需要按空格和非空格进行分割。</p>\n<h5 id=\"分割逻辑\"><a href=\"#分割逻辑\" class=\"headerlink\" title=\"分割逻辑\"></a><strong>分割逻辑</strong></h5><ul>\n<li>输入字符串: <code>&quot;Hello, how are you? &lt;|end_of_text|&gt;&quot;</code></li>\n<li>按空格和非空格分割：<ul>\n<li><code>&quot;Hello,&quot;</code>（非空格）</li>\n<li><code>&quot; how &quot;</code>（空格）</li>\n<li><code>&quot;are&quot;</code>（非空格）</li>\n<li><code>&quot; you? &quot;</code>（空格）</li>\n<li><code>&quot;&lt;|end_of_text|&gt;&quot;</code>（非空格）</li>\n</ul>\n</li>\n</ul>\n<h5 id=\"分割结果\"><a href=\"#分割结果\" class=\"headerlink\" title=\"分割结果\"></a><strong>分割结果</strong></h5><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">substrs = [<span class=\"hljs-string\">&quot;Hello,&quot;</span>, <span class=\"hljs-string\">&quot; how &quot;</span>, <span class=\"hljs-string\">&quot;are&quot;</span>, <span class=\"hljs-string\">&quot; you? &quot;</span>, <span class=\"hljs-string\">&quot;&lt;|end_of_text|&gt;&quot;</span>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"5-子串编码\"><a href=\"#5-子串编码\" class=\"headerlink\" title=\"5. 子串编码\"></a><strong>5. 子串编码</strong></h4><p>对每个子串进行编码，生成 token ID 序列。</p>\n<h5 id=\"假设的-Tiktoken-模型\"><a href=\"#假设的-Tiktoken-模型\" class=\"headerlink\" title=\"假设的 Tiktoken 模型\"></a><strong>假设的 Tiktoken 模型</strong></h5><p>假设 Tiktoken 模型的词汇表和编码规则如下：</p>\n<ul>\n<li><code>&quot;Hello&quot;</code> → <code>[15496]</code></li>\n<li><code>&quot;,&quot;</code> → <code>[11]</code></li>\n<li><code>&quot; how&quot;</code> → <code>[703]</code></li>\n<li><code>&quot;are&quot;</code> → <code>[527]</code></li>\n<li><code>&quot; you&quot;</code> → <code>[366]</code></li>\n<li><code>&quot;?&quot;</code> → <code>[30]</code></li>\n<li><code>&quot;&lt;|end_of_text|&gt;&quot;</code> → <code>[50256]</code>（特殊 token）</li>\n</ul>\n<h5 id=\"编码过程\"><a href=\"#编码过程\" class=\"headerlink\" title=\"编码过程\"></a><strong>编码过程</strong></h5><ol>\n<li><strong>子串 <code>&quot;Hello,&quot;</code></strong>:<ul>\n<li>编码为 <code>[15496, 11]</code>。</li>\n</ul>\n</li>\n<li><strong>子串 <code>&quot; how &quot;</code></strong>:<ul>\n<li>编码为 <code>[703]</code>。</li>\n</ul>\n</li>\n<li><strong>子串 <code>&quot;are&quot;</code></strong>:<ul>\n<li>编码为 <code>[527]</code>。</li>\n</ul>\n</li>\n<li><strong>子串 <code>&quot; you? &quot;</code></strong>:<ul>\n<li>编码为 <code>[366, 30]</code>。</li>\n</ul>\n</li>\n<li><strong>子串 <code>&quot;&lt;|end_of_text|&gt;&quot;</code></strong>:<ul>\n<li>这是一个特殊 token，编码为 <code>[50256]</code>。</li>\n</ul>\n</li>\n</ol>\n<h5 id=\"编码结果\"><a href=\"#编码结果\" class=\"headerlink\" title=\"编码结果\"></a><strong>编码结果</strong></h5><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">t = [<span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"6-添加特殊-token\"><a href=\"#6-添加特殊-token\" class=\"headerlink\" title=\"6. 添加特殊 token\"></a><strong>6. 添加特殊 token</strong></h4><p>根据参数设置，需要在开头添加 BOS token，不添加 EOS token。</p>\n<h5 id=\"BOS-token\"><a href=\"#BOS-token\" class=\"headerlink\" title=\"BOS token\"></a><strong>BOS token</strong></h5><p>假设 BOS token 的 ID 为 <code>50257</code>：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">if</span> bos:<br>    t.insert(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">50257</span>)<br></code></pre></td></tr></table></figure>\n\n<h5 id=\"更新后的-token-序列\"><a href=\"#更新后的-token-序列\" class=\"headerlink\" title=\"更新后的 token 序列\"></a><strong>更新后的 token 序列</strong></h5><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">t = [<span class=\"hljs-number\">50257</span>, <span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"7-返回编码结果\"><a href=\"#7-返回编码结果\" class=\"headerlink\" title=\"7. 返回编码结果\"></a><strong>7. 返回编码结果</strong></h4><p>最终的 token ID 序列为：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50257</span>, <span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"8-解码过程\"><a href=\"#8-解码过程\" class=\"headerlink\" title=\"8. 解码过程\"></a><strong>8. 解码过程</strong></h4><p>如果需要将 token ID 序列解码回字符串，可以使用 <code>decode</code> 方法。</p>\n<h5 id=\"解码逻辑\"><a href=\"#解码逻辑\" class=\"headerlink\" title=\"解码逻辑\"></a><strong>解码逻辑</strong></h5><ul>\n<li>将每个 token ID 映射回对应的子词或字符。</li>\n<li>特殊 token（如 <code>&lt;|end_of_text|&gt;</code>）会被解码为原始字符串。</li>\n</ul>\n<h5 id=\"解码结果\"><a href=\"#解码结果\" class=\"headerlink\" title=\"解码结果\"></a><strong>解码结果</strong></h5><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">decoded_str = <span class=\"hljs-string\">&quot;&lt;|begin_of_text|&gt;Hello, how are you? &lt;|end_of_text|&gt;&quot;</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"9-总结\"><a href=\"#9-总结\" class=\"headerlink\" title=\"9. 总结\"></a><strong>9. 总结</strong></h4><p>结合具体示例，<code>Tokenizer</code> 处理输入字符串的详细流程如下：</p>\n<ol>\n<li><strong>输入字符串</strong>: <code>&quot;Hello, how are you? &lt;|end_of_text|&gt;&quot;</code></li>\n<li><strong>分割字符串</strong>: 按空格和非空格分割为 <code>[&quot;Hello,&quot;, &quot; how &quot;, &quot;are&quot;, &quot; you? &quot;, &quot;&lt;|end_of_text|&gt;&quot;]</code>。</li>\n<li><strong>编码子串</strong>: 将每个子串编码为 token ID 序列 <code>[15496, 11, 703, 527, 366, 30, 50256]</code>。</li>\n<li><strong>添加 BOS token</strong>: 在开头插入 BOS token，得到 <code>[50257, 15496, 11, 703, 527, 366, 30, 50256]</code>。</li>\n<li><strong>返回结果</strong>: 返回最终的 token ID 序列。</li>\n<li><strong>解码</strong>: 将 token ID 序列解码回原始字符串 <code>&quot;&lt;|begin_of_text|&gt;Hello, how are you? &lt;|end_of_text|&gt;&quot;</code>。</li>\n</ol>\n<p>通过这种分步骤的处理方式，<code>Tokenizer</code> 能够高效地将输入字符串转换为模型可处理的 token ID 序列，并支持特殊 token 的灵活处理。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p><code>Tokenizer</code> 类负责文本的编码和解码，使用 Tiktoken 作为底层分词器。它支持特殊 token 的处理，并提供了灵活的编码和解码接口。通过 <code>encode</code> 方法，可以将文本转换为 token ID 序列；通过 <code>decode</code> 方法，可以将 token ID 序列转换回文本。此外，<code>Tokenizer</code> 还提供了对长文本的分割功能，确保编码过程不会因输入过长而失败。</p>\n<h2 id=\"ChatFormat类\"><a href=\"#ChatFormat类\" class=\"headerlink\" title=\"ChatFormat类\"></a>ChatFormat类</h2><p><code>ChatFormat</code> 类的主要功能是将对话消息（<code>Message</code>）编码为模型可以理解的 token 序列，特别适用于对话生成任务。</p>\n<hr>\n<h3 id=\"代码注释\"><a href=\"#代码注释\" class=\"headerlink\" title=\"代码注释\"></a><strong>代码注释</strong></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ChatFormat</span>:<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, tokenizer: Tokenizer</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">        初始化 ChatFormat 类。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">        Args:</span><br><span class=\"hljs-string\">            tokenizer (Tokenizer): 用于编码和解码的 Tokenizer 实例。</span><br><span class=\"hljs-string\">        &quot;&quot;&quot;</span><br>        <span class=\"hljs-variable language_\">self</span>.tokenizer = tokenizer<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li><strong>功能</strong>: 初始化 <code>ChatFormat</code> 类，绑定一个 <code>Tokenizer</code> 实例，用于后续的编码操作。</li>\n<li><strong>参数</strong>:<ul>\n<li><code>tokenizer</code>: 一个 <code>Tokenizer</code> 对象，用于将文本转换为 token ID 序列。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">encode_header</span>(<span class=\"hljs-params\">self, message: Message</span>) -&gt; <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]:<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    编码消息头，包括角色信息和分隔符。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    Args:</span><br><span class=\"hljs-string\">        message (Message): 包含角色和内容的消息字典。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    Returns:</span><br><span class=\"hljs-string\">        List[int]: 编码后的 token ID 序列。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    tokens = []<br>    <span class=\"hljs-comment\"># 添加消息头开始标记</span><br>    tokens.append(<span class=\"hljs-variable language_\">self</span>.tokenizer.special_tokens[<span class=\"hljs-string\">&quot;&lt;|start_header_id|&gt;&quot;</span>])<br>    <span class=\"hljs-comment\"># 编码角色信息（如 &quot;user&quot; 或 &quot;assistant&quot;）</span><br>    tokens.extend(<span class=\"hljs-variable language_\">self</span>.tokenizer.encode(message[<span class=\"hljs-string\">&quot;role&quot;</span>], bos=<span class=\"hljs-literal\">False</span>, eos=<span class=\"hljs-literal\">False</span>))<br>    <span class=\"hljs-comment\"># 添加消息头结束标记</span><br>    tokens.append(<span class=\"hljs-variable language_\">self</span>.tokenizer.special_tokens[<span class=\"hljs-string\">&quot;&lt;|end_header_id|&gt;&quot;</span>])<br>    <span class=\"hljs-comment\"># 添加换行符（两个换行符，用于分隔消息头和内容）</span><br>    tokens.extend(<span class=\"hljs-variable language_\">self</span>.tokenizer.encode(<span class=\"hljs-string\">&quot;\\n\\n&quot;</span>, bos=<span class=\"hljs-literal\">False</span>, eos=<span class=\"hljs-literal\">False</span>))<br>    <span class=\"hljs-keyword\">return</span> tokens<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li><strong>功能</strong>: 编码消息头，包括角色信息和分隔符。</li>\n<li><strong>参数</strong>:<ul>\n<li><code>message</code>: 一个 <code>Message</code> 字典，包含 <code>role</code>（角色）和 <code>content</code>（内容）。</li>\n</ul>\n</li>\n<li><strong>返回值</strong>: 编码后的 token ID 序列。</li>\n<li><strong>详细步骤</strong>:<ol>\n<li>添加消息头开始标记 <code>&lt;|start_header_id|&gt;</code>。</li>\n<li>编码角色信息（如 <code>&quot;user&quot;</code> 或 <code>&quot;assistant&quot;</code>）。</li>\n<li>添加消息头结束标记 <code>&lt;|end_header_id|&gt;</code>。</li>\n<li>添加两个换行符 <code>\\n\\n</code>，用于分隔消息头和内容。</li>\n</ol>\n</li>\n</ul>\n<hr>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">encode_message</span>(<span class=\"hljs-params\">self, message: Message</span>) -&gt; <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]:<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    编码整个消息，包括消息头和内容。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    Args:</span><br><span class=\"hljs-string\">        message (Message): 包含角色和内容的消息字典。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    Returns:</span><br><span class=\"hljs-string\">        List[int]: 编码后的 token ID 序列。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 编码消息头</span><br>    tokens = <span class=\"hljs-variable language_\">self</span>.encode_header(message)<br>    <span class=\"hljs-comment\"># 编码消息内容，并去除首尾空白字符</span><br>    tokens.extend(<br>        <span class=\"hljs-variable language_\">self</span>.tokenizer.encode(message[<span class=\"hljs-string\">&quot;content&quot;</span>].strip(), bos=<span class=\"hljs-literal\">False</span>, eos=<span class=\"hljs-literal\">False</span>)<br>    )<br>    <span class=\"hljs-comment\"># 添加消息结束标记 &lt;|eot_id|&gt;</span><br>    tokens.append(<span class=\"hljs-variable language_\">self</span>.tokenizer.special_tokens[<span class=\"hljs-string\">&quot;&lt;|eot_id|&gt;&quot;</span>])<br>    <span class=\"hljs-keyword\">return</span> tokens<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li><strong>功能</strong>: 编码整个消息，包括消息头和内容。</li>\n<li><strong>参数</strong>:<ul>\n<li><code>message</code>: 一个 <code>Message</code> 字典，包含 <code>role</code>（角色）和 <code>content</code>（内容）。</li>\n</ul>\n</li>\n<li><strong>返回值</strong>: 编码后的 token ID 序列。</li>\n<li><strong>详细步骤</strong>:<ol>\n<li>调用 <code>encode_header</code> 方法，编码消息头。</li>\n<li>编码消息内容，并去除首尾空白字符。</li>\n<li>添加消息结束标记 <code>&lt;|eot_id|&gt;</code>，表示当前消息的结束。</li>\n</ol>\n</li>\n</ul>\n<hr>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">encode_dialog_prompt</span>(<span class=\"hljs-params\">self, dialog: Dialog</span>) -&gt; <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]:<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    编码整个对话，生成模型输入的 token 序列。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    Args:</span><br><span class=\"hljs-string\">        dialog (Dialog): 对话列表，包含多条消息。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    Returns:</span><br><span class=\"hljs-string\">        List[int]: 编码后的 token ID 序列。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    tokens = []<br>    <span class=\"hljs-comment\"># 添加对话开始标记 &lt;|begin_of_text|&gt;</span><br>    tokens.append(<span class=\"hljs-variable language_\">self</span>.tokenizer.special_tokens[<span class=\"hljs-string\">&quot;&lt;|begin_of_text|&gt;&quot;</span>])<br>    <span class=\"hljs-comment\"># 编码每条消息</span><br>    <span class=\"hljs-keyword\">for</span> message <span class=\"hljs-keyword\">in</span> dialog:<br>        tokens.extend(<span class=\"hljs-variable language_\">self</span>.encode_message(message))<br>    <span class=\"hljs-comment\"># 添加助手消息的开始标记，供模型生成回复</span><br>    tokens.extend(<span class=\"hljs-variable language_\">self</span>.encode_header(&#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;assistant&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;&quot;</span>&#125;))<br>    <span class=\"hljs-keyword\">return</span> tokens<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li><strong>功能</strong>: 编码整个对话，生成模型输入的 token 序列。</li>\n<li><strong>参数</strong>:<ul>\n<li><code>dialog</code>: 一个 <code>Dialog</code> 列表，包含多条消息。</li>\n</ul>\n</li>\n<li><strong>返回值</strong>: 编码后的 token ID 序列。</li>\n<li><strong>详细步骤</strong>:<ol>\n<li>添加对话开始标记 <code>&lt;|begin_of_text|&gt;</code>。</li>\n<li>遍历对话中的每条消息，调用 <code>encode_message</code> 方法进行编码。</li>\n<li>添加助手消息的开始标记（包括角色信息和分隔符），供模型生成回复。</li>\n</ol>\n</li>\n</ul>\n<hr>\n<h3 id=\"总结-1\"><a href=\"#总结-1\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h3><h4 id=\"功能\"><a href=\"#功能\" class=\"headerlink\" title=\"功能\"></a><strong>功能</strong></h4><p><code>ChatFormat</code> 类的主要功能是将对话消息（<code>Message</code>）编码为模型可以理解的 token 序列。它特别适用于对话生成任务，能够处理多轮对话，并生成符合模型输入格式的 token 序列。</p>\n<h4 id=\"核心方法\"><a href=\"#核心方法\" class=\"headerlink\" title=\"核心方法\"></a><strong>核心方法</strong></h4><ol>\n<li><p><strong><code>encode_header</code></strong>:</p>\n<ul>\n<li>编码消息头，包括角色信息和分隔符。</li>\n<li>用于标识每条消息的角色（如 <code>&quot;user&quot;</code> 或 <code>&quot;assistant&quot;</code>）。</li>\n</ul>\n</li>\n<li><p><strong><code>encode_message</code></strong>:</p>\n<ul>\n<li>编码整个消息，包括消息头和内容。</li>\n<li>在消息末尾添加结束标记 <code>&lt;|eot_id|&gt;</code>，表示当前消息的结束。</li>\n</ul>\n</li>\n<li><p><strong><code>encode_dialog_prompt</code></strong>:</p>\n<ul>\n<li>编码整个对话，生成模型输入的 token 序列。</li>\n<li>在对话末尾添加助手消息的开始标记，供模型生成回复。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"特殊-token\"><a href=\"#特殊-token\" class=\"headerlink\" title=\"特殊 token\"></a><strong>特殊 token</strong></h4><ul>\n<li><code>&lt;|begin_of_text|&gt;</code>: 对话开始标记。</li>\n<li><code>&lt;|start_header_id|&gt;</code>: 消息头开始标记。</li>\n<li><code>&lt;|end_header_id|&gt;</code>: 消息头结束标记。</li>\n<li><code>&lt;|eot_id|&gt;</code>: 消息结束标记。</li>\n</ul>\n<h4 id=\"适用场景\"><a href=\"#适用场景\" class=\"headerlink\" title=\"适用场景\"></a><strong>适用场景</strong></h4><ul>\n<li><strong>对话生成</strong>: 将多轮对话编码为模型输入，生成助手的回复。</li>\n<li><strong>消息格式化</strong>: 确保每条消息的格式符合模型的要求，包括角色信息和内容分隔符。</li>\n</ul>\n<h4 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a><strong>示例</strong></h4><p>假设有以下对话：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">dialog = [<br>    &#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;user&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;Hello, how are you?&quot;</span>&#125;,<br>    &#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;assistant&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;I&#x27;m fine, thank you!&quot;</span>&#125;,<br>]<br></code></pre></td></tr></table></figure>\n<p>调用 <code>encode_dialog_prompt(dialog)</code> 后，生成的 token 序列可能如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<br>    &lt;|begin_of_text|&gt;,<br>    &lt;|start_header_id|&gt;, <span class=\"hljs-string\">&quot;user&quot;</span>, &lt;|end_header_id|&gt;, <span class=\"hljs-string\">&quot;\\n\\n&quot;</span>, <span class=\"hljs-string\">&quot;Hello, how are you?&quot;</span>, &lt;|eot_id|&gt;,<br>    &lt;|start_header_id|&gt;, <span class=\"hljs-string\">&quot;assistant&quot;</span>, &lt;|end_header_id|&gt;, <span class=\"hljs-string\">&quot;\\n\\n&quot;</span>, <span class=\"hljs-string\">&quot;I&#x27;m fine, thank you!&quot;</span>, &lt;|eot_id|&gt;,<br>    &lt;|start_header_id|&gt;, <span class=\"hljs-string\">&quot;assistant&quot;</span>, &lt;|end_header_id|&gt;, <span class=\"hljs-string\">&quot;\\n\\n&quot;</span><br>]<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"总结-2\"><a href=\"#总结-2\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h4><p><code>ChatFormat</code> 类通过定义清晰的对话格式和特殊 token，确保对话消息能够被模型正确理解和处理。它是对话生成任务中不可或缺的一部分，能够有效提升模型生成回复的准确性和连贯性。</p>\n<h2 id=\"Message-实例解析\"><a href=\"#Message-实例解析\" class=\"headerlink\" title=\"Message 实例解析\"></a><strong>Message</strong> 实例解析</h2><p>结合实际的 <code>Message</code> 输入，详细说明 <code>Tokenizer</code> 和 <code>ChatFormat</code> 两个类如何协同工作，从 <code>Message</code> 输入到输出的完整流程。我们将重点关注 <code>encode_message</code>、<code>decode_message</code> 和 <code>encode_dialog_prompt</code> 方法，并明确区分 <code>encode_message</code> 和 <code>encode_dialog_prompt</code> 的输入和输出。</p>\n<hr>\n<h3 id=\"1-输入数据\"><a href=\"#1-输入数据\" class=\"headerlink\" title=\"1. 输入数据\"></a><strong>1. 输入数据</strong></h3><p>假设我们有以下 <code>Message</code> 和 <code>Dialog</code> 输入：</p>\n<h4 id=\"单个消息（Message）\"><a href=\"#单个消息（Message）\" class=\"headerlink\" title=\"单个消息（Message）\"></a><strong>单个消息（Message）</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">message = &#123;<br>    <span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;user&quot;</span>,<br>    <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;Hello, how are you?&quot;</span><br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"多轮对话（Dialog）\"><a href=\"#多轮对话（Dialog）\" class=\"headerlink\" title=\"多轮对话（Dialog）\"></a><strong>多轮对话（Dialog）</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">dialog = [<br>    &#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;user&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;Hello, how are you?&quot;</span>&#125;,<br>    &#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;assistant&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;I&#x27;m fine, thank you!&quot;</span>&#125;,<br>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"2-Tokenizer-和-ChatFormat-初始化\"><a href=\"#2-Tokenizer-和-ChatFormat-初始化\" class=\"headerlink\" title=\"2. Tokenizer 和 ChatFormat 初始化\"></a><strong>2. Tokenizer 和 ChatFormat 初始化</strong></h3><p>首先，我们需要初始化 <code>Tokenizer</code> 和 <code>ChatFormat</code> 类。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 假设模型文件路径为 &quot;tiktoken_model.model&quot;</span><br>tokenizer = Tokenizer(model_path=<span class=\"hljs-string\">&quot;tiktoken_model.model&quot;</span>)<br>chat_format = ChatFormat(tokenizer)<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"3-encode-message-的流程\"><a href=\"#3-encode-message-的流程\" class=\"headerlink\" title=\"3. encode_message 的流程\"></a><strong>3. encode_message 的流程</strong></h3><p><code>encode_message</code> 方法用于编码单个消息，包括消息头和内容。</p>\n<h4 id=\"输入\"><a href=\"#输入\" class=\"headerlink\" title=\"输入\"></a><strong>输入</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">message = &#123;<br>    <span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;user&quot;</span>,<br>    <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;Hello, how are you?&quot;</span><br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a><strong>步骤</strong></h4><ol>\n<li><p><strong>编码消息头</strong>:</p>\n<ul>\n<li>调用 <code>encode_header</code> 方法，生成消息头的 token 序列。</li>\n<li>假设 <code>encode_header</code> 返回的 token 序列为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>]  <span class=\"hljs-comment\"># &lt;|start_header_id|&gt;, &quot;user&quot;, &lt;|end_header_id|&gt;, &quot;\\n\\n&quot;</span><br></code></pre></td></tr></table></figure></li>\n</ul>\n</li>\n<li><p><strong>编码消息内容</strong>:</p>\n<ul>\n<li>调用 <code>Tokenizer.encode</code> 方法，编码消息内容 <code>&quot;Hello, how are you?&quot;</code>。</li>\n<li>假设返回的 token 序列为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>]  <span class=\"hljs-comment\"># &quot;Hello, how are you?&quot;</span><br></code></pre></td></tr></table></figure></li>\n</ul>\n</li>\n<li><p><strong>添加消息结束标记</strong>:</p>\n<ul>\n<li>添加 <code>&lt;|eot_id|&gt;</code> 标记，假设其 ID 为 <code>50256</code>。</li>\n<li>最终的 token 序列为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>]<br></code></pre></td></tr></table></figure></li>\n</ul>\n</li>\n</ol>\n<h4 id=\"输出\"><a href=\"#输出\" class=\"headerlink\" title=\"输出\"></a><strong>输出</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">encoded_message = chat_format.encode_message(message)<br><span class=\"hljs-comment\"># encoded_message = [50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256]</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"4-decode-message-的流程\"><a href=\"#4-decode-message-的流程\" class=\"headerlink\" title=\"4. decode_message 的流程\"></a><strong>4. decode_message 的流程</strong></h3><p><code>decode_message</code> 方法用于将 token 序列解码回原始消息。</p>\n<h4 id=\"输入-1\"><a href=\"#输入-1\" class=\"headerlink\" title=\"输入\"></a><strong>输入</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">encoded_message = [<span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>]<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"步骤-1\"><a href=\"#步骤-1\" class=\"headerlink\" title=\"步骤\"></a><strong>步骤</strong></h4><ol>\n<li><p><strong>解码 token 序列</strong>:</p>\n<ul>\n<li>调用 <code>Tokenizer.decode</code> 方法，将 token 序列解码为字符串。</li>\n<li>假设解码结果为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-string\">&quot;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHello, how are you?&lt;|eot_id|&gt;&quot;</span><br></code></pre></td></tr></table></figure></li>\n</ul>\n</li>\n<li><p><strong>提取消息内容</strong>:</p>\n<ul>\n<li>从解码结果中提取消息内容 <code>&quot;Hello, how are you?&quot;</code>。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"输出-1\"><a href=\"#输出-1\" class=\"headerlink\" title=\"输出\"></a><strong>输出</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">decoded_message = tokenizer.decode(encoded_message)<br><span class=\"hljs-comment\"># decoded_message = &quot;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHello, how are you?&lt;|eot_id|&gt;&quot;</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"5-encode-dialog-prompt-的流程\"><a href=\"#5-encode-dialog-prompt-的流程\" class=\"headerlink\" title=\"5. encode_dialog_prompt 的流程\"></a><strong>5. encode_dialog_prompt 的流程</strong></h3><p><code>encode_dialog_prompt</code> 方法用于编码整个对话，生成模型输入的 token 序列。</p>\n<h4 id=\"输入-2\"><a href=\"#输入-2\" class=\"headerlink\" title=\"输入\"></a><strong>输入</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">dialog = [<br>    &#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;user&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;Hello, how are you?&quot;</span>&#125;,<br>    &#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;assistant&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;I&#x27;m fine, thank you!&quot;</span>&#125;,<br>]<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"步骤-2\"><a href=\"#步骤-2\" class=\"headerlink\" title=\"步骤\"></a><strong>步骤</strong></h4><ol>\n<li><p><strong>添加对话开始标记</strong>:</p>\n<ul>\n<li>添加 <code>&lt;|begin_of_text|&gt;</code> 标记，假设其 ID 为 <code>50257</code>。</li>\n<li>当前的 token 序列为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50257</span>]<br></code></pre></td></tr></table></figure></li>\n</ul>\n</li>\n<li><p><strong>编码每条消息</strong>:</p>\n<ul>\n<li>对每条消息调用 <code>encode_message</code> 方法，生成 token 序列。</li>\n<li>假设第一条消息的 token 序列为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>]<br></code></pre></td></tr></table></figure></li>\n<li>假设第二条消息的 token 序列为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>]<br></code></pre></td></tr></table></figure></li>\n<li>将两条消息的 token 序列合并：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50257</span>, <span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>, <span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>]<br></code></pre></td></tr></table></figure></li>\n</ul>\n</li>\n<li><p><strong>添加助手消息的开始标记</strong>:</p>\n<ul>\n<li>添加助手消息的开始标记（包括角色信息和分隔符），供模型生成回复。</li>\n<li>假设生成的 token 序列为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>]<br></code></pre></td></tr></table></figure></li>\n<li>最终的 token 序列为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50257</span>, <span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>, <span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>, <span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>]<br></code></pre></td></tr></table></figure></li>\n</ul>\n</li>\n</ol>\n<h4 id=\"输出-2\"><a href=\"#输出-2\" class=\"headerlink\" title=\"输出\"></a><strong>输出</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">encoded_dialog = chat_format.encode_dialog_prompt(dialog)<br><span class=\"hljs-comment\"># encoded_dialog = [50257, 50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256, 50258, 527, 50259, 11, 11, 366, 30, 703, 527, 366, 30, 50256, 50258, 527, 50259, 11, 11]</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"6-区分-encode-message-和-encode-dialog-prompt\"><a href=\"#6-区分-encode-message-和-encode-dialog-prompt\" class=\"headerlink\" title=\"6. 区分 encode_message 和 encode_dialog_prompt\"></a><strong>6. 区分 encode_message 和 encode_dialog_prompt</strong></h3><h4 id=\"encode-message\"><a href=\"#encode-message\" class=\"headerlink\" title=\"encode_message\"></a><strong>encode_message</strong></h4><ul>\n<li><strong>输入</strong>: 单个 <code>Message</code> 字典。</li>\n<li><strong>输出</strong>: 编码后的 token 序列，包含消息头、内容和结束标记。</li>\n<li><strong>用途</strong>: 用于编码单条消息。</li>\n</ul>\n<h4 id=\"encode-dialog-prompt\"><a href=\"#encode-dialog-prompt\" class=\"headerlink\" title=\"encode_dialog_prompt\"></a><strong>encode_dialog_prompt</strong></h4><ul>\n<li><strong>输入</strong>: 一个 <code>Dialog</code> 列表，包含多条消息。</li>\n<li><strong>输出</strong>: 编码后的 token 序列，包含对话开始标记、所有消息的编码以及助手消息的开始标记。</li>\n<li><strong>用途</strong>: 用于编码整个对话，生成模型输入的 token 序列。</li>\n</ul>\n<hr>\n<h3 id=\"7-总结\"><a href=\"#7-总结\" class=\"headerlink\" title=\"7. 总结\"></a><strong>7. 总结</strong></h3><p>通过 <code>Tokenizer</code> 和 <code>ChatFormat</code> 两个类的协同工作，我们可以将 <code>Message</code> 和 <code>Dialog</code> 编码为模型可以理解的 token 序列，并能够将 token 序列解码回原始文本。以下是完整的流程总结：</p>\n<ol>\n<li><p><strong>单个消息编码</strong>:</p>\n<ul>\n<li>使用 <code>encode_message</code> 方法，将 <code>Message</code> 编码为 token 序列。</li>\n<li>输出包含消息头、内容和结束标记。</li>\n</ul>\n</li>\n<li><p><strong>对话编码</strong>:</p>\n<ul>\n<li>使用 <code>encode_dialog_prompt</code> 方法，将 <code>Dialog</code> 编码为 token 序列。</li>\n<li>输出包含对话开始标记、所有消息的编码以及助手消息的开始标记。</li>\n</ul>\n</li>\n<li><p><strong>解码</strong>:</p>\n<ul>\n<li>使用 <code>Tokenizer.decode</code> 方法，将 token 序列解码回原始文本。</li>\n</ul>\n</li>\n</ol>\n<p>通过这种方式，<code>Tokenizer</code> 和 <code>ChatFormat</code> 能够高效地处理对话数据，为语言模型提供格式化的输入。</p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n","excerpt":"","more":"<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/Llama3_Repo.jpeg\" alt=\"img\"></p>\n<h2 id=\"Tokenizer类\"><a href=\"#Tokenizer类\" class=\"headerlink\" title=\"Tokenizer类\"></a>Tokenizer类</h2><p>以下是 <code>tokenizer.py</code> 中 <code>Tokenizer</code> 类的逐行详细解释：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">Tokenizer</span>:<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    Tokenizing and encoding/decoding text using the Tiktoken tokenizer.</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 特殊 token 的字典，用于存储特殊 token 及其对应的 token ID</span><br>    special_tokens: <span class=\"hljs-type\">Dict</span>[<span class=\"hljs-built_in\">str</span>, <span class=\"hljs-built_in\">int</span>]<br><br>    <span class=\"hljs-comment\"># 保留的特殊 token 数量，默认为 256</span><br>    num_reserved_special_tokens = <span class=\"hljs-number\">256</span><br><br>    <span class=\"hljs-comment\"># 正则表达式模式，用于匹配文本中的子词和特殊字符</span><br>    pat_str = <span class=\"hljs-string\">r&quot;(?i:&#x27;s|&#x27;t|&#x27;re|&#x27;ve|&#x27;m|&#x27;ll|&#x27;d)|[^\\r\\n\\p&#123;L&#125;\\p&#123;N&#125;]?\\p&#123;L&#125;+|\\p&#123;N&#125;&#123;1,3&#125;| ?[^\\s\\p&#123;L&#125;\\p&#123;N&#125;]+[\\r\\n]*|\\s*[\\r\\n]+|\\s+(?!\\S)|\\s+&quot;</span>  <span class=\"hljs-comment\"># noqa: E501</span><br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, model_path: <span class=\"hljs-built_in\">str</span></span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">        Initializes the Tokenizer with a Tiktoken model.</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">        Args:</span><br><span class=\"hljs-string\">            model_path (str): The path to the Tiktoken model file.</span><br><span class=\"hljs-string\">        &quot;&quot;&quot;</span><br>        <span class=\"hljs-comment\"># 检查模型文件是否存在</span><br>        <span class=\"hljs-keyword\">assert</span> os.path.isfile(model_path), model_path<br><br>        <span class=\"hljs-comment\"># 加载 Tiktoken 模型的 BPE（Byte Pair Encoding）合并表</span><br>        mergeable_ranks = load_tiktoken_bpe(model_path)<br>        <span class=\"hljs-comment\"># 获取基础 token 的数量</span><br>        num_base_tokens = <span class=\"hljs-built_in\">len</span>(mergeable_ranks)<br>        <span class=\"hljs-comment\"># 定义特殊 token 列表</span><br>        special_tokens = [<br>            <span class=\"hljs-string\">&quot;&lt;|begin_of_text|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|end_of_text|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|reserved_special_token_0|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|reserved_special_token_1|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|reserved_special_token_2|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|reserved_special_token_3|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|start_header_id|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|end_header_id|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|reserved_special_token_4|&gt;&quot;</span>,<br>            <span class=\"hljs-string\">&quot;&lt;|eot_id|&gt;&quot;</span>,  <span class=\"hljs-comment\"># end of turn</span><br>        ] + [<br>            <span class=\"hljs-comment\"># 生成剩余的保留特殊 token</span><br>            <span class=\"hljs-string\">f&quot;&lt;|reserved_special_token_<span class=\"hljs-subst\">&#123;i&#125;</span>|&gt;&quot;</span><br>            <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">5</span>, <span class=\"hljs-variable language_\">self</span>.num_reserved_special_tokens - <span class=\"hljs-number\">5</span>)<br>        ]<br>        <span class=\"hljs-comment\"># 将特殊 token 映射到 token ID，ID 从基础 token 数量开始递增</span><br>        <span class=\"hljs-variable language_\">self</span>.special_tokens = &#123;<br>            token: num_base_tokens + i <span class=\"hljs-keyword\">for</span> i, token <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(special_tokens)<br>        &#125;<br>        <span class=\"hljs-comment\"># 初始化 Tiktoken 的 Encoding 对象</span><br>        <span class=\"hljs-variable language_\">self</span>.model = tiktoken.Encoding(<br>            name=Path(model_path).name,<br>            pat_str=<span class=\"hljs-variable language_\">self</span>.pat_str,<br>            mergeable_ranks=mergeable_ranks,<br>            special_tokens=<span class=\"hljs-variable language_\">self</span>.special_tokens,<br>        )<br>        <span class=\"hljs-comment\"># 记录日志，表示模型已加载</span><br>        logger.info(<span class=\"hljs-string\">f&quot;Reloaded tiktoken model from <span class=\"hljs-subst\">&#123;model_path&#125;</span>&quot;</span>)<br><br>        <span class=\"hljs-comment\"># 获取词汇表大小</span><br>        <span class=\"hljs-variable language_\">self</span>.n_words: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-variable language_\">self</span>.model.n_vocab<br>        <span class=\"hljs-comment\"># 获取 BOS（Begin of Sequence）token 的 ID</span><br>        <span class=\"hljs-variable language_\">self</span>.bos_id: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-variable language_\">self</span>.special_tokens[<span class=\"hljs-string\">&quot;&lt;|begin_of_text|&gt;&quot;</span>]<br>        <span class=\"hljs-comment\"># 获取 EOS（End of Sequence）token 的 ID</span><br>        <span class=\"hljs-variable language_\">self</span>.eos_id: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-variable language_\">self</span>.special_tokens[<span class=\"hljs-string\">&quot;&lt;|end_of_text|&gt;&quot;</span>]<br>        <span class=\"hljs-comment\"># 设置 pad token 的 ID，默认为 -1</span><br>        <span class=\"hljs-variable language_\">self</span>.pad_id: <span class=\"hljs-built_in\">int</span> = -<span class=\"hljs-number\">1</span><br>        <span class=\"hljs-comment\"># 定义停止 token 集合，包含 EOS 和 EOT（End of Turn）token</span><br>        <span class=\"hljs-variable language_\">self</span>.stop_tokens = &#123;<br>            <span class=\"hljs-variable language_\">self</span>.special_tokens[<span class=\"hljs-string\">&quot;&lt;|end_of_text|&gt;&quot;</span>],<br>            <span class=\"hljs-variable language_\">self</span>.special_tokens[<span class=\"hljs-string\">&quot;&lt;|eot_id|&gt;&quot;</span>],<br>        &#125;<br>        <span class=\"hljs-comment\"># 记录词汇表大小、BOS ID 和 EOS ID</span><br>        logger.info(<br>            <span class=\"hljs-string\">f&quot;#words: <span class=\"hljs-subst\">&#123;self.n_words&#125;</span> - BOS ID: <span class=\"hljs-subst\">&#123;self.bos_id&#125;</span> - EOS ID: <span class=\"hljs-subst\">&#123;self.eos_id&#125;</span>&quot;</span><br>        )<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">encode</span>(<span class=\"hljs-params\"></span><br><span class=\"hljs-params\">        self,</span><br><span class=\"hljs-params\">        s: <span class=\"hljs-built_in\">str</span>,</span><br><span class=\"hljs-params\">        *,</span><br><span class=\"hljs-params\">        bos: <span class=\"hljs-built_in\">bool</span>,</span><br><span class=\"hljs-params\">        eos: <span class=\"hljs-built_in\">bool</span>,</span><br><span class=\"hljs-params\">        allowed_special: <span class=\"hljs-type\">Union</span>[<span class=\"hljs-type\">Literal</span>[<span class=\"hljs-string\">&quot;all&quot;</span>], AbstractSet[<span class=\"hljs-built_in\">str</span>]] = <span class=\"hljs-built_in\">set</span>(<span class=\"hljs-params\"></span>),</span><br><span class=\"hljs-params\">        disallowed_special: <span class=\"hljs-type\">Union</span>[<span class=\"hljs-type\">Literal</span>[<span class=\"hljs-string\">&quot;all&quot;</span>], Collection[<span class=\"hljs-built_in\">str</span>]] = (<span class=\"hljs-params\"></span>),</span><br><span class=\"hljs-params\">    </span>) -&gt; <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]:<br>        <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">        Encodes a string into a list of token IDs.</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">        Args:</span><br><span class=\"hljs-string\">            s (str): The input string to be encoded.</span><br><span class=\"hljs-string\">            bos (bool): Whether to prepend the beginning-of-sequence token.</span><br><span class=\"hljs-string\">            eos (bool): Whether to append the end-of-sequence token.</span><br><span class=\"hljs-string\">            allowed_tokens (&quot;all&quot;|set[str]): allowed special tokens in string</span><br><span class=\"hljs-string\">            disallowed_tokens (&quot;all&quot;|set[str]): special tokens that raise an error when in string</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">        Returns:</span><br><span class=\"hljs-string\">            list[int]: A list of token IDs.</span><br><span class=\"hljs-string\">        &quot;&quot;&quot;</span><br>        <span class=\"hljs-comment\"># 确保输入是字符串</span><br>        <span class=\"hljs-keyword\">assert</span> <span class=\"hljs-built_in\">type</span>(s) <span class=\"hljs-keyword\">is</span> <span class=\"hljs-built_in\">str</span><br><br>        <span class=\"hljs-comment\"># Tiktoken 分词器单次编码的最大字符数</span><br>        TIKTOKEN_MAX_ENCODE_CHARS = <span class=\"hljs-number\">400_000</span><br><br>        <span class=\"hljs-comment\"># 最大连续非空格或空格字符数</span><br>        MAX_NO_WHITESPACES_CHARS = <span class=\"hljs-number\">25_000</span><br><br>        <span class=\"hljs-comment\"># 将输入字符串分割为子串，确保每个子串不超过最大字符数</span><br>        substrs = (<br>            substr<br>            <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-number\">0</span>, <span class=\"hljs-built_in\">len</span>(s), TIKTOKEN_MAX_ENCODE_CHARS)<br>            <span class=\"hljs-keyword\">for</span> substr <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>._split_whitespaces_or_nonwhitespaces(<br>                s[i : i + TIKTOKEN_MAX_ENCODE_CHARS], MAX_NO_WHITESPACES_CHARS<br>            )<br>        )<br>        <span class=\"hljs-comment\"># 初始化 token ID 列表</span><br>        t: <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>] = []<br>        <span class=\"hljs-comment\"># 对每个子串进行编码</span><br>        <span class=\"hljs-keyword\">for</span> substr <span class=\"hljs-keyword\">in</span> substrs:<br>            t.extend(<br>                <span class=\"hljs-variable language_\">self</span>.model.encode(<br>                    substr,<br>                    allowed_special=allowed_special,<br>                    disallowed_special=disallowed_special,<br>                )<br>            )<br>        <span class=\"hljs-comment\"># 如果需要，在开头添加 BOS token</span><br>        <span class=\"hljs-keyword\">if</span> bos:<br>            t.insert(<span class=\"hljs-number\">0</span>, <span class=\"hljs-variable language_\">self</span>.bos_id)<br>        <span class=\"hljs-comment\"># 如果需要，在结尾添加 EOS token</span><br>        <span class=\"hljs-keyword\">if</span> eos:<br>            t.append(<span class=\"hljs-variable language_\">self</span>.eos_id)<br>        <span class=\"hljs-comment\"># 返回编码后的 token ID 列表</span><br>        <span class=\"hljs-keyword\">return</span> t<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">decode</span>(<span class=\"hljs-params\">self, t: <span class=\"hljs-type\">Sequence</span>[<span class=\"hljs-built_in\">int</span>]</span>) -&gt; <span class=\"hljs-built_in\">str</span>:<br>        <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">        Decodes a list of token IDs into a string.</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">        Args:</span><br><span class=\"hljs-string\">            t (List[int]): The list of token IDs to be decoded.</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">        Returns:</span><br><span class=\"hljs-string\">            str: The decoded string.</span><br><span class=\"hljs-string\">        &quot;&quot;&quot;</span><br>        <span class=\"hljs-comment\"># 将 token ID 序列解码为字符串</span><br>        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-variable language_\">self</span>.model.decode(cast(<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>], t))<br><br><span class=\"hljs-meta\">    @staticmethod</span><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">_split_whitespaces_or_nonwhitespaces</span>(<span class=\"hljs-params\"></span><br><span class=\"hljs-params\">        s: <span class=\"hljs-built_in\">str</span>, max_consecutive_slice_len: <span class=\"hljs-built_in\">int</span></span><br><span class=\"hljs-params\">    </span>) -&gt; Iterator[<span class=\"hljs-built_in\">str</span>]:<br>        <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">        Splits the string `s` so that each substring contains no more than `max_consecutive_slice_len`</span><br><span class=\"hljs-string\">        consecutive whitespaces or consecutive non-whitespaces.</span><br><span class=\"hljs-string\">        &quot;&quot;&quot;</span><br>        <span class=\"hljs-comment\"># 初始化当前子串的长度和类型</span><br>        current_slice_len = <span class=\"hljs-number\">0</span><br>        current_slice_is_space = s[<span class=\"hljs-number\">0</span>].isspace() <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">len</span>(s) &gt; <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">False</span><br>        slice_start = <span class=\"hljs-number\">0</span><br><br>        <span class=\"hljs-comment\"># 遍历字符串，按空格或非空格进行分割</span><br>        <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(<span class=\"hljs-built_in\">len</span>(s)):<br>            is_now_space = s[i].isspace()<br><br>            <span class=\"hljs-keyword\">if</span> current_slice_is_space ^ is_now_space:<br>                current_slice_len = <span class=\"hljs-number\">1</span><br>                current_slice_is_space = is_now_space<br>            <span class=\"hljs-keyword\">else</span>:<br>                current_slice_len += <span class=\"hljs-number\">1</span><br>                <span class=\"hljs-keyword\">if</span> current_slice_len &gt; max_consecutive_slice_len:<br>                    <span class=\"hljs-keyword\">yield</span> s[slice_start:i]<br>                    slice_start = i<br>                    current_slice_len = <span class=\"hljs-number\">1</span><br>        <span class=\"hljs-keyword\">yield</span> s[slice_start:]<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"逐行解释总结\"><a href=\"#逐行解释总结\" class=\"headerlink\" title=\"逐行解释总结\"></a>逐行解释总结</h3><ol>\n<li><p><strong>特殊 token 处理</strong>:</p>\n<ul>\n<li><code>special_tokens</code> 字典存储特殊 token 及其对应的 token ID。</li>\n<li><code>num_reserved_special_tokens</code> 定义了保留的特殊 token 数量。</li>\n<li><code>pat_str</code> 是正则表达式模式，用于匹配文本中的子词和特殊字符。</li>\n</ul>\n</li>\n<li><p><strong>初始化方法 (<code>__init__</code>)</strong>:</p>\n<ul>\n<li>加载 Tiktoken 模型的 BPE 合并表，并初始化特殊 token。</li>\n<li>设置 BOS、EOS 和 pad token 的 ID，并定义停止 token 集合。</li>\n<li>初始化 Tiktoken 的 <code>Encoding</code> 对象，用于实际的编码和解码操作。</li>\n</ul>\n</li>\n<li><p><strong>编码方法 (<code>encode</code>)</strong>:</p>\n<ul>\n<li>将输入字符串分割为子串，确保每个子串不超过最大字符数。</li>\n<li>对每个子串进行编码，并根据参数决定是否添加 BOS 和 EOS token。</li>\n<li>返回编码后的 token ID 列表。</li>\n</ul>\n</li>\n<li><p><strong>解码方法 (<code>decode</code>)</strong>:</p>\n<ul>\n<li>将 token ID 序列解码为字符串。</li>\n</ul>\n</li>\n<li><p><strong>子串分割方法 (<code>_split_whitespaces_or_nonwhitespaces</code>)</strong>:</p>\n<ul>\n<li><p>将字符串按空格或非空格进行分割，确保每个子串不超过最大连续字符数。</p>\n</li>\n<li><h3 id=\"什么保留空格？\"><a href=\"#什么保留空格？\" class=\"headerlink\" title=\"什么保留空格？\"></a><strong>什么保留空格？</strong></h3><ol>\n<li><strong>语义完整性</strong>:<ul>\n<li>空格在文本中用于分隔单词、标点符号等，是文本结构的重要组成部分。</li>\n<li>如果丢弃空格，分词结果可能会将多个单词合并，导致语义错误。例如：<ul>\n<li>输入: <code>&quot;Hello, how are you?&quot;</code></li>\n<li>丢弃空格: <code>&quot;Hello,howareyou?&quot;</code>（分词结果错误）</li>\n<li>保留空格: <code>&quot;Hello, how are you?&quot;</code>（分词结果正确）</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><strong>特殊 token 处理</strong>:<ul>\n<li>某些特殊 token（如 <code>&lt;|end_of_text|&gt;</code>）可能被空格包围，保留空格可以确保这些特殊 token 被正确识别和处理。</li>\n</ul>\n</li>\n<li><strong>模型输入格式</strong>:<ul>\n<li>许多语言模型（如 GPT）的输入需要保留空格，以确保生成的文本格式正确。</li>\n</ul>\n</li>\n</ol>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"对输入字符串进行tokenize的详细流程\"><a href=\"#对输入字符串进行tokenize的详细流程\" class=\"headerlink\" title=\"对输入字符串进行tokenize的详细流程\"></a>对输入字符串进行tokenize的详细流程</h3><p>结合一个具体的字符串示例，详细说明 <code>Tokenizer</code> 如何处理输入字符串。假设我们已经有一个 Tiktoken 模型文件，并且输入字符串为：</p>\n<figure class=\"highlight 1c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs 1c\"><span class=\"hljs-string\">&quot;Hello, how are you? &lt;|end_of_text|&gt;&quot;</span><br></code></pre></td></tr></table></figure>\n\n<p>我们将逐步分析 <code>Tokenizer</code> 如何处理这个字符串。</p>\n<hr>\n<h4 id=\"1-输入字符串\"><a href=\"#1-输入字符串\" class=\"headerlink\" title=\"1. 输入字符串\"></a><strong>1. 输入字符串</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">s = <span class=\"hljs-string\">&quot;Hello, how are you? &lt;|end_of_text|&gt;&quot;</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"2-参数设置\"><a href=\"#2-参数设置\" class=\"headerlink\" title=\"2. 参数设置\"></a><strong>2. 参数设置</strong></h4><p>假设调用 <code>encode</code> 方法时，参数如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">bos = <span class=\"hljs-literal\">True</span>  <span class=\"hljs-comment\"># 添加 BOS token</span><br>eos = <span class=\"hljs-literal\">False</span>  <span class=\"hljs-comment\"># 不添加 EOS token</span><br>allowed_special = &#123;<span class=\"hljs-string\">&quot;&lt;|end_of_text|&gt;&quot;</span>&#125;  <span class=\"hljs-comment\"># 允许的特殊 token</span><br>disallowed_special = ()  <span class=\"hljs-comment\"># 不允许的特殊 token（为空）</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"3-输入验证\"><a href=\"#3-输入验证\" class=\"headerlink\" title=\"3. 输入验证\"></a><strong>3. 输入验证</strong></h4><ul>\n<li><strong>类型检查</strong>:<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">assert</span> <span class=\"hljs-built_in\">type</span>(s) <span class=\"hljs-keyword\">is</span> <span class=\"hljs-built_in\">str</span><br></code></pre></td></tr></table></figure>\n输入是一个字符串，检查通过。</li>\n</ul>\n<hr>\n<h4 id=\"4-字符串分割\"><a href=\"#4-字符串分割\" class=\"headerlink\" title=\"4. 字符串分割\"></a><strong>4. 字符串分割</strong></h4><p>由于输入字符串较短（远小于 <code>TIKTOKEN_MAX_ENCODE_CHARS = 400_000</code>），不需要按字符数分割。但为了演示，我们假设字符串较长，需要按空格和非空格进行分割。</p>\n<h5 id=\"分割逻辑\"><a href=\"#分割逻辑\" class=\"headerlink\" title=\"分割逻辑\"></a><strong>分割逻辑</strong></h5><ul>\n<li>输入字符串: <code>&quot;Hello, how are you? &lt;|end_of_text|&gt;&quot;</code></li>\n<li>按空格和非空格分割：<ul>\n<li><code>&quot;Hello,&quot;</code>（非空格）</li>\n<li><code>&quot; how &quot;</code>（空格）</li>\n<li><code>&quot;are&quot;</code>（非空格）</li>\n<li><code>&quot; you? &quot;</code>（空格）</li>\n<li><code>&quot;&lt;|end_of_text|&gt;&quot;</code>（非空格）</li>\n</ul>\n</li>\n</ul>\n<h5 id=\"分割结果\"><a href=\"#分割结果\" class=\"headerlink\" title=\"分割结果\"></a><strong>分割结果</strong></h5><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">substrs = [<span class=\"hljs-string\">&quot;Hello,&quot;</span>, <span class=\"hljs-string\">&quot; how &quot;</span>, <span class=\"hljs-string\">&quot;are&quot;</span>, <span class=\"hljs-string\">&quot; you? &quot;</span>, <span class=\"hljs-string\">&quot;&lt;|end_of_text|&gt;&quot;</span>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"5-子串编码\"><a href=\"#5-子串编码\" class=\"headerlink\" title=\"5. 子串编码\"></a><strong>5. 子串编码</strong></h4><p>对每个子串进行编码，生成 token ID 序列。</p>\n<h5 id=\"假设的-Tiktoken-模型\"><a href=\"#假设的-Tiktoken-模型\" class=\"headerlink\" title=\"假设的 Tiktoken 模型\"></a><strong>假设的 Tiktoken 模型</strong></h5><p>假设 Tiktoken 模型的词汇表和编码规则如下：</p>\n<ul>\n<li><code>&quot;Hello&quot;</code> → <code>[15496]</code></li>\n<li><code>&quot;,&quot;</code> → <code>[11]</code></li>\n<li><code>&quot; how&quot;</code> → <code>[703]</code></li>\n<li><code>&quot;are&quot;</code> → <code>[527]</code></li>\n<li><code>&quot; you&quot;</code> → <code>[366]</code></li>\n<li><code>&quot;?&quot;</code> → <code>[30]</code></li>\n<li><code>&quot;&lt;|end_of_text|&gt;&quot;</code> → <code>[50256]</code>（特殊 token）</li>\n</ul>\n<h5 id=\"编码过程\"><a href=\"#编码过程\" class=\"headerlink\" title=\"编码过程\"></a><strong>编码过程</strong></h5><ol>\n<li><strong>子串 <code>&quot;Hello,&quot;</code></strong>:<ul>\n<li>编码为 <code>[15496, 11]</code>。</li>\n</ul>\n</li>\n<li><strong>子串 <code>&quot; how &quot;</code></strong>:<ul>\n<li>编码为 <code>[703]</code>。</li>\n</ul>\n</li>\n<li><strong>子串 <code>&quot;are&quot;</code></strong>:<ul>\n<li>编码为 <code>[527]</code>。</li>\n</ul>\n</li>\n<li><strong>子串 <code>&quot; you? &quot;</code></strong>:<ul>\n<li>编码为 <code>[366, 30]</code>。</li>\n</ul>\n</li>\n<li><strong>子串 <code>&quot;&lt;|end_of_text|&gt;&quot;</code></strong>:<ul>\n<li>这是一个特殊 token，编码为 <code>[50256]</code>。</li>\n</ul>\n</li>\n</ol>\n<h5 id=\"编码结果\"><a href=\"#编码结果\" class=\"headerlink\" title=\"编码结果\"></a><strong>编码结果</strong></h5><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">t = [<span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"6-添加特殊-token\"><a href=\"#6-添加特殊-token\" class=\"headerlink\" title=\"6. 添加特殊 token\"></a><strong>6. 添加特殊 token</strong></h4><p>根据参数设置，需要在开头添加 BOS token，不添加 EOS token。</p>\n<h5 id=\"BOS-token\"><a href=\"#BOS-token\" class=\"headerlink\" title=\"BOS token\"></a><strong>BOS token</strong></h5><p>假设 BOS token 的 ID 为 <code>50257</code>：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">if</span> bos:<br>    t.insert(<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">50257</span>)<br></code></pre></td></tr></table></figure>\n\n<h5 id=\"更新后的-token-序列\"><a href=\"#更新后的-token-序列\" class=\"headerlink\" title=\"更新后的 token 序列\"></a><strong>更新后的 token 序列</strong></h5><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">t = [<span class=\"hljs-number\">50257</span>, <span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"7-返回编码结果\"><a href=\"#7-返回编码结果\" class=\"headerlink\" title=\"7. 返回编码结果\"></a><strong>7. 返回编码结果</strong></h4><p>最终的 token ID 序列为：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50257</span>, <span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"8-解码过程\"><a href=\"#8-解码过程\" class=\"headerlink\" title=\"8. 解码过程\"></a><strong>8. 解码过程</strong></h4><p>如果需要将 token ID 序列解码回字符串，可以使用 <code>decode</code> 方法。</p>\n<h5 id=\"解码逻辑\"><a href=\"#解码逻辑\" class=\"headerlink\" title=\"解码逻辑\"></a><strong>解码逻辑</strong></h5><ul>\n<li>将每个 token ID 映射回对应的子词或字符。</li>\n<li>特殊 token（如 <code>&lt;|end_of_text|&gt;</code>）会被解码为原始字符串。</li>\n</ul>\n<h5 id=\"解码结果\"><a href=\"#解码结果\" class=\"headerlink\" title=\"解码结果\"></a><strong>解码结果</strong></h5><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">decoded_str = <span class=\"hljs-string\">&quot;&lt;|begin_of_text|&gt;Hello, how are you? &lt;|end_of_text|&gt;&quot;</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"9-总结\"><a href=\"#9-总结\" class=\"headerlink\" title=\"9. 总结\"></a><strong>9. 总结</strong></h4><p>结合具体示例，<code>Tokenizer</code> 处理输入字符串的详细流程如下：</p>\n<ol>\n<li><strong>输入字符串</strong>: <code>&quot;Hello, how are you? &lt;|end_of_text|&gt;&quot;</code></li>\n<li><strong>分割字符串</strong>: 按空格和非空格分割为 <code>[&quot;Hello,&quot;, &quot; how &quot;, &quot;are&quot;, &quot; you? &quot;, &quot;&lt;|end_of_text|&gt;&quot;]</code>。</li>\n<li><strong>编码子串</strong>: 将每个子串编码为 token ID 序列 <code>[15496, 11, 703, 527, 366, 30, 50256]</code>。</li>\n<li><strong>添加 BOS token</strong>: 在开头插入 BOS token，得到 <code>[50257, 15496, 11, 703, 527, 366, 30, 50256]</code>。</li>\n<li><strong>返回结果</strong>: 返回最终的 token ID 序列。</li>\n<li><strong>解码</strong>: 将 token ID 序列解码回原始字符串 <code>&quot;&lt;|begin_of_text|&gt;Hello, how are you? &lt;|end_of_text|&gt;&quot;</code>。</li>\n</ol>\n<p>通过这种分步骤的处理方式，<code>Tokenizer</code> 能够高效地将输入字符串转换为模型可处理的 token ID 序列，并支持特殊 token 的灵活处理。</p>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a>总结</h3><p><code>Tokenizer</code> 类负责文本的编码和解码，使用 Tiktoken 作为底层分词器。它支持特殊 token 的处理，并提供了灵活的编码和解码接口。通过 <code>encode</code> 方法，可以将文本转换为 token ID 序列；通过 <code>decode</code> 方法，可以将 token ID 序列转换回文本。此外，<code>Tokenizer</code> 还提供了对长文本的分割功能，确保编码过程不会因输入过长而失败。</p>\n<h2 id=\"ChatFormat类\"><a href=\"#ChatFormat类\" class=\"headerlink\" title=\"ChatFormat类\"></a>ChatFormat类</h2><p><code>ChatFormat</code> 类的主要功能是将对话消息（<code>Message</code>）编码为模型可以理解的 token 序列，特别适用于对话生成任务。</p>\n<hr>\n<h3 id=\"代码注释\"><a href=\"#代码注释\" class=\"headerlink\" title=\"代码注释\"></a><strong>代码注释</strong></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ChatFormat</span>:<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, tokenizer: Tokenizer</span>):<br>        <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">        初始化 ChatFormat 类。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">        Args:</span><br><span class=\"hljs-string\">            tokenizer (Tokenizer): 用于编码和解码的 Tokenizer 实例。</span><br><span class=\"hljs-string\">        &quot;&quot;&quot;</span><br>        <span class=\"hljs-variable language_\">self</span>.tokenizer = tokenizer<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li><strong>功能</strong>: 初始化 <code>ChatFormat</code> 类，绑定一个 <code>Tokenizer</code> 实例，用于后续的编码操作。</li>\n<li><strong>参数</strong>:<ul>\n<li><code>tokenizer</code>: 一个 <code>Tokenizer</code> 对象，用于将文本转换为 token ID 序列。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">encode_header</span>(<span class=\"hljs-params\">self, message: Message</span>) -&gt; <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]:<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    编码消息头，包括角色信息和分隔符。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    Args:</span><br><span class=\"hljs-string\">        message (Message): 包含角色和内容的消息字典。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    Returns:</span><br><span class=\"hljs-string\">        List[int]: 编码后的 token ID 序列。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    tokens = []<br>    <span class=\"hljs-comment\"># 添加消息头开始标记</span><br>    tokens.append(<span class=\"hljs-variable language_\">self</span>.tokenizer.special_tokens[<span class=\"hljs-string\">&quot;&lt;|start_header_id|&gt;&quot;</span>])<br>    <span class=\"hljs-comment\"># 编码角色信息（如 &quot;user&quot; 或 &quot;assistant&quot;）</span><br>    tokens.extend(<span class=\"hljs-variable language_\">self</span>.tokenizer.encode(message[<span class=\"hljs-string\">&quot;role&quot;</span>], bos=<span class=\"hljs-literal\">False</span>, eos=<span class=\"hljs-literal\">False</span>))<br>    <span class=\"hljs-comment\"># 添加消息头结束标记</span><br>    tokens.append(<span class=\"hljs-variable language_\">self</span>.tokenizer.special_tokens[<span class=\"hljs-string\">&quot;&lt;|end_header_id|&gt;&quot;</span>])<br>    <span class=\"hljs-comment\"># 添加换行符（两个换行符，用于分隔消息头和内容）</span><br>    tokens.extend(<span class=\"hljs-variable language_\">self</span>.tokenizer.encode(<span class=\"hljs-string\">&quot;\\n\\n&quot;</span>, bos=<span class=\"hljs-literal\">False</span>, eos=<span class=\"hljs-literal\">False</span>))<br>    <span class=\"hljs-keyword\">return</span> tokens<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li><strong>功能</strong>: 编码消息头，包括角色信息和分隔符。</li>\n<li><strong>参数</strong>:<ul>\n<li><code>message</code>: 一个 <code>Message</code> 字典，包含 <code>role</code>（角色）和 <code>content</code>（内容）。</li>\n</ul>\n</li>\n<li><strong>返回值</strong>: 编码后的 token ID 序列。</li>\n<li><strong>详细步骤</strong>:<ol>\n<li>添加消息头开始标记 <code>&lt;|start_header_id|&gt;</code>。</li>\n<li>编码角色信息（如 <code>&quot;user&quot;</code> 或 <code>&quot;assistant&quot;</code>）。</li>\n<li>添加消息头结束标记 <code>&lt;|end_header_id|&gt;</code>。</li>\n<li>添加两个换行符 <code>\\n\\n</code>，用于分隔消息头和内容。</li>\n</ol>\n</li>\n</ul>\n<hr>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">encode_message</span>(<span class=\"hljs-params\">self, message: Message</span>) -&gt; <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]:<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    编码整个消息，包括消息头和内容。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    Args:</span><br><span class=\"hljs-string\">        message (Message): 包含角色和内容的消息字典。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    Returns:</span><br><span class=\"hljs-string\">        List[int]: 编码后的 token ID 序列。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 编码消息头</span><br>    tokens = <span class=\"hljs-variable language_\">self</span>.encode_header(message)<br>    <span class=\"hljs-comment\"># 编码消息内容，并去除首尾空白字符</span><br>    tokens.extend(<br>        <span class=\"hljs-variable language_\">self</span>.tokenizer.encode(message[<span class=\"hljs-string\">&quot;content&quot;</span>].strip(), bos=<span class=\"hljs-literal\">False</span>, eos=<span class=\"hljs-literal\">False</span>)<br>    )<br>    <span class=\"hljs-comment\"># 添加消息结束标记 &lt;|eot_id|&gt;</span><br>    tokens.append(<span class=\"hljs-variable language_\">self</span>.tokenizer.special_tokens[<span class=\"hljs-string\">&quot;&lt;|eot_id|&gt;&quot;</span>])<br>    <span class=\"hljs-keyword\">return</span> tokens<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li><strong>功能</strong>: 编码整个消息，包括消息头和内容。</li>\n<li><strong>参数</strong>:<ul>\n<li><code>message</code>: 一个 <code>Message</code> 字典，包含 <code>role</code>（角色）和 <code>content</code>（内容）。</li>\n</ul>\n</li>\n<li><strong>返回值</strong>: 编码后的 token ID 序列。</li>\n<li><strong>详细步骤</strong>:<ol>\n<li>调用 <code>encode_header</code> 方法，编码消息头。</li>\n<li>编码消息内容，并去除首尾空白字符。</li>\n<li>添加消息结束标记 <code>&lt;|eot_id|&gt;</code>，表示当前消息的结束。</li>\n</ol>\n</li>\n</ul>\n<hr>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">encode_dialog_prompt</span>(<span class=\"hljs-params\">self, dialog: Dialog</span>) -&gt; <span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]:<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    编码整个对话，生成模型输入的 token 序列。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    Args:</span><br><span class=\"hljs-string\">        dialog (Dialog): 对话列表，包含多条消息。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    Returns:</span><br><span class=\"hljs-string\">        List[int]: 编码后的 token ID 序列。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    tokens = []<br>    <span class=\"hljs-comment\"># 添加对话开始标记 &lt;|begin_of_text|&gt;</span><br>    tokens.append(<span class=\"hljs-variable language_\">self</span>.tokenizer.special_tokens[<span class=\"hljs-string\">&quot;&lt;|begin_of_text|&gt;&quot;</span>])<br>    <span class=\"hljs-comment\"># 编码每条消息</span><br>    <span class=\"hljs-keyword\">for</span> message <span class=\"hljs-keyword\">in</span> dialog:<br>        tokens.extend(<span class=\"hljs-variable language_\">self</span>.encode_message(message))<br>    <span class=\"hljs-comment\"># 添加助手消息的开始标记，供模型生成回复</span><br>    tokens.extend(<span class=\"hljs-variable language_\">self</span>.encode_header(&#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;assistant&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;&quot;</span>&#125;))<br>    <span class=\"hljs-keyword\">return</span> tokens<br></code></pre></td></tr></table></figure>\n\n<ul>\n<li><strong>功能</strong>: 编码整个对话，生成模型输入的 token 序列。</li>\n<li><strong>参数</strong>:<ul>\n<li><code>dialog</code>: 一个 <code>Dialog</code> 列表，包含多条消息。</li>\n</ul>\n</li>\n<li><strong>返回值</strong>: 编码后的 token ID 序列。</li>\n<li><strong>详细步骤</strong>:<ol>\n<li>添加对话开始标记 <code>&lt;|begin_of_text|&gt;</code>。</li>\n<li>遍历对话中的每条消息，调用 <code>encode_message</code> 方法进行编码。</li>\n<li>添加助手消息的开始标记（包括角色信息和分隔符），供模型生成回复。</li>\n</ol>\n</li>\n</ul>\n<hr>\n<h3 id=\"总结-1\"><a href=\"#总结-1\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h3><h4 id=\"功能\"><a href=\"#功能\" class=\"headerlink\" title=\"功能\"></a><strong>功能</strong></h4><p><code>ChatFormat</code> 类的主要功能是将对话消息（<code>Message</code>）编码为模型可以理解的 token 序列。它特别适用于对话生成任务，能够处理多轮对话，并生成符合模型输入格式的 token 序列。</p>\n<h4 id=\"核心方法\"><a href=\"#核心方法\" class=\"headerlink\" title=\"核心方法\"></a><strong>核心方法</strong></h4><ol>\n<li><p><strong><code>encode_header</code></strong>:</p>\n<ul>\n<li>编码消息头，包括角色信息和分隔符。</li>\n<li>用于标识每条消息的角色（如 <code>&quot;user&quot;</code> 或 <code>&quot;assistant&quot;</code>）。</li>\n</ul>\n</li>\n<li><p><strong><code>encode_message</code></strong>:</p>\n<ul>\n<li>编码整个消息，包括消息头和内容。</li>\n<li>在消息末尾添加结束标记 <code>&lt;|eot_id|&gt;</code>，表示当前消息的结束。</li>\n</ul>\n</li>\n<li><p><strong><code>encode_dialog_prompt</code></strong>:</p>\n<ul>\n<li>编码整个对话，生成模型输入的 token 序列。</li>\n<li>在对话末尾添加助手消息的开始标记，供模型生成回复。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"特殊-token\"><a href=\"#特殊-token\" class=\"headerlink\" title=\"特殊 token\"></a><strong>特殊 token</strong></h4><ul>\n<li><code>&lt;|begin_of_text|&gt;</code>: 对话开始标记。</li>\n<li><code>&lt;|start_header_id|&gt;</code>: 消息头开始标记。</li>\n<li><code>&lt;|end_header_id|&gt;</code>: 消息头结束标记。</li>\n<li><code>&lt;|eot_id|&gt;</code>: 消息结束标记。</li>\n</ul>\n<h4 id=\"适用场景\"><a href=\"#适用场景\" class=\"headerlink\" title=\"适用场景\"></a><strong>适用场景</strong></h4><ul>\n<li><strong>对话生成</strong>: 将多轮对话编码为模型输入，生成助手的回复。</li>\n<li><strong>消息格式化</strong>: 确保每条消息的格式符合模型的要求，包括角色信息和内容分隔符。</li>\n</ul>\n<h4 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a><strong>示例</strong></h4><p>假设有以下对话：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">dialog = [<br>    &#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;user&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;Hello, how are you?&quot;</span>&#125;,<br>    &#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;assistant&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;I&#x27;m fine, thank you!&quot;</span>&#125;,<br>]<br></code></pre></td></tr></table></figure>\n<p>调用 <code>encode_dialog_prompt(dialog)</code> 后，生成的 token 序列可能如下：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<br>    &lt;|begin_of_text|&gt;,<br>    &lt;|start_header_id|&gt;, <span class=\"hljs-string\">&quot;user&quot;</span>, &lt;|end_header_id|&gt;, <span class=\"hljs-string\">&quot;\\n\\n&quot;</span>, <span class=\"hljs-string\">&quot;Hello, how are you?&quot;</span>, &lt;|eot_id|&gt;,<br>    &lt;|start_header_id|&gt;, <span class=\"hljs-string\">&quot;assistant&quot;</span>, &lt;|end_header_id|&gt;, <span class=\"hljs-string\">&quot;\\n\\n&quot;</span>, <span class=\"hljs-string\">&quot;I&#x27;m fine, thank you!&quot;</span>, &lt;|eot_id|&gt;,<br>    &lt;|start_header_id|&gt;, <span class=\"hljs-string\">&quot;assistant&quot;</span>, &lt;|end_header_id|&gt;, <span class=\"hljs-string\">&quot;\\n\\n&quot;</span><br>]<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"总结-2\"><a href=\"#总结-2\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h4><p><code>ChatFormat</code> 类通过定义清晰的对话格式和特殊 token，确保对话消息能够被模型正确理解和处理。它是对话生成任务中不可或缺的一部分，能够有效提升模型生成回复的准确性和连贯性。</p>\n<h2 id=\"Message-实例解析\"><a href=\"#Message-实例解析\" class=\"headerlink\" title=\"Message 实例解析\"></a><strong>Message</strong> 实例解析</h2><p>结合实际的 <code>Message</code> 输入，详细说明 <code>Tokenizer</code> 和 <code>ChatFormat</code> 两个类如何协同工作，从 <code>Message</code> 输入到输出的完整流程。我们将重点关注 <code>encode_message</code>、<code>decode_message</code> 和 <code>encode_dialog_prompt</code> 方法，并明确区分 <code>encode_message</code> 和 <code>encode_dialog_prompt</code> 的输入和输出。</p>\n<hr>\n<h3 id=\"1-输入数据\"><a href=\"#1-输入数据\" class=\"headerlink\" title=\"1. 输入数据\"></a><strong>1. 输入数据</strong></h3><p>假设我们有以下 <code>Message</code> 和 <code>Dialog</code> 输入：</p>\n<h4 id=\"单个消息（Message）\"><a href=\"#单个消息（Message）\" class=\"headerlink\" title=\"单个消息（Message）\"></a><strong>单个消息（Message）</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">message = &#123;<br>    <span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;user&quot;</span>,<br>    <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;Hello, how are you?&quot;</span><br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"多轮对话（Dialog）\"><a href=\"#多轮对话（Dialog）\" class=\"headerlink\" title=\"多轮对话（Dialog）\"></a><strong>多轮对话（Dialog）</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">dialog = [<br>    &#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;user&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;Hello, how are you?&quot;</span>&#125;,<br>    &#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;assistant&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;I&#x27;m fine, thank you!&quot;</span>&#125;,<br>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"2-Tokenizer-和-ChatFormat-初始化\"><a href=\"#2-Tokenizer-和-ChatFormat-初始化\" class=\"headerlink\" title=\"2. Tokenizer 和 ChatFormat 初始化\"></a><strong>2. Tokenizer 和 ChatFormat 初始化</strong></h3><p>首先，我们需要初始化 <code>Tokenizer</code> 和 <code>ChatFormat</code> 类。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 假设模型文件路径为 &quot;tiktoken_model.model&quot;</span><br>tokenizer = Tokenizer(model_path=<span class=\"hljs-string\">&quot;tiktoken_model.model&quot;</span>)<br>chat_format = ChatFormat(tokenizer)<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"3-encode-message-的流程\"><a href=\"#3-encode-message-的流程\" class=\"headerlink\" title=\"3. encode_message 的流程\"></a><strong>3. encode_message 的流程</strong></h3><p><code>encode_message</code> 方法用于编码单个消息，包括消息头和内容。</p>\n<h4 id=\"输入\"><a href=\"#输入\" class=\"headerlink\" title=\"输入\"></a><strong>输入</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">message = &#123;<br>    <span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;user&quot;</span>,<br>    <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;Hello, how are you?&quot;</span><br>&#125;<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤\"></a><strong>步骤</strong></h4><ol>\n<li><p><strong>编码消息头</strong>:</p>\n<ul>\n<li>调用 <code>encode_header</code> 方法，生成消息头的 token 序列。</li>\n<li>假设 <code>encode_header</code> 返回的 token 序列为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>]  <span class=\"hljs-comment\"># &lt;|start_header_id|&gt;, &quot;user&quot;, &lt;|end_header_id|&gt;, &quot;\\n\\n&quot;</span><br></code></pre></td></tr></table></figure></li>\n</ul>\n</li>\n<li><p><strong>编码消息内容</strong>:</p>\n<ul>\n<li>调用 <code>Tokenizer.encode</code> 方法，编码消息内容 <code>&quot;Hello, how are you?&quot;</code>。</li>\n<li>假设返回的 token 序列为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>]  <span class=\"hljs-comment\"># &quot;Hello, how are you?&quot;</span><br></code></pre></td></tr></table></figure></li>\n</ul>\n</li>\n<li><p><strong>添加消息结束标记</strong>:</p>\n<ul>\n<li>添加 <code>&lt;|eot_id|&gt;</code> 标记，假设其 ID 为 <code>50256</code>。</li>\n<li>最终的 token 序列为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>]<br></code></pre></td></tr></table></figure></li>\n</ul>\n</li>\n</ol>\n<h4 id=\"输出\"><a href=\"#输出\" class=\"headerlink\" title=\"输出\"></a><strong>输出</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">encoded_message = chat_format.encode_message(message)<br><span class=\"hljs-comment\"># encoded_message = [50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256]</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"4-decode-message-的流程\"><a href=\"#4-decode-message-的流程\" class=\"headerlink\" title=\"4. decode_message 的流程\"></a><strong>4. decode_message 的流程</strong></h3><p><code>decode_message</code> 方法用于将 token 序列解码回原始消息。</p>\n<h4 id=\"输入-1\"><a href=\"#输入-1\" class=\"headerlink\" title=\"输入\"></a><strong>输入</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">encoded_message = [<span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>]<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"步骤-1\"><a href=\"#步骤-1\" class=\"headerlink\" title=\"步骤\"></a><strong>步骤</strong></h4><ol>\n<li><p><strong>解码 token 序列</strong>:</p>\n<ul>\n<li>调用 <code>Tokenizer.decode</code> 方法，将 token 序列解码为字符串。</li>\n<li>假设解码结果为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-string\">&quot;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHello, how are you?&lt;|eot_id|&gt;&quot;</span><br></code></pre></td></tr></table></figure></li>\n</ul>\n</li>\n<li><p><strong>提取消息内容</strong>:</p>\n<ul>\n<li>从解码结果中提取消息内容 <code>&quot;Hello, how are you?&quot;</code>。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"输出-1\"><a href=\"#输出-1\" class=\"headerlink\" title=\"输出\"></a><strong>输出</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">decoded_message = tokenizer.decode(encoded_message)<br><span class=\"hljs-comment\"># decoded_message = &quot;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\nHello, how are you?&lt;|eot_id|&gt;&quot;</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"5-encode-dialog-prompt-的流程\"><a href=\"#5-encode-dialog-prompt-的流程\" class=\"headerlink\" title=\"5. encode_dialog_prompt 的流程\"></a><strong>5. encode_dialog_prompt 的流程</strong></h3><p><code>encode_dialog_prompt</code> 方法用于编码整个对话，生成模型输入的 token 序列。</p>\n<h4 id=\"输入-2\"><a href=\"#输入-2\" class=\"headerlink\" title=\"输入\"></a><strong>输入</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">dialog = [<br>    &#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;user&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;Hello, how are you?&quot;</span>&#125;,<br>    &#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;assistant&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;I&#x27;m fine, thank you!&quot;</span>&#125;,<br>]<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"步骤-2\"><a href=\"#步骤-2\" class=\"headerlink\" title=\"步骤\"></a><strong>步骤</strong></h4><ol>\n<li><p><strong>添加对话开始标记</strong>:</p>\n<ul>\n<li>添加 <code>&lt;|begin_of_text|&gt;</code> 标记，假设其 ID 为 <code>50257</code>。</li>\n<li>当前的 token 序列为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50257</span>]<br></code></pre></td></tr></table></figure></li>\n</ul>\n</li>\n<li><p><strong>编码每条消息</strong>:</p>\n<ul>\n<li>对每条消息调用 <code>encode_message</code> 方法，生成 token 序列。</li>\n<li>假设第一条消息的 token 序列为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>]<br></code></pre></td></tr></table></figure></li>\n<li>假设第二条消息的 token 序列为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>]<br></code></pre></td></tr></table></figure></li>\n<li>将两条消息的 token 序列合并：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50257</span>, <span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>, <span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>]<br></code></pre></td></tr></table></figure></li>\n</ul>\n</li>\n<li><p><strong>添加助手消息的开始标记</strong>:</p>\n<ul>\n<li>添加助手消息的开始标记（包括角色信息和分隔符），供模型生成回复。</li>\n<li>假设生成的 token 序列为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>]<br></code></pre></td></tr></table></figure></li>\n<li>最终的 token 序列为：<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">[<span class=\"hljs-number\">50257</span>, <span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">15496</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>, <span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">703</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">366</span>, <span class=\"hljs-number\">30</span>, <span class=\"hljs-number\">50256</span>, <span class=\"hljs-number\">50258</span>, <span class=\"hljs-number\">527</span>, <span class=\"hljs-number\">50259</span>, <span class=\"hljs-number\">11</span>, <span class=\"hljs-number\">11</span>]<br></code></pre></td></tr></table></figure></li>\n</ul>\n</li>\n</ol>\n<h4 id=\"输出-2\"><a href=\"#输出-2\" class=\"headerlink\" title=\"输出\"></a><strong>输出</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">encoded_dialog = chat_format.encode_dialog_prompt(dialog)<br><span class=\"hljs-comment\"># encoded_dialog = [50257, 50258, 366, 50259, 11, 11, 15496, 11, 703, 527, 366, 30, 50256, 50258, 527, 50259, 11, 11, 366, 30, 703, 527, 366, 30, 50256, 50258, 527, 50259, 11, 11]</span><br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"6-区分-encode-message-和-encode-dialog-prompt\"><a href=\"#6-区分-encode-message-和-encode-dialog-prompt\" class=\"headerlink\" title=\"6. 区分 encode_message 和 encode_dialog_prompt\"></a><strong>6. 区分 encode_message 和 encode_dialog_prompt</strong></h3><h4 id=\"encode-message\"><a href=\"#encode-message\" class=\"headerlink\" title=\"encode_message\"></a><strong>encode_message</strong></h4><ul>\n<li><strong>输入</strong>: 单个 <code>Message</code> 字典。</li>\n<li><strong>输出</strong>: 编码后的 token 序列，包含消息头、内容和结束标记。</li>\n<li><strong>用途</strong>: 用于编码单条消息。</li>\n</ul>\n<h4 id=\"encode-dialog-prompt\"><a href=\"#encode-dialog-prompt\" class=\"headerlink\" title=\"encode_dialog_prompt\"></a><strong>encode_dialog_prompt</strong></h4><ul>\n<li><strong>输入</strong>: 一个 <code>Dialog</code> 列表，包含多条消息。</li>\n<li><strong>输出</strong>: 编码后的 token 序列，包含对话开始标记、所有消息的编码以及助手消息的开始标记。</li>\n<li><strong>用途</strong>: 用于编码整个对话，生成模型输入的 token 序列。</li>\n</ul>\n<hr>\n<h3 id=\"7-总结\"><a href=\"#7-总结\" class=\"headerlink\" title=\"7. 总结\"></a><strong>7. 总结</strong></h3><p>通过 <code>Tokenizer</code> 和 <code>ChatFormat</code> 两个类的协同工作，我们可以将 <code>Message</code> 和 <code>Dialog</code> 编码为模型可以理解的 token 序列，并能够将 token 序列解码回原始文本。以下是完整的流程总结：</p>\n<ol>\n<li><p><strong>单个消息编码</strong>:</p>\n<ul>\n<li>使用 <code>encode_message</code> 方法，将 <code>Message</code> 编码为 token 序列。</li>\n<li>输出包含消息头、内容和结束标记。</li>\n</ul>\n</li>\n<li><p><strong>对话编码</strong>:</p>\n<ul>\n<li>使用 <code>encode_dialog_prompt</code> 方法，将 <code>Dialog</code> 编码为 token 序列。</li>\n<li>输出包含对话开始标记、所有消息的编码以及助手消息的开始标记。</li>\n</ul>\n</li>\n<li><p><strong>解码</strong>:</p>\n<ul>\n<li>使用 <code>Tokenizer.decode</code> 方法，将 token 序列解码回原始文本。</li>\n</ul>\n</li>\n</ol>\n<p>通过这种方式，<code>Tokenizer</code> 和 <code>ChatFormat</code> 能够高效地处理对话数据，为语言模型提供格式化的输入。</p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n"},{"title":"llama3源码解析-03：model.py模块解析","date":"2024-12-30T04:00:00.000Z","_content":"\n![llama](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/Llama3_Repo.jpeg)\n\n\n\n## 整体\n\n`model.py` 模块是 Llama 3 模型的核心实现部分，主要负责定义和实现 Transformer 模型的结构及其相关组件。\n\n### 1. **模型参数定义 (`ModelArgs` 类)**\n   - `ModelArgs` 类是一个数据类，用于定义和存储模型的各种超参数，例如：\n     - `dim`: 模型的维度。\n     - `n_layers`: Transformer 的层数。\n     - `n_heads`: 注意力机制中的头数。\n     - `vocab_size`: 词汇表大小。\n     - `max_batch_size`: 最大批处理大小。\n     - `max_seq_len`: 最大序列长度。\n   - 这些参数在模型初始化时被使用，决定了模型的结构和行为。\n\n### 2. **RMSNorm 层 (`RMSNorm` 类)**\n   - `RMSNorm` 是一个自定义的归一化层，用于替代传统的 LayerNorm。它通过对输入进行**均方根归一化**来稳定训练过程。\n   - 该层在 Transformer 的每个子层（如注意力机制和前馈网络）之后使用。\n\n### 3. **RoPE (Rotary Positional Embedding)**\n   - 该模块实现了旋转位置编码（RoPE），用于为输入序列中的每个位置生成位置编码。RoPE 通过将位置信息嵌入到注意力机制中，帮助模型捕捉序列中的位置关系。\n   - `precompute_freqs_cis` 函数预计算了频率矩阵，`apply_rotary_emb` 函数将旋转**位置编码应用到查询和键向量上。**\n\n### 4. **注意力机制 (`Attention` 类)**\n   - `Attention` 类实现了多头注意力机制（Multi-Head Attention），这是 Transformer 模型的核心组件之一。\n   - 它使用 `ColumnParallelLinear` 和 `RowParallelLinear` 来实现并行的线性变换，支持模型并行化。\n   - 该模块还实现了键值缓存（KV Cache），用于在生成过程中缓存先前的键和值，以减少重复计算。\n\n### 5. **前馈网络 (`FeedForward` 类)**\n   - `FeedForward` 类实现了 Transformer 中的前馈神经网络（FFN），通常由两个线性变换和一个激活函数（如 SiLU）组成。\n   - 该模块也支持模型并行化，使用 `ColumnParallelLinear` 和 `RowParallelLinear` 来实现并行的线性变换。\n\n### 6. **Transformer 块 (`TransformerBlock` 类)**\n   - `TransformerBlock` 类将注意力机制和前馈网络组合在一起，形成一个完整的 Transformer 层。\n   - 每个 Transformer 块包含一个注意力层和一个前馈网络层，并且在每个子层之后应用 RMSNorm 进行归一化。\n\n### 7. **Transformer 模型 (`Transformer` 类)**\n   - `Transformer` 类是整个模型的核心，它由多个 `TransformerBlock` 组成，形成一个深层的 Transformer 网络。\n   - 该模块还负责处理输入嵌入、位置编码、以及最终的输出线性变换。\n   - `forward` 方法实现了模型的前向传播过程，包括嵌入、位置编码、多层 Transformer 块的处理以及最终的输出生成。\n\n### 8. **模型并行化**\n   - 该模块使用了 `fairscale` 库中的 `ColumnParallelLinear` 和 `RowParallelLinear` 来实现模型并行化，允许模型在多个 GPU 上分布计算，从而提高训练和推理的效率。\n\n### 9. **推理模式**\n   - 在推理模式下，模型使用 `torch.inference_mode()` 来禁用梯度计算，从而提高推理速度并减少内存占用。\n\n### 总结：\n`model.py` 模块定义了 Llama 3 模型的核心架构，包括 Transformer 的各个组件（如注意力机制、前馈网络、归一化层等），并实现了模型并行化和推理优化。它是整个 Llama 3 模型的基础，负责处理输入数据并生成输出。\n\n## 模型详细流程图\n\n```mermaid\ngraph TD\n    A[输入 tokens] --> B[Token Embedding]\n    B --> C[添加位置编码 freqs_cis]\n    C --> D[初始化 mask]\n    D --> E[进入 Transformer 层]\n    E --> F[Transformer Block 1]\n    E --> G[Transformer Block 2]\n    E --> H[...]\n    E --> I[Transformer Block N]\n    F --> J[输出 logits]\n    G --> J\n    H --> J\n    I --> J\n\n    subgraph Transformer Block\n        direction TB\n        K[输入] --> L[RMSNorm]\n        L --> M[Attention]\n        M --> N[Add & Norm]\n        N --> O[FeedForward]\n        O --> P[Add & Norm]\n        P --> Q[输出]\n    end\n\n    F --> K\n    G --> K\n    I --> K\n```\n\n1. **输入 tokens**  \n   - 输入是一个批次的 token IDs，形状为 `(batch_size, seq_len)`。\n\n2. **Token Embedding**  \n   - 通过 `tok_embeddings` 将 token IDs 转换为嵌入向量，形状为 `(batch_size, seq_len, dim)`。\n\n3. **添加位置编码 freqs_cis**  \n   - 使用预计算的 `freqs_cis` 为嵌入向量添加旋转位置编码，帮助模型捕捉序列中的位置信息。\n\n4. **初始化 mask**  \n   - 根据 `seq_len` 和 `start_pos` 生成注意力掩码 `mask`，用于防止模型看到未来的 token。\n\n5. **进入 Transformer 层**  \n   - 嵌入向量和位置编码进入多层 Transformer 块进行处理。\n\n6. **Transformer Block 1 到 N**  \n   - 每个 Transformer 块包含以下步骤：\n     - **RMSNorm**: 对输入进行归一化。\n     - **Attention**: 应用多头注意力机制，生成注意力输出。\n     - **RMSNorm**: 对注意力输出进行归一化。\n     - **FeedForward**: 应用前馈网络，生成最终的 Transformer 块输出。\n\n7. **应用 RMSNorm**  \n   - 在所有 Transformer 块处理完成后，对最终输出应用 RMSNorm 进行归一化。\n\n8. **输出线性变换**  \n   - 通过 `output` 线性层将归一化后的输出映射到词汇表空间，形状为 `(batch_size, seq_len, vocab_size)`。\n\n9. **输出 logits**  \n   - 返回最终的 logits，表示每个 token 的概率分布。\n\n\n\n## `class ModelArgs`\n\n```python\n@dataclass\nclass ModelArgs:\n    dim: int = 4096  # 模型的维度，即每个token的向量表示的大小\n    n_layers: int = 32  # 模型的层数，即Transformer的层数\n    n_heads: int = 32  # 注意力机制中的头数\n    n_kv_heads: Optional[int] = None  # 键值头的数量，如果为None，则与n_heads相同\n    vocab_size: int = -1  # 词汇表的大小，通常由tokenizer决定\n    multiple_of: int = 256  # SwiGLU激活函数中隐藏层大小的倍数，确保是256的倍数\n    ffn_dim_multiplier: Optional[float] = None  # 前馈网络维度的乘数，用于调整隐藏层大小\n    norm_eps: float = 1e-5  # Layer Normalization中的epsilon值，用于数值稳定性\n    rope_theta: float = 500000  # RoPE（Rotary Position Embedding）中的theta参数\n\n    max_batch_size: int = 32  # 最大批处理大小\n    max_seq_len: int = 2048  # 最大序列长度\n```\n\n## `class RMSNorm`\n```python\nclass RMSNorm(torch.nn.Module):\n    def __init__(self, dim: int, eps: float = 1e-6):\n        super().__init__()\n        self.eps = eps  # 用于数值稳定性的小值，防止除以零\n        self.weight = nn.Parameter(torch.ones(dim))  # 可学习的缩放参数，初始化为1\n\n    def _norm(self, x):\n        # 计算RMS（Root Mean Square）归一化，对输入x进行归一化处理\n        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n\n    def forward(self, x):\n        # 前向传播函数，先对输入x进行归一化，然后乘以可学习的缩放参数\n        output = self._norm(x.float()).type_as(x)  # 归一化并保持与输入x相同的数据类型\n        return output * self.weight  # 乘以缩放参数\n```\n\n### 解释：\n1. **`ModelArgs`**:\n   - 这是一个数据类，用于存储模型的配置参数。它定义了模型的结构和超参数，如模型的维度、层数、注意力头数等。\n   - `dim` 是每个token的向量表示的大小，`n_layers` 是Transformer的层数，`n_heads` 是注意力机制中的头数。\n   - `vocab_size` 是词汇表的大小，通常由tokenizer决定。\n   - `multiple_of` 和 `ffn_dim_multiplier` 用于调整前馈网络的隐藏层大小。\n   - `norm_eps` 是Layer Normalization中的epsilon值，用于数值稳定性。\n   - `rope_theta` 是RoPE（Rotary Position Embedding）中的theta参数，用于位置编码。\n   - `max_batch_size` 和 `max_seq_len` 分别定义了模型的最大批处理大小和最大序列长度。\n\n2. **`RMSNorm`**:\n   - 这是一个自定义的归一化层，类似于Layer Normalization，但使用了RMS（Root Mean Square）归一化。\n   - `_norm` 方法计算输入的RMS归一化值，`forward` 方法在前向传播时对输入进行归一化并乘以可学习的缩放参数。\n   - `eps` 是一个小值，用于防止除以零的情况，`weight` 是可学习的缩放参数，初始化为1。\n\n这两个类在模型中分别用于定义模型的结构和实现归一化操作，是Transformer模型的重要组成部分。\n\n\n\n---\n\n## 旋转位置编码\n\n### **`precompute_freqs_cis`**\n\n```python\ndef precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n    \"\"\"\n    预计算旋转位置编码的频率矩阵 (freqs_cis)。\n\n    旋转位置编码 (Rotary Positional Embedding, RoPE) 是一种将位置信息嵌入到注意力机制中的方法。\n    它通过将位置信息编码为复数形式，应用到查询和键向量上。\n\n    参数:\n        dim (int): 模型的维度（通常是注意力头的维度）。\n        end (int): 序列的最大长度。\n        theta (float): 控制频率的基数，默认为 10000.0。\n\n    返回:\n        freqs_cis (torch.Tensor): 预计算的频率矩阵，形状为 (end, dim // 2)，数据类型为 complex64。\n    \"\"\"\n    # 计算频率向量\n    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n    # 生成位置向量\n    t = torch.arange(end, device=freqs.device, dtype=torch.float32)\n    # 计算外积，得到频率矩阵\n    freqs = torch.outer(t, freqs)\n    # 将频率矩阵转换为复数形式（极坐标表示）\n    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n    return freqs_cis\n```\n\n#### 解释：\n- **作用**: 预计算旋转位置编码的频率矩阵 `freqs_cis`，用于将位置信息嵌入到查询和键向量中。\n- **输入**:\n  - `dim`: 模型的维度，通常是注意力头的维度。\n  - `end`: 序列的最大长度。\n  - `theta`: 控制频率的基数，默认为 10000.0。\n- **输出**:\n  - `freqs_cis`: 预计算的频率矩阵，形状为 `(end, dim // 2)`，数据类型为 `complex64`。\n- **关键点**:\n  - 使用 `torch.outer` 计算位置向量和频率向量的外积，得到频率矩阵。\n  - 通过 `torch.polar` 将频率矩阵转换为复数形式，表示极坐标。\n\n---\n\n### **`reshape_for_broadcast`**\n```python\ndef reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n    \"\"\"\n    将频率矩阵 `freqs_cis` 重塑为适合广播的形状，以便与查询或键向量进行逐元素操作。\n\n    参数:\n        freqs_cis (torch.Tensor): 频率矩阵，形状为 (seq_len, dim // 2)。\n        x (torch.Tensor): 查询或键向量，形状为 (batch_size, seq_len, n_heads, head_dim)。\n\n    返回:\n        freqs_cis (torch.Tensor): 重塑后的频率矩阵，形状为 (1, seq_len, 1, dim // 2)。\n    \"\"\"\n    ndim = x.ndim\n    assert 0 <= 1 < ndim\n    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n    # 重塑频率矩阵，使其形状为 (1, seq_len, 1, dim // 2)\n    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n    return freqs_cis.view(*shape)\n```\n\n#### 解释：\n- **作用**: 将频率矩阵 `freqs_cis` 重塑为适合广播的形状，以便与查询或键向量进行逐元素操作。\n- **输入**:\n  - `freqs_cis`: 频率矩阵，形状为 `(seq_len, dim // 2)`。\n  - `x`: 查询或键向量，形状为 `(batch_size, seq_len, n_heads, head_dim)`。\n- **输出**:\n  - 重塑后的频率矩阵，形状为 `(1, seq_len, 1, dim // 2)`。\n- **关键点**:\n  - 通过 `view` 方法将频率矩阵重塑为适合广播的形状，使其能够与查询或键向量进行逐元素操作。\n\n---\n\n### **`apply_rotary_emb`**\n```python\ndef apply_rotary_emb(\n    xq: torch.Tensor,\n    xk: torch.Tensor,\n    freqs_cis: torch.Tensor,\n) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    将旋转位置编码应用到查询和键向量上。\n\n    旋转位置编码通过将位置信息嵌入到查询和键向量中，帮助模型捕捉序列中的位置关系。\n\n    参数:\n        xq (torch.Tensor): 查询向量，形状为 (batch_size, seq_len, n_heads, head_dim)。\n        xk (torch.Tensor): 键向量，形状为 (batch_size, seq_len, n_heads, head_dim)。\n        freqs_cis (torch.Tensor): 频率矩阵，形状为 (1, seq_len, 1, head_dim // 2)。\n\n    返回:\n        xq_out (torch.Tensor): 应用旋转位置编码后的查询向量。\n        xk_out (torch.Tensor): 应用旋转位置编码后的键向量。\n    \"\"\"\n    # 将查询和键向量转换为复数形式\n    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n    # 重塑频率矩阵以匹配查询和键向量的形状\n    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n    # 应用旋转位置编码\n    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n    return xq_out.type_as(xq), xk_out.type_as(xk)\n```\n\n#### 解释：\n- **作用**: 将旋转位置编码应用到查询和键向量上，帮助模型捕捉序列中的位置关系。\n- **输入**:\n  - `xq`: 查询向量，形状为 `(batch_size, seq_len, n_heads, head_dim)`。\n  - `xk`: 键向量，形状为 `(batch_size, seq_len, n_heads, head_dim)`。\n  - `freqs_cis`: 频率矩阵，形状为 `(1, seq_len, 1, head_dim // 2)`。\n- **输出**:\n  - `xq_out`: 应用旋转位置编码后的查询向量。\n  - `xk_out`: 应用旋转位置编码后的键向量。\n- **关键点**:\n  - 使用 `torch.view_as_complex` 将查询和键向量转换为复数形式。\n  - 通过逐元素乘法将频率矩阵应用到查询和键向量上。\n  - 使用 `torch.view_as_real` 将结果转换回实数形式。\n  \n  \n  \n  这些函数共同实现了旋转位置编码（RoPE）\n  \n  ### 总结：\n  \n  - **`precompute_freqs_cis`**: 预计算旋转位置编码的频率矩阵。\n  - **`reshape_for_broadcast`**: 将频率矩阵重塑为适合广播的形状。\n  - **`apply_rotary_emb`**: 将旋转位置编码应用到查询和键向量上。\n\n---\n\n## **`repeat_kv`**\n```python\ndef repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:\n    \"\"\"\n    重复键或值向量，以匹配查询向量的头数。\n\n    在分组注意力机制中，键和值向量的头数可能少于查询向量的头数，因此需要重复键和值向量以匹配查询向量的头数。\n\n    参数:\n        x (torch.Tensor): 键或值向量，形状为 (batch_size, seq_len, n_kv_heads, head_dim)。\n        n_rep (int): 重复次数，通常为查询头数与键值头数的比值。\n\n    返回:\n        torch.Tensor: 重复后的键或值向量，形状为 (batch_size, seq_len, n_kv_heads * n_rep, head_dim)。\n    \"\"\"\n    bs, slen, n_kv_heads, head_dim = x.shape\n    if n_rep == 1:\n        return x\n    return (\n        x[:, :, :, None, :]\n        .expand(bs, slen, n_kv_heads, n_rep, head_dim)\n        .reshape(bs, slen, n_kv_heads * n_rep, head_dim)\n    )\n```\n\n#### 解释：\n- **作用**: 重复键或值向量，以匹配查询向量的头数。\n- **输入**:\n  - `x`: 键或值向量，形状为 `(batch_size, seq_len, n_kv_heads, head_dim)`。\n  - `n_rep`: 重复次数，通常为查询头数与键值头数的比值。\n- **输出**:\n  - 重复后的键或值向量，形状为 `(batch_size, seq_len, n_kv_heads * n_rep, head_dim)`。\n- **关键点**:\n  - 使用 `expand` 和 `reshape` 方法重复键或值向量，使其头数与查询向量匹配。\n\n## `class Attention` \n\n`class Attention` 实现了 Transformer 中的 **多头注意力机制（Multi-Head Attention）**，它是 Transformer 模型的核心组件之一。以下是该类的详细解释：\n\n#### **主要功能**：\n1. **多头注意力机制**：\n   - 将输入向量拆分为多个头，每个头独立计算注意力分数。\n   - 通过并行计算，捕捉输入序列中不同位置之间的关系。\n\n2. **键值缓存（KV Cache）**：\n   - 在生成任务中，缓存先前的键和值，避免重复计算，提高效率。\n\n3. **模型并行化**：\n   - 使用 `ColumnParallelLinear` 和 `RowParallelLinear` 实现并行的线性变换，支持多 GPU 计算。\n\n#### **关键组件**：\n1. **线性变换**：\n   - `wq`、`wk`、`wv`：分别对输入进行线性变换，生成查询（Query）、键（Key）和值（Value）向量。\n   - `wo`：将多头注意力的输出进行线性变换，合并为最终输出。\n\n2. **键值缓存**：\n   - `cache_k` 和 `cache_v`：用于缓存先前的键和值，形状为 `(batch_size, max_seq_len, n_local_kv_heads, head_dim)`。\n\n3. **旋转位置编码（RoPE）**：\n   - 通过 `apply_rotary_emb` 将位置信息嵌入到查询和键向量中。\n\n4. **注意力分数计算**：\n   - 计算查询和键的点积，除以 `sqrt(head_dim)` 进行缩放，然后应用 Softmax 得到注意力分数。\n\n5. **输出计算**：\n   - 使用注意力分数对值向量进行加权求和，得到多头注意力的输出。\n\n---\n\n### **`流程图**\n\n```mermaid\ngraph TD\n    A[输入 x] --> B[线性变换]\n    B --> C[生成 Query]\n    B --> D[生成 Key]\n    B --> E[生成 Value]\n    C --> F[应用旋转位置编码]\n    D --> F\n    F --> G[更新键值缓存]\n    G --> H[计算注意力分数]\n    H --> I[应用 Softmax]\n    I --> J[加权求和]\n    J --> K[线性变换]\n    K --> L[输出]\n```\n\n### **详细步骤说明**：\n\n1. **输入 x**  \n   - 输入是一个批次的嵌入向量，形状为 `(batch_size, seq_len, dim)`。\n\n2. **线性变换**  \n   - 通过 `wq`、`wk`、`wv` 分别对输入进行线性变换，生成查询（Query）、键（Key）和值（Value）向量。\n\n3. **生成 Query、Key、Value**  \n   - 查询向量形状为 `(batch_size, seq_len, n_local_heads, head_dim)`。\n   - 键和值向量形状为 `(batch_size, seq_len, n_local_kv_heads, head_dim)`。\n\n4. **应用旋转位置编码**  \n   - 使用 `apply_rotary_emb` 将旋转位置编码应用到查询和键向量上。\n\n5. **更新键值缓存**  \n   - 将当前的键和值向量缓存到 `cache_k` 和 `cache_v` 中。\n\n6. **计算注意力分数**  \n   - 计算查询和键的点积，除以 `sqrt(head_dim)` 进行缩放，得到注意力分数。\n\n7. **应用 Softmax**  \n   - 对注意力分数应用 Softmax，得到归一化的注意力权重。\n\n8. **加权求和**  \n   - 使用注意力权重对值向量进行加权求和，得到多头注意力的输出。\n\n9. **线性变换**  \n   - 通过 `wo` 对多头注意力的输出进行线性变换，合并为最终输出。\n\n10. **输出**  \n    - 返回最终的输出，形状为 `(batch_size, seq_len, dim)`。\n\n---\n\n### **代码实现的关键点**：\n1. **并行化**：\n   - 使用 `ColumnParallelLinear` 和 `RowParallelLinear` 实现并行的线性变换，支持多 GPU 计算。\n\n2. **键值缓存**：\n   - 在生成任务中，缓存先前的键和值，避免重复计算，提高效率。\n\n3. **旋转位置编码**：\n   - 通过 `apply_rotary_emb` 将位置信息嵌入到查询和键向量中，帮助模型捕捉序列中的位置关系。\n\n4. **注意力分数计算**：\n   - 使用点积计算注意力分数，并通过 Softmax 进行归一化。\n\n5. **输出计算**：\n   - 使用注意力权重对值向量进行加权求和，得到多头注意力的输出。\n\n---\n\n### **总结**：\n`class Attention` 实现了 Transformer 中的多头注意力机制，通过并行化、键值缓存和旋转位置编码等技术，高效地捕捉输入序列中的关系。\n\n## `FeedForward` \n\n```mermaid\ngraph TD\n    A[输入 x] --> B[线性变换 W1]\n    B --> C[激活函数 SiLU]\n    C --> D[线性变换 W3]\n    D --> E[逐元素乘法]\n    E --> F[线性变换 W2]\n    F --> G[输出]\n```\n\n### **详细步骤说明**：\n\n1. **输入 x**  \n   - 输入是一个批次的向量，形状为 `(batch_size, seq_len, dim)`。\n\n2. **线性变换 W1**  \n   - 通过 `w1` 对输入进行线性变换，生成中间向量，形状为 `(batch_size, seq_len, hidden_dim)`。\n\n3. **激活函数 SiLU**  \n   - 对线性变换后的结果应用 SiLU（Sigmoid Linear Unit）激活函数，公式为：  \n   \n     ![](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241230114851133.png)\n   \n4. **线性变换 W3**  \n   \n   - 通过 `w3` 对输入进行另一个线性变换，生成中间向量，形状为 `(batch_size, seq_len, hidden_dim)`。\n   \n5. **逐元素乘法**  \n   \n   - 将 `SiLU(W1(x))` 和 `W3(x)` 进行逐元素乘法，生成加权后的中间向量。\n   \n6. **线性变换 W2**  \n   - 通过 `w2` 对加权后的中间向量进行线性变换，生成最终输出，形状为 `(batch_size, seq_len, dim)`。\n\n7. **输出**  \n   - 返回最终的输出，作为前馈网络的结果。\n\n---\n\n### **代码实现的关键点**：\n1. **并行化**：\n   - 使用 `ColumnParallelLinear` 和 `RowParallelLinear` 实现并行的线性变换，支持多 GPU 计算。\n\n2. **激活函数**：\n   - 使用 SiLU 激活函数，结合了 Sigmoid 和线性变换的优点，增强了模型的非线性表达能力。\n\n3. **逐元素乘法**：\n   - 将两个线性变换的结果进行逐元素乘法，生成加权后的中间向量。\n\n4. **输出计算**：\n   - 通过 `w2` 对加权后的中间向量进行线性变换，生成最终输出。\n\n---\n\n### **总结**：\n`FeedForward` 类实现了 Transformer 中的前馈网络，通过线性变换、激活函数和逐元素乘法等技术，增强了模型的非线性表达能力。\n\n\n\n## `TransformerBlock` \n\n```mermaid\ngraph TD\n    A[输入 x] --> B[RMSNorm]\n    B --> C[Attention]\n    C --> D[Add & Norm]\n    D --> E[FeedForward]\n    E --> F[Add & Norm]\n    F --> G[输出]\n```\n\n### **详细步骤说明**：\n\n1. **输入 x**  \n   - 输入是一个批次的向量，形状为 `(batch_size, seq_len, dim)`。\n\n2. **RMSNorm**  \n   - 对输入进行 RMSNorm 归一化，公式为：  \n     \\[\n     \\text{RMSNorm}(x) = \\frac{x}{\\sqrt{\\text{mean}(x^2) + \\epsilon}} \\cdot \\gamma\n     \\]  \n     其中，\\(\\gamma\\) 是可学习的缩放参数，\\(\\epsilon\\) 是防止除零的小常数。\n\n3. **Attention**  \n   - 将归一化后的输入传递给 `Attention` 模块，计算多头注意力机制的输出。\n\n4. **Add & Norm**  \n   - 将注意力输出与输入进行残差连接，然后再次应用 RMSNorm 归一化。\n\n5. **FeedForward**  \n   - 将归一化后的结果传递给 `FeedForward` 模块，计算前馈网络的输出。\n\n6. **Add & Norm**  \n   - 将前馈网络输出与上一层的输出进行残差连接，然后再次应用 RMSNorm 归一化。\n\n7. **输出**  \n   - 返回最终的输出，作为 Transformer 块的结果。\n\n---\n\n### **代码实现的关键点**：\n1. **残差连接**：\n   - 在注意力机制和前馈网络之后，分别使用残差连接，将输入与输出相加，缓解梯度消失问题。\n\n2. **归一化**：\n   - 使用 RMSNorm 对输入和输出进行归一化，稳定训练过程。\n\n3. **注意力机制**：\n   - 通过 `Attention` 模块计算多头注意力机制的输出，捕捉输入序列中的关系。\n\n4. **前馈网络**：\n   - 通过 `FeedForward` 模块增强模型的非线性表达能力。\n\n---\n\n### **总结**：\n`TransformerBlock` 类实现了 Transformer 中的一个完整块，包括注意力机制、前馈网络、残差连接和归一化操作。\n\n## `class Transformer` \n\n```mermaid\ngraph TD\n    A[输入 tokens] --> B[Token Embedding]\n    B --> C[添加位置编码 freqs_cis]\n    C --> D[初始化 mask]\n    D --> E[进入 Transformer 层]\n    E --> F[Transformer Block 1]\n    E --> G[Transformer Block 2]\n    E --> H[...]\n    E --> I[Transformer Block N]\n    F --> J[RMSNorm]\n    G --> J\n    H --> J\n    I --> J\n    J --> K[输出线性变换]\n    K --> L[输出 logits]\n\n    subgraph Transformer Block\n        direction TB\n        M[输入] --> N[RMSNorm]\n        N --> O[Attention]\n        O --> P[Add & Norm]\n        P --> Q[FeedForward]\n        Q --> R[Add & Norm]\n        R --> S[输出]\n    end\n\n    F --> M\n    G --> M\n    I --> M\n```\n\n### **详细步骤说明**：\n\n#### **整体流程**：\n1. **输入 tokens**  \n   - 输入是一个批次的 token IDs，形状为 `(batch_size, seq_len)`。\n\n2. **Token Embedding**  \n   - 通过 `tok_embeddings` 将 token IDs 转换为嵌入向量，形状为 `(batch_size, seq_len, dim)`。\n\n3. **添加位置编码 freqs_cis**  \n   - 使用预计算的 `freqs_cis` 为嵌入向量添加旋转位置编码，帮助模型捕捉序列中的位置信息。\n\n4. **初始化 mask**  \n   - 根据 `seq_len` 和 `start_pos` 生成注意力掩码 `mask`，用于防止模型看到未来的 token。\n\n5. **进入 Transformer 层**  \n   - 嵌入向量和位置编码进入多层 Transformer 块进行处理。\n\n6. **Transformer Block 1 到 N**  \n   - 每个 Transformer 块内部执行子图中的流程。\n\n7. **RMSNorm**  \n   - 在所有 Transformer 块处理完成后，对最终输出应用 RMSNorm 进行归一化。\n\n8. **输出线性变换**  \n   - 通过 `output` 线性层将归一化后的输出映射到词汇表空间，形状为 `(batch_size, seq_len, vocab_size)`。\n\n9. **输出 logits**  \n   - 返回最终的 logits，表示每个 token 的概率分布。\n\n#### **Transformer Block 子流程**：\n1. **输入**  \n   - 接收来自上一层的输入。\n\n2. **RMSNorm**  \n   - 对输入进行归一化。\n\n3. **Attention**  \n   - 应用多头注意力机制，生成注意力输出。\n\n4. **Add & Norm**  \n   - 将注意力输出与输入进行残差连接，并再次应用 RMSNorm 进行归一化。\n\n5. **FeedForward**  \n   - 应用前馈网络，生成前馈输出。\n\n6. **Add & Norm**  \n   - 将前馈输出与上一层的输出进行残差连接，并再次应用 RMSNorm 进行归一化。\n\n7. **输出**  \n   - 返回当前 Transformer 块的输出，作为下一层的输入。\n\n---\n\n### **代码实现的关键点**：\n1. **嵌入和位置编码**：\n   - 使用 `tok_embeddings` 将 token IDs 转换为嵌入向量，并通过 `freqs_cis` 添加位置信息。\n\n2. **注意力掩码**：\n   - 生成注意力掩码 `mask`，防止模型看到未来的 token。\n\n3. **多层 Transformer 块**：\n   - 通过多个 Transformer 块处理输入，每个块包含注意力机制、前馈网络、残差连接和归一化操作。\n\n4. **输出生成**：\n   - 对最终输出进行归一化和线性变换，生成 logits。\n\n---\n\n### **总结**：\n`class Transformer` 实现了完整的 Transformer 模型，包括嵌入、位置编码、多层 Transformer 块的处理以及最终的输出生成。\n\n## 示例解析\n\n### **示例输入**\n假设我们有以下输入：\n- **输入 tokens**: `[[1, 2, 3]]`，形状为 `(batch_size=1, seq_len=3)`。\n- **模型参数**:\n  - `dim=4`（模型维度）。\n  - `n_heads=2`（注意力头数）。\n  - `vocab_size=10`（词汇表大小）。\n  - `max_seq_len=8`（最大序列长度）。\n\n---\n\n### **执行流程**\n\n#### 1. **Token Embedding**\n- **输入**: `tokens = [[1, 2, 3]]`，形状为 `(1, 3)`。\n- **操作**: 将 token IDs 转换为嵌入向量。\n- **输出**: 嵌入向量，形状为 `(1, 3, 4)`。\n\n```python\n# 假设嵌入矩阵为：\nembedding_matrix = [\n    [0.1, 0.2, 0.3, 0.4],  # token 1\n    [0.5, 0.6, 0.7, 0.8],  # token 2\n    [0.9, 1.0, 1.1, 1.2],  # token 3\n]\n# 输出：\nh = [\n    [[0.1, 0.2, 0.3, 0.4],  # token 1\n     [0.5, 0.6, 0.7, 0.8],  # token 2\n     [0.9, 1.0, 1.1, 1.2]]  # token 3\n]\n```\n\n---\n\n#### 2. **添加位置编码**\n- **输入**: 嵌入向量 `h`，形状为 `(1, 3, 4)`。\n- **操作**: 使用 `freqs_cis` 添加旋转位置编码。\n- **输出**: 添加位置编码后的向量，形状为 `(1, 3, 4)`。\n\n```python\n# 假设 freqs_cis 为：\nfreqs_cis = [\n    [1.0, 1.0],  # 位置 1\n    [1.1, 1.1],  # 位置 2\n    [1.2, 1.2],  # 位置 3\n]\n# 输出：\nh_with_pos = [\n    [[0.1, 0.2, 1.0, 1.0],  # token 1\n     [0.5, 0.6, 1.1, 1.1],  # token 2\n     [0.9, 1.0, 1.2, 1.2]]  # token 3\n]\n```\n\n---\n\n#### 3. **初始化 mask**\n- **输入**: 序列长度 `seq_len=3`。\n- **操作**: 生成注意力掩码，防止模型看到未来的 token。\n- **输出**: 注意力掩码，形状为 `(3, 3)`。\n\n```python\n# 输出：\nmask = [\n    [0, -inf, -inf],  # 位置 1\n    [0, 0, -inf],     # 位置 2\n    [0, 0, 0]         # 位置 3\n]\n```\n\n---\n\n#### 4. **进入 Transformer 层**\n- **输入**: 添加位置编码后的向量 `h_with_pos`，形状为 `(1, 3, 4)`。\n- **操作**: 通过多层 Transformer 块处理输入。\n\n---\n\n#### 5. **Transformer Block 1**\n- **输入**: `h_with_pos`，形状为 `(1, 3, 4)`。\n- **操作**:\n  1. **RMSNorm**: 对输入进行归一化。\n  2. **Attention**: 计算多头注意力机制。\n  3. **Add & Norm**: 残差连接和归一化。\n  4. **FeedForward**: 计算前馈网络。\n  5. **Add & Norm**: 残差连接和归一化。\n- **输出**: Transformer 块的输出，形状为 `(1, 3, 4)`。\n\n```python\n# 假设输出为：\nh_block1 = [\n    [[0.2, 0.3, 1.1, 1.1],  # token 1\n     [0.6, 0.7, 1.2, 1.2],  # token 2\n     [1.0, 1.1, 1.3, 1.3]]  # token 3\n]\n```\n\n---\n\n#### 6. **Transformer Block N**\n- **输入**: 上一层的输出，形状为 `(1, 3, 4)`。\n- **操作**: 重复 Transformer 块的处理。\n- **输出**: 最后一层 Transformer 块的输出，形状为 `(1, 3, 4)`。\n\n```python\n# 假设输出为：\nh_blockN = [\n    [[0.3, 0.4, 1.2, 1.2],  # token 1\n     [0.7, 0.8, 1.3, 1.3],  # token 2\n     [1.1, 1.2, 1.4, 1.4]]  # token 3\n]\n```\n\n---\n\n#### 7. **RMSNorm**\n- **输入**: 最后一层 Transformer 块的输出，形状为 `(1, 3, 4)`。\n- **操作**: 对输出进行归一化。\n- **输出**: 归一化后的输出，形状为 `(1, 3, 4)`。\n\n```python\n# 假设输出为：\nh_norm = [\n    [[0.4, 0.5, 1.3, 1.3],  # token 1\n     [0.8, 0.9, 1.4, 1.4],  # token 2\n     [1.2, 1.3, 1.5, 1.5]]  # token 3\n]\n```\n\n---\n\n#### 8. **输出线性变换**\n- **输入**: 归一化后的输出，形状为 `(1, 3, 4)`。\n- **操作**: 通过线性层将输出映射到词汇表空间。\n- **输出**: logits，形状为 `(1, 3, vocab_size=10)`。\n\n```python\n# 假设输出为：\nlogits = [\n    [[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # token 1\n     [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1],  # token 2\n     [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2]]  # token 3\n]\n```\n\n---\n\n### **最终输出**\n- **输出**: logits，形状为 `(1, 3, 10)`。\n- **解释**: 每个 token 的输出是一个长度为 `vocab_size=10` 的向量，表示每个 token 的概率分布。\n\n---\n\n### **总结**\n- **输入**: `tokens = [[1, 2, 3]]`，形状为 `(1, 3)`。\n- **输出**: logits，形状为 `(1, 3, 10)`。\n- **中间步骤**:\n  1. Token Embedding：`(1, 3) -> (1, 3, 4)`。\n  2. 添加位置编码：`(1, 3, 4) -> (1, 3, 4)`。\n  3. 初始化 mask：`(3, 3)`。\n  4. 多层 Transformer 块：`(1, 3, 4) -> (1, 3, 4)`。\n  5. RMSNorm：`(1, 3, 4) -> (1, 3, 4)`。\n  6. 输出线性变换：`(1, 3, 4) -> (1, 3, 10)`。\n\n\n\n\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","source":"_posts/人工智能/nlp/llm/源码解析：llama3源码解析-03：model.py模块解析.md","raw":"---\ntitle: 'llama3源码解析-03：model.py模块解析'\ncategories:\n  - [人工智能,nlp,llm]\ntags:\n  - nlp\n  - llm\n  - llama\n  - 源码解析\ndate: 2024-12-30 12:00:00\n---\n\n![llama](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/Llama3_Repo.jpeg)\n\n\n\n## 整体\n\n`model.py` 模块是 Llama 3 模型的核心实现部分，主要负责定义和实现 Transformer 模型的结构及其相关组件。\n\n### 1. **模型参数定义 (`ModelArgs` 类)**\n   - `ModelArgs` 类是一个数据类，用于定义和存储模型的各种超参数，例如：\n     - `dim`: 模型的维度。\n     - `n_layers`: Transformer 的层数。\n     - `n_heads`: 注意力机制中的头数。\n     - `vocab_size`: 词汇表大小。\n     - `max_batch_size`: 最大批处理大小。\n     - `max_seq_len`: 最大序列长度。\n   - 这些参数在模型初始化时被使用，决定了模型的结构和行为。\n\n### 2. **RMSNorm 层 (`RMSNorm` 类)**\n   - `RMSNorm` 是一个自定义的归一化层，用于替代传统的 LayerNorm。它通过对输入进行**均方根归一化**来稳定训练过程。\n   - 该层在 Transformer 的每个子层（如注意力机制和前馈网络）之后使用。\n\n### 3. **RoPE (Rotary Positional Embedding)**\n   - 该模块实现了旋转位置编码（RoPE），用于为输入序列中的每个位置生成位置编码。RoPE 通过将位置信息嵌入到注意力机制中，帮助模型捕捉序列中的位置关系。\n   - `precompute_freqs_cis` 函数预计算了频率矩阵，`apply_rotary_emb` 函数将旋转**位置编码应用到查询和键向量上。**\n\n### 4. **注意力机制 (`Attention` 类)**\n   - `Attention` 类实现了多头注意力机制（Multi-Head Attention），这是 Transformer 模型的核心组件之一。\n   - 它使用 `ColumnParallelLinear` 和 `RowParallelLinear` 来实现并行的线性变换，支持模型并行化。\n   - 该模块还实现了键值缓存（KV Cache），用于在生成过程中缓存先前的键和值，以减少重复计算。\n\n### 5. **前馈网络 (`FeedForward` 类)**\n   - `FeedForward` 类实现了 Transformer 中的前馈神经网络（FFN），通常由两个线性变换和一个激活函数（如 SiLU）组成。\n   - 该模块也支持模型并行化，使用 `ColumnParallelLinear` 和 `RowParallelLinear` 来实现并行的线性变换。\n\n### 6. **Transformer 块 (`TransformerBlock` 类)**\n   - `TransformerBlock` 类将注意力机制和前馈网络组合在一起，形成一个完整的 Transformer 层。\n   - 每个 Transformer 块包含一个注意力层和一个前馈网络层，并且在每个子层之后应用 RMSNorm 进行归一化。\n\n### 7. **Transformer 模型 (`Transformer` 类)**\n   - `Transformer` 类是整个模型的核心，它由多个 `TransformerBlock` 组成，形成一个深层的 Transformer 网络。\n   - 该模块还负责处理输入嵌入、位置编码、以及最终的输出线性变换。\n   - `forward` 方法实现了模型的前向传播过程，包括嵌入、位置编码、多层 Transformer 块的处理以及最终的输出生成。\n\n### 8. **模型并行化**\n   - 该模块使用了 `fairscale` 库中的 `ColumnParallelLinear` 和 `RowParallelLinear` 来实现模型并行化，允许模型在多个 GPU 上分布计算，从而提高训练和推理的效率。\n\n### 9. **推理模式**\n   - 在推理模式下，模型使用 `torch.inference_mode()` 来禁用梯度计算，从而提高推理速度并减少内存占用。\n\n### 总结：\n`model.py` 模块定义了 Llama 3 模型的核心架构，包括 Transformer 的各个组件（如注意力机制、前馈网络、归一化层等），并实现了模型并行化和推理优化。它是整个 Llama 3 模型的基础，负责处理输入数据并生成输出。\n\n## 模型详细流程图\n\n```mermaid\ngraph TD\n    A[输入 tokens] --> B[Token Embedding]\n    B --> C[添加位置编码 freqs_cis]\n    C --> D[初始化 mask]\n    D --> E[进入 Transformer 层]\n    E --> F[Transformer Block 1]\n    E --> G[Transformer Block 2]\n    E --> H[...]\n    E --> I[Transformer Block N]\n    F --> J[输出 logits]\n    G --> J\n    H --> J\n    I --> J\n\n    subgraph Transformer Block\n        direction TB\n        K[输入] --> L[RMSNorm]\n        L --> M[Attention]\n        M --> N[Add & Norm]\n        N --> O[FeedForward]\n        O --> P[Add & Norm]\n        P --> Q[输出]\n    end\n\n    F --> K\n    G --> K\n    I --> K\n```\n\n1. **输入 tokens**  \n   - 输入是一个批次的 token IDs，形状为 `(batch_size, seq_len)`。\n\n2. **Token Embedding**  \n   - 通过 `tok_embeddings` 将 token IDs 转换为嵌入向量，形状为 `(batch_size, seq_len, dim)`。\n\n3. **添加位置编码 freqs_cis**  \n   - 使用预计算的 `freqs_cis` 为嵌入向量添加旋转位置编码，帮助模型捕捉序列中的位置信息。\n\n4. **初始化 mask**  \n   - 根据 `seq_len` 和 `start_pos` 生成注意力掩码 `mask`，用于防止模型看到未来的 token。\n\n5. **进入 Transformer 层**  \n   - 嵌入向量和位置编码进入多层 Transformer 块进行处理。\n\n6. **Transformer Block 1 到 N**  \n   - 每个 Transformer 块包含以下步骤：\n     - **RMSNorm**: 对输入进行归一化。\n     - **Attention**: 应用多头注意力机制，生成注意力输出。\n     - **RMSNorm**: 对注意力输出进行归一化。\n     - **FeedForward**: 应用前馈网络，生成最终的 Transformer 块输出。\n\n7. **应用 RMSNorm**  \n   - 在所有 Transformer 块处理完成后，对最终输出应用 RMSNorm 进行归一化。\n\n8. **输出线性变换**  \n   - 通过 `output` 线性层将归一化后的输出映射到词汇表空间，形状为 `(batch_size, seq_len, vocab_size)`。\n\n9. **输出 logits**  \n   - 返回最终的 logits，表示每个 token 的概率分布。\n\n\n\n## `class ModelArgs`\n\n```python\n@dataclass\nclass ModelArgs:\n    dim: int = 4096  # 模型的维度，即每个token的向量表示的大小\n    n_layers: int = 32  # 模型的层数，即Transformer的层数\n    n_heads: int = 32  # 注意力机制中的头数\n    n_kv_heads: Optional[int] = None  # 键值头的数量，如果为None，则与n_heads相同\n    vocab_size: int = -1  # 词汇表的大小，通常由tokenizer决定\n    multiple_of: int = 256  # SwiGLU激活函数中隐藏层大小的倍数，确保是256的倍数\n    ffn_dim_multiplier: Optional[float] = None  # 前馈网络维度的乘数，用于调整隐藏层大小\n    norm_eps: float = 1e-5  # Layer Normalization中的epsilon值，用于数值稳定性\n    rope_theta: float = 500000  # RoPE（Rotary Position Embedding）中的theta参数\n\n    max_batch_size: int = 32  # 最大批处理大小\n    max_seq_len: int = 2048  # 最大序列长度\n```\n\n## `class RMSNorm`\n```python\nclass RMSNorm(torch.nn.Module):\n    def __init__(self, dim: int, eps: float = 1e-6):\n        super().__init__()\n        self.eps = eps  # 用于数值稳定性的小值，防止除以零\n        self.weight = nn.Parameter(torch.ones(dim))  # 可学习的缩放参数，初始化为1\n\n    def _norm(self, x):\n        # 计算RMS（Root Mean Square）归一化，对输入x进行归一化处理\n        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n\n    def forward(self, x):\n        # 前向传播函数，先对输入x进行归一化，然后乘以可学习的缩放参数\n        output = self._norm(x.float()).type_as(x)  # 归一化并保持与输入x相同的数据类型\n        return output * self.weight  # 乘以缩放参数\n```\n\n### 解释：\n1. **`ModelArgs`**:\n   - 这是一个数据类，用于存储模型的配置参数。它定义了模型的结构和超参数，如模型的维度、层数、注意力头数等。\n   - `dim` 是每个token的向量表示的大小，`n_layers` 是Transformer的层数，`n_heads` 是注意力机制中的头数。\n   - `vocab_size` 是词汇表的大小，通常由tokenizer决定。\n   - `multiple_of` 和 `ffn_dim_multiplier` 用于调整前馈网络的隐藏层大小。\n   - `norm_eps` 是Layer Normalization中的epsilon值，用于数值稳定性。\n   - `rope_theta` 是RoPE（Rotary Position Embedding）中的theta参数，用于位置编码。\n   - `max_batch_size` 和 `max_seq_len` 分别定义了模型的最大批处理大小和最大序列长度。\n\n2. **`RMSNorm`**:\n   - 这是一个自定义的归一化层，类似于Layer Normalization，但使用了RMS（Root Mean Square）归一化。\n   - `_norm` 方法计算输入的RMS归一化值，`forward` 方法在前向传播时对输入进行归一化并乘以可学习的缩放参数。\n   - `eps` 是一个小值，用于防止除以零的情况，`weight` 是可学习的缩放参数，初始化为1。\n\n这两个类在模型中分别用于定义模型的结构和实现归一化操作，是Transformer模型的重要组成部分。\n\n\n\n---\n\n## 旋转位置编码\n\n### **`precompute_freqs_cis`**\n\n```python\ndef precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n    \"\"\"\n    预计算旋转位置编码的频率矩阵 (freqs_cis)。\n\n    旋转位置编码 (Rotary Positional Embedding, RoPE) 是一种将位置信息嵌入到注意力机制中的方法。\n    它通过将位置信息编码为复数形式，应用到查询和键向量上。\n\n    参数:\n        dim (int): 模型的维度（通常是注意力头的维度）。\n        end (int): 序列的最大长度。\n        theta (float): 控制频率的基数，默认为 10000.0。\n\n    返回:\n        freqs_cis (torch.Tensor): 预计算的频率矩阵，形状为 (end, dim // 2)，数据类型为 complex64。\n    \"\"\"\n    # 计算频率向量\n    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n    # 生成位置向量\n    t = torch.arange(end, device=freqs.device, dtype=torch.float32)\n    # 计算外积，得到频率矩阵\n    freqs = torch.outer(t, freqs)\n    # 将频率矩阵转换为复数形式（极坐标表示）\n    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n    return freqs_cis\n```\n\n#### 解释：\n- **作用**: 预计算旋转位置编码的频率矩阵 `freqs_cis`，用于将位置信息嵌入到查询和键向量中。\n- **输入**:\n  - `dim`: 模型的维度，通常是注意力头的维度。\n  - `end`: 序列的最大长度。\n  - `theta`: 控制频率的基数，默认为 10000.0。\n- **输出**:\n  - `freqs_cis`: 预计算的频率矩阵，形状为 `(end, dim // 2)`，数据类型为 `complex64`。\n- **关键点**:\n  - 使用 `torch.outer` 计算位置向量和频率向量的外积，得到频率矩阵。\n  - 通过 `torch.polar` 将频率矩阵转换为复数形式，表示极坐标。\n\n---\n\n### **`reshape_for_broadcast`**\n```python\ndef reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n    \"\"\"\n    将频率矩阵 `freqs_cis` 重塑为适合广播的形状，以便与查询或键向量进行逐元素操作。\n\n    参数:\n        freqs_cis (torch.Tensor): 频率矩阵，形状为 (seq_len, dim // 2)。\n        x (torch.Tensor): 查询或键向量，形状为 (batch_size, seq_len, n_heads, head_dim)。\n\n    返回:\n        freqs_cis (torch.Tensor): 重塑后的频率矩阵，形状为 (1, seq_len, 1, dim // 2)。\n    \"\"\"\n    ndim = x.ndim\n    assert 0 <= 1 < ndim\n    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n    # 重塑频率矩阵，使其形状为 (1, seq_len, 1, dim // 2)\n    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n    return freqs_cis.view(*shape)\n```\n\n#### 解释：\n- **作用**: 将频率矩阵 `freqs_cis` 重塑为适合广播的形状，以便与查询或键向量进行逐元素操作。\n- **输入**:\n  - `freqs_cis`: 频率矩阵，形状为 `(seq_len, dim // 2)`。\n  - `x`: 查询或键向量，形状为 `(batch_size, seq_len, n_heads, head_dim)`。\n- **输出**:\n  - 重塑后的频率矩阵，形状为 `(1, seq_len, 1, dim // 2)`。\n- **关键点**:\n  - 通过 `view` 方法将频率矩阵重塑为适合广播的形状，使其能够与查询或键向量进行逐元素操作。\n\n---\n\n### **`apply_rotary_emb`**\n```python\ndef apply_rotary_emb(\n    xq: torch.Tensor,\n    xk: torch.Tensor,\n    freqs_cis: torch.Tensor,\n) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    将旋转位置编码应用到查询和键向量上。\n\n    旋转位置编码通过将位置信息嵌入到查询和键向量中，帮助模型捕捉序列中的位置关系。\n\n    参数:\n        xq (torch.Tensor): 查询向量，形状为 (batch_size, seq_len, n_heads, head_dim)。\n        xk (torch.Tensor): 键向量，形状为 (batch_size, seq_len, n_heads, head_dim)。\n        freqs_cis (torch.Tensor): 频率矩阵，形状为 (1, seq_len, 1, head_dim // 2)。\n\n    返回:\n        xq_out (torch.Tensor): 应用旋转位置编码后的查询向量。\n        xk_out (torch.Tensor): 应用旋转位置编码后的键向量。\n    \"\"\"\n    # 将查询和键向量转换为复数形式\n    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n    # 重塑频率矩阵以匹配查询和键向量的形状\n    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n    # 应用旋转位置编码\n    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n    return xq_out.type_as(xq), xk_out.type_as(xk)\n```\n\n#### 解释：\n- **作用**: 将旋转位置编码应用到查询和键向量上，帮助模型捕捉序列中的位置关系。\n- **输入**:\n  - `xq`: 查询向量，形状为 `(batch_size, seq_len, n_heads, head_dim)`。\n  - `xk`: 键向量，形状为 `(batch_size, seq_len, n_heads, head_dim)`。\n  - `freqs_cis`: 频率矩阵，形状为 `(1, seq_len, 1, head_dim // 2)`。\n- **输出**:\n  - `xq_out`: 应用旋转位置编码后的查询向量。\n  - `xk_out`: 应用旋转位置编码后的键向量。\n- **关键点**:\n  - 使用 `torch.view_as_complex` 将查询和键向量转换为复数形式。\n  - 通过逐元素乘法将频率矩阵应用到查询和键向量上。\n  - 使用 `torch.view_as_real` 将结果转换回实数形式。\n  \n  \n  \n  这些函数共同实现了旋转位置编码（RoPE）\n  \n  ### 总结：\n  \n  - **`precompute_freqs_cis`**: 预计算旋转位置编码的频率矩阵。\n  - **`reshape_for_broadcast`**: 将频率矩阵重塑为适合广播的形状。\n  - **`apply_rotary_emb`**: 将旋转位置编码应用到查询和键向量上。\n\n---\n\n## **`repeat_kv`**\n```python\ndef repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:\n    \"\"\"\n    重复键或值向量，以匹配查询向量的头数。\n\n    在分组注意力机制中，键和值向量的头数可能少于查询向量的头数，因此需要重复键和值向量以匹配查询向量的头数。\n\n    参数:\n        x (torch.Tensor): 键或值向量，形状为 (batch_size, seq_len, n_kv_heads, head_dim)。\n        n_rep (int): 重复次数，通常为查询头数与键值头数的比值。\n\n    返回:\n        torch.Tensor: 重复后的键或值向量，形状为 (batch_size, seq_len, n_kv_heads * n_rep, head_dim)。\n    \"\"\"\n    bs, slen, n_kv_heads, head_dim = x.shape\n    if n_rep == 1:\n        return x\n    return (\n        x[:, :, :, None, :]\n        .expand(bs, slen, n_kv_heads, n_rep, head_dim)\n        .reshape(bs, slen, n_kv_heads * n_rep, head_dim)\n    )\n```\n\n#### 解释：\n- **作用**: 重复键或值向量，以匹配查询向量的头数。\n- **输入**:\n  - `x`: 键或值向量，形状为 `(batch_size, seq_len, n_kv_heads, head_dim)`。\n  - `n_rep`: 重复次数，通常为查询头数与键值头数的比值。\n- **输出**:\n  - 重复后的键或值向量，形状为 `(batch_size, seq_len, n_kv_heads * n_rep, head_dim)`。\n- **关键点**:\n  - 使用 `expand` 和 `reshape` 方法重复键或值向量，使其头数与查询向量匹配。\n\n## `class Attention` \n\n`class Attention` 实现了 Transformer 中的 **多头注意力机制（Multi-Head Attention）**，它是 Transformer 模型的核心组件之一。以下是该类的详细解释：\n\n#### **主要功能**：\n1. **多头注意力机制**：\n   - 将输入向量拆分为多个头，每个头独立计算注意力分数。\n   - 通过并行计算，捕捉输入序列中不同位置之间的关系。\n\n2. **键值缓存（KV Cache）**：\n   - 在生成任务中，缓存先前的键和值，避免重复计算，提高效率。\n\n3. **模型并行化**：\n   - 使用 `ColumnParallelLinear` 和 `RowParallelLinear` 实现并行的线性变换，支持多 GPU 计算。\n\n#### **关键组件**：\n1. **线性变换**：\n   - `wq`、`wk`、`wv`：分别对输入进行线性变换，生成查询（Query）、键（Key）和值（Value）向量。\n   - `wo`：将多头注意力的输出进行线性变换，合并为最终输出。\n\n2. **键值缓存**：\n   - `cache_k` 和 `cache_v`：用于缓存先前的键和值，形状为 `(batch_size, max_seq_len, n_local_kv_heads, head_dim)`。\n\n3. **旋转位置编码（RoPE）**：\n   - 通过 `apply_rotary_emb` 将位置信息嵌入到查询和键向量中。\n\n4. **注意力分数计算**：\n   - 计算查询和键的点积，除以 `sqrt(head_dim)` 进行缩放，然后应用 Softmax 得到注意力分数。\n\n5. **输出计算**：\n   - 使用注意力分数对值向量进行加权求和，得到多头注意力的输出。\n\n---\n\n### **`流程图**\n\n```mermaid\ngraph TD\n    A[输入 x] --> B[线性变换]\n    B --> C[生成 Query]\n    B --> D[生成 Key]\n    B --> E[生成 Value]\n    C --> F[应用旋转位置编码]\n    D --> F\n    F --> G[更新键值缓存]\n    G --> H[计算注意力分数]\n    H --> I[应用 Softmax]\n    I --> J[加权求和]\n    J --> K[线性变换]\n    K --> L[输出]\n```\n\n### **详细步骤说明**：\n\n1. **输入 x**  \n   - 输入是一个批次的嵌入向量，形状为 `(batch_size, seq_len, dim)`。\n\n2. **线性变换**  \n   - 通过 `wq`、`wk`、`wv` 分别对输入进行线性变换，生成查询（Query）、键（Key）和值（Value）向量。\n\n3. **生成 Query、Key、Value**  \n   - 查询向量形状为 `(batch_size, seq_len, n_local_heads, head_dim)`。\n   - 键和值向量形状为 `(batch_size, seq_len, n_local_kv_heads, head_dim)`。\n\n4. **应用旋转位置编码**  \n   - 使用 `apply_rotary_emb` 将旋转位置编码应用到查询和键向量上。\n\n5. **更新键值缓存**  \n   - 将当前的键和值向量缓存到 `cache_k` 和 `cache_v` 中。\n\n6. **计算注意力分数**  \n   - 计算查询和键的点积，除以 `sqrt(head_dim)` 进行缩放，得到注意力分数。\n\n7. **应用 Softmax**  \n   - 对注意力分数应用 Softmax，得到归一化的注意力权重。\n\n8. **加权求和**  \n   - 使用注意力权重对值向量进行加权求和，得到多头注意力的输出。\n\n9. **线性变换**  \n   - 通过 `wo` 对多头注意力的输出进行线性变换，合并为最终输出。\n\n10. **输出**  \n    - 返回最终的输出，形状为 `(batch_size, seq_len, dim)`。\n\n---\n\n### **代码实现的关键点**：\n1. **并行化**：\n   - 使用 `ColumnParallelLinear` 和 `RowParallelLinear` 实现并行的线性变换，支持多 GPU 计算。\n\n2. **键值缓存**：\n   - 在生成任务中，缓存先前的键和值，避免重复计算，提高效率。\n\n3. **旋转位置编码**：\n   - 通过 `apply_rotary_emb` 将位置信息嵌入到查询和键向量中，帮助模型捕捉序列中的位置关系。\n\n4. **注意力分数计算**：\n   - 使用点积计算注意力分数，并通过 Softmax 进行归一化。\n\n5. **输出计算**：\n   - 使用注意力权重对值向量进行加权求和，得到多头注意力的输出。\n\n---\n\n### **总结**：\n`class Attention` 实现了 Transformer 中的多头注意力机制，通过并行化、键值缓存和旋转位置编码等技术，高效地捕捉输入序列中的关系。\n\n## `FeedForward` \n\n```mermaid\ngraph TD\n    A[输入 x] --> B[线性变换 W1]\n    B --> C[激活函数 SiLU]\n    C --> D[线性变换 W3]\n    D --> E[逐元素乘法]\n    E --> F[线性变换 W2]\n    F --> G[输出]\n```\n\n### **详细步骤说明**：\n\n1. **输入 x**  \n   - 输入是一个批次的向量，形状为 `(batch_size, seq_len, dim)`。\n\n2. **线性变换 W1**  \n   - 通过 `w1` 对输入进行线性变换，生成中间向量，形状为 `(batch_size, seq_len, hidden_dim)`。\n\n3. **激活函数 SiLU**  \n   - 对线性变换后的结果应用 SiLU（Sigmoid Linear Unit）激活函数，公式为：  \n   \n     ![](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241230114851133.png)\n   \n4. **线性变换 W3**  \n   \n   - 通过 `w3` 对输入进行另一个线性变换，生成中间向量，形状为 `(batch_size, seq_len, hidden_dim)`。\n   \n5. **逐元素乘法**  \n   \n   - 将 `SiLU(W1(x))` 和 `W3(x)` 进行逐元素乘法，生成加权后的中间向量。\n   \n6. **线性变换 W2**  \n   - 通过 `w2` 对加权后的中间向量进行线性变换，生成最终输出，形状为 `(batch_size, seq_len, dim)`。\n\n7. **输出**  \n   - 返回最终的输出，作为前馈网络的结果。\n\n---\n\n### **代码实现的关键点**：\n1. **并行化**：\n   - 使用 `ColumnParallelLinear` 和 `RowParallelLinear` 实现并行的线性变换，支持多 GPU 计算。\n\n2. **激活函数**：\n   - 使用 SiLU 激活函数，结合了 Sigmoid 和线性变换的优点，增强了模型的非线性表达能力。\n\n3. **逐元素乘法**：\n   - 将两个线性变换的结果进行逐元素乘法，生成加权后的中间向量。\n\n4. **输出计算**：\n   - 通过 `w2` 对加权后的中间向量进行线性变换，生成最终输出。\n\n---\n\n### **总结**：\n`FeedForward` 类实现了 Transformer 中的前馈网络，通过线性变换、激活函数和逐元素乘法等技术，增强了模型的非线性表达能力。\n\n\n\n## `TransformerBlock` \n\n```mermaid\ngraph TD\n    A[输入 x] --> B[RMSNorm]\n    B --> C[Attention]\n    C --> D[Add & Norm]\n    D --> E[FeedForward]\n    E --> F[Add & Norm]\n    F --> G[输出]\n```\n\n### **详细步骤说明**：\n\n1. **输入 x**  \n   - 输入是一个批次的向量，形状为 `(batch_size, seq_len, dim)`。\n\n2. **RMSNorm**  \n   - 对输入进行 RMSNorm 归一化，公式为：  \n     \\[\n     \\text{RMSNorm}(x) = \\frac{x}{\\sqrt{\\text{mean}(x^2) + \\epsilon}} \\cdot \\gamma\n     \\]  \n     其中，\\(\\gamma\\) 是可学习的缩放参数，\\(\\epsilon\\) 是防止除零的小常数。\n\n3. **Attention**  \n   - 将归一化后的输入传递给 `Attention` 模块，计算多头注意力机制的输出。\n\n4. **Add & Norm**  \n   - 将注意力输出与输入进行残差连接，然后再次应用 RMSNorm 归一化。\n\n5. **FeedForward**  \n   - 将归一化后的结果传递给 `FeedForward` 模块，计算前馈网络的输出。\n\n6. **Add & Norm**  \n   - 将前馈网络输出与上一层的输出进行残差连接，然后再次应用 RMSNorm 归一化。\n\n7. **输出**  \n   - 返回最终的输出，作为 Transformer 块的结果。\n\n---\n\n### **代码实现的关键点**：\n1. **残差连接**：\n   - 在注意力机制和前馈网络之后，分别使用残差连接，将输入与输出相加，缓解梯度消失问题。\n\n2. **归一化**：\n   - 使用 RMSNorm 对输入和输出进行归一化，稳定训练过程。\n\n3. **注意力机制**：\n   - 通过 `Attention` 模块计算多头注意力机制的输出，捕捉输入序列中的关系。\n\n4. **前馈网络**：\n   - 通过 `FeedForward` 模块增强模型的非线性表达能力。\n\n---\n\n### **总结**：\n`TransformerBlock` 类实现了 Transformer 中的一个完整块，包括注意力机制、前馈网络、残差连接和归一化操作。\n\n## `class Transformer` \n\n```mermaid\ngraph TD\n    A[输入 tokens] --> B[Token Embedding]\n    B --> C[添加位置编码 freqs_cis]\n    C --> D[初始化 mask]\n    D --> E[进入 Transformer 层]\n    E --> F[Transformer Block 1]\n    E --> G[Transformer Block 2]\n    E --> H[...]\n    E --> I[Transformer Block N]\n    F --> J[RMSNorm]\n    G --> J\n    H --> J\n    I --> J\n    J --> K[输出线性变换]\n    K --> L[输出 logits]\n\n    subgraph Transformer Block\n        direction TB\n        M[输入] --> N[RMSNorm]\n        N --> O[Attention]\n        O --> P[Add & Norm]\n        P --> Q[FeedForward]\n        Q --> R[Add & Norm]\n        R --> S[输出]\n    end\n\n    F --> M\n    G --> M\n    I --> M\n```\n\n### **详细步骤说明**：\n\n#### **整体流程**：\n1. **输入 tokens**  \n   - 输入是一个批次的 token IDs，形状为 `(batch_size, seq_len)`。\n\n2. **Token Embedding**  \n   - 通过 `tok_embeddings` 将 token IDs 转换为嵌入向量，形状为 `(batch_size, seq_len, dim)`。\n\n3. **添加位置编码 freqs_cis**  \n   - 使用预计算的 `freqs_cis` 为嵌入向量添加旋转位置编码，帮助模型捕捉序列中的位置信息。\n\n4. **初始化 mask**  \n   - 根据 `seq_len` 和 `start_pos` 生成注意力掩码 `mask`，用于防止模型看到未来的 token。\n\n5. **进入 Transformer 层**  \n   - 嵌入向量和位置编码进入多层 Transformer 块进行处理。\n\n6. **Transformer Block 1 到 N**  \n   - 每个 Transformer 块内部执行子图中的流程。\n\n7. **RMSNorm**  \n   - 在所有 Transformer 块处理完成后，对最终输出应用 RMSNorm 进行归一化。\n\n8. **输出线性变换**  \n   - 通过 `output` 线性层将归一化后的输出映射到词汇表空间，形状为 `(batch_size, seq_len, vocab_size)`。\n\n9. **输出 logits**  \n   - 返回最终的 logits，表示每个 token 的概率分布。\n\n#### **Transformer Block 子流程**：\n1. **输入**  \n   - 接收来自上一层的输入。\n\n2. **RMSNorm**  \n   - 对输入进行归一化。\n\n3. **Attention**  \n   - 应用多头注意力机制，生成注意力输出。\n\n4. **Add & Norm**  \n   - 将注意力输出与输入进行残差连接，并再次应用 RMSNorm 进行归一化。\n\n5. **FeedForward**  \n   - 应用前馈网络，生成前馈输出。\n\n6. **Add & Norm**  \n   - 将前馈输出与上一层的输出进行残差连接，并再次应用 RMSNorm 进行归一化。\n\n7. **输出**  \n   - 返回当前 Transformer 块的输出，作为下一层的输入。\n\n---\n\n### **代码实现的关键点**：\n1. **嵌入和位置编码**：\n   - 使用 `tok_embeddings` 将 token IDs 转换为嵌入向量，并通过 `freqs_cis` 添加位置信息。\n\n2. **注意力掩码**：\n   - 生成注意力掩码 `mask`，防止模型看到未来的 token。\n\n3. **多层 Transformer 块**：\n   - 通过多个 Transformer 块处理输入，每个块包含注意力机制、前馈网络、残差连接和归一化操作。\n\n4. **输出生成**：\n   - 对最终输出进行归一化和线性变换，生成 logits。\n\n---\n\n### **总结**：\n`class Transformer` 实现了完整的 Transformer 模型，包括嵌入、位置编码、多层 Transformer 块的处理以及最终的输出生成。\n\n## 示例解析\n\n### **示例输入**\n假设我们有以下输入：\n- **输入 tokens**: `[[1, 2, 3]]`，形状为 `(batch_size=1, seq_len=3)`。\n- **模型参数**:\n  - `dim=4`（模型维度）。\n  - `n_heads=2`（注意力头数）。\n  - `vocab_size=10`（词汇表大小）。\n  - `max_seq_len=8`（最大序列长度）。\n\n---\n\n### **执行流程**\n\n#### 1. **Token Embedding**\n- **输入**: `tokens = [[1, 2, 3]]`，形状为 `(1, 3)`。\n- **操作**: 将 token IDs 转换为嵌入向量。\n- **输出**: 嵌入向量，形状为 `(1, 3, 4)`。\n\n```python\n# 假设嵌入矩阵为：\nembedding_matrix = [\n    [0.1, 0.2, 0.3, 0.4],  # token 1\n    [0.5, 0.6, 0.7, 0.8],  # token 2\n    [0.9, 1.0, 1.1, 1.2],  # token 3\n]\n# 输出：\nh = [\n    [[0.1, 0.2, 0.3, 0.4],  # token 1\n     [0.5, 0.6, 0.7, 0.8],  # token 2\n     [0.9, 1.0, 1.1, 1.2]]  # token 3\n]\n```\n\n---\n\n#### 2. **添加位置编码**\n- **输入**: 嵌入向量 `h`，形状为 `(1, 3, 4)`。\n- **操作**: 使用 `freqs_cis` 添加旋转位置编码。\n- **输出**: 添加位置编码后的向量，形状为 `(1, 3, 4)`。\n\n```python\n# 假设 freqs_cis 为：\nfreqs_cis = [\n    [1.0, 1.0],  # 位置 1\n    [1.1, 1.1],  # 位置 2\n    [1.2, 1.2],  # 位置 3\n]\n# 输出：\nh_with_pos = [\n    [[0.1, 0.2, 1.0, 1.0],  # token 1\n     [0.5, 0.6, 1.1, 1.1],  # token 2\n     [0.9, 1.0, 1.2, 1.2]]  # token 3\n]\n```\n\n---\n\n#### 3. **初始化 mask**\n- **输入**: 序列长度 `seq_len=3`。\n- **操作**: 生成注意力掩码，防止模型看到未来的 token。\n- **输出**: 注意力掩码，形状为 `(3, 3)`。\n\n```python\n# 输出：\nmask = [\n    [0, -inf, -inf],  # 位置 1\n    [0, 0, -inf],     # 位置 2\n    [0, 0, 0]         # 位置 3\n]\n```\n\n---\n\n#### 4. **进入 Transformer 层**\n- **输入**: 添加位置编码后的向量 `h_with_pos`，形状为 `(1, 3, 4)`。\n- **操作**: 通过多层 Transformer 块处理输入。\n\n---\n\n#### 5. **Transformer Block 1**\n- **输入**: `h_with_pos`，形状为 `(1, 3, 4)`。\n- **操作**:\n  1. **RMSNorm**: 对输入进行归一化。\n  2. **Attention**: 计算多头注意力机制。\n  3. **Add & Norm**: 残差连接和归一化。\n  4. **FeedForward**: 计算前馈网络。\n  5. **Add & Norm**: 残差连接和归一化。\n- **输出**: Transformer 块的输出，形状为 `(1, 3, 4)`。\n\n```python\n# 假设输出为：\nh_block1 = [\n    [[0.2, 0.3, 1.1, 1.1],  # token 1\n     [0.6, 0.7, 1.2, 1.2],  # token 2\n     [1.0, 1.1, 1.3, 1.3]]  # token 3\n]\n```\n\n---\n\n#### 6. **Transformer Block N**\n- **输入**: 上一层的输出，形状为 `(1, 3, 4)`。\n- **操作**: 重复 Transformer 块的处理。\n- **输出**: 最后一层 Transformer 块的输出，形状为 `(1, 3, 4)`。\n\n```python\n# 假设输出为：\nh_blockN = [\n    [[0.3, 0.4, 1.2, 1.2],  # token 1\n     [0.7, 0.8, 1.3, 1.3],  # token 2\n     [1.1, 1.2, 1.4, 1.4]]  # token 3\n]\n```\n\n---\n\n#### 7. **RMSNorm**\n- **输入**: 最后一层 Transformer 块的输出，形状为 `(1, 3, 4)`。\n- **操作**: 对输出进行归一化。\n- **输出**: 归一化后的输出，形状为 `(1, 3, 4)`。\n\n```python\n# 假设输出为：\nh_norm = [\n    [[0.4, 0.5, 1.3, 1.3],  # token 1\n     [0.8, 0.9, 1.4, 1.4],  # token 2\n     [1.2, 1.3, 1.5, 1.5]]  # token 3\n]\n```\n\n---\n\n#### 8. **输出线性变换**\n- **输入**: 归一化后的输出，形状为 `(1, 3, 4)`。\n- **操作**: 通过线性层将输出映射到词汇表空间。\n- **输出**: logits，形状为 `(1, 3, vocab_size=10)`。\n\n```python\n# 假设输出为：\nlogits = [\n    [[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # token 1\n     [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1],  # token 2\n     [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2]]  # token 3\n]\n```\n\n---\n\n### **最终输出**\n- **输出**: logits，形状为 `(1, 3, 10)`。\n- **解释**: 每个 token 的输出是一个长度为 `vocab_size=10` 的向量，表示每个 token 的概率分布。\n\n---\n\n### **总结**\n- **输入**: `tokens = [[1, 2, 3]]`，形状为 `(1, 3)`。\n- **输出**: logits，形状为 `(1, 3, 10)`。\n- **中间步骤**:\n  1. Token Embedding：`(1, 3) -> (1, 3, 4)`。\n  2. 添加位置编码：`(1, 3, 4) -> (1, 3, 4)`。\n  3. 初始化 mask：`(3, 3)`。\n  4. 多层 Transformer 块：`(1, 3, 4) -> (1, 3, 4)`。\n  5. RMSNorm：`(1, 3, 4) -> (1, 3, 4)`。\n  6. 输出线性变换：`(1, 3, 4) -> (1, 3, 10)`。\n\n\n\n\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","slug":"人工智能/nlp/llm/源码解析：llama3源码解析-03：model.py模块解析","published":1,"updated":"2024-12-30T03:49:30.874Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3o001ihghib9xdh2a9","content":"<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/Llama3_Repo.jpeg\" alt=\"llama\"></p>\n<h2 id=\"整体\"><a href=\"#整体\" class=\"headerlink\" title=\"整体\"></a>整体</h2><p><code>model.py</code> 模块是 Llama 3 模型的核心实现部分，主要负责定义和实现 Transformer 模型的结构及其相关组件。</p>\n<h3 id=\"1-模型参数定义-ModelArgs-类\"><a href=\"#1-模型参数定义-ModelArgs-类\" class=\"headerlink\" title=\"1. 模型参数定义 (ModelArgs 类)\"></a>1. <strong>模型参数定义 (<code>ModelArgs</code> 类)</strong></h3><ul>\n<li><code>ModelArgs</code> 类是一个数据类，用于定义和存储模型的各种超参数，例如：<ul>\n<li><code>dim</code>: 模型的维度。</li>\n<li><code>n_layers</code>: Transformer 的层数。</li>\n<li><code>n_heads</code>: 注意力机制中的头数。</li>\n<li><code>vocab_size</code>: 词汇表大小。</li>\n<li><code>max_batch_size</code>: 最大批处理大小。</li>\n<li><code>max_seq_len</code>: 最大序列长度。</li>\n</ul>\n</li>\n<li>这些参数在模型初始化时被使用，决定了模型的结构和行为。</li>\n</ul>\n<h3 id=\"2-RMSNorm-层-RMSNorm-类\"><a href=\"#2-RMSNorm-层-RMSNorm-类\" class=\"headerlink\" title=\"2. RMSNorm 层 (RMSNorm 类)\"></a>2. <strong>RMSNorm 层 (<code>RMSNorm</code> 类)</strong></h3><ul>\n<li><code>RMSNorm</code> 是一个自定义的归一化层，用于替代传统的 LayerNorm。它通过对输入进行<strong>均方根归一化</strong>来稳定训练过程。</li>\n<li>该层在 Transformer 的每个子层（如注意力机制和前馈网络）之后使用。</li>\n</ul>\n<h3 id=\"3-RoPE-Rotary-Positional-Embedding\"><a href=\"#3-RoPE-Rotary-Positional-Embedding\" class=\"headerlink\" title=\"3. RoPE (Rotary Positional Embedding)\"></a>3. <strong>RoPE (Rotary Positional Embedding)</strong></h3><ul>\n<li>该模块实现了旋转位置编码（RoPE），用于为输入序列中的每个位置生成位置编码。RoPE 通过将位置信息嵌入到注意力机制中，帮助模型捕捉序列中的位置关系。</li>\n<li><code>precompute_freqs_cis</code> 函数预计算了频率矩阵，<code>apply_rotary_emb</code> 函数将旋转<strong>位置编码应用到查询和键向量上。</strong></li>\n</ul>\n<h3 id=\"4-注意力机制-Attention-类\"><a href=\"#4-注意力机制-Attention-类\" class=\"headerlink\" title=\"4. 注意力机制 (Attention 类)\"></a>4. <strong>注意力机制 (<code>Attention</code> 类)</strong></h3><ul>\n<li><code>Attention</code> 类实现了多头注意力机制（Multi-Head Attention），这是 Transformer 模型的核心组件之一。</li>\n<li>它使用 <code>ColumnParallelLinear</code> 和 <code>RowParallelLinear</code> 来实现并行的线性变换，支持模型并行化。</li>\n<li>该模块还实现了键值缓存（KV Cache），用于在生成过程中缓存先前的键和值，以减少重复计算。</li>\n</ul>\n<h3 id=\"5-前馈网络-FeedForward-类\"><a href=\"#5-前馈网络-FeedForward-类\" class=\"headerlink\" title=\"5. 前馈网络 (FeedForward 类)\"></a>5. <strong>前馈网络 (<code>FeedForward</code> 类)</strong></h3><ul>\n<li><code>FeedForward</code> 类实现了 Transformer 中的前馈神经网络（FFN），通常由两个线性变换和一个激活函数（如 SiLU）组成。</li>\n<li>该模块也支持模型并行化，使用 <code>ColumnParallelLinear</code> 和 <code>RowParallelLinear</code> 来实现并行的线性变换。</li>\n</ul>\n<h3 id=\"6-Transformer-块-TransformerBlock-类\"><a href=\"#6-Transformer-块-TransformerBlock-类\" class=\"headerlink\" title=\"6. Transformer 块 (TransformerBlock 类)\"></a>6. <strong>Transformer 块 (<code>TransformerBlock</code> 类)</strong></h3><ul>\n<li><code>TransformerBlock</code> 类将注意力机制和前馈网络组合在一起，形成一个完整的 Transformer 层。</li>\n<li>每个 Transformer 块包含一个注意力层和一个前馈网络层，并且在每个子层之后应用 RMSNorm 进行归一化。</li>\n</ul>\n<h3 id=\"7-Transformer-模型-Transformer-类\"><a href=\"#7-Transformer-模型-Transformer-类\" class=\"headerlink\" title=\"7. Transformer 模型 (Transformer 类)\"></a>7. <strong>Transformer 模型 (<code>Transformer</code> 类)</strong></h3><ul>\n<li><code>Transformer</code> 类是整个模型的核心，它由多个 <code>TransformerBlock</code> 组成，形成一个深层的 Transformer 网络。</li>\n<li>该模块还负责处理输入嵌入、位置编码、以及最终的输出线性变换。</li>\n<li><code>forward</code> 方法实现了模型的前向传播过程，包括嵌入、位置编码、多层 Transformer 块的处理以及最终的输出生成。</li>\n</ul>\n<h3 id=\"8-模型并行化\"><a href=\"#8-模型并行化\" class=\"headerlink\" title=\"8. 模型并行化\"></a>8. <strong>模型并行化</strong></h3><ul>\n<li>该模块使用了 <code>fairscale</code> 库中的 <code>ColumnParallelLinear</code> 和 <code>RowParallelLinear</code> 来实现模型并行化，允许模型在多个 GPU 上分布计算，从而提高训练和推理的效率。</li>\n</ul>\n<h3 id=\"9-推理模式\"><a href=\"#9-推理模式\" class=\"headerlink\" title=\"9. 推理模式\"></a>9. <strong>推理模式</strong></h3><ul>\n<li>在推理模式下，模型使用 <code>torch.inference_mode()</code> 来禁用梯度计算，从而提高推理速度并减少内存占用。</li>\n</ul>\n<h3 id=\"总结：\"><a href=\"#总结：\" class=\"headerlink\" title=\"总结：\"></a>总结：</h3><p><code>model.py</code> 模块定义了 Llama 3 模型的核心架构，包括 Transformer 的各个组件（如注意力机制、前馈网络、归一化层等），并实现了模型并行化和推理优化。它是整个 Llama 3 模型的基础，负责处理输入数据并生成输出。</p>\n<h2 id=\"模型详细流程图\"><a href=\"#模型详细流程图\" class=\"headerlink\" title=\"模型详细流程图\"></a>模型详细流程图</h2><pre><code class=\" mermaid\">graph TD\n    A[输入 tokens] --&gt; B[Token Embedding]\n    B --&gt; C[添加位置编码 freqs_cis]\n    C --&gt; D[初始化 mask]\n    D --&gt; E[进入 Transformer 层]\n    E --&gt; F[Transformer Block 1]\n    E --&gt; G[Transformer Block 2]\n    E --&gt; H[...]\n    E --&gt; I[Transformer Block N]\n    F --&gt; J[输出 logits]\n    G --&gt; J\n    H --&gt; J\n    I --&gt; J\n\n    subgraph Transformer Block\n        direction TB\n        K[输入] --&gt; L[RMSNorm]\n        L --&gt; M[Attention]\n        M --&gt; N[Add &amp; Norm]\n        N --&gt; O[FeedForward]\n        O --&gt; P[Add &amp; Norm]\n        P --&gt; Q[输出]\n    end\n\n    F --&gt; K\n    G --&gt; K\n    I --&gt; K\n</code></pre>\n\n<ol>\n<li><p><strong>输入 tokens</strong>  </p>\n<ul>\n<li>输入是一个批次的 token IDs，形状为 <code>(batch_size, seq_len)</code>。</li>\n</ul>\n</li>\n<li><p><strong>Token Embedding</strong>  </p>\n<ul>\n<li>通过 <code>tok_embeddings</code> 将 token IDs 转换为嵌入向量，形状为 <code>(batch_size, seq_len, dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>添加位置编码 freqs_cis</strong>  </p>\n<ul>\n<li>使用预计算的 <code>freqs_cis</code> 为嵌入向量添加旋转位置编码，帮助模型捕捉序列中的位置信息。</li>\n</ul>\n</li>\n<li><p><strong>初始化 mask</strong>  </p>\n<ul>\n<li>根据 <code>seq_len</code> 和 <code>start_pos</code> 生成注意力掩码 <code>mask</code>，用于防止模型看到未来的 token。</li>\n</ul>\n</li>\n<li><p><strong>进入 Transformer 层</strong>  </p>\n<ul>\n<li>嵌入向量和位置编码进入多层 Transformer 块进行处理。</li>\n</ul>\n</li>\n<li><p><strong>Transformer Block 1 到 N</strong>  </p>\n<ul>\n<li>每个 Transformer 块包含以下步骤：<ul>\n<li><strong>RMSNorm</strong>: 对输入进行归一化。</li>\n<li><strong>Attention</strong>: 应用多头注意力机制，生成注意力输出。</li>\n<li><strong>RMSNorm</strong>: 对注意力输出进行归一化。</li>\n<li><strong>FeedForward</strong>: 应用前馈网络，生成最终的 Transformer 块输出。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p><strong>应用 RMSNorm</strong>  </p>\n<ul>\n<li>在所有 Transformer 块处理完成后，对最终输出应用 RMSNorm 进行归一化。</li>\n</ul>\n</li>\n<li><p><strong>输出线性变换</strong>  </p>\n<ul>\n<li>通过 <code>output</code> 线性层将归一化后的输出映射到词汇表空间，形状为 <code>(batch_size, seq_len, vocab_size)</code>。</li>\n</ul>\n</li>\n<li><p><strong>输出 logits</strong>  </p>\n<ul>\n<li>返回最终的 logits，表示每个 token 的概率分布。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"class-ModelArgs\"><a href=\"#class-ModelArgs\" class=\"headerlink\" title=\"class ModelArgs\"></a><code>class ModelArgs</code></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-meta\">@dataclass</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ModelArgs</span>:<br>    dim: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">4096</span>  <span class=\"hljs-comment\"># 模型的维度，即每个token的向量表示的大小</span><br>    n_layers: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">32</span>  <span class=\"hljs-comment\"># 模型的层数，即Transformer的层数</span><br>    n_heads: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">32</span>  <span class=\"hljs-comment\"># 注意力机制中的头数</span><br>    n_kv_heads: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">int</span>] = <span class=\"hljs-literal\">None</span>  <span class=\"hljs-comment\"># 键值头的数量，如果为None，则与n_heads相同</span><br>    vocab_size: <span class=\"hljs-built_in\">int</span> = -<span class=\"hljs-number\">1</span>  <span class=\"hljs-comment\"># 词汇表的大小，通常由tokenizer决定</span><br>    multiple_of: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">256</span>  <span class=\"hljs-comment\"># SwiGLU激活函数中隐藏层大小的倍数，确保是256的倍数</span><br>    ffn_dim_multiplier: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">float</span>] = <span class=\"hljs-literal\">None</span>  <span class=\"hljs-comment\"># 前馈网络维度的乘数，用于调整隐藏层大小</span><br>    norm_eps: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">1e-5</span>  <span class=\"hljs-comment\"># Layer Normalization中的epsilon值，用于数值稳定性</span><br>    rope_theta: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">500000</span>  <span class=\"hljs-comment\"># RoPE（Rotary Position Embedding）中的theta参数</span><br><br>    max_batch_size: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">32</span>  <span class=\"hljs-comment\"># 最大批处理大小</span><br>    max_seq_len: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">2048</span>  <span class=\"hljs-comment\"># 最大序列长度</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"class-RMSNorm\"><a href=\"#class-RMSNorm\" class=\"headerlink\" title=\"class RMSNorm\"></a><code>class RMSNorm</code></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">RMSNorm</span>(torch.nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, dim: <span class=\"hljs-built_in\">int</span>, eps: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">1e-6</span></span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        <span class=\"hljs-variable language_\">self</span>.eps = eps  <span class=\"hljs-comment\"># 用于数值稳定性的小值，防止除以零</span><br>        <span class=\"hljs-variable language_\">self</span>.weight = nn.Parameter(torch.ones(dim))  <span class=\"hljs-comment\"># 可学习的缩放参数，初始化为1</span><br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">_norm</span>(<span class=\"hljs-params\">self, x</span>):<br>        <span class=\"hljs-comment\"># 计算RMS（Root Mean Square）归一化，对输入x进行归一化处理</span><br>        <span class=\"hljs-keyword\">return</span> x * torch.rsqrt(x.<span class=\"hljs-built_in\">pow</span>(<span class=\"hljs-number\">2</span>).mean(-<span class=\"hljs-number\">1</span>, keepdim=<span class=\"hljs-literal\">True</span>) + <span class=\"hljs-variable language_\">self</span>.eps)<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        <span class=\"hljs-comment\"># 前向传播函数，先对输入x进行归一化，然后乘以可学习的缩放参数</span><br>        output = <span class=\"hljs-variable language_\">self</span>._norm(x.<span class=\"hljs-built_in\">float</span>()).type_as(x)  <span class=\"hljs-comment\"># 归一化并保持与输入x相同的数据类型</span><br>        <span class=\"hljs-keyword\">return</span> output * <span class=\"hljs-variable language_\">self</span>.weight  <span class=\"hljs-comment\"># 乘以缩放参数</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"解释：\"><a href=\"#解释：\" class=\"headerlink\" title=\"解释：\"></a>解释：</h3><ol>\n<li><p><strong><code>ModelArgs</code></strong>:</p>\n<ul>\n<li>这是一个数据类，用于存储模型的配置参数。它定义了模型的结构和超参数，如模型的维度、层数、注意力头数等。</li>\n<li><code>dim</code> 是每个token的向量表示的大小，<code>n_layers</code> 是Transformer的层数，<code>n_heads</code> 是注意力机制中的头数。</li>\n<li><code>vocab_size</code> 是词汇表的大小，通常由tokenizer决定。</li>\n<li><code>multiple_of</code> 和 <code>ffn_dim_multiplier</code> 用于调整前馈网络的隐藏层大小。</li>\n<li><code>norm_eps</code> 是Layer Normalization中的epsilon值，用于数值稳定性。</li>\n<li><code>rope_theta</code> 是RoPE（Rotary Position Embedding）中的theta参数，用于位置编码。</li>\n<li><code>max_batch_size</code> 和 <code>max_seq_len</code> 分别定义了模型的最大批处理大小和最大序列长度。</li>\n</ul>\n</li>\n<li><p><strong><code>RMSNorm</code></strong>:</p>\n<ul>\n<li>这是一个自定义的归一化层，类似于Layer Normalization，但使用了RMS（Root Mean Square）归一化。</li>\n<li><code>_norm</code> 方法计算输入的RMS归一化值，<code>forward</code> 方法在前向传播时对输入进行归一化并乘以可学习的缩放参数。</li>\n<li><code>eps</code> 是一个小值，用于防止除以零的情况，<code>weight</code> 是可学习的缩放参数，初始化为1。</li>\n</ul>\n</li>\n</ol>\n<p>这两个类在模型中分别用于定义模型的结构和实现归一化操作，是Transformer模型的重要组成部分。</p>\n<hr>\n<h2 id=\"旋转位置编码\"><a href=\"#旋转位置编码\" class=\"headerlink\" title=\"旋转位置编码\"></a>旋转位置编码</h2><h3 id=\"precompute-freqs-cis\"><a href=\"#precompute-freqs-cis\" class=\"headerlink\" title=\"precompute_freqs_cis\"></a><strong><code>precompute_freqs_cis</code></strong></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">precompute_freqs_cis</span>(<span class=\"hljs-params\">dim: <span class=\"hljs-built_in\">int</span>, end: <span class=\"hljs-built_in\">int</span>, theta: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">10000.0</span></span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    预计算旋转位置编码的频率矩阵 (freqs_cis)。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    旋转位置编码 (Rotary Positional Embedding, RoPE) 是一种将位置信息嵌入到注意力机制中的方法。</span><br><span class=\"hljs-string\">    它通过将位置信息编码为复数形式，应用到查询和键向量上。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    参数:</span><br><span class=\"hljs-string\">        dim (int): 模型的维度（通常是注意力头的维度）。</span><br><span class=\"hljs-string\">        end (int): 序列的最大长度。</span><br><span class=\"hljs-string\">        theta (float): 控制频率的基数，默认为 10000.0。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    返回:</span><br><span class=\"hljs-string\">        freqs_cis (torch.Tensor): 预计算的频率矩阵，形状为 (end, dim // 2)，数据类型为 complex64。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 计算频率向量</span><br>    freqs = <span class=\"hljs-number\">1.0</span> / (theta ** (torch.arange(<span class=\"hljs-number\">0</span>, dim, <span class=\"hljs-number\">2</span>)[: (dim // <span class=\"hljs-number\">2</span>)].<span class=\"hljs-built_in\">float</span>() / dim))<br>    <span class=\"hljs-comment\"># 生成位置向量</span><br>    t = torch.arange(end, device=freqs.device, dtype=torch.float32)<br>    <span class=\"hljs-comment\"># 计算外积，得到频率矩阵</span><br>    freqs = torch.outer(t, freqs)<br>    <span class=\"hljs-comment\"># 将频率矩阵转换为复数形式（极坐标表示）</span><br>    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  <span class=\"hljs-comment\"># complex64</span><br>    <span class=\"hljs-keyword\">return</span> freqs_cis<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-1\"><a href=\"#解释：-1\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><strong>作用</strong>: 预计算旋转位置编码的频率矩阵 <code>freqs_cis</code>，用于将位置信息嵌入到查询和键向量中。</li>\n<li><strong>输入</strong>:<ul>\n<li><code>dim</code>: 模型的维度，通常是注意力头的维度。</li>\n<li><code>end</code>: 序列的最大长度。</li>\n<li><code>theta</code>: 控制频率的基数，默认为 10000.0。</li>\n</ul>\n</li>\n<li><strong>输出</strong>:<ul>\n<li><code>freqs_cis</code>: 预计算的频率矩阵，形状为 <code>(end, dim // 2)</code>，数据类型为 <code>complex64</code>。</li>\n</ul>\n</li>\n<li><strong>关键点</strong>:<ul>\n<li>使用 <code>torch.outer</code> 计算位置向量和频率向量的外积，得到频率矩阵。</li>\n<li>通过 <code>torch.polar</code> 将频率矩阵转换为复数形式，表示极坐标。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"reshape-for-broadcast\"><a href=\"#reshape-for-broadcast\" class=\"headerlink\" title=\"reshape_for_broadcast\"></a><strong><code>reshape_for_broadcast</code></strong></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">reshape_for_broadcast</span>(<span class=\"hljs-params\">freqs_cis: torch.Tensor, x: torch.Tensor</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    将频率矩阵 `freqs_cis` 重塑为适合广播的形状，以便与查询或键向量进行逐元素操作。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    参数:</span><br><span class=\"hljs-string\">        freqs_cis (torch.Tensor): 频率矩阵，形状为 (seq_len, dim // 2)。</span><br><span class=\"hljs-string\">        x (torch.Tensor): 查询或键向量，形状为 (batch_size, seq_len, n_heads, head_dim)。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    返回:</span><br><span class=\"hljs-string\">        freqs_cis (torch.Tensor): 重塑后的频率矩阵，形状为 (1, seq_len, 1, dim // 2)。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    ndim = x.ndim<br>    <span class=\"hljs-keyword\">assert</span> <span class=\"hljs-number\">0</span> &lt;= <span class=\"hljs-number\">1</span> &lt; ndim<br>    <span class=\"hljs-keyword\">assert</span> freqs_cis.shape == (x.shape[<span class=\"hljs-number\">1</span>], x.shape[-<span class=\"hljs-number\">1</span>])<br>    <span class=\"hljs-comment\"># 重塑频率矩阵，使其形状为 (1, seq_len, 1, dim // 2)</span><br>    shape = [d <span class=\"hljs-keyword\">if</span> i == <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">or</span> i == ndim - <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">for</span> i, d <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(x.shape)]<br>    <span class=\"hljs-keyword\">return</span> freqs_cis.view(*shape)<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-2\"><a href=\"#解释：-2\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><strong>作用</strong>: 将频率矩阵 <code>freqs_cis</code> 重塑为适合广播的形状，以便与查询或键向量进行逐元素操作。</li>\n<li><strong>输入</strong>:<ul>\n<li><code>freqs_cis</code>: 频率矩阵，形状为 <code>(seq_len, dim // 2)</code>。</li>\n<li><code>x</code>: 查询或键向量，形状为 <code>(batch_size, seq_len, n_heads, head_dim)</code>。</li>\n</ul>\n</li>\n<li><strong>输出</strong>:<ul>\n<li>重塑后的频率矩阵，形状为 <code>(1, seq_len, 1, dim // 2)</code>。</li>\n</ul>\n</li>\n<li><strong>关键点</strong>:<ul>\n<li>通过 <code>view</code> 方法将频率矩阵重塑为适合广播的形状，使其能够与查询或键向量进行逐元素操作。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"apply-rotary-emb\"><a href=\"#apply-rotary-emb\" class=\"headerlink\" title=\"apply_rotary_emb\"></a><strong><code>apply_rotary_emb</code></strong></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">apply_rotary_emb</span>(<span class=\"hljs-params\"></span><br><span class=\"hljs-params\">    xq: torch.Tensor,</span><br><span class=\"hljs-params\">    xk: torch.Tensor,</span><br><span class=\"hljs-params\">    freqs_cis: torch.Tensor,</span><br><span class=\"hljs-params\"></span>) -&gt; <span class=\"hljs-type\">Tuple</span>[torch.Tensor, torch.Tensor]:<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    将旋转位置编码应用到查询和键向量上。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    旋转位置编码通过将位置信息嵌入到查询和键向量中，帮助模型捕捉序列中的位置关系。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    参数:</span><br><span class=\"hljs-string\">        xq (torch.Tensor): 查询向量，形状为 (batch_size, seq_len, n_heads, head_dim)。</span><br><span class=\"hljs-string\">        xk (torch.Tensor): 键向量，形状为 (batch_size, seq_len, n_heads, head_dim)。</span><br><span class=\"hljs-string\">        freqs_cis (torch.Tensor): 频率矩阵，形状为 (1, seq_len, 1, head_dim // 2)。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    返回:</span><br><span class=\"hljs-string\">        xq_out (torch.Tensor): 应用旋转位置编码后的查询向量。</span><br><span class=\"hljs-string\">        xk_out (torch.Tensor): 应用旋转位置编码后的键向量。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 将查询和键向量转换为复数形式</span><br>    xq_ = torch.view_as_complex(xq.<span class=\"hljs-built_in\">float</span>().reshape(*xq.shape[:-<span class=\"hljs-number\">1</span>], -<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>))<br>    xk_ = torch.view_as_complex(xk.<span class=\"hljs-built_in\">float</span>().reshape(*xk.shape[:-<span class=\"hljs-number\">1</span>], -<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>))<br>    <span class=\"hljs-comment\"># 重塑频率矩阵以匹配查询和键向量的形状</span><br>    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)<br>    <span class=\"hljs-comment\"># 应用旋转位置编码</span><br>    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(<span class=\"hljs-number\">3</span>)<br>    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(<span class=\"hljs-number\">3</span>)<br>    <span class=\"hljs-keyword\">return</span> xq_out.type_as(xq), xk_out.type_as(xk)<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-3\"><a href=\"#解释：-3\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><p><strong>作用</strong>: 将旋转位置编码应用到查询和键向量上，帮助模型捕捉序列中的位置关系。</p>\n</li>\n<li><p><strong>输入</strong>:</p>\n<ul>\n<li><code>xq</code>: 查询向量，形状为 <code>(batch_size, seq_len, n_heads, head_dim)</code>。</li>\n<li><code>xk</code>: 键向量，形状为 <code>(batch_size, seq_len, n_heads, head_dim)</code>。</li>\n<li><code>freqs_cis</code>: 频率矩阵，形状为 <code>(1, seq_len, 1, head_dim // 2)</code>。</li>\n</ul>\n</li>\n<li><p><strong>输出</strong>:</p>\n<ul>\n<li><code>xq_out</code>: 应用旋转位置编码后的查询向量。</li>\n<li><code>xk_out</code>: 应用旋转位置编码后的键向量。</li>\n</ul>\n</li>\n<li><p><strong>关键点</strong>:</p>\n<ul>\n<li>使用 <code>torch.view_as_complex</code> 将查询和键向量转换为复数形式。</li>\n<li>通过逐元素乘法将频率矩阵应用到查询和键向量上。</li>\n<li>使用 <code>torch.view_as_real</code> 将结果转换回实数形式。</li>\n</ul>\n<p>这些函数共同实现了旋转位置编码（RoPE）</p>\n<h3 id=\"总结：-1\"><a href=\"#总结：-1\" class=\"headerlink\" title=\"总结：\"></a>总结：</h3><ul>\n<li><strong><code>precompute_freqs_cis</code></strong>: 预计算旋转位置编码的频率矩阵。</li>\n<li><strong><code>reshape_for_broadcast</code></strong>: 将频率矩阵重塑为适合广播的形状。</li>\n<li><strong><code>apply_rotary_emb</code></strong>: 将旋转位置编码应用到查询和键向量上。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2 id=\"repeat-kv\"><a href=\"#repeat-kv\" class=\"headerlink\" title=\"repeat_kv\"></a><strong><code>repeat_kv</code></strong></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">repeat_kv</span>(<span class=\"hljs-params\">x: torch.Tensor, n_rep: <span class=\"hljs-built_in\">int</span></span>) -&gt; torch.Tensor:<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    重复键或值向量，以匹配查询向量的头数。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    在分组注意力机制中，键和值向量的头数可能少于查询向量的头数，因此需要重复键和值向量以匹配查询向量的头数。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    参数:</span><br><span class=\"hljs-string\">        x (torch.Tensor): 键或值向量，形状为 (batch_size, seq_len, n_kv_heads, head_dim)。</span><br><span class=\"hljs-string\">        n_rep (int): 重复次数，通常为查询头数与键值头数的比值。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    返回:</span><br><span class=\"hljs-string\">        torch.Tensor: 重复后的键或值向量，形状为 (batch_size, seq_len, n_kv_heads * n_rep, head_dim)。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    bs, slen, n_kv_heads, head_dim = x.shape<br>    <span class=\"hljs-keyword\">if</span> n_rep == <span class=\"hljs-number\">1</span>:<br>        <span class=\"hljs-keyword\">return</span> x<br>    <span class=\"hljs-keyword\">return</span> (<br>        x[:, :, :, <span class=\"hljs-literal\">None</span>, :]<br>        .expand(bs, slen, n_kv_heads, n_rep, head_dim)<br>        .reshape(bs, slen, n_kv_heads * n_rep, head_dim)<br>    )<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-4\"><a href=\"#解释：-4\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><strong>作用</strong>: 重复键或值向量，以匹配查询向量的头数。</li>\n<li><strong>输入</strong>:<ul>\n<li><code>x</code>: 键或值向量，形状为 <code>(batch_size, seq_len, n_kv_heads, head_dim)</code>。</li>\n<li><code>n_rep</code>: 重复次数，通常为查询头数与键值头数的比值。</li>\n</ul>\n</li>\n<li><strong>输出</strong>:<ul>\n<li>重复后的键或值向量，形状为 <code>(batch_size, seq_len, n_kv_heads * n_rep, head_dim)</code>。</li>\n</ul>\n</li>\n<li><strong>关键点</strong>:<ul>\n<li>使用 <code>expand</code> 和 <code>reshape</code> 方法重复键或值向量，使其头数与查询向量匹配。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"class-Attention\"><a href=\"#class-Attention\" class=\"headerlink\" title=\"class Attention\"></a><code>class Attention</code></h2><p><code>class Attention</code> 实现了 Transformer 中的 <strong>多头注意力机制（Multi-Head Attention）</strong>，它是 Transformer 模型的核心组件之一。以下是该类的详细解释：</p>\n<h4 id=\"主要功能：\"><a href=\"#主要功能：\" class=\"headerlink\" title=\"主要功能：\"></a><strong>主要功能</strong>：</h4><ol>\n<li><p><strong>多头注意力机制</strong>：</p>\n<ul>\n<li>将输入向量拆分为多个头，每个头独立计算注意力分数。</li>\n<li>通过并行计算，捕捉输入序列中不同位置之间的关系。</li>\n</ul>\n</li>\n<li><p><strong>键值缓存（KV Cache）</strong>：</p>\n<ul>\n<li>在生成任务中，缓存先前的键和值，避免重复计算，提高效率。</li>\n</ul>\n</li>\n<li><p><strong>模型并行化</strong>：</p>\n<ul>\n<li>使用 <code>ColumnParallelLinear</code> 和 <code>RowParallelLinear</code> 实现并行的线性变换，支持多 GPU 计算。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"关键组件：\"><a href=\"#关键组件：\" class=\"headerlink\" title=\"关键组件：\"></a><strong>关键组件</strong>：</h4><ol>\n<li><p><strong>线性变换</strong>：</p>\n<ul>\n<li><code>wq</code>、<code>wk</code>、<code>wv</code>：分别对输入进行线性变换，生成查询（Query）、键（Key）和值（Value）向量。</li>\n<li><code>wo</code>：将多头注意力的输出进行线性变换，合并为最终输出。</li>\n</ul>\n</li>\n<li><p><strong>键值缓存</strong>：</p>\n<ul>\n<li><code>cache_k</code> 和 <code>cache_v</code>：用于缓存先前的键和值，形状为 <code>(batch_size, max_seq_len, n_local_kv_heads, head_dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>旋转位置编码（RoPE）</strong>：</p>\n<ul>\n<li>通过 <code>apply_rotary_emb</code> 将位置信息嵌入到查询和键向量中。</li>\n</ul>\n</li>\n<li><p><strong>注意力分数计算</strong>：</p>\n<ul>\n<li>计算查询和键的点积，除以 <code>sqrt(head_dim)</code> 进行缩放，然后应用 Softmax 得到注意力分数。</li>\n</ul>\n</li>\n<li><p><strong>输出计算</strong>：</p>\n<ul>\n<li>使用注意力分数对值向量进行加权求和，得到多头注意力的输出。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"流程图\"><a href=\"#流程图\" class=\"headerlink\" title=\"&#96;流程图\"></a><strong>&#96;流程图</strong></h3><pre><code class=\" mermaid\">graph TD\n    A[输入 x] --&gt; B[线性变换]\n    B --&gt; C[生成 Query]\n    B --&gt; D[生成 Key]\n    B --&gt; E[生成 Value]\n    C --&gt; F[应用旋转位置编码]\n    D --&gt; F\n    F --&gt; G[更新键值缓存]\n    G --&gt; H[计算注意力分数]\n    H --&gt; I[应用 Softmax]\n    I --&gt; J[加权求和]\n    J --&gt; K[线性变换]\n    K --&gt; L[输出]\n</code></pre>\n\n<h3 id=\"详细步骤说明：\"><a href=\"#详细步骤说明：\" class=\"headerlink\" title=\"详细步骤说明：\"></a><strong>详细步骤说明</strong>：</h3><ol>\n<li><p><strong>输入 x</strong>  </p>\n<ul>\n<li>输入是一个批次的嵌入向量，形状为 <code>(batch_size, seq_len, dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>线性变换</strong>  </p>\n<ul>\n<li>通过 <code>wq</code>、<code>wk</code>、<code>wv</code> 分别对输入进行线性变换，生成查询（Query）、键（Key）和值（Value）向量。</li>\n</ul>\n</li>\n<li><p><strong>生成 Query、Key、Value</strong>  </p>\n<ul>\n<li>查询向量形状为 <code>(batch_size, seq_len, n_local_heads, head_dim)</code>。</li>\n<li>键和值向量形状为 <code>(batch_size, seq_len, n_local_kv_heads, head_dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>应用旋转位置编码</strong>  </p>\n<ul>\n<li>使用 <code>apply_rotary_emb</code> 将旋转位置编码应用到查询和键向量上。</li>\n</ul>\n</li>\n<li><p><strong>更新键值缓存</strong>  </p>\n<ul>\n<li>将当前的键和值向量缓存到 <code>cache_k</code> 和 <code>cache_v</code> 中。</li>\n</ul>\n</li>\n<li><p><strong>计算注意力分数</strong>  </p>\n<ul>\n<li>计算查询和键的点积，除以 <code>sqrt(head_dim)</code> 进行缩放，得到注意力分数。</li>\n</ul>\n</li>\n<li><p><strong>应用 Softmax</strong>  </p>\n<ul>\n<li>对注意力分数应用 Softmax，得到归一化的注意力权重。</li>\n</ul>\n</li>\n<li><p><strong>加权求和</strong>  </p>\n<ul>\n<li>使用注意力权重对值向量进行加权求和，得到多头注意力的输出。</li>\n</ul>\n</li>\n<li><p><strong>线性变换</strong>  </p>\n<ul>\n<li>通过 <code>wo</code> 对多头注意力的输出进行线性变换，合并为最终输出。</li>\n</ul>\n</li>\n<li><p><strong>输出</strong>  </p>\n<ul>\n<li>返回最终的输出，形状为 <code>(batch_size, seq_len, dim)</code>。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"代码实现的关键点：\"><a href=\"#代码实现的关键点：\" class=\"headerlink\" title=\"代码实现的关键点：\"></a><strong>代码实现的关键点</strong>：</h3><ol>\n<li><p><strong>并行化</strong>：</p>\n<ul>\n<li>使用 <code>ColumnParallelLinear</code> 和 <code>RowParallelLinear</code> 实现并行的线性变换，支持多 GPU 计算。</li>\n</ul>\n</li>\n<li><p><strong>键值缓存</strong>：</p>\n<ul>\n<li>在生成任务中，缓存先前的键和值，避免重复计算，提高效率。</li>\n</ul>\n</li>\n<li><p><strong>旋转位置编码</strong>：</p>\n<ul>\n<li>通过 <code>apply_rotary_emb</code> 将位置信息嵌入到查询和键向量中，帮助模型捕捉序列中的位置关系。</li>\n</ul>\n</li>\n<li><p><strong>注意力分数计算</strong>：</p>\n<ul>\n<li>使用点积计算注意力分数，并通过 Softmax 进行归一化。</li>\n</ul>\n</li>\n<li><p><strong>输出计算</strong>：</p>\n<ul>\n<li>使用注意力权重对值向量进行加权求和，得到多头注意力的输出。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"总结：-2\"><a href=\"#总结：-2\" class=\"headerlink\" title=\"总结：\"></a><strong>总结</strong>：</h3><p><code>class Attention</code> 实现了 Transformer 中的多头注意力机制，通过并行化、键值缓存和旋转位置编码等技术，高效地捕捉输入序列中的关系。</p>\n<h2 id=\"FeedForward\"><a href=\"#FeedForward\" class=\"headerlink\" title=\"FeedForward\"></a><code>FeedForward</code></h2><pre><code class=\" mermaid\">graph TD\n    A[输入 x] --&gt; B[线性变换 W1]\n    B --&gt; C[激活函数 SiLU]\n    C --&gt; D[线性变换 W3]\n    D --&gt; E[逐元素乘法]\n    E --&gt; F[线性变换 W2]\n    F --&gt; G[输出]\n</code></pre>\n\n<h3 id=\"详细步骤说明：-1\"><a href=\"#详细步骤说明：-1\" class=\"headerlink\" title=\"详细步骤说明：\"></a><strong>详细步骤说明</strong>：</h3><ol>\n<li><p><strong>输入 x</strong>  </p>\n<ul>\n<li>输入是一个批次的向量，形状为 <code>(batch_size, seq_len, dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>线性变换 W1</strong>  </p>\n<ul>\n<li>通过 <code>w1</code> 对输入进行线性变换，生成中间向量，形状为 <code>(batch_size, seq_len, hidden_dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>激活函数 SiLU</strong>  </p>\n<ul>\n<li><p>对线性变换后的结果应用 SiLU（Sigmoid Linear Unit）激活函数，公式为：  </p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241230114851133.png\"></p>\n</li>\n</ul>\n</li>\n<li><p><strong>线性变换 W3</strong>  </p>\n<ul>\n<li>通过 <code>w3</code> 对输入进行另一个线性变换，生成中间向量，形状为 <code>(batch_size, seq_len, hidden_dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>逐元素乘法</strong>  </p>\n<ul>\n<li>将 <code>SiLU(W1(x))</code> 和 <code>W3(x)</code> 进行逐元素乘法，生成加权后的中间向量。</li>\n</ul>\n</li>\n<li><p><strong>线性变换 W2</strong>  </p>\n<ul>\n<li>通过 <code>w2</code> 对加权后的中间向量进行线性变换，生成最终输出，形状为 <code>(batch_size, seq_len, dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>输出</strong>  </p>\n<ul>\n<li>返回最终的输出，作为前馈网络的结果。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"代码实现的关键点：-1\"><a href=\"#代码实现的关键点：-1\" class=\"headerlink\" title=\"代码实现的关键点：\"></a><strong>代码实现的关键点</strong>：</h3><ol>\n<li><p><strong>并行化</strong>：</p>\n<ul>\n<li>使用 <code>ColumnParallelLinear</code> 和 <code>RowParallelLinear</code> 实现并行的线性变换，支持多 GPU 计算。</li>\n</ul>\n</li>\n<li><p><strong>激活函数</strong>：</p>\n<ul>\n<li>使用 SiLU 激活函数，结合了 Sigmoid 和线性变换的优点，增强了模型的非线性表达能力。</li>\n</ul>\n</li>\n<li><p><strong>逐元素乘法</strong>：</p>\n<ul>\n<li>将两个线性变换的结果进行逐元素乘法，生成加权后的中间向量。</li>\n</ul>\n</li>\n<li><p><strong>输出计算</strong>：</p>\n<ul>\n<li>通过 <code>w2</code> 对加权后的中间向量进行线性变换，生成最终输出。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"总结：-3\"><a href=\"#总结：-3\" class=\"headerlink\" title=\"总结：\"></a><strong>总结</strong>：</h3><p><code>FeedForward</code> 类实现了 Transformer 中的前馈网络，通过线性变换、激活函数和逐元素乘法等技术，增强了模型的非线性表达能力。</p>\n<h2 id=\"TransformerBlock\"><a href=\"#TransformerBlock\" class=\"headerlink\" title=\"TransformerBlock\"></a><code>TransformerBlock</code></h2><pre><code class=\" mermaid\">graph TD\n    A[输入 x] --&gt; B[RMSNorm]\n    B --&gt; C[Attention]\n    C --&gt; D[Add &amp; Norm]\n    D --&gt; E[FeedForward]\n    E --&gt; F[Add &amp; Norm]\n    F --&gt; G[输出]\n</code></pre>\n\n<h3 id=\"详细步骤说明：-2\"><a href=\"#详细步骤说明：-2\" class=\"headerlink\" title=\"详细步骤说明：\"></a><strong>详细步骤说明</strong>：</h3><ol>\n<li><p><strong>输入 x</strong>  </p>\n<ul>\n<li>输入是一个批次的向量，形状为 <code>(batch_size, seq_len, dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>RMSNorm</strong>  </p>\n<ul>\n<li>对输入进行 RMSNorm 归一化，公式为：<br>[<br>\\text{RMSNorm}(x) &#x3D; \\frac{x}{\\sqrt{\\text{mean}(x^2) + \\epsilon}} \\cdot \\gamma<br>]<br>其中，(\\gamma) 是可学习的缩放参数，(\\epsilon) 是防止除零的小常数。</li>\n</ul>\n</li>\n<li><p><strong>Attention</strong>  </p>\n<ul>\n<li>将归一化后的输入传递给 <code>Attention</code> 模块，计算多头注意力机制的输出。</li>\n</ul>\n</li>\n<li><p><strong>Add &amp; Norm</strong>  </p>\n<ul>\n<li>将注意力输出与输入进行残差连接，然后再次应用 RMSNorm 归一化。</li>\n</ul>\n</li>\n<li><p><strong>FeedForward</strong>  </p>\n<ul>\n<li>将归一化后的结果传递给 <code>FeedForward</code> 模块，计算前馈网络的输出。</li>\n</ul>\n</li>\n<li><p><strong>Add &amp; Norm</strong>  </p>\n<ul>\n<li>将前馈网络输出与上一层的输出进行残差连接，然后再次应用 RMSNorm 归一化。</li>\n</ul>\n</li>\n<li><p><strong>输出</strong>  </p>\n<ul>\n<li>返回最终的输出，作为 Transformer 块的结果。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"代码实现的关键点：-2\"><a href=\"#代码实现的关键点：-2\" class=\"headerlink\" title=\"代码实现的关键点：\"></a><strong>代码实现的关键点</strong>：</h3><ol>\n<li><p><strong>残差连接</strong>：</p>\n<ul>\n<li>在注意力机制和前馈网络之后，分别使用残差连接，将输入与输出相加，缓解梯度消失问题。</li>\n</ul>\n</li>\n<li><p><strong>归一化</strong>：</p>\n<ul>\n<li>使用 RMSNorm 对输入和输出进行归一化，稳定训练过程。</li>\n</ul>\n</li>\n<li><p><strong>注意力机制</strong>：</p>\n<ul>\n<li>通过 <code>Attention</code> 模块计算多头注意力机制的输出，捕捉输入序列中的关系。</li>\n</ul>\n</li>\n<li><p><strong>前馈网络</strong>：</p>\n<ul>\n<li>通过 <code>FeedForward</code> 模块增强模型的非线性表达能力。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"总结：-4\"><a href=\"#总结：-4\" class=\"headerlink\" title=\"总结：\"></a><strong>总结</strong>：</h3><p><code>TransformerBlock</code> 类实现了 Transformer 中的一个完整块，包括注意力机制、前馈网络、残差连接和归一化操作。</p>\n<h2 id=\"class-Transformer\"><a href=\"#class-Transformer\" class=\"headerlink\" title=\"class Transformer\"></a><code>class Transformer</code></h2><pre><code class=\" mermaid\">graph TD\n    A[输入 tokens] --&gt; B[Token Embedding]\n    B --&gt; C[添加位置编码 freqs_cis]\n    C --&gt; D[初始化 mask]\n    D --&gt; E[进入 Transformer 层]\n    E --&gt; F[Transformer Block 1]\n    E --&gt; G[Transformer Block 2]\n    E --&gt; H[...]\n    E --&gt; I[Transformer Block N]\n    F --&gt; J[RMSNorm]\n    G --&gt; J\n    H --&gt; J\n    I --&gt; J\n    J --&gt; K[输出线性变换]\n    K --&gt; L[输出 logits]\n\n    subgraph Transformer Block\n        direction TB\n        M[输入] --&gt; N[RMSNorm]\n        N --&gt; O[Attention]\n        O --&gt; P[Add &amp; Norm]\n        P --&gt; Q[FeedForward]\n        Q --&gt; R[Add &amp; Norm]\n        R --&gt; S[输出]\n    end\n\n    F --&gt; M\n    G --&gt; M\n    I --&gt; M\n</code></pre>\n\n<h3 id=\"详细步骤说明：-3\"><a href=\"#详细步骤说明：-3\" class=\"headerlink\" title=\"详细步骤说明：\"></a><strong>详细步骤说明</strong>：</h3><h4 id=\"整体流程：\"><a href=\"#整体流程：\" class=\"headerlink\" title=\"整体流程：\"></a><strong>整体流程</strong>：</h4><ol>\n<li><p><strong>输入 tokens</strong>  </p>\n<ul>\n<li>输入是一个批次的 token IDs，形状为 <code>(batch_size, seq_len)</code>。</li>\n</ul>\n</li>\n<li><p><strong>Token Embedding</strong>  </p>\n<ul>\n<li>通过 <code>tok_embeddings</code> 将 token IDs 转换为嵌入向量，形状为 <code>(batch_size, seq_len, dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>添加位置编码 freqs_cis</strong>  </p>\n<ul>\n<li>使用预计算的 <code>freqs_cis</code> 为嵌入向量添加旋转位置编码，帮助模型捕捉序列中的位置信息。</li>\n</ul>\n</li>\n<li><p><strong>初始化 mask</strong>  </p>\n<ul>\n<li>根据 <code>seq_len</code> 和 <code>start_pos</code> 生成注意力掩码 <code>mask</code>，用于防止模型看到未来的 token。</li>\n</ul>\n</li>\n<li><p><strong>进入 Transformer 层</strong>  </p>\n<ul>\n<li>嵌入向量和位置编码进入多层 Transformer 块进行处理。</li>\n</ul>\n</li>\n<li><p><strong>Transformer Block 1 到 N</strong>  </p>\n<ul>\n<li>每个 Transformer 块内部执行子图中的流程。</li>\n</ul>\n</li>\n<li><p><strong>RMSNorm</strong>  </p>\n<ul>\n<li>在所有 Transformer 块处理完成后，对最终输出应用 RMSNorm 进行归一化。</li>\n</ul>\n</li>\n<li><p><strong>输出线性变换</strong>  </p>\n<ul>\n<li>通过 <code>output</code> 线性层将归一化后的输出映射到词汇表空间，形状为 <code>(batch_size, seq_len, vocab_size)</code>。</li>\n</ul>\n</li>\n<li><p><strong>输出 logits</strong>  </p>\n<ul>\n<li>返回最终的 logits，表示每个 token 的概率分布。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"Transformer-Block-子流程：\"><a href=\"#Transformer-Block-子流程：\" class=\"headerlink\" title=\"Transformer Block 子流程：\"></a><strong>Transformer Block 子流程</strong>：</h4><ol>\n<li><p><strong>输入</strong>  </p>\n<ul>\n<li>接收来自上一层的输入。</li>\n</ul>\n</li>\n<li><p><strong>RMSNorm</strong>  </p>\n<ul>\n<li>对输入进行归一化。</li>\n</ul>\n</li>\n<li><p><strong>Attention</strong>  </p>\n<ul>\n<li>应用多头注意力机制，生成注意力输出。</li>\n</ul>\n</li>\n<li><p><strong>Add &amp; Norm</strong>  </p>\n<ul>\n<li>将注意力输出与输入进行残差连接，并再次应用 RMSNorm 进行归一化。</li>\n</ul>\n</li>\n<li><p><strong>FeedForward</strong>  </p>\n<ul>\n<li>应用前馈网络，生成前馈输出。</li>\n</ul>\n</li>\n<li><p><strong>Add &amp; Norm</strong>  </p>\n<ul>\n<li>将前馈输出与上一层的输出进行残差连接，并再次应用 RMSNorm 进行归一化。</li>\n</ul>\n</li>\n<li><p><strong>输出</strong>  </p>\n<ul>\n<li>返回当前 Transformer 块的输出，作为下一层的输入。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"代码实现的关键点：-3\"><a href=\"#代码实现的关键点：-3\" class=\"headerlink\" title=\"代码实现的关键点：\"></a><strong>代码实现的关键点</strong>：</h3><ol>\n<li><p><strong>嵌入和位置编码</strong>：</p>\n<ul>\n<li>使用 <code>tok_embeddings</code> 将 token IDs 转换为嵌入向量，并通过 <code>freqs_cis</code> 添加位置信息。</li>\n</ul>\n</li>\n<li><p><strong>注意力掩码</strong>：</p>\n<ul>\n<li>生成注意力掩码 <code>mask</code>，防止模型看到未来的 token。</li>\n</ul>\n</li>\n<li><p><strong>多层 Transformer 块</strong>：</p>\n<ul>\n<li>通过多个 Transformer 块处理输入，每个块包含注意力机制、前馈网络、残差连接和归一化操作。</li>\n</ul>\n</li>\n<li><p><strong>输出生成</strong>：</p>\n<ul>\n<li>对最终输出进行归一化和线性变换，生成 logits。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"总结：-5\"><a href=\"#总结：-5\" class=\"headerlink\" title=\"总结：\"></a><strong>总结</strong>：</h3><p><code>class Transformer</code> 实现了完整的 Transformer 模型，包括嵌入、位置编码、多层 Transformer 块的处理以及最终的输出生成。</p>\n<h2 id=\"示例解析\"><a href=\"#示例解析\" class=\"headerlink\" title=\"示例解析\"></a>示例解析</h2><h3 id=\"示例输入\"><a href=\"#示例输入\" class=\"headerlink\" title=\"示例输入\"></a><strong>示例输入</strong></h3><p>假设我们有以下输入：</p>\n<ul>\n<li><strong>输入 tokens</strong>: <code>[[1, 2, 3]]</code>，形状为 <code>(batch_size=1, seq_len=3)</code>。</li>\n<li><strong>模型参数</strong>:<ul>\n<li><code>dim=4</code>（模型维度）。</li>\n<li><code>n_heads=2</code>（注意力头数）。</li>\n<li><code>vocab_size=10</code>（词汇表大小）。</li>\n<li><code>max_seq_len=8</code>（最大序列长度）。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"执行流程\"><a href=\"#执行流程\" class=\"headerlink\" title=\"执行流程\"></a><strong>执行流程</strong></h3><h4 id=\"1-Token-Embedding\"><a href=\"#1-Token-Embedding\" class=\"headerlink\" title=\"1. Token Embedding\"></a>1. <strong>Token Embedding</strong></h4><ul>\n<li><strong>输入</strong>: <code>tokens = [[1, 2, 3]]</code>，形状为 <code>(1, 3)</code>。</li>\n<li><strong>操作</strong>: 将 token IDs 转换为嵌入向量。</li>\n<li><strong>输出</strong>: 嵌入向量，形状为 <code>(1, 3, 4)</code>。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 假设嵌入矩阵为：</span><br>embedding_matrix = [<br>    [<span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">0.2</span>, <span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.4</span>],  <span class=\"hljs-comment\"># token 1</span><br>    [<span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">0.6</span>, <span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">0.8</span>],  <span class=\"hljs-comment\"># token 2</span><br>    [<span class=\"hljs-number\">0.9</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.1</span>, <span class=\"hljs-number\">1.2</span>],  <span class=\"hljs-comment\"># token 3</span><br>]<br><span class=\"hljs-comment\"># 输出：</span><br>h = [<br>    [[<span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">0.2</span>, <span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.4</span>],  <span class=\"hljs-comment\"># token 1</span><br>     [<span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">0.6</span>, <span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">0.8</span>],  <span class=\"hljs-comment\"># token 2</span><br>     [<span class=\"hljs-number\">0.9</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.1</span>, <span class=\"hljs-number\">1.2</span>]]  <span class=\"hljs-comment\"># token 3</span><br>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"2-添加位置编码\"><a href=\"#2-添加位置编码\" class=\"headerlink\" title=\"2. 添加位置编码\"></a>2. <strong>添加位置编码</strong></h4><ul>\n<li><strong>输入</strong>: 嵌入向量 <code>h</code>，形状为 <code>(1, 3, 4)</code>。</li>\n<li><strong>操作</strong>: 使用 <code>freqs_cis</code> 添加旋转位置编码。</li>\n<li><strong>输出</strong>: 添加位置编码后的向量，形状为 <code>(1, 3, 4)</code>。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 假设 freqs_cis 为：</span><br>freqs_cis = [<br>    [<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.0</span>],  <span class=\"hljs-comment\"># 位置 1</span><br>    [<span class=\"hljs-number\">1.1</span>, <span class=\"hljs-number\">1.1</span>],  <span class=\"hljs-comment\"># 位置 2</span><br>    [<span class=\"hljs-number\">1.2</span>, <span class=\"hljs-number\">1.2</span>],  <span class=\"hljs-comment\"># 位置 3</span><br>]<br><span class=\"hljs-comment\"># 输出：</span><br>h_with_pos = [<br>    [[<span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">0.2</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.0</span>],  <span class=\"hljs-comment\"># token 1</span><br>     [<span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">0.6</span>, <span class=\"hljs-number\">1.1</span>, <span class=\"hljs-number\">1.1</span>],  <span class=\"hljs-comment\"># token 2</span><br>     [<span class=\"hljs-number\">0.9</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.2</span>, <span class=\"hljs-number\">1.2</span>]]  <span class=\"hljs-comment\"># token 3</span><br>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"3-初始化-mask\"><a href=\"#3-初始化-mask\" class=\"headerlink\" title=\"3. 初始化 mask\"></a>3. <strong>初始化 mask</strong></h4><ul>\n<li><strong>输入</strong>: 序列长度 <code>seq_len=3</code>。</li>\n<li><strong>操作</strong>: 生成注意力掩码，防止模型看到未来的 token。</li>\n<li><strong>输出</strong>: 注意力掩码，形状为 <code>(3, 3)</code>。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 输出：</span><br>mask = [<br>    [<span class=\"hljs-number\">0</span>, -inf, -inf],  <span class=\"hljs-comment\"># 位置 1</span><br>    [<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, -inf],     <span class=\"hljs-comment\"># 位置 2</span><br>    [<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>]         <span class=\"hljs-comment\"># 位置 3</span><br>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"4-进入-Transformer-层\"><a href=\"#4-进入-Transformer-层\" class=\"headerlink\" title=\"4. 进入 Transformer 层\"></a>4. <strong>进入 Transformer 层</strong></h4><ul>\n<li><strong>输入</strong>: 添加位置编码后的向量 <code>h_with_pos</code>，形状为 <code>(1, 3, 4)</code>。</li>\n<li><strong>操作</strong>: 通过多层 Transformer 块处理输入。</li>\n</ul>\n<hr>\n<h4 id=\"5-Transformer-Block-1\"><a href=\"#5-Transformer-Block-1\" class=\"headerlink\" title=\"5. Transformer Block 1\"></a>5. <strong>Transformer Block 1</strong></h4><ul>\n<li><strong>输入</strong>: <code>h_with_pos</code>，形状为 <code>(1, 3, 4)</code>。</li>\n<li><strong>操作</strong>:<ol>\n<li><strong>RMSNorm</strong>: 对输入进行归一化。</li>\n<li><strong>Attention</strong>: 计算多头注意力机制。</li>\n<li><strong>Add &amp; Norm</strong>: 残差连接和归一化。</li>\n<li><strong>FeedForward</strong>: 计算前馈网络。</li>\n<li><strong>Add &amp; Norm</strong>: 残差连接和归一化。</li>\n</ol>\n</li>\n<li><strong>输出</strong>: Transformer 块的输出，形状为 <code>(1, 3, 4)</code>。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 假设输出为：</span><br>h_block1 = [<br>    [[<span class=\"hljs-number\">0.2</span>, <span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">1.1</span>, <span class=\"hljs-number\">1.1</span>],  <span class=\"hljs-comment\"># token 1</span><br>     [<span class=\"hljs-number\">0.6</span>, <span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">1.2</span>, <span class=\"hljs-number\">1.2</span>],  <span class=\"hljs-comment\"># token 2</span><br>     [<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.1</span>, <span class=\"hljs-number\">1.3</span>, <span class=\"hljs-number\">1.3</span>]]  <span class=\"hljs-comment\"># token 3</span><br>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"6-Transformer-Block-N\"><a href=\"#6-Transformer-Block-N\" class=\"headerlink\" title=\"6. Transformer Block N\"></a>6. <strong>Transformer Block N</strong></h4><ul>\n<li><strong>输入</strong>: 上一层的输出，形状为 <code>(1, 3, 4)</code>。</li>\n<li><strong>操作</strong>: 重复 Transformer 块的处理。</li>\n<li><strong>输出</strong>: 最后一层 Transformer 块的输出，形状为 <code>(1, 3, 4)</code>。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 假设输出为：</span><br>h_blockN = [<br>    [[<span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.4</span>, <span class=\"hljs-number\">1.2</span>, <span class=\"hljs-number\">1.2</span>],  <span class=\"hljs-comment\"># token 1</span><br>     [<span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">1.3</span>, <span class=\"hljs-number\">1.3</span>],  <span class=\"hljs-comment\"># token 2</span><br>     [<span class=\"hljs-number\">1.1</span>, <span class=\"hljs-number\">1.2</span>, <span class=\"hljs-number\">1.4</span>, <span class=\"hljs-number\">1.4</span>]]  <span class=\"hljs-comment\"># token 3</span><br>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"7-RMSNorm\"><a href=\"#7-RMSNorm\" class=\"headerlink\" title=\"7. RMSNorm\"></a>7. <strong>RMSNorm</strong></h4><ul>\n<li><strong>输入</strong>: 最后一层 Transformer 块的输出，形状为 <code>(1, 3, 4)</code>。</li>\n<li><strong>操作</strong>: 对输出进行归一化。</li>\n<li><strong>输出</strong>: 归一化后的输出，形状为 <code>(1, 3, 4)</code>。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 假设输出为：</span><br>h_norm = [<br>    [[<span class=\"hljs-number\">0.4</span>, <span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">1.3</span>, <span class=\"hljs-number\">1.3</span>],  <span class=\"hljs-comment\"># token 1</span><br>     [<span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.9</span>, <span class=\"hljs-number\">1.4</span>, <span class=\"hljs-number\">1.4</span>],  <span class=\"hljs-comment\"># token 2</span><br>     [<span class=\"hljs-number\">1.2</span>, <span class=\"hljs-number\">1.3</span>, <span class=\"hljs-number\">1.5</span>, <span class=\"hljs-number\">1.5</span>]]  <span class=\"hljs-comment\"># token 3</span><br>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"8-输出线性变换\"><a href=\"#8-输出线性变换\" class=\"headerlink\" title=\"8. 输出线性变换\"></a>8. <strong>输出线性变换</strong></h4><ul>\n<li><strong>输入</strong>: 归一化后的输出，形状为 <code>(1, 3, 4)</code>。</li>\n<li><strong>操作</strong>: 通过线性层将输出映射到词汇表空间。</li>\n<li><strong>输出</strong>: logits，形状为 <code>(1, 3, vocab_size=10)</code>。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 假设输出为：</span><br>logits = [<br>    [[<span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">0.2</span>, <span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.4</span>, <span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">0.6</span>, <span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.9</span>, <span class=\"hljs-number\">1.0</span>],  <span class=\"hljs-comment\"># token 1</span><br>     [<span class=\"hljs-number\">0.2</span>, <span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.4</span>, <span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">0.6</span>, <span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.9</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.1</span>],  <span class=\"hljs-comment\"># token 2</span><br>     [<span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.4</span>, <span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">0.6</span>, <span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.9</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.1</span>, <span class=\"hljs-number\">1.2</span>]]  <span class=\"hljs-comment\"># token 3</span><br>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"最终输出\"><a href=\"#最终输出\" class=\"headerlink\" title=\"最终输出\"></a><strong>最终输出</strong></h3><ul>\n<li><strong>输出</strong>: logits，形状为 <code>(1, 3, 10)</code>。</li>\n<li><strong>解释</strong>: 每个 token 的输出是一个长度为 <code>vocab_size=10</code> 的向量，表示每个 token 的概率分布。</li>\n</ul>\n<hr>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h3><ul>\n<li><strong>输入</strong>: <code>tokens = [[1, 2, 3]]</code>，形状为 <code>(1, 3)</code>。</li>\n<li><strong>输出</strong>: logits，形状为 <code>(1, 3, 10)</code>。</li>\n<li><strong>中间步骤</strong>:<ol>\n<li>Token Embedding：<code>(1, 3) -&gt; (1, 3, 4)</code>。</li>\n<li>添加位置编码：<code>(1, 3, 4) -&gt; (1, 3, 4)</code>。</li>\n<li>初始化 mask：<code>(3, 3)</code>。</li>\n<li>多层 Transformer 块：<code>(1, 3, 4) -&gt; (1, 3, 4)</code>。</li>\n<li>RMSNorm：<code>(1, 3, 4) -&gt; (1, 3, 4)</code>。</li>\n<li>输出线性变换：<code>(1, 3, 4) -&gt; (1, 3, 10)</code>。</li>\n</ol>\n</li>\n</ul>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n","excerpt":"","more":"<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/Llama3_Repo.jpeg\" alt=\"llama\"></p>\n<h2 id=\"整体\"><a href=\"#整体\" class=\"headerlink\" title=\"整体\"></a>整体</h2><p><code>model.py</code> 模块是 Llama 3 模型的核心实现部分，主要负责定义和实现 Transformer 模型的结构及其相关组件。</p>\n<h3 id=\"1-模型参数定义-ModelArgs-类\"><a href=\"#1-模型参数定义-ModelArgs-类\" class=\"headerlink\" title=\"1. 模型参数定义 (ModelArgs 类)\"></a>1. <strong>模型参数定义 (<code>ModelArgs</code> 类)</strong></h3><ul>\n<li><code>ModelArgs</code> 类是一个数据类，用于定义和存储模型的各种超参数，例如：<ul>\n<li><code>dim</code>: 模型的维度。</li>\n<li><code>n_layers</code>: Transformer 的层数。</li>\n<li><code>n_heads</code>: 注意力机制中的头数。</li>\n<li><code>vocab_size</code>: 词汇表大小。</li>\n<li><code>max_batch_size</code>: 最大批处理大小。</li>\n<li><code>max_seq_len</code>: 最大序列长度。</li>\n</ul>\n</li>\n<li>这些参数在模型初始化时被使用，决定了模型的结构和行为。</li>\n</ul>\n<h3 id=\"2-RMSNorm-层-RMSNorm-类\"><a href=\"#2-RMSNorm-层-RMSNorm-类\" class=\"headerlink\" title=\"2. RMSNorm 层 (RMSNorm 类)\"></a>2. <strong>RMSNorm 层 (<code>RMSNorm</code> 类)</strong></h3><ul>\n<li><code>RMSNorm</code> 是一个自定义的归一化层，用于替代传统的 LayerNorm。它通过对输入进行<strong>均方根归一化</strong>来稳定训练过程。</li>\n<li>该层在 Transformer 的每个子层（如注意力机制和前馈网络）之后使用。</li>\n</ul>\n<h3 id=\"3-RoPE-Rotary-Positional-Embedding\"><a href=\"#3-RoPE-Rotary-Positional-Embedding\" class=\"headerlink\" title=\"3. RoPE (Rotary Positional Embedding)\"></a>3. <strong>RoPE (Rotary Positional Embedding)</strong></h3><ul>\n<li>该模块实现了旋转位置编码（RoPE），用于为输入序列中的每个位置生成位置编码。RoPE 通过将位置信息嵌入到注意力机制中，帮助模型捕捉序列中的位置关系。</li>\n<li><code>precompute_freqs_cis</code> 函数预计算了频率矩阵，<code>apply_rotary_emb</code> 函数将旋转<strong>位置编码应用到查询和键向量上。</strong></li>\n</ul>\n<h3 id=\"4-注意力机制-Attention-类\"><a href=\"#4-注意力机制-Attention-类\" class=\"headerlink\" title=\"4. 注意力机制 (Attention 类)\"></a>4. <strong>注意力机制 (<code>Attention</code> 类)</strong></h3><ul>\n<li><code>Attention</code> 类实现了多头注意力机制（Multi-Head Attention），这是 Transformer 模型的核心组件之一。</li>\n<li>它使用 <code>ColumnParallelLinear</code> 和 <code>RowParallelLinear</code> 来实现并行的线性变换，支持模型并行化。</li>\n<li>该模块还实现了键值缓存（KV Cache），用于在生成过程中缓存先前的键和值，以减少重复计算。</li>\n</ul>\n<h3 id=\"5-前馈网络-FeedForward-类\"><a href=\"#5-前馈网络-FeedForward-类\" class=\"headerlink\" title=\"5. 前馈网络 (FeedForward 类)\"></a>5. <strong>前馈网络 (<code>FeedForward</code> 类)</strong></h3><ul>\n<li><code>FeedForward</code> 类实现了 Transformer 中的前馈神经网络（FFN），通常由两个线性变换和一个激活函数（如 SiLU）组成。</li>\n<li>该模块也支持模型并行化，使用 <code>ColumnParallelLinear</code> 和 <code>RowParallelLinear</code> 来实现并行的线性变换。</li>\n</ul>\n<h3 id=\"6-Transformer-块-TransformerBlock-类\"><a href=\"#6-Transformer-块-TransformerBlock-类\" class=\"headerlink\" title=\"6. Transformer 块 (TransformerBlock 类)\"></a>6. <strong>Transformer 块 (<code>TransformerBlock</code> 类)</strong></h3><ul>\n<li><code>TransformerBlock</code> 类将注意力机制和前馈网络组合在一起，形成一个完整的 Transformer 层。</li>\n<li>每个 Transformer 块包含一个注意力层和一个前馈网络层，并且在每个子层之后应用 RMSNorm 进行归一化。</li>\n</ul>\n<h3 id=\"7-Transformer-模型-Transformer-类\"><a href=\"#7-Transformer-模型-Transformer-类\" class=\"headerlink\" title=\"7. Transformer 模型 (Transformer 类)\"></a>7. <strong>Transformer 模型 (<code>Transformer</code> 类)</strong></h3><ul>\n<li><code>Transformer</code> 类是整个模型的核心，它由多个 <code>TransformerBlock</code> 组成，形成一个深层的 Transformer 网络。</li>\n<li>该模块还负责处理输入嵌入、位置编码、以及最终的输出线性变换。</li>\n<li><code>forward</code> 方法实现了模型的前向传播过程，包括嵌入、位置编码、多层 Transformer 块的处理以及最终的输出生成。</li>\n</ul>\n<h3 id=\"8-模型并行化\"><a href=\"#8-模型并行化\" class=\"headerlink\" title=\"8. 模型并行化\"></a>8. <strong>模型并行化</strong></h3><ul>\n<li>该模块使用了 <code>fairscale</code> 库中的 <code>ColumnParallelLinear</code> 和 <code>RowParallelLinear</code> 来实现模型并行化，允许模型在多个 GPU 上分布计算，从而提高训练和推理的效率。</li>\n</ul>\n<h3 id=\"9-推理模式\"><a href=\"#9-推理模式\" class=\"headerlink\" title=\"9. 推理模式\"></a>9. <strong>推理模式</strong></h3><ul>\n<li>在推理模式下，模型使用 <code>torch.inference_mode()</code> 来禁用梯度计算，从而提高推理速度并减少内存占用。</li>\n</ul>\n<h3 id=\"总结：\"><a href=\"#总结：\" class=\"headerlink\" title=\"总结：\"></a>总结：</h3><p><code>model.py</code> 模块定义了 Llama 3 模型的核心架构，包括 Transformer 的各个组件（如注意力机制、前馈网络、归一化层等），并实现了模型并行化和推理优化。它是整个 Llama 3 模型的基础，负责处理输入数据并生成输出。</p>\n<h2 id=\"模型详细流程图\"><a href=\"#模型详细流程图\" class=\"headerlink\" title=\"模型详细流程图\"></a>模型详细流程图</h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mermaid\">graph TD<br>    A[输入 tokens] --&gt; B[Token Embedding]<br>    B --&gt; C[添加位置编码 freqs_cis]<br>    C --&gt; D[初始化 mask]<br>    D --&gt; E[进入 Transformer 层]<br>    E --&gt; F[Transformer Block 1]<br>    E --&gt; G[Transformer Block 2]<br>    E --&gt; H[...]<br>    E --&gt; I[Transformer Block N]<br>    F --&gt; J[输出 logits]<br>    G --&gt; J<br>    H --&gt; J<br>    I --&gt; J<br><br>    subgraph Transformer Block<br>        direction TB<br>        K[输入] --&gt; L[RMSNorm]<br>        L --&gt; M[Attention]<br>        M --&gt; N[Add &amp; Norm]<br>        N --&gt; O[FeedForward]<br>        O --&gt; P[Add &amp; Norm]<br>        P --&gt; Q[输出]<br>    end<br><br>    F --&gt; K<br>    G --&gt; K<br>    I --&gt; K<br></code></pre></td></tr></table></figure>\n\n<ol>\n<li><p><strong>输入 tokens</strong>  </p>\n<ul>\n<li>输入是一个批次的 token IDs，形状为 <code>(batch_size, seq_len)</code>。</li>\n</ul>\n</li>\n<li><p><strong>Token Embedding</strong>  </p>\n<ul>\n<li>通过 <code>tok_embeddings</code> 将 token IDs 转换为嵌入向量，形状为 <code>(batch_size, seq_len, dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>添加位置编码 freqs_cis</strong>  </p>\n<ul>\n<li>使用预计算的 <code>freqs_cis</code> 为嵌入向量添加旋转位置编码，帮助模型捕捉序列中的位置信息。</li>\n</ul>\n</li>\n<li><p><strong>初始化 mask</strong>  </p>\n<ul>\n<li>根据 <code>seq_len</code> 和 <code>start_pos</code> 生成注意力掩码 <code>mask</code>，用于防止模型看到未来的 token。</li>\n</ul>\n</li>\n<li><p><strong>进入 Transformer 层</strong>  </p>\n<ul>\n<li>嵌入向量和位置编码进入多层 Transformer 块进行处理。</li>\n</ul>\n</li>\n<li><p><strong>Transformer Block 1 到 N</strong>  </p>\n<ul>\n<li>每个 Transformer 块包含以下步骤：<ul>\n<li><strong>RMSNorm</strong>: 对输入进行归一化。</li>\n<li><strong>Attention</strong>: 应用多头注意力机制，生成注意力输出。</li>\n<li><strong>RMSNorm</strong>: 对注意力输出进行归一化。</li>\n<li><strong>FeedForward</strong>: 应用前馈网络，生成最终的 Transformer 块输出。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p><strong>应用 RMSNorm</strong>  </p>\n<ul>\n<li>在所有 Transformer 块处理完成后，对最终输出应用 RMSNorm 进行归一化。</li>\n</ul>\n</li>\n<li><p><strong>输出线性变换</strong>  </p>\n<ul>\n<li>通过 <code>output</code> 线性层将归一化后的输出映射到词汇表空间，形状为 <code>(batch_size, seq_len, vocab_size)</code>。</li>\n</ul>\n</li>\n<li><p><strong>输出 logits</strong>  </p>\n<ul>\n<li>返回最终的 logits，表示每个 token 的概率分布。</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"class-ModelArgs\"><a href=\"#class-ModelArgs\" class=\"headerlink\" title=\"class ModelArgs\"></a><code>class ModelArgs</code></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-meta\">@dataclass</span><br><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">ModelArgs</span>:<br>    dim: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">4096</span>  <span class=\"hljs-comment\"># 模型的维度，即每个token的向量表示的大小</span><br>    n_layers: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">32</span>  <span class=\"hljs-comment\"># 模型的层数，即Transformer的层数</span><br>    n_heads: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">32</span>  <span class=\"hljs-comment\"># 注意力机制中的头数</span><br>    n_kv_heads: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">int</span>] = <span class=\"hljs-literal\">None</span>  <span class=\"hljs-comment\"># 键值头的数量，如果为None，则与n_heads相同</span><br>    vocab_size: <span class=\"hljs-built_in\">int</span> = -<span class=\"hljs-number\">1</span>  <span class=\"hljs-comment\"># 词汇表的大小，通常由tokenizer决定</span><br>    multiple_of: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">256</span>  <span class=\"hljs-comment\"># SwiGLU激活函数中隐藏层大小的倍数，确保是256的倍数</span><br>    ffn_dim_multiplier: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">float</span>] = <span class=\"hljs-literal\">None</span>  <span class=\"hljs-comment\"># 前馈网络维度的乘数，用于调整隐藏层大小</span><br>    norm_eps: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">1e-5</span>  <span class=\"hljs-comment\"># Layer Normalization中的epsilon值，用于数值稳定性</span><br>    rope_theta: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">500000</span>  <span class=\"hljs-comment\"># RoPE（Rotary Position Embedding）中的theta参数</span><br><br>    max_batch_size: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">32</span>  <span class=\"hljs-comment\"># 最大批处理大小</span><br>    max_seq_len: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">2048</span>  <span class=\"hljs-comment\"># 最大序列长度</span><br></code></pre></td></tr></table></figure>\n\n<h2 id=\"class-RMSNorm\"><a href=\"#class-RMSNorm\" class=\"headerlink\" title=\"class RMSNorm\"></a><code>class RMSNorm</code></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title class_\">RMSNorm</span>(torch.nn.Module):<br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">__init__</span>(<span class=\"hljs-params\">self, dim: <span class=\"hljs-built_in\">int</span>, eps: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">1e-6</span></span>):<br>        <span class=\"hljs-built_in\">super</span>().__init__()<br>        <span class=\"hljs-variable language_\">self</span>.eps = eps  <span class=\"hljs-comment\"># 用于数值稳定性的小值，防止除以零</span><br>        <span class=\"hljs-variable language_\">self</span>.weight = nn.Parameter(torch.ones(dim))  <span class=\"hljs-comment\"># 可学习的缩放参数，初始化为1</span><br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">_norm</span>(<span class=\"hljs-params\">self, x</span>):<br>        <span class=\"hljs-comment\"># 计算RMS（Root Mean Square）归一化，对输入x进行归一化处理</span><br>        <span class=\"hljs-keyword\">return</span> x * torch.rsqrt(x.<span class=\"hljs-built_in\">pow</span>(<span class=\"hljs-number\">2</span>).mean(-<span class=\"hljs-number\">1</span>, keepdim=<span class=\"hljs-literal\">True</span>) + <span class=\"hljs-variable language_\">self</span>.eps)<br><br>    <span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">forward</span>(<span class=\"hljs-params\">self, x</span>):<br>        <span class=\"hljs-comment\"># 前向传播函数，先对输入x进行归一化，然后乘以可学习的缩放参数</span><br>        output = <span class=\"hljs-variable language_\">self</span>._norm(x.<span class=\"hljs-built_in\">float</span>()).type_as(x)  <span class=\"hljs-comment\"># 归一化并保持与输入x相同的数据类型</span><br>        <span class=\"hljs-keyword\">return</span> output * <span class=\"hljs-variable language_\">self</span>.weight  <span class=\"hljs-comment\"># 乘以缩放参数</span><br></code></pre></td></tr></table></figure>\n\n<h3 id=\"解释：\"><a href=\"#解释：\" class=\"headerlink\" title=\"解释：\"></a>解释：</h3><ol>\n<li><p><strong><code>ModelArgs</code></strong>:</p>\n<ul>\n<li>这是一个数据类，用于存储模型的配置参数。它定义了模型的结构和超参数，如模型的维度、层数、注意力头数等。</li>\n<li><code>dim</code> 是每个token的向量表示的大小，<code>n_layers</code> 是Transformer的层数，<code>n_heads</code> 是注意力机制中的头数。</li>\n<li><code>vocab_size</code> 是词汇表的大小，通常由tokenizer决定。</li>\n<li><code>multiple_of</code> 和 <code>ffn_dim_multiplier</code> 用于调整前馈网络的隐藏层大小。</li>\n<li><code>norm_eps</code> 是Layer Normalization中的epsilon值，用于数值稳定性。</li>\n<li><code>rope_theta</code> 是RoPE（Rotary Position Embedding）中的theta参数，用于位置编码。</li>\n<li><code>max_batch_size</code> 和 <code>max_seq_len</code> 分别定义了模型的最大批处理大小和最大序列长度。</li>\n</ul>\n</li>\n<li><p><strong><code>RMSNorm</code></strong>:</p>\n<ul>\n<li>这是一个自定义的归一化层，类似于Layer Normalization，但使用了RMS（Root Mean Square）归一化。</li>\n<li><code>_norm</code> 方法计算输入的RMS归一化值，<code>forward</code> 方法在前向传播时对输入进行归一化并乘以可学习的缩放参数。</li>\n<li><code>eps</code> 是一个小值，用于防止除以零的情况，<code>weight</code> 是可学习的缩放参数，初始化为1。</li>\n</ul>\n</li>\n</ol>\n<p>这两个类在模型中分别用于定义模型的结构和实现归一化操作，是Transformer模型的重要组成部分。</p>\n<hr>\n<h2 id=\"旋转位置编码\"><a href=\"#旋转位置编码\" class=\"headerlink\" title=\"旋转位置编码\"></a>旋转位置编码</h2><h3 id=\"precompute-freqs-cis\"><a href=\"#precompute-freqs-cis\" class=\"headerlink\" title=\"precompute_freqs_cis\"></a><strong><code>precompute_freqs_cis</code></strong></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">precompute_freqs_cis</span>(<span class=\"hljs-params\">dim: <span class=\"hljs-built_in\">int</span>, end: <span class=\"hljs-built_in\">int</span>, theta: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">10000.0</span></span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    预计算旋转位置编码的频率矩阵 (freqs_cis)。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    旋转位置编码 (Rotary Positional Embedding, RoPE) 是一种将位置信息嵌入到注意力机制中的方法。</span><br><span class=\"hljs-string\">    它通过将位置信息编码为复数形式，应用到查询和键向量上。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    参数:</span><br><span class=\"hljs-string\">        dim (int): 模型的维度（通常是注意力头的维度）。</span><br><span class=\"hljs-string\">        end (int): 序列的最大长度。</span><br><span class=\"hljs-string\">        theta (float): 控制频率的基数，默认为 10000.0。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    返回:</span><br><span class=\"hljs-string\">        freqs_cis (torch.Tensor): 预计算的频率矩阵，形状为 (end, dim // 2)，数据类型为 complex64。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 计算频率向量</span><br>    freqs = <span class=\"hljs-number\">1.0</span> / (theta ** (torch.arange(<span class=\"hljs-number\">0</span>, dim, <span class=\"hljs-number\">2</span>)[: (dim // <span class=\"hljs-number\">2</span>)].<span class=\"hljs-built_in\">float</span>() / dim))<br>    <span class=\"hljs-comment\"># 生成位置向量</span><br>    t = torch.arange(end, device=freqs.device, dtype=torch.float32)<br>    <span class=\"hljs-comment\"># 计算外积，得到频率矩阵</span><br>    freqs = torch.outer(t, freqs)<br>    <span class=\"hljs-comment\"># 将频率矩阵转换为复数形式（极坐标表示）</span><br>    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  <span class=\"hljs-comment\"># complex64</span><br>    <span class=\"hljs-keyword\">return</span> freqs_cis<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-1\"><a href=\"#解释：-1\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><strong>作用</strong>: 预计算旋转位置编码的频率矩阵 <code>freqs_cis</code>，用于将位置信息嵌入到查询和键向量中。</li>\n<li><strong>输入</strong>:<ul>\n<li><code>dim</code>: 模型的维度，通常是注意力头的维度。</li>\n<li><code>end</code>: 序列的最大长度。</li>\n<li><code>theta</code>: 控制频率的基数，默认为 10000.0。</li>\n</ul>\n</li>\n<li><strong>输出</strong>:<ul>\n<li><code>freqs_cis</code>: 预计算的频率矩阵，形状为 <code>(end, dim // 2)</code>，数据类型为 <code>complex64</code>。</li>\n</ul>\n</li>\n<li><strong>关键点</strong>:<ul>\n<li>使用 <code>torch.outer</code> 计算位置向量和频率向量的外积，得到频率矩阵。</li>\n<li>通过 <code>torch.polar</code> 将频率矩阵转换为复数形式，表示极坐标。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"reshape-for-broadcast\"><a href=\"#reshape-for-broadcast\" class=\"headerlink\" title=\"reshape_for_broadcast\"></a><strong><code>reshape_for_broadcast</code></strong></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">reshape_for_broadcast</span>(<span class=\"hljs-params\">freqs_cis: torch.Tensor, x: torch.Tensor</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    将频率矩阵 `freqs_cis` 重塑为适合广播的形状，以便与查询或键向量进行逐元素操作。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    参数:</span><br><span class=\"hljs-string\">        freqs_cis (torch.Tensor): 频率矩阵，形状为 (seq_len, dim // 2)。</span><br><span class=\"hljs-string\">        x (torch.Tensor): 查询或键向量，形状为 (batch_size, seq_len, n_heads, head_dim)。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    返回:</span><br><span class=\"hljs-string\">        freqs_cis (torch.Tensor): 重塑后的频率矩阵，形状为 (1, seq_len, 1, dim // 2)。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    ndim = x.ndim<br>    <span class=\"hljs-keyword\">assert</span> <span class=\"hljs-number\">0</span> &lt;= <span class=\"hljs-number\">1</span> &lt; ndim<br>    <span class=\"hljs-keyword\">assert</span> freqs_cis.shape == (x.shape[<span class=\"hljs-number\">1</span>], x.shape[-<span class=\"hljs-number\">1</span>])<br>    <span class=\"hljs-comment\"># 重塑频率矩阵，使其形状为 (1, seq_len, 1, dim // 2)</span><br>    shape = [d <span class=\"hljs-keyword\">if</span> i == <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">or</span> i == ndim - <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">else</span> <span class=\"hljs-number\">1</span> <span class=\"hljs-keyword\">for</span> i, d <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(x.shape)]<br>    <span class=\"hljs-keyword\">return</span> freqs_cis.view(*shape)<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-2\"><a href=\"#解释：-2\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><strong>作用</strong>: 将频率矩阵 <code>freqs_cis</code> 重塑为适合广播的形状，以便与查询或键向量进行逐元素操作。</li>\n<li><strong>输入</strong>:<ul>\n<li><code>freqs_cis</code>: 频率矩阵，形状为 <code>(seq_len, dim // 2)</code>。</li>\n<li><code>x</code>: 查询或键向量，形状为 <code>(batch_size, seq_len, n_heads, head_dim)</code>。</li>\n</ul>\n</li>\n<li><strong>输出</strong>:<ul>\n<li>重塑后的频率矩阵，形状为 <code>(1, seq_len, 1, dim // 2)</code>。</li>\n</ul>\n</li>\n<li><strong>关键点</strong>:<ul>\n<li>通过 <code>view</code> 方法将频率矩阵重塑为适合广播的形状，使其能够与查询或键向量进行逐元素操作。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"apply-rotary-emb\"><a href=\"#apply-rotary-emb\" class=\"headerlink\" title=\"apply_rotary_emb\"></a><strong><code>apply_rotary_emb</code></strong></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">apply_rotary_emb</span>(<span class=\"hljs-params\"></span><br><span class=\"hljs-params\">    xq: torch.Tensor,</span><br><span class=\"hljs-params\">    xk: torch.Tensor,</span><br><span class=\"hljs-params\">    freqs_cis: torch.Tensor,</span><br><span class=\"hljs-params\"></span>) -&gt; <span class=\"hljs-type\">Tuple</span>[torch.Tensor, torch.Tensor]:<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    将旋转位置编码应用到查询和键向量上。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    旋转位置编码通过将位置信息嵌入到查询和键向量中，帮助模型捕捉序列中的位置关系。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    参数:</span><br><span class=\"hljs-string\">        xq (torch.Tensor): 查询向量，形状为 (batch_size, seq_len, n_heads, head_dim)。</span><br><span class=\"hljs-string\">        xk (torch.Tensor): 键向量，形状为 (batch_size, seq_len, n_heads, head_dim)。</span><br><span class=\"hljs-string\">        freqs_cis (torch.Tensor): 频率矩阵，形状为 (1, seq_len, 1, head_dim // 2)。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    返回:</span><br><span class=\"hljs-string\">        xq_out (torch.Tensor): 应用旋转位置编码后的查询向量。</span><br><span class=\"hljs-string\">        xk_out (torch.Tensor): 应用旋转位置编码后的键向量。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 将查询和键向量转换为复数形式</span><br>    xq_ = torch.view_as_complex(xq.<span class=\"hljs-built_in\">float</span>().reshape(*xq.shape[:-<span class=\"hljs-number\">1</span>], -<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>))<br>    xk_ = torch.view_as_complex(xk.<span class=\"hljs-built_in\">float</span>().reshape(*xk.shape[:-<span class=\"hljs-number\">1</span>], -<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>))<br>    <span class=\"hljs-comment\"># 重塑频率矩阵以匹配查询和键向量的形状</span><br>    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)<br>    <span class=\"hljs-comment\"># 应用旋转位置编码</span><br>    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(<span class=\"hljs-number\">3</span>)<br>    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(<span class=\"hljs-number\">3</span>)<br>    <span class=\"hljs-keyword\">return</span> xq_out.type_as(xq), xk_out.type_as(xk)<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-3\"><a href=\"#解释：-3\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><p><strong>作用</strong>: 将旋转位置编码应用到查询和键向量上，帮助模型捕捉序列中的位置关系。</p>\n</li>\n<li><p><strong>输入</strong>:</p>\n<ul>\n<li><code>xq</code>: 查询向量，形状为 <code>(batch_size, seq_len, n_heads, head_dim)</code>。</li>\n<li><code>xk</code>: 键向量，形状为 <code>(batch_size, seq_len, n_heads, head_dim)</code>。</li>\n<li><code>freqs_cis</code>: 频率矩阵，形状为 <code>(1, seq_len, 1, head_dim // 2)</code>。</li>\n</ul>\n</li>\n<li><p><strong>输出</strong>:</p>\n<ul>\n<li><code>xq_out</code>: 应用旋转位置编码后的查询向量。</li>\n<li><code>xk_out</code>: 应用旋转位置编码后的键向量。</li>\n</ul>\n</li>\n<li><p><strong>关键点</strong>:</p>\n<ul>\n<li>使用 <code>torch.view_as_complex</code> 将查询和键向量转换为复数形式。</li>\n<li>通过逐元素乘法将频率矩阵应用到查询和键向量上。</li>\n<li>使用 <code>torch.view_as_real</code> 将结果转换回实数形式。</li>\n</ul>\n<p>这些函数共同实现了旋转位置编码（RoPE）</p>\n<h3 id=\"总结：-1\"><a href=\"#总结：-1\" class=\"headerlink\" title=\"总结：\"></a>总结：</h3><ul>\n<li><strong><code>precompute_freqs_cis</code></strong>: 预计算旋转位置编码的频率矩阵。</li>\n<li><strong><code>reshape_for_broadcast</code></strong>: 将频率矩阵重塑为适合广播的形状。</li>\n<li><strong><code>apply_rotary_emb</code></strong>: 将旋转位置编码应用到查询和键向量上。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h2 id=\"repeat-kv\"><a href=\"#repeat-kv\" class=\"headerlink\" title=\"repeat_kv\"></a><strong><code>repeat_kv</code></strong></h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">repeat_kv</span>(<span class=\"hljs-params\">x: torch.Tensor, n_rep: <span class=\"hljs-built_in\">int</span></span>) -&gt; torch.Tensor:<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    重复键或值向量，以匹配查询向量的头数。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    在分组注意力机制中，键和值向量的头数可能少于查询向量的头数，因此需要重复键和值向量以匹配查询向量的头数。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    参数:</span><br><span class=\"hljs-string\">        x (torch.Tensor): 键或值向量，形状为 (batch_size, seq_len, n_kv_heads, head_dim)。</span><br><span class=\"hljs-string\">        n_rep (int): 重复次数，通常为查询头数与键值头数的比值。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    返回:</span><br><span class=\"hljs-string\">        torch.Tensor: 重复后的键或值向量，形状为 (batch_size, seq_len, n_kv_heads * n_rep, head_dim)。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    bs, slen, n_kv_heads, head_dim = x.shape<br>    <span class=\"hljs-keyword\">if</span> n_rep == <span class=\"hljs-number\">1</span>:<br>        <span class=\"hljs-keyword\">return</span> x<br>    <span class=\"hljs-keyword\">return</span> (<br>        x[:, :, :, <span class=\"hljs-literal\">None</span>, :]<br>        .expand(bs, slen, n_kv_heads, n_rep, head_dim)<br>        .reshape(bs, slen, n_kv_heads * n_rep, head_dim)<br>    )<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"解释：-4\"><a href=\"#解释：-4\" class=\"headerlink\" title=\"解释：\"></a>解释：</h4><ul>\n<li><strong>作用</strong>: 重复键或值向量，以匹配查询向量的头数。</li>\n<li><strong>输入</strong>:<ul>\n<li><code>x</code>: 键或值向量，形状为 <code>(batch_size, seq_len, n_kv_heads, head_dim)</code>。</li>\n<li><code>n_rep</code>: 重复次数，通常为查询头数与键值头数的比值。</li>\n</ul>\n</li>\n<li><strong>输出</strong>:<ul>\n<li>重复后的键或值向量，形状为 <code>(batch_size, seq_len, n_kv_heads * n_rep, head_dim)</code>。</li>\n</ul>\n</li>\n<li><strong>关键点</strong>:<ul>\n<li>使用 <code>expand</code> 和 <code>reshape</code> 方法重复键或值向量，使其头数与查询向量匹配。</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"class-Attention\"><a href=\"#class-Attention\" class=\"headerlink\" title=\"class Attention\"></a><code>class Attention</code></h2><p><code>class Attention</code> 实现了 Transformer 中的 <strong>多头注意力机制（Multi-Head Attention）</strong>，它是 Transformer 模型的核心组件之一。以下是该类的详细解释：</p>\n<h4 id=\"主要功能：\"><a href=\"#主要功能：\" class=\"headerlink\" title=\"主要功能：\"></a><strong>主要功能</strong>：</h4><ol>\n<li><p><strong>多头注意力机制</strong>：</p>\n<ul>\n<li>将输入向量拆分为多个头，每个头独立计算注意力分数。</li>\n<li>通过并行计算，捕捉输入序列中不同位置之间的关系。</li>\n</ul>\n</li>\n<li><p><strong>键值缓存（KV Cache）</strong>：</p>\n<ul>\n<li>在生成任务中，缓存先前的键和值，避免重复计算，提高效率。</li>\n</ul>\n</li>\n<li><p><strong>模型并行化</strong>：</p>\n<ul>\n<li>使用 <code>ColumnParallelLinear</code> 和 <code>RowParallelLinear</code> 实现并行的线性变换，支持多 GPU 计算。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"关键组件：\"><a href=\"#关键组件：\" class=\"headerlink\" title=\"关键组件：\"></a><strong>关键组件</strong>：</h4><ol>\n<li><p><strong>线性变换</strong>：</p>\n<ul>\n<li><code>wq</code>、<code>wk</code>、<code>wv</code>：分别对输入进行线性变换，生成查询（Query）、键（Key）和值（Value）向量。</li>\n<li><code>wo</code>：将多头注意力的输出进行线性变换，合并为最终输出。</li>\n</ul>\n</li>\n<li><p><strong>键值缓存</strong>：</p>\n<ul>\n<li><code>cache_k</code> 和 <code>cache_v</code>：用于缓存先前的键和值，形状为 <code>(batch_size, max_seq_len, n_local_kv_heads, head_dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>旋转位置编码（RoPE）</strong>：</p>\n<ul>\n<li>通过 <code>apply_rotary_emb</code> 将位置信息嵌入到查询和键向量中。</li>\n</ul>\n</li>\n<li><p><strong>注意力分数计算</strong>：</p>\n<ul>\n<li>计算查询和键的点积，除以 <code>sqrt(head_dim)</code> 进行缩放，然后应用 Softmax 得到注意力分数。</li>\n</ul>\n</li>\n<li><p><strong>输出计算</strong>：</p>\n<ul>\n<li>使用注意力分数对值向量进行加权求和，得到多头注意力的输出。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"流程图\"><a href=\"#流程图\" class=\"headerlink\" title=\"&#96;流程图\"></a><strong>&#96;流程图</strong></h3><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mermaid\">graph TD<br>    A[输入 x] --&gt; B[线性变换]<br>    B --&gt; C[生成 Query]<br>    B --&gt; D[生成 Key]<br>    B --&gt; E[生成 Value]<br>    C --&gt; F[应用旋转位置编码]<br>    D --&gt; F<br>    F --&gt; G[更新键值缓存]<br>    G --&gt; H[计算注意力分数]<br>    H --&gt; I[应用 Softmax]<br>    I --&gt; J[加权求和]<br>    J --&gt; K[线性变换]<br>    K --&gt; L[输出]<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"详细步骤说明：\"><a href=\"#详细步骤说明：\" class=\"headerlink\" title=\"详细步骤说明：\"></a><strong>详细步骤说明</strong>：</h3><ol>\n<li><p><strong>输入 x</strong>  </p>\n<ul>\n<li>输入是一个批次的嵌入向量，形状为 <code>(batch_size, seq_len, dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>线性变换</strong>  </p>\n<ul>\n<li>通过 <code>wq</code>、<code>wk</code>、<code>wv</code> 分别对输入进行线性变换，生成查询（Query）、键（Key）和值（Value）向量。</li>\n</ul>\n</li>\n<li><p><strong>生成 Query、Key、Value</strong>  </p>\n<ul>\n<li>查询向量形状为 <code>(batch_size, seq_len, n_local_heads, head_dim)</code>。</li>\n<li>键和值向量形状为 <code>(batch_size, seq_len, n_local_kv_heads, head_dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>应用旋转位置编码</strong>  </p>\n<ul>\n<li>使用 <code>apply_rotary_emb</code> 将旋转位置编码应用到查询和键向量上。</li>\n</ul>\n</li>\n<li><p><strong>更新键值缓存</strong>  </p>\n<ul>\n<li>将当前的键和值向量缓存到 <code>cache_k</code> 和 <code>cache_v</code> 中。</li>\n</ul>\n</li>\n<li><p><strong>计算注意力分数</strong>  </p>\n<ul>\n<li>计算查询和键的点积，除以 <code>sqrt(head_dim)</code> 进行缩放，得到注意力分数。</li>\n</ul>\n</li>\n<li><p><strong>应用 Softmax</strong>  </p>\n<ul>\n<li>对注意力分数应用 Softmax，得到归一化的注意力权重。</li>\n</ul>\n</li>\n<li><p><strong>加权求和</strong>  </p>\n<ul>\n<li>使用注意力权重对值向量进行加权求和，得到多头注意力的输出。</li>\n</ul>\n</li>\n<li><p><strong>线性变换</strong>  </p>\n<ul>\n<li>通过 <code>wo</code> 对多头注意力的输出进行线性变换，合并为最终输出。</li>\n</ul>\n</li>\n<li><p><strong>输出</strong>  </p>\n<ul>\n<li>返回最终的输出，形状为 <code>(batch_size, seq_len, dim)</code>。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"代码实现的关键点：\"><a href=\"#代码实现的关键点：\" class=\"headerlink\" title=\"代码实现的关键点：\"></a><strong>代码实现的关键点</strong>：</h3><ol>\n<li><p><strong>并行化</strong>：</p>\n<ul>\n<li>使用 <code>ColumnParallelLinear</code> 和 <code>RowParallelLinear</code> 实现并行的线性变换，支持多 GPU 计算。</li>\n</ul>\n</li>\n<li><p><strong>键值缓存</strong>：</p>\n<ul>\n<li>在生成任务中，缓存先前的键和值，避免重复计算，提高效率。</li>\n</ul>\n</li>\n<li><p><strong>旋转位置编码</strong>：</p>\n<ul>\n<li>通过 <code>apply_rotary_emb</code> 将位置信息嵌入到查询和键向量中，帮助模型捕捉序列中的位置关系。</li>\n</ul>\n</li>\n<li><p><strong>注意力分数计算</strong>：</p>\n<ul>\n<li>使用点积计算注意力分数，并通过 Softmax 进行归一化。</li>\n</ul>\n</li>\n<li><p><strong>输出计算</strong>：</p>\n<ul>\n<li>使用注意力权重对值向量进行加权求和，得到多头注意力的输出。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"总结：-2\"><a href=\"#总结：-2\" class=\"headerlink\" title=\"总结：\"></a><strong>总结</strong>：</h3><p><code>class Attention</code> 实现了 Transformer 中的多头注意力机制，通过并行化、键值缓存和旋转位置编码等技术，高效地捕捉输入序列中的关系。</p>\n<h2 id=\"FeedForward\"><a href=\"#FeedForward\" class=\"headerlink\" title=\"FeedForward\"></a><code>FeedForward</code></h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mermaid\">graph TD<br>    A[输入 x] --&gt; B[线性变换 W1]<br>    B --&gt; C[激活函数 SiLU]<br>    C --&gt; D[线性变换 W3]<br>    D --&gt; E[逐元素乘法]<br>    E --&gt; F[线性变换 W2]<br>    F --&gt; G[输出]<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"详细步骤说明：-1\"><a href=\"#详细步骤说明：-1\" class=\"headerlink\" title=\"详细步骤说明：\"></a><strong>详细步骤说明</strong>：</h3><ol>\n<li><p><strong>输入 x</strong>  </p>\n<ul>\n<li>输入是一个批次的向量，形状为 <code>(batch_size, seq_len, dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>线性变换 W1</strong>  </p>\n<ul>\n<li>通过 <code>w1</code> 对输入进行线性变换，生成中间向量，形状为 <code>(batch_size, seq_len, hidden_dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>激活函数 SiLU</strong>  </p>\n<ul>\n<li><p>对线性变换后的结果应用 SiLU（Sigmoid Linear Unit）激活函数，公式为：  </p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241230114851133.png\"></p>\n</li>\n</ul>\n</li>\n<li><p><strong>线性变换 W3</strong>  </p>\n<ul>\n<li>通过 <code>w3</code> 对输入进行另一个线性变换，生成中间向量，形状为 <code>(batch_size, seq_len, hidden_dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>逐元素乘法</strong>  </p>\n<ul>\n<li>将 <code>SiLU(W1(x))</code> 和 <code>W3(x)</code> 进行逐元素乘法，生成加权后的中间向量。</li>\n</ul>\n</li>\n<li><p><strong>线性变换 W2</strong>  </p>\n<ul>\n<li>通过 <code>w2</code> 对加权后的中间向量进行线性变换，生成最终输出，形状为 <code>(batch_size, seq_len, dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>输出</strong>  </p>\n<ul>\n<li>返回最终的输出，作为前馈网络的结果。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"代码实现的关键点：-1\"><a href=\"#代码实现的关键点：-1\" class=\"headerlink\" title=\"代码实现的关键点：\"></a><strong>代码实现的关键点</strong>：</h3><ol>\n<li><p><strong>并行化</strong>：</p>\n<ul>\n<li>使用 <code>ColumnParallelLinear</code> 和 <code>RowParallelLinear</code> 实现并行的线性变换，支持多 GPU 计算。</li>\n</ul>\n</li>\n<li><p><strong>激活函数</strong>：</p>\n<ul>\n<li>使用 SiLU 激活函数，结合了 Sigmoid 和线性变换的优点，增强了模型的非线性表达能力。</li>\n</ul>\n</li>\n<li><p><strong>逐元素乘法</strong>：</p>\n<ul>\n<li>将两个线性变换的结果进行逐元素乘法，生成加权后的中间向量。</li>\n</ul>\n</li>\n<li><p><strong>输出计算</strong>：</p>\n<ul>\n<li>通过 <code>w2</code> 对加权后的中间向量进行线性变换，生成最终输出。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"总结：-3\"><a href=\"#总结：-3\" class=\"headerlink\" title=\"总结：\"></a><strong>总结</strong>：</h3><p><code>FeedForward</code> 类实现了 Transformer 中的前馈网络，通过线性变换、激活函数和逐元素乘法等技术，增强了模型的非线性表达能力。</p>\n<h2 id=\"TransformerBlock\"><a href=\"#TransformerBlock\" class=\"headerlink\" title=\"TransformerBlock\"></a><code>TransformerBlock</code></h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mermaid\">graph TD<br>    A[输入 x] --&gt; B[RMSNorm]<br>    B --&gt; C[Attention]<br>    C --&gt; D[Add &amp; Norm]<br>    D --&gt; E[FeedForward]<br>    E --&gt; F[Add &amp; Norm]<br>    F --&gt; G[输出]<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"详细步骤说明：-2\"><a href=\"#详细步骤说明：-2\" class=\"headerlink\" title=\"详细步骤说明：\"></a><strong>详细步骤说明</strong>：</h3><ol>\n<li><p><strong>输入 x</strong>  </p>\n<ul>\n<li>输入是一个批次的向量，形状为 <code>(batch_size, seq_len, dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>RMSNorm</strong>  </p>\n<ul>\n<li>对输入进行 RMSNorm 归一化，公式为：<br>[<br>\\text{RMSNorm}(x) &#x3D; \\frac{x}{\\sqrt{\\text{mean}(x^2) + \\epsilon}} \\cdot \\gamma<br>]<br>其中，(\\gamma) 是可学习的缩放参数，(\\epsilon) 是防止除零的小常数。</li>\n</ul>\n</li>\n<li><p><strong>Attention</strong>  </p>\n<ul>\n<li>将归一化后的输入传递给 <code>Attention</code> 模块，计算多头注意力机制的输出。</li>\n</ul>\n</li>\n<li><p><strong>Add &amp; Norm</strong>  </p>\n<ul>\n<li>将注意力输出与输入进行残差连接，然后再次应用 RMSNorm 归一化。</li>\n</ul>\n</li>\n<li><p><strong>FeedForward</strong>  </p>\n<ul>\n<li>将归一化后的结果传递给 <code>FeedForward</code> 模块，计算前馈网络的输出。</li>\n</ul>\n</li>\n<li><p><strong>Add &amp; Norm</strong>  </p>\n<ul>\n<li>将前馈网络输出与上一层的输出进行残差连接，然后再次应用 RMSNorm 归一化。</li>\n</ul>\n</li>\n<li><p><strong>输出</strong>  </p>\n<ul>\n<li>返回最终的输出，作为 Transformer 块的结果。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"代码实现的关键点：-2\"><a href=\"#代码实现的关键点：-2\" class=\"headerlink\" title=\"代码实现的关键点：\"></a><strong>代码实现的关键点</strong>：</h3><ol>\n<li><p><strong>残差连接</strong>：</p>\n<ul>\n<li>在注意力机制和前馈网络之后，分别使用残差连接，将输入与输出相加，缓解梯度消失问题。</li>\n</ul>\n</li>\n<li><p><strong>归一化</strong>：</p>\n<ul>\n<li>使用 RMSNorm 对输入和输出进行归一化，稳定训练过程。</li>\n</ul>\n</li>\n<li><p><strong>注意力机制</strong>：</p>\n<ul>\n<li>通过 <code>Attention</code> 模块计算多头注意力机制的输出，捕捉输入序列中的关系。</li>\n</ul>\n</li>\n<li><p><strong>前馈网络</strong>：</p>\n<ul>\n<li>通过 <code>FeedForward</code> 模块增强模型的非线性表达能力。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"总结：-4\"><a href=\"#总结：-4\" class=\"headerlink\" title=\"总结：\"></a><strong>总结</strong>：</h3><p><code>TransformerBlock</code> 类实现了 Transformer 中的一个完整块，包括注意力机制、前馈网络、残差连接和归一化操作。</p>\n<h2 id=\"class-Transformer\"><a href=\"#class-Transformer\" class=\"headerlink\" title=\"class Transformer\"></a><code>class Transformer</code></h2><figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs mermaid\">graph TD<br>    A[输入 tokens] --&gt; B[Token Embedding]<br>    B --&gt; C[添加位置编码 freqs_cis]<br>    C --&gt; D[初始化 mask]<br>    D --&gt; E[进入 Transformer 层]<br>    E --&gt; F[Transformer Block 1]<br>    E --&gt; G[Transformer Block 2]<br>    E --&gt; H[...]<br>    E --&gt; I[Transformer Block N]<br>    F --&gt; J[RMSNorm]<br>    G --&gt; J<br>    H --&gt; J<br>    I --&gt; J<br>    J --&gt; K[输出线性变换]<br>    K --&gt; L[输出 logits]<br><br>    subgraph Transformer Block<br>        direction TB<br>        M[输入] --&gt; N[RMSNorm]<br>        N --&gt; O[Attention]<br>        O --&gt; P[Add &amp; Norm]<br>        P --&gt; Q[FeedForward]<br>        Q --&gt; R[Add &amp; Norm]<br>        R --&gt; S[输出]<br>    end<br><br>    F --&gt; M<br>    G --&gt; M<br>    I --&gt; M<br></code></pre></td></tr></table></figure>\n\n<h3 id=\"详细步骤说明：-3\"><a href=\"#详细步骤说明：-3\" class=\"headerlink\" title=\"详细步骤说明：\"></a><strong>详细步骤说明</strong>：</h3><h4 id=\"整体流程：\"><a href=\"#整体流程：\" class=\"headerlink\" title=\"整体流程：\"></a><strong>整体流程</strong>：</h4><ol>\n<li><p><strong>输入 tokens</strong>  </p>\n<ul>\n<li>输入是一个批次的 token IDs，形状为 <code>(batch_size, seq_len)</code>。</li>\n</ul>\n</li>\n<li><p><strong>Token Embedding</strong>  </p>\n<ul>\n<li>通过 <code>tok_embeddings</code> 将 token IDs 转换为嵌入向量，形状为 <code>(batch_size, seq_len, dim)</code>。</li>\n</ul>\n</li>\n<li><p><strong>添加位置编码 freqs_cis</strong>  </p>\n<ul>\n<li>使用预计算的 <code>freqs_cis</code> 为嵌入向量添加旋转位置编码，帮助模型捕捉序列中的位置信息。</li>\n</ul>\n</li>\n<li><p><strong>初始化 mask</strong>  </p>\n<ul>\n<li>根据 <code>seq_len</code> 和 <code>start_pos</code> 生成注意力掩码 <code>mask</code>，用于防止模型看到未来的 token。</li>\n</ul>\n</li>\n<li><p><strong>进入 Transformer 层</strong>  </p>\n<ul>\n<li>嵌入向量和位置编码进入多层 Transformer 块进行处理。</li>\n</ul>\n</li>\n<li><p><strong>Transformer Block 1 到 N</strong>  </p>\n<ul>\n<li>每个 Transformer 块内部执行子图中的流程。</li>\n</ul>\n</li>\n<li><p><strong>RMSNorm</strong>  </p>\n<ul>\n<li>在所有 Transformer 块处理完成后，对最终输出应用 RMSNorm 进行归一化。</li>\n</ul>\n</li>\n<li><p><strong>输出线性变换</strong>  </p>\n<ul>\n<li>通过 <code>output</code> 线性层将归一化后的输出映射到词汇表空间，形状为 <code>(batch_size, seq_len, vocab_size)</code>。</li>\n</ul>\n</li>\n<li><p><strong>输出 logits</strong>  </p>\n<ul>\n<li>返回最终的 logits，表示每个 token 的概率分布。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"Transformer-Block-子流程：\"><a href=\"#Transformer-Block-子流程：\" class=\"headerlink\" title=\"Transformer Block 子流程：\"></a><strong>Transformer Block 子流程</strong>：</h4><ol>\n<li><p><strong>输入</strong>  </p>\n<ul>\n<li>接收来自上一层的输入。</li>\n</ul>\n</li>\n<li><p><strong>RMSNorm</strong>  </p>\n<ul>\n<li>对输入进行归一化。</li>\n</ul>\n</li>\n<li><p><strong>Attention</strong>  </p>\n<ul>\n<li>应用多头注意力机制，生成注意力输出。</li>\n</ul>\n</li>\n<li><p><strong>Add &amp; Norm</strong>  </p>\n<ul>\n<li>将注意力输出与输入进行残差连接，并再次应用 RMSNorm 进行归一化。</li>\n</ul>\n</li>\n<li><p><strong>FeedForward</strong>  </p>\n<ul>\n<li>应用前馈网络，生成前馈输出。</li>\n</ul>\n</li>\n<li><p><strong>Add &amp; Norm</strong>  </p>\n<ul>\n<li>将前馈输出与上一层的输出进行残差连接，并再次应用 RMSNorm 进行归一化。</li>\n</ul>\n</li>\n<li><p><strong>输出</strong>  </p>\n<ul>\n<li>返回当前 Transformer 块的输出，作为下一层的输入。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"代码实现的关键点：-3\"><a href=\"#代码实现的关键点：-3\" class=\"headerlink\" title=\"代码实现的关键点：\"></a><strong>代码实现的关键点</strong>：</h3><ol>\n<li><p><strong>嵌入和位置编码</strong>：</p>\n<ul>\n<li>使用 <code>tok_embeddings</code> 将 token IDs 转换为嵌入向量，并通过 <code>freqs_cis</code> 添加位置信息。</li>\n</ul>\n</li>\n<li><p><strong>注意力掩码</strong>：</p>\n<ul>\n<li>生成注意力掩码 <code>mask</code>，防止模型看到未来的 token。</li>\n</ul>\n</li>\n<li><p><strong>多层 Transformer 块</strong>：</p>\n<ul>\n<li>通过多个 Transformer 块处理输入，每个块包含注意力机制、前馈网络、残差连接和归一化操作。</li>\n</ul>\n</li>\n<li><p><strong>输出生成</strong>：</p>\n<ul>\n<li>对最终输出进行归一化和线性变换，生成 logits。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"总结：-5\"><a href=\"#总结：-5\" class=\"headerlink\" title=\"总结：\"></a><strong>总结</strong>：</h3><p><code>class Transformer</code> 实现了完整的 Transformer 模型，包括嵌入、位置编码、多层 Transformer 块的处理以及最终的输出生成。</p>\n<h2 id=\"示例解析\"><a href=\"#示例解析\" class=\"headerlink\" title=\"示例解析\"></a>示例解析</h2><h3 id=\"示例输入\"><a href=\"#示例输入\" class=\"headerlink\" title=\"示例输入\"></a><strong>示例输入</strong></h3><p>假设我们有以下输入：</p>\n<ul>\n<li><strong>输入 tokens</strong>: <code>[[1, 2, 3]]</code>，形状为 <code>(batch_size=1, seq_len=3)</code>。</li>\n<li><strong>模型参数</strong>:<ul>\n<li><code>dim=4</code>（模型维度）。</li>\n<li><code>n_heads=2</code>（注意力头数）。</li>\n<li><code>vocab_size=10</code>（词汇表大小）。</li>\n<li><code>max_seq_len=8</code>（最大序列长度）。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"执行流程\"><a href=\"#执行流程\" class=\"headerlink\" title=\"执行流程\"></a><strong>执行流程</strong></h3><h4 id=\"1-Token-Embedding\"><a href=\"#1-Token-Embedding\" class=\"headerlink\" title=\"1. Token Embedding\"></a>1. <strong>Token Embedding</strong></h4><ul>\n<li><strong>输入</strong>: <code>tokens = [[1, 2, 3]]</code>，形状为 <code>(1, 3)</code>。</li>\n<li><strong>操作</strong>: 将 token IDs 转换为嵌入向量。</li>\n<li><strong>输出</strong>: 嵌入向量，形状为 <code>(1, 3, 4)</code>。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 假设嵌入矩阵为：</span><br>embedding_matrix = [<br>    [<span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">0.2</span>, <span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.4</span>],  <span class=\"hljs-comment\"># token 1</span><br>    [<span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">0.6</span>, <span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">0.8</span>],  <span class=\"hljs-comment\"># token 2</span><br>    [<span class=\"hljs-number\">0.9</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.1</span>, <span class=\"hljs-number\">1.2</span>],  <span class=\"hljs-comment\"># token 3</span><br>]<br><span class=\"hljs-comment\"># 输出：</span><br>h = [<br>    [[<span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">0.2</span>, <span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.4</span>],  <span class=\"hljs-comment\"># token 1</span><br>     [<span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">0.6</span>, <span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">0.8</span>],  <span class=\"hljs-comment\"># token 2</span><br>     [<span class=\"hljs-number\">0.9</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.1</span>, <span class=\"hljs-number\">1.2</span>]]  <span class=\"hljs-comment\"># token 3</span><br>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"2-添加位置编码\"><a href=\"#2-添加位置编码\" class=\"headerlink\" title=\"2. 添加位置编码\"></a>2. <strong>添加位置编码</strong></h4><ul>\n<li><strong>输入</strong>: 嵌入向量 <code>h</code>，形状为 <code>(1, 3, 4)</code>。</li>\n<li><strong>操作</strong>: 使用 <code>freqs_cis</code> 添加旋转位置编码。</li>\n<li><strong>输出</strong>: 添加位置编码后的向量，形状为 <code>(1, 3, 4)</code>。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 假设 freqs_cis 为：</span><br>freqs_cis = [<br>    [<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.0</span>],  <span class=\"hljs-comment\"># 位置 1</span><br>    [<span class=\"hljs-number\">1.1</span>, <span class=\"hljs-number\">1.1</span>],  <span class=\"hljs-comment\"># 位置 2</span><br>    [<span class=\"hljs-number\">1.2</span>, <span class=\"hljs-number\">1.2</span>],  <span class=\"hljs-comment\"># 位置 3</span><br>]<br><span class=\"hljs-comment\"># 输出：</span><br>h_with_pos = [<br>    [[<span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">0.2</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.0</span>],  <span class=\"hljs-comment\"># token 1</span><br>     [<span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">0.6</span>, <span class=\"hljs-number\">1.1</span>, <span class=\"hljs-number\">1.1</span>],  <span class=\"hljs-comment\"># token 2</span><br>     [<span class=\"hljs-number\">0.9</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.2</span>, <span class=\"hljs-number\">1.2</span>]]  <span class=\"hljs-comment\"># token 3</span><br>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"3-初始化-mask\"><a href=\"#3-初始化-mask\" class=\"headerlink\" title=\"3. 初始化 mask\"></a>3. <strong>初始化 mask</strong></h4><ul>\n<li><strong>输入</strong>: 序列长度 <code>seq_len=3</code>。</li>\n<li><strong>操作</strong>: 生成注意力掩码，防止模型看到未来的 token。</li>\n<li><strong>输出</strong>: 注意力掩码，形状为 <code>(3, 3)</code>。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 输出：</span><br>mask = [<br>    [<span class=\"hljs-number\">0</span>, -inf, -inf],  <span class=\"hljs-comment\"># 位置 1</span><br>    [<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, -inf],     <span class=\"hljs-comment\"># 位置 2</span><br>    [<span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>, <span class=\"hljs-number\">0</span>]         <span class=\"hljs-comment\"># 位置 3</span><br>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"4-进入-Transformer-层\"><a href=\"#4-进入-Transformer-层\" class=\"headerlink\" title=\"4. 进入 Transformer 层\"></a>4. <strong>进入 Transformer 层</strong></h4><ul>\n<li><strong>输入</strong>: 添加位置编码后的向量 <code>h_with_pos</code>，形状为 <code>(1, 3, 4)</code>。</li>\n<li><strong>操作</strong>: 通过多层 Transformer 块处理输入。</li>\n</ul>\n<hr>\n<h4 id=\"5-Transformer-Block-1\"><a href=\"#5-Transformer-Block-1\" class=\"headerlink\" title=\"5. Transformer Block 1\"></a>5. <strong>Transformer Block 1</strong></h4><ul>\n<li><strong>输入</strong>: <code>h_with_pos</code>，形状为 <code>(1, 3, 4)</code>。</li>\n<li><strong>操作</strong>:<ol>\n<li><strong>RMSNorm</strong>: 对输入进行归一化。</li>\n<li><strong>Attention</strong>: 计算多头注意力机制。</li>\n<li><strong>Add &amp; Norm</strong>: 残差连接和归一化。</li>\n<li><strong>FeedForward</strong>: 计算前馈网络。</li>\n<li><strong>Add &amp; Norm</strong>: 残差连接和归一化。</li>\n</ol>\n</li>\n<li><strong>输出</strong>: Transformer 块的输出，形状为 <code>(1, 3, 4)</code>。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 假设输出为：</span><br>h_block1 = [<br>    [[<span class=\"hljs-number\">0.2</span>, <span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">1.1</span>, <span class=\"hljs-number\">1.1</span>],  <span class=\"hljs-comment\"># token 1</span><br>     [<span class=\"hljs-number\">0.6</span>, <span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">1.2</span>, <span class=\"hljs-number\">1.2</span>],  <span class=\"hljs-comment\"># token 2</span><br>     [<span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.1</span>, <span class=\"hljs-number\">1.3</span>, <span class=\"hljs-number\">1.3</span>]]  <span class=\"hljs-comment\"># token 3</span><br>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"6-Transformer-Block-N\"><a href=\"#6-Transformer-Block-N\" class=\"headerlink\" title=\"6. Transformer Block N\"></a>6. <strong>Transformer Block N</strong></h4><ul>\n<li><strong>输入</strong>: 上一层的输出，形状为 <code>(1, 3, 4)</code>。</li>\n<li><strong>操作</strong>: 重复 Transformer 块的处理。</li>\n<li><strong>输出</strong>: 最后一层 Transformer 块的输出，形状为 <code>(1, 3, 4)</code>。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 假设输出为：</span><br>h_blockN = [<br>    [[<span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.4</span>, <span class=\"hljs-number\">1.2</span>, <span class=\"hljs-number\">1.2</span>],  <span class=\"hljs-comment\"># token 1</span><br>     [<span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">1.3</span>, <span class=\"hljs-number\">1.3</span>],  <span class=\"hljs-comment\"># token 2</span><br>     [<span class=\"hljs-number\">1.1</span>, <span class=\"hljs-number\">1.2</span>, <span class=\"hljs-number\">1.4</span>, <span class=\"hljs-number\">1.4</span>]]  <span class=\"hljs-comment\"># token 3</span><br>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"7-RMSNorm\"><a href=\"#7-RMSNorm\" class=\"headerlink\" title=\"7. RMSNorm\"></a>7. <strong>RMSNorm</strong></h4><ul>\n<li><strong>输入</strong>: 最后一层 Transformer 块的输出，形状为 <code>(1, 3, 4)</code>。</li>\n<li><strong>操作</strong>: 对输出进行归一化。</li>\n<li><strong>输出</strong>: 归一化后的输出，形状为 <code>(1, 3, 4)</code>。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 假设输出为：</span><br>h_norm = [<br>    [[<span class=\"hljs-number\">0.4</span>, <span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">1.3</span>, <span class=\"hljs-number\">1.3</span>],  <span class=\"hljs-comment\"># token 1</span><br>     [<span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.9</span>, <span class=\"hljs-number\">1.4</span>, <span class=\"hljs-number\">1.4</span>],  <span class=\"hljs-comment\"># token 2</span><br>     [<span class=\"hljs-number\">1.2</span>, <span class=\"hljs-number\">1.3</span>, <span class=\"hljs-number\">1.5</span>, <span class=\"hljs-number\">1.5</span>]]  <span class=\"hljs-comment\"># token 3</span><br>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h4 id=\"8-输出线性变换\"><a href=\"#8-输出线性变换\" class=\"headerlink\" title=\"8. 输出线性变换\"></a>8. <strong>输出线性变换</strong></h4><ul>\n<li><strong>输入</strong>: 归一化后的输出，形状为 <code>(1, 3, 4)</code>。</li>\n<li><strong>操作</strong>: 通过线性层将输出映射到词汇表空间。</li>\n<li><strong>输出</strong>: logits，形状为 <code>(1, 3, vocab_size=10)</code>。</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-comment\"># 假设输出为：</span><br>logits = [<br>    [[<span class=\"hljs-number\">0.1</span>, <span class=\"hljs-number\">0.2</span>, <span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.4</span>, <span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">0.6</span>, <span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.9</span>, <span class=\"hljs-number\">1.0</span>],  <span class=\"hljs-comment\"># token 1</span><br>     [<span class=\"hljs-number\">0.2</span>, <span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.4</span>, <span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">0.6</span>, <span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.9</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.1</span>],  <span class=\"hljs-comment\"># token 2</span><br>     [<span class=\"hljs-number\">0.3</span>, <span class=\"hljs-number\">0.4</span>, <span class=\"hljs-number\">0.5</span>, <span class=\"hljs-number\">0.6</span>, <span class=\"hljs-number\">0.7</span>, <span class=\"hljs-number\">0.8</span>, <span class=\"hljs-number\">0.9</span>, <span class=\"hljs-number\">1.0</span>, <span class=\"hljs-number\">1.1</span>, <span class=\"hljs-number\">1.2</span>]]  <span class=\"hljs-comment\"># token 3</span><br>]<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"最终输出\"><a href=\"#最终输出\" class=\"headerlink\" title=\"最终输出\"></a><strong>最终输出</strong></h3><ul>\n<li><strong>输出</strong>: logits，形状为 <code>(1, 3, 10)</code>。</li>\n<li><strong>解释</strong>: 每个 token 的输出是一个长度为 <code>vocab_size=10</code> 的向量，表示每个 token 的概率分布。</li>\n</ul>\n<hr>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h3><ul>\n<li><strong>输入</strong>: <code>tokens = [[1, 2, 3]]</code>，形状为 <code>(1, 3)</code>。</li>\n<li><strong>输出</strong>: logits，形状为 <code>(1, 3, 10)</code>。</li>\n<li><strong>中间步骤</strong>:<ol>\n<li>Token Embedding：<code>(1, 3) -&gt; (1, 3, 4)</code>。</li>\n<li>添加位置编码：<code>(1, 3, 4) -&gt; (1, 3, 4)</code>。</li>\n<li>初始化 mask：<code>(3, 3)</code>。</li>\n<li>多层 Transformer 块：<code>(1, 3, 4) -&gt; (1, 3, 4)</code>。</li>\n<li>RMSNorm：<code>(1, 3, 4) -&gt; (1, 3, 4)</code>。</li>\n<li>输出线性变换：<code>(1, 3, 4) -&gt; (1, 3, 10)</code>。</li>\n</ol>\n</li>\n</ul>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n"},{"title":"llama3源码解析-04：generation.py模块解析","date":"2024-12-30T04:00:00.000Z","_content":"\n![llama](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/Llama3_Repo.jpeg)\n\n## 整体\n\n`generation.py` 模块是 Llama 3 模型的核心生成模块，负责实现文本生成功能，包括文本补全和对话生成。\n\n---\n\n### **1. 核心功能**\n- **文本生成**：根据输入的提示（prompt）生成文本。\n- **文本补全**：对给定的文本提示进行补全。\n- **对话生成**：根据对话历史生成助理的回复。\n- **生成控制**：支持通过温度（temperature）、top-p 采样（nucleus sampling）等参数控制生成过程。\n\n---\n\n### **2. 主要类和方法**\n\n#### **`class Llama`**\n- **`build` 方法**：初始化并加载 Llama 模型和分词器。\n- **`generate` 方法**：核心生成方法，根据输入的 tokenized prompts 生成文本。\n- **`text_completion` 方法**：对文本提示进行补全。\n- **`chat_completion` 方法**：根据对话历史生成助理的回复。\n\n#### **`class CompletionPrediction`**\n- 用于表示文本补全的生成结果，包含生成的文本、token 列表和 logprobs（可选）。\n\n#### **`class ChatPrediction`**\n- 用于表示对话生成的生成结果，包含助理的回复、token 列表和 logprobs（可选）。\n\n---\n\n### **3. 核心方法详解**\n\n#### **`generate` 方法**\n- **功能**：根据输入的 tokenized prompts 生成文本。\n- **参数**：\n  - `prompt_tokens`：tokenized prompts，形状为 `(batch_size, seq_len)`。\n  - `max_gen_len`：生成文本的最大长度。\n  - `temperature`：控制生成随机性的温度参数。\n  - `top_p`：top-p 采样的概率阈值。\n  - `logprobs`：是否计算 token 的 log 概率。\n  - `echo`：是否在生成结果中包含输入提示。\n- **返回值**：生成的 token 序列和 logprobs（可选）。\n\n#### **`text_completion` 方法**\n- **功能**：对文本提示进行补全。\n- **参数**：\n  - `prompts`：文本提示列表。\n  - `temperature`：控制生成随机性的温度参数。\n  - `top_p`：top-p 采样的概率阈值。\n  - `max_gen_len`：生成文本的最大长度。\n  - `logprobs`：是否计算 token 的 log 概率。\n  - `echo`：是否在生成结果中包含输入提示。\n- **返回值**：文本补全的生成结果列表。\n\n#### **`chat_completion` 方法**\n- **功能**：根据对话历史生成助理的回复。\n- **参数**：\n  - `dialogs`：对话历史列表。\n  - `temperature`：控制生成随机性的温度参数。\n  - `top_p`：top-p 采样的概率阈值。\n  - `max_gen_len`：生成文本的最大长度。\n  - `logprobs`：是否计算 token 的 log 概率。\n- **返回值**：对话生成的生成结果列表。\n\n---\n\n### **4. 生成控制参数**\n- **温度（temperature）**：\n  - 控制生成随机性的参数。\n  - 值越大，生成结果越随机；值越小，生成结果越确定。\n- **top-p 采样（nucleus sampling）**：\n  - 从概率累积值超过 `top_p` 的最小 token 集合中采样。\n  - 用于控制生成结果的多样性和质量。\n- **logprobs**：\n  - 是否计算生成 token 的 log 概率。\n  - 用于分析生成结果的置信度。\n\n---\n\n### **5. 生成流程**\n1. **输入处理**：\n   - 将输入提示或对话历史转换为 tokenized prompts。\n2. **生成文本**：\n   - 使用 `generate` 方法生成 token 序列。\n   - 通过温度、top-p 采样等参数控制生成过程。\n3. **输出处理**：\n   - 将生成的 token 序列解码为文本。\n   - 返回生成结果，包含生成的文本、token 列表和 logprobs（可选）。\n\n---\n\n### **6. 示例**\n\n#### **文本补全**\n```python\nprompts = [\"Once upon a time\"]\nresults = llama.text_completion(prompts, max_gen_len=50)\nfor result in results:\n    print(result[\"generation\"])\n```\n\n#### **对话生成**\n```python\ndialogs = [\n    [{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n]\nresults = llama.chat_completion(dialogs, max_gen_len=50)\nfor result in results:\n    print(result[\"generation\"][\"content\"])\n```\n\n---\n\n### **7. 总结**\n`generation.py` 模块是 Llama 3 模型的核心生成模块，提供了文本补全和对话生成功能。通过温度、top-p 采样等参数，用户可以灵活控制生成过程。\n\n\n\n## `build` 方法\n\n```python\n@staticmethod\ndef build(\n    ckpt_dir: str,\n    tokenizer_path: str,\n    max_seq_len: int,\n    max_batch_size: int,\n    model_parallel_size: Optional[int] = None,\n    seed: int = 1,\n) -> \"Llama\":\n    \"\"\"\n    初始化并加载 Llama 模型。\n\n    参数:\n        ckpt_dir (str): 包含模型检查点文件的目录路径。\n        tokenizer_path (str): 分词器文件的路径。\n        max_seq_len (int): 输入序列的最大长度。\n        max_batch_size (int): 推理时的最大批次大小。\n        model_parallel_size (Optional[int], optional): 模型并行的大小（GPU 数量）。如果未提供，则从环境变量中获取。默认为 None。\n        seed (int, optional): 随机种子，确保所有进程的随机性一致。默认为 1。\n\n    返回:\n        Llama: 加载了模型和分词器的 Llama 实例。\n\n    异常:\n        AssertionError: 如果检查点目录中没有检查点文件，或者模型并行大小与检查点文件数量不匹配。\n\n    注意:\n        该方法会初始化分布式进程组，设置设备为 CUDA，并加载预训练模型和分词器。\n    \"\"\"\n    # 检查 max_seq_len 是否在有效范围内\n    assert 1 <= max_seq_len <= 8192, f\"max_seq_len must be between 1 and 8192, got {max_seq_len}.\"\n    # 检查检查点目录是否存在\n    assert os.path.isdir(ckpt_dir), f\"Checkpoint directory '{ckpt_dir}' does not exist.\"\n    # 检查分词器文件是否存在\n    assert os.path.isfile(tokenizer_path), f\"Tokenizer file '{tokenizer_path}' does not exist.\"\n\n    # 如果分布式进程组未初始化，则初始化\n    if not torch.distributed.is_initialized():\n        torch.distributed.init_process_group(\"nccl\")\n    # 如果模型并行未初始化，则初始化\n    if not model_parallel_is_initialized():\n        # 如果未提供 model_parallel_size，则从环境变量中获取\n        if model_parallel_size is None:\n            model_parallel_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n        initialize_model_parallel(model_parallel_size)\n\n    # 获取当前进程的本地 rank\n    local_rank = int(os.environ.get(\"LOCAL_RANK\", 0))\n    # 设置当前进程使用的 GPU 设备\n    torch.cuda.set_device(local_rank)\n\n    # 设置随机种子，确保所有进程的随机性一致\n    torch.manual_seed(seed)\n\n    # 如果当前进程不是主进程（rank > 0），则关闭标准输出\n    if local_rank > 0:\n        sys.stdout = open(os.devnull, \"w\")\n\n    # 记录加载模型的开始时间\n    start_time = time.time()\n    # 获取检查点目录中的所有 .pth 文件，并按文件名排序\n    checkpoints = sorted(Path(ckpt_dir).glob(\"*.pth\"))\n    # 检查检查点目录中是否有检查点文件\n    assert len(checkpoints) > 0, f\"no checkpoint files found in {ckpt_dir}\"\n    # 检查模型并行大小是否与检查点文件数量匹配\n    assert model_parallel_size == len(\n        checkpoints\n    ), f\"Loading a checkpoint for MP={len(checkpoints)} but world size is {model_parallel_size}\"\n    # 获取当前进程对应的检查点文件\n    ckpt_path = checkpoints[get_model_parallel_rank()]\n    # 加载检查点文件到 CPU\n    checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n    # 加载模型参数文件\n    with open(Path(ckpt_dir) / \"params.json\", \"r\") as f:\n        params = json.loads(f.read())\n\n    # 初始化模型参数\n    model_args: ModelArgs = ModelArgs(\n        max_seq_len=max_seq_len,\n        max_batch_size=max_batch_size,\n        **params,\n    )\n    # 初始化分词器\n    tokenizer = Tokenizer(model_path=tokenizer_path)\n    # 检查模型词汇表大小是否与分词器词汇表大小匹配\n    assert model_args.vocab_size == tokenizer.n_words\n    # 如果当前设备支持 bfloat16，则设置默认张量类型为 bfloat16，否则设置为 float16\n    if torch.cuda.is_bf16_supported():\n        torch.set_default_tensor_type(torch.cuda.BFloat16Tensor)\n    else:\n        torch.set_default_tensor_type(torch.cuda.HalfTensor)\n    # 初始化 Transformer 模型\n    model = Transformer(model_args)\n    # 加载模型权重\n    model.load_state_dict(checkpoint, strict=False)\n    # 打印模型加载时间\n    print(f\"Loaded in {time.time() - start_time:.2f} seconds\")\n\n    # 返回 Llama 实例，包含加载的模型和分词器\n    return Llama(model, tokenizer)\n```\n\n---\n\n### **详细解释**\n\n#### **1. 参数检查**\n- **`max_seq_len`**: 检查输入序列的最大长度是否在有效范围内（1 到 8192）。\n- **`ckpt_dir`**: 检查检查点目录是否存在。\n- **`tokenizer_path`**: 检查分词器文件是否存在。\n\n#### **2. 分布式初始化**\n- 如果分布式进程组未初始化，则使用 `torch.distributed.init_process_group` 初始化。\n- 如果模型并行未初始化，则根据 `model_parallel_size` 或环境变量初始化模型并行。\n\n#### **3. 设备设置**\n- 获取当前进程的本地 rank，并设置使用的 GPU 设备。\n\n#### **4. 随机种子**\n- 设置随机种子，确保所有进程的随机性一致。\n\n#### **5. 检查点加载**\n- 获取检查点目录中的所有 `.pth` 文件，并按文件名排序。\n- 检查检查点文件数量和模型并行大小是否匹配。\n- 加载当前进程对应的检查点文件到 CPU。\n\n#### **6. 模型参数加载**\n- 从 `params.json` 文件中加载模型参数。\n- 使用 `ModelArgs` 初始化模型参数。\n\n#### **7. 分词器初始化**\n- 使用 `Tokenizer` 初始化分词器，并检查模型词汇表大小是否与分词器词汇表大小匹配。\n\n#### **8. 张量类型设置**\n- 如果当前设备支持 `bfloat16`，则设置默认张量类型为 `bfloat16`，否则设置为 `float16`。\n\n#### **9. 模型初始化**\n- 使用 `Transformer` 初始化模型，并加载检查点中的权重。\n\n#### **10. 返回 Llama 实例**\n- 返回包含加载的模型和分词器的 `Llama` 实例。\n\n---\n\n### **总结**\n`build` 方法负责初始化并加载 Llama 模型，包括分布式设置、设备配置、检查点加载、模型参数初始化、分词器初始化等。它是 Llama 模型的核心初始化方法，确保模型能够正确加载并准备好进行推理或训练。\n\n## `generate` 方法\n\n\n\n```python\n@torch.inference_mode()\ndef generate(\n    self,\n    prompt_tokens: List[List[int]],\n    max_gen_len: int,\n    temperature: float = 0.6,\n    top_p: float = 0.9,\n    logprobs: bool = False,\n    echo: bool = False,\n) -> Tuple[List[List[int]], Optional[List[List[float]]]]:\n    \"\"\"\n    根据输入的 tokenized prompts 生成文本。\n\n    参数:\n        prompt_tokens (List[List[int]]): tokenized prompts，每个 prompt 是一个整数列表。\n        max_gen_len (int): 生成文本的最大长度。\n        temperature (float, optional): 控制生成随机性的温度参数。默认为 0.6。\n        top_p (float, optional): top-p 采样的概率阈值。默认为 0.9。\n        logprobs (bool, optional): 是否计算 token 的 log 概率。默认为 False。\n        echo (bool, optional): 是否在生成结果中包含输入提示。默认为 False。\n\n    返回:\n        Tuple[List[List[int]], Optional[List[List[float]]]]: 生成的 token 序列和 logprobs（可选）。\n\n    注意:\n        该方法使用 nucleus sampling（top-p 采样）生成文本，支持通过温度参数控制生成随机性。\n        如果 logprobs 为 True，则返回每个生成 token 的 log 概率。\n    \"\"\"\n    # 获取模型参数\n    params = self.model.params\n    # 获取批次大小\n    bsz = len(prompt_tokens)\n    # 检查批次大小是否超过模型的最大批次大小\n    assert bsz <= params.max_batch_size, (bsz, params.max_batch_size)\n\n    # 计算输入 prompts 的最小和最大长度\n    min_prompt_len = min(len(t) for t in prompt_tokens)\n    max_prompt_len = max(len(t) for t in prompt_tokens)\n    # 检查输入 prompts 的最大长度是否超过模型的最大序列长度\n    assert max_prompt_len <= params.max_seq_len\n    # 计算总长度（输入 prompts 长度 + 生成文本长度）\n    total_len = min(params.max_seq_len, max_gen_len + max_prompt_len)\n\n    # 获取填充 token 的 ID\n    pad_id = self.tokenizer.pad_id\n    # 初始化 tokens 张量，用 pad_id 填充\n    tokens = torch.full((bsz, total_len), pad_id, dtype=torch.long, device=\"cuda\")\n    # 将输入 prompts 填充到 tokens 张量中\n    for k, t in enumerate(prompt_tokens):\n        tokens[k, : len(t)] = torch.tensor(t, dtype=torch.long, device=\"cuda\")\n    # 如果 logprobs 为 True，则初始化 token_logprobs 张量\n    if logprobs:\n        token_logprobs = torch.zeros_like(tokens, dtype=torch.float)\n\n    # 初始化当前位置和 EOS（结束符）标记\n    prev_pos = 0\n    eos_reached = torch.tensor([False] * bsz, device=\"cuda\")\n    # 创建输入文本的掩码（非填充部分为 True）\n    input_text_mask = tokens != pad_id\n\n    # 如果输入 prompts 的长度等于总长度，则直接计算 logits\n    if min_prompt_len == total_len:\n        logits = self.model.forward(tokens, prev_pos)\n        # 计算 token 的 log 概率\n        token_logprobs = -F.cross_entropy(\n            input=logits.transpose(1, 2),\n            target=tokens,\n            reduction=\"none\",\n            ignore_index=pad_id,\n        )\n\n    # 获取停止 token 的 ID\n    stop_tokens = torch.tensor(list(self.tokenizer.stop_tokens))\n\n    # 逐 token 生成文本\n    for cur_pos in range(min_prompt_len, total_len):\n        # 计算当前 token 的 logits\n        logits = self.model.forward(tokens[:, prev_pos:cur_pos], prev_pos)\n        # 如果 temperature > 0，则使用温度参数和 top-p 采样生成下一个 token\n        if temperature > 0:\n            probs = torch.softmax(logits[:, -1] / temperature, dim=-1)\n            next_token = sample_top_p(probs, top_p)\n        else:\n            # 如果 temperature = 0，则选择概率最大的 token\n            next_token = torch.argmax(logits[:, -1], dim=-1)\n        # 将下一个 token 填充到 tokens 张量中\n        next_token = next_token.reshape(-1)\n        # 如果当前位置在输入 prompts 范围内，则保留输入 token\n        next_token = torch.where(\n            input_text_mask[:, cur_pos], tokens[:, cur_pos], next_token\n        )\n        tokens[:, cur_pos] = next_token\n        # 如果 logprobs 为 True，则计算 token 的 log 概率\n        if logprobs:\n            token_logprobs[:, prev_pos + 1 : cur_pos + 1] = -F.cross_entropy(\n                input=logits.transpose(1, 2),\n                target=tokens[:, prev_pos + 1 : cur_pos + 1],\n                reduction=\"none\",\n                ignore_index=pad_id,\n            )\n        # 检查是否生成停止 token\n        eos_reached |= (~input_text_mask[:, cur_pos]) & (\n            torch.isin(next_token, stop_tokens)\n        )\n        # 更新当前位置\n        prev_pos = cur_pos\n        # 如果所有批次都生成停止 token，则提前结束\n        if all(eos_reached):\n            break\n\n    # 如果 logprobs 为 True，则将 token_logprobs 转换为列表\n    if logprobs:\n        token_logprobs = token_logprobs.tolist()\n    # 初始化输出 token 序列和 logprobs\n    out_tokens, out_logprobs = [], []\n    # 处理每个批次的生成结果\n    for i, toks in enumerate(tokens.tolist()):\n        # 如果 echo 为 False，则从生成部分开始截取\n        start = 0 if echo else len(prompt_tokens[i])\n        toks = toks[start : len(prompt_tokens[i]) + max_gen_len]\n        probs = None\n        # 如果 logprobs 为 True，则截取对应的 logprobs\n        if logprobs:\n            probs = token_logprobs[i][start : len(prompt_tokens[i]) + max_gen_len]\n        # 如果生成结果中包含停止 token，则截取到停止 token 之前\n        for stop_token in self.tokenizer.stop_tokens:\n            try:\n                eos_idx = toks.index(stop_token)\n                toks = toks[:eos_idx]\n                probs = probs[:eos_idx] if logprobs else None\n            except ValueError:\n                pass\n        # 将结果添加到输出列表中\n        out_tokens.append(toks)\n        out_logprobs.append(probs)\n    # 返回生成的 token 序列和 logprobs（可选）\n    return (out_tokens, out_logprobs if logprobs else None)\n```\n\n---\n\n### **详细解释**\n\n#### **1. 输入处理**\n- **`prompt_tokens`**: 输入的 tokenized prompts，每个 prompt 是一个整数列表。\n- **`max_gen_len`**: 生成文本的最大长度。\n- **`temperature`**: 控制生成随机性的温度参数。\n- **`top_p`**: top-p 采样的概率阈值。\n- **`logprobs`**: 是否计算 token 的 log 概率。\n- **`echo`**: 是否在生成结果中包含输入提示。\n\n#### **2. 初始化**\n- **`params`**: 获取模型参数。\n- **`bsz`**: 获取批次大小。\n- **`min_prompt_len` 和 `max_prompt_len`**: 计算输入 prompts 的最小和最大长度。\n- **`total_len`**: 计算总长度（输入 prompts 长度 + 生成文本长度）。\n- **`tokens`**: 初始化 tokens 张量，用 pad_id 填充，并将输入 prompts 填充到 tokens 张量中。\n\n#### **3. 生成文本**\n- **逐 token 生成**:\n  - 使用 `model.forward` 计算当前 token 的 logits。\n  - 如果 `temperature > 0`，则使用温度参数和 top-p 采样生成下一个 token。\n  - 如果 `temperature = 0`，则选择概率最大的 token。\n  - 将下一个 token 填充到 tokens 张量中。\n  - 如果 `logprobs` 为 True，则计算 token 的 log 概率。\n  - 检查是否生成停止 token，如果所有批次都生成停止 token，则提前结束。\n\n#### **4. 输出处理**\n- **`out_tokens` 和 `out_logprobs`**: 处理每个批次的生成结果。\n  - 如果 `echo` 为 False，则从生成部分开始截取。\n  - 如果生成结果中包含停止 token，则截取到停止 token 之前。\n- **返回结果**: 返回生成的 token 序列和 logprobs（可选）。\n\n---\n\n### **总结**\n`generate` 方法是 Llama 3 模型的核心生成方法，负责根据输入的 tokenized prompts 生成文本。通过温度、top-p 采样等参数，用户可以灵活控制生成过程。该方法支持计算 token 的 log 概率，并可以处理停止 token 和输入提示。\n\n## `generate` 详细流程图\n\n![generate流程图](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241230115215231.png)\n\n---\n\n### **详细步骤说明**\n\n#### **1. 输入处理**\n- **输入**: `prompt_tokens`，tokenized prompts，每个 prompt 是一个整数列表。\n\n#### **2. 初始化**\n- **初始化 tokens 张量**: 用 pad_id 填充，并将输入 prompts 填充到 tokens 张量中。\n- **计算 min_prompt_len 和 max_prompt_len**: 输入 prompts 的最小和最大长度。\n- **检查 max_prompt_len 是否超过 max_seq_len**: 确保输入 prompts 的长度不超过模型的最大序列长度。\n- **计算 total_len**: 输入 prompts 长度 + 生成文本长度。\n- **初始化 token_logprobs**: 如果 `logprobs=True`，则初始化 token_logprobs 张量。\n- **初始化 prev_pos 和 eos_reached**: 当前位置和 EOS（结束符）标记。\n- **创建 input_text_mask**: 输入文本的掩码（非填充部分为 True）。\n\n#### **3. 生成文本**\n- **检查 min_prompt_len 是否等于 total_len**:\n  - 如果相等，则直接计算 logits 和 token_logprobs。\n  - 否则，逐 token 生成文本。\n- **逐 token 生成文本**:\n  - **计算当前 token 的 logits**。\n  - **检查 temperature 是否大于 0**:\n    - 如果大于 0，则使用温度参数和 top-p 采样生成下一个 token。\n    - 否则，选择概率最大的 token。\n  - **填充下一个 token 到 tokens 张量**。\n  - **检查 logprobs 是否为 True**:\n    - 如果为 True，则计算 token 的 log 概率。\n  - **检查是否生成停止 token**。\n  - **更新 prev_pos**。\n  - **检查所有批次是否都生成停止 token**:\n    - 如果是，则提前结束。\n    - 否则，继续生成下一个 token。\n\n#### **4. 输出处理**\n- **处理每个批次的生成结果**:\n  - **检查 echo 是否为 False**:\n    - 如果为 False，则从生成部分开始截取。\n    - 否则，保留输入提示。\n  - **截取到停止 token 之前**。\n  - **将结果添加到输出列表中**。\n- **返回生成的 token 序列和 logprobs（可选）**。\n\n---\n\n### **总结**\n`generate` 方法的流程图清晰地展示了从输入到输出的完整生成过程，包括初始化、逐 token 生成和输出处理。通过该流程图，可以更好地理解 Llama 3 模型的文本生成机制。\n\n## `text_completion` 和 `chat_completion` \n\n---\n\n### **1. `text_completion` 方法**\n\n#### **功能**\n对给定的文本提示进行补全，生成后续文本。\n\n#### **参数**\n- **`prompts`**: 文本提示列表，每个提示是一个字符串。\n- **`temperature`**: 控制生成随机性的温度参数。值越大，生成结果越随机；值越小，生成结果越确定。\n- **`top_p`**: top-p 采样的概率阈值。用于控制生成结果的多样性和质量。\n- **`max_gen_len`**: 生成文本的最大长度。如果未提供，则使用模型的最大序列长度减 1。\n- **`logprobs`**: 是否计算 token 的 log 概率。默认为 False。\n- **`echo`**: 是否在生成结果中包含输入提示。默认为 False。\n\n#### **返回值**\n- **`List[CompletionPrediction]`**: 文本补全的生成结果列表，每个结果包含生成的文本、token 列表和 logprobs（可选）。\n\n#### **代码逻辑**\n1. **检查 `max_gen_len`**:\n   - 如果未提供 `max_gen_len`，则使用模型的最大序列长度减 1。\n2. **编码输入提示**:\n   - 使用分词器将输入提示编码为 tokenized prompts。\n3. **调用 `generate` 方法**:\n   - 使用 `generate` 方法生成 token 序列。\n4. **解码生成结果**:\n   - 将生成的 token 序列解码为文本。\n5. **返回生成结果**:\n   - 如果 `logprobs` 为 True，则返回生成的文本、token 列表和 logprobs。\n   - 否则，仅返回生成的文本。\n\n#### **示例**\n```python\nprompts = [\"Once upon a time\"]\nresults = llama.text_completion(prompts, max_gen_len=50)\nfor result in results:\n    print(result[\"generation\"])\n```\n\n---\n\n### **2. `chat_completion` 方法**\n\n#### **功能**\n根据对话历史生成助理的回复。\n\n#### **参数**\n- **`dialogs`**: 对话历史列表，每个对话是一个消息列表，每个消息包含角色（`role`）和内容（`content`）。\n- **`temperature`**: 控制生成随机性的温度参数。值越大，生成结果越随机；值越小，生成结果越确定。\n- **`top_p`**: top-p 采样的概率阈值。用于控制生成结果的多样性和质量。\n- **`max_gen_len`**: 生成文本的最大长度。如果未提供，则使用模型的最大序列长度减 1。\n- **`logprobs`**: 是否计算 token 的 log 概率。默认为 False。\n\n#### **返回值**\n- **`List[ChatPrediction]`**: 对话生成的生成结果列表，每个结果包含助理的回复、token 列表和 logprobs（可选）。\n\n#### **代码逻辑**\n1. **检查 `max_gen_len`**:\n   - 如果未提供 `max_gen_len`，则使用模型的最大序列长度减 1。\n2. **编码对话历史**:\n   - 使用 `ChatFormat` 将对话历史编码为 tokenized prompts。\n3. **调用 `generate` 方法**:\n   - 使用 `generate` 方法生成 token 序列。\n4. **解码生成结果**:\n   - 将生成的 token 序列解码为文本。\n5. **返回生成结果**:\n   - 如果 `logprobs` 为 True，则返回助理的回复、token 列表和 logprobs。\n   - 否则，仅返回助理的回复。\n\n#### **示例**\n```python\ndialogs = [\n    [{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n]\nresults = llama.chat_completion(dialogs, max_gen_len=50)\nfor result in results:\n    print(result[\"generation\"][\"content\"])\n```\n\n---\n\n### **3. 主要区别**\n| 特性         | `text_completion`      | `chat_completion`              |\n| ------------ | ---------------------- | ------------------------------ |\n| **输入**     | 文本提示列表           | 对话历史列表                   |\n| **输出**     | 文本补全结果           | 助理的回复                     |\n| **编码方式** | 直接使用分词器编码     | 使用 `ChatFormat` 编码对话历史 |\n| **适用场景** | 单轮文本补全           | 多轮对话生成                   |\n| **返回格式** | `CompletionPrediction` | `ChatPrediction`               |\n\n---\n\n### **4. 生成控制参数**\n- **温度（temperature）**:\n  - 控制生成随机性的参数。\n  - 值越大，生成结果越随机；值越小，生成结果越确定。\n- **top-p 采样（nucleus sampling）**:\n  - 从概率累积值超过 `top_p` 的最小 token 集合中采样。\n  - 用于控制生成结果的多样性和质量。\n- **logprobs**:\n  - 是否计算生成 token 的 log 概率。\n  - 用于分析生成结果的置信度。\n\n---\n\n### **5. 总结**\n- **`text_completion`**: 用于文本补全，适用于单轮文本生成任务。\n- **`chat_completion`**: 用于对话生成，适用于多轮对话任务。\n- 两者都通过 `generate` 方法实现核心生成逻辑，并支持温度、top-p 采样等参数控制生成过程。\n\n## sample_top_p\n\n该函数实现了 **top-p 采样（nucleus sampling）**，用于从概率分布中选择 token。\n\n---\n\n### **代码注释**\n\n```python\ndef sample_top_p(probs, p):\n    \"\"\"\n    对概率分布进行 top-p 采样（nucleus sampling）。\n\n    参数:\n        probs (torch.Tensor): 概率分布张量，形状为 (batch_size, vocab_size)。\n        p (float): top-p 采样的概率阈值，取值范围为 (0, 1]。\n\n    返回:\n        torch.Tensor: 采样得到的 token 索引，形状为 (batch_size, 1)。\n\n    注意:\n        top-p 采样从概率累积值超过 p 的最小 token 集合中采样，用于控制生成结果的多样性和质量。\n    \"\"\"\n    # 对概率分布进行降序排序，并获取排序后的概率和索引\n    probs_sort, probs_idx = torch.sort(probs, dim=-1, descending=True)\n    # 计算概率分布的累积和\n    probs_sum = torch.cumsum(probs_sort, dim=-1)\n    # 创建掩码，标记概率累积值超过 p 的 token\n    mask = probs_sum - probs_sort > p\n    # 将掩码对应的概率置为 0\n    probs_sort[mask] = 0.0\n    # 对剩余的概率进行归一化\n    probs_sort.div_(probs_sort.sum(dim=-1, keepdim=True))\n    # 从归一化后的概率分布中进行多项式采样\n    next_token = torch.multinomial(probs_sort, num_samples=1)\n    # 根据采样结果获取原始 token 索引\n    next_token = torch.gather(probs_idx, -1, next_token)\n    return next_token\n```\n\n---\n\n### **详细解释**\n\n#### **1. 输入参数**\n- **`probs`**: 概率分布张量，形状为 `(batch_size, vocab_size)`，表示每个 token 的概率。\n- **`p`**: top-p 采样的概率阈值，取值范围为 `(0, 1]`。例如，`p=0.9` 表示从概率累积值超过 0.9 的最小 token 集合中采样。\n\n#### **2. 概率排序**\n- **`torch.sort`**: 对概率分布进行降序排序，返回排序后的概率 `probs_sort` 和对应的索引 `probs_idx`。\n\n#### **3. 计算累积和**\n- **`torch.cumsum`**: 计算排序后概率的累积和 `probs_sum`。\n\n#### **4. 创建掩码**\n- **`mask`**: 标记概率累积值超过 `p` 的 token。例如，如果 `p=0.9`，则掩码标记概率累积值超过 0.9 的 token。\n\n#### **5. 概率置零**\n- **`probs_sort[mask] = 0.0`**: 将掩码对应的概率置为 0，排除概率累积值超过 `p` 的 token。\n\n#### **6. 归一化**\n- **`probs_sort.div_`**: 对剩余的概率进行归一化，使其总和为 1。\n\n#### **7. 多项式采样**\n- **`torch.multinomial`**: 从归一化后的概率分布中进行多项式采样，返回采样得到的 token 索引。\n\n#### **8. 获取原始索引**\n- **`torch.gather`**: 根据采样结果获取原始 token 索引。\n\n#### **9. 返回结果**\n- **`next_token`**: 采样得到的 token 索引，形状为 `(batch_size, 1)`。\n\n---\n\n### **示例**\n\n假设有以下概率分布和参数：\n- **`probs`**: `[[0.1, 0.4, 0.2, 0.3]]`，形状为 `(1, 4)`。\n- **`p`**: `0.9`。\n\n#### **执行步骤**\n1. **排序**:\n   - `probs_sort`: `[[0.4, 0.3, 0.2, 0.1]]`。\n   - `probs_idx`: `[[1, 3, 2, 0]]`。\n2. **计算累积和**:\n   - `probs_sum`: `[[0.4, 0.7, 0.9, 1.0]]`。\n3. **创建掩码**:\n   - `mask`: `[[False, False, True, True]]`。\n4. **概率置零**:\n   - `probs_sort`: `[[0.4, 0.3, 0.0, 0.0]]`。\n5. **归一化**:\n   - `probs_sort`: `[[0.57, 0.43, 0.0, 0.0]]`。\n6. **多项式采样**:\n   - `next_token`: `[[1]]`（假设采样结果为 1）。\n7. **获取原始索引**:\n   - `next_token`: `[[3]]`。\n\n#### **返回结果**\n- `next_token`: `[[3]]`。\n\n---\n\n### **总结**\n`sample_top_p` 函数实现了 top-p 采样（nucleus sampling），用于从概率分布中选择 token。通过控制概率阈值 `p`，可以灵活调整生成结果的多样性和质量。该函数是 Llama 3 模型生成过程的核心组件之一。\n\n\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","source":"_posts/人工智能/nlp/llm/源码解析：llama3源码解析-04：generation.py模块解析.md","raw":"---\ntitle: 'llama3源码解析-04：generation.py模块解析'\ncategories:\n  - [人工智能,nlp,llm]\ntags:\n  - nlp\n  - llm\n  - llama\n  - 源码解析\ndate: 2024-12-30 12:00:00\n---\n\n![llama](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/Llama3_Repo.jpeg)\n\n## 整体\n\n`generation.py` 模块是 Llama 3 模型的核心生成模块，负责实现文本生成功能，包括文本补全和对话生成。\n\n---\n\n### **1. 核心功能**\n- **文本生成**：根据输入的提示（prompt）生成文本。\n- **文本补全**：对给定的文本提示进行补全。\n- **对话生成**：根据对话历史生成助理的回复。\n- **生成控制**：支持通过温度（temperature）、top-p 采样（nucleus sampling）等参数控制生成过程。\n\n---\n\n### **2. 主要类和方法**\n\n#### **`class Llama`**\n- **`build` 方法**：初始化并加载 Llama 模型和分词器。\n- **`generate` 方法**：核心生成方法，根据输入的 tokenized prompts 生成文本。\n- **`text_completion` 方法**：对文本提示进行补全。\n- **`chat_completion` 方法**：根据对话历史生成助理的回复。\n\n#### **`class CompletionPrediction`**\n- 用于表示文本补全的生成结果，包含生成的文本、token 列表和 logprobs（可选）。\n\n#### **`class ChatPrediction`**\n- 用于表示对话生成的生成结果，包含助理的回复、token 列表和 logprobs（可选）。\n\n---\n\n### **3. 核心方法详解**\n\n#### **`generate` 方法**\n- **功能**：根据输入的 tokenized prompts 生成文本。\n- **参数**：\n  - `prompt_tokens`：tokenized prompts，形状为 `(batch_size, seq_len)`。\n  - `max_gen_len`：生成文本的最大长度。\n  - `temperature`：控制生成随机性的温度参数。\n  - `top_p`：top-p 采样的概率阈值。\n  - `logprobs`：是否计算 token 的 log 概率。\n  - `echo`：是否在生成结果中包含输入提示。\n- **返回值**：生成的 token 序列和 logprobs（可选）。\n\n#### **`text_completion` 方法**\n- **功能**：对文本提示进行补全。\n- **参数**：\n  - `prompts`：文本提示列表。\n  - `temperature`：控制生成随机性的温度参数。\n  - `top_p`：top-p 采样的概率阈值。\n  - `max_gen_len`：生成文本的最大长度。\n  - `logprobs`：是否计算 token 的 log 概率。\n  - `echo`：是否在生成结果中包含输入提示。\n- **返回值**：文本补全的生成结果列表。\n\n#### **`chat_completion` 方法**\n- **功能**：根据对话历史生成助理的回复。\n- **参数**：\n  - `dialogs`：对话历史列表。\n  - `temperature`：控制生成随机性的温度参数。\n  - `top_p`：top-p 采样的概率阈值。\n  - `max_gen_len`：生成文本的最大长度。\n  - `logprobs`：是否计算 token 的 log 概率。\n- **返回值**：对话生成的生成结果列表。\n\n---\n\n### **4. 生成控制参数**\n- **温度（temperature）**：\n  - 控制生成随机性的参数。\n  - 值越大，生成结果越随机；值越小，生成结果越确定。\n- **top-p 采样（nucleus sampling）**：\n  - 从概率累积值超过 `top_p` 的最小 token 集合中采样。\n  - 用于控制生成结果的多样性和质量。\n- **logprobs**：\n  - 是否计算生成 token 的 log 概率。\n  - 用于分析生成结果的置信度。\n\n---\n\n### **5. 生成流程**\n1. **输入处理**：\n   - 将输入提示或对话历史转换为 tokenized prompts。\n2. **生成文本**：\n   - 使用 `generate` 方法生成 token 序列。\n   - 通过温度、top-p 采样等参数控制生成过程。\n3. **输出处理**：\n   - 将生成的 token 序列解码为文本。\n   - 返回生成结果，包含生成的文本、token 列表和 logprobs（可选）。\n\n---\n\n### **6. 示例**\n\n#### **文本补全**\n```python\nprompts = [\"Once upon a time\"]\nresults = llama.text_completion(prompts, max_gen_len=50)\nfor result in results:\n    print(result[\"generation\"])\n```\n\n#### **对话生成**\n```python\ndialogs = [\n    [{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n]\nresults = llama.chat_completion(dialogs, max_gen_len=50)\nfor result in results:\n    print(result[\"generation\"][\"content\"])\n```\n\n---\n\n### **7. 总结**\n`generation.py` 模块是 Llama 3 模型的核心生成模块，提供了文本补全和对话生成功能。通过温度、top-p 采样等参数，用户可以灵活控制生成过程。\n\n\n\n## `build` 方法\n\n```python\n@staticmethod\ndef build(\n    ckpt_dir: str,\n    tokenizer_path: str,\n    max_seq_len: int,\n    max_batch_size: int,\n    model_parallel_size: Optional[int] = None,\n    seed: int = 1,\n) -> \"Llama\":\n    \"\"\"\n    初始化并加载 Llama 模型。\n\n    参数:\n        ckpt_dir (str): 包含模型检查点文件的目录路径。\n        tokenizer_path (str): 分词器文件的路径。\n        max_seq_len (int): 输入序列的最大长度。\n        max_batch_size (int): 推理时的最大批次大小。\n        model_parallel_size (Optional[int], optional): 模型并行的大小（GPU 数量）。如果未提供，则从环境变量中获取。默认为 None。\n        seed (int, optional): 随机种子，确保所有进程的随机性一致。默认为 1。\n\n    返回:\n        Llama: 加载了模型和分词器的 Llama 实例。\n\n    异常:\n        AssertionError: 如果检查点目录中没有检查点文件，或者模型并行大小与检查点文件数量不匹配。\n\n    注意:\n        该方法会初始化分布式进程组，设置设备为 CUDA，并加载预训练模型和分词器。\n    \"\"\"\n    # 检查 max_seq_len 是否在有效范围内\n    assert 1 <= max_seq_len <= 8192, f\"max_seq_len must be between 1 and 8192, got {max_seq_len}.\"\n    # 检查检查点目录是否存在\n    assert os.path.isdir(ckpt_dir), f\"Checkpoint directory '{ckpt_dir}' does not exist.\"\n    # 检查分词器文件是否存在\n    assert os.path.isfile(tokenizer_path), f\"Tokenizer file '{tokenizer_path}' does not exist.\"\n\n    # 如果分布式进程组未初始化，则初始化\n    if not torch.distributed.is_initialized():\n        torch.distributed.init_process_group(\"nccl\")\n    # 如果模型并行未初始化，则初始化\n    if not model_parallel_is_initialized():\n        # 如果未提供 model_parallel_size，则从环境变量中获取\n        if model_parallel_size is None:\n            model_parallel_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n        initialize_model_parallel(model_parallel_size)\n\n    # 获取当前进程的本地 rank\n    local_rank = int(os.environ.get(\"LOCAL_RANK\", 0))\n    # 设置当前进程使用的 GPU 设备\n    torch.cuda.set_device(local_rank)\n\n    # 设置随机种子，确保所有进程的随机性一致\n    torch.manual_seed(seed)\n\n    # 如果当前进程不是主进程（rank > 0），则关闭标准输出\n    if local_rank > 0:\n        sys.stdout = open(os.devnull, \"w\")\n\n    # 记录加载模型的开始时间\n    start_time = time.time()\n    # 获取检查点目录中的所有 .pth 文件，并按文件名排序\n    checkpoints = sorted(Path(ckpt_dir).glob(\"*.pth\"))\n    # 检查检查点目录中是否有检查点文件\n    assert len(checkpoints) > 0, f\"no checkpoint files found in {ckpt_dir}\"\n    # 检查模型并行大小是否与检查点文件数量匹配\n    assert model_parallel_size == len(\n        checkpoints\n    ), f\"Loading a checkpoint for MP={len(checkpoints)} but world size is {model_parallel_size}\"\n    # 获取当前进程对应的检查点文件\n    ckpt_path = checkpoints[get_model_parallel_rank()]\n    # 加载检查点文件到 CPU\n    checkpoint = torch.load(ckpt_path, map_location=\"cpu\")\n    # 加载模型参数文件\n    with open(Path(ckpt_dir) / \"params.json\", \"r\") as f:\n        params = json.loads(f.read())\n\n    # 初始化模型参数\n    model_args: ModelArgs = ModelArgs(\n        max_seq_len=max_seq_len,\n        max_batch_size=max_batch_size,\n        **params,\n    )\n    # 初始化分词器\n    tokenizer = Tokenizer(model_path=tokenizer_path)\n    # 检查模型词汇表大小是否与分词器词汇表大小匹配\n    assert model_args.vocab_size == tokenizer.n_words\n    # 如果当前设备支持 bfloat16，则设置默认张量类型为 bfloat16，否则设置为 float16\n    if torch.cuda.is_bf16_supported():\n        torch.set_default_tensor_type(torch.cuda.BFloat16Tensor)\n    else:\n        torch.set_default_tensor_type(torch.cuda.HalfTensor)\n    # 初始化 Transformer 模型\n    model = Transformer(model_args)\n    # 加载模型权重\n    model.load_state_dict(checkpoint, strict=False)\n    # 打印模型加载时间\n    print(f\"Loaded in {time.time() - start_time:.2f} seconds\")\n\n    # 返回 Llama 实例，包含加载的模型和分词器\n    return Llama(model, tokenizer)\n```\n\n---\n\n### **详细解释**\n\n#### **1. 参数检查**\n- **`max_seq_len`**: 检查输入序列的最大长度是否在有效范围内（1 到 8192）。\n- **`ckpt_dir`**: 检查检查点目录是否存在。\n- **`tokenizer_path`**: 检查分词器文件是否存在。\n\n#### **2. 分布式初始化**\n- 如果分布式进程组未初始化，则使用 `torch.distributed.init_process_group` 初始化。\n- 如果模型并行未初始化，则根据 `model_parallel_size` 或环境变量初始化模型并行。\n\n#### **3. 设备设置**\n- 获取当前进程的本地 rank，并设置使用的 GPU 设备。\n\n#### **4. 随机种子**\n- 设置随机种子，确保所有进程的随机性一致。\n\n#### **5. 检查点加载**\n- 获取检查点目录中的所有 `.pth` 文件，并按文件名排序。\n- 检查检查点文件数量和模型并行大小是否匹配。\n- 加载当前进程对应的检查点文件到 CPU。\n\n#### **6. 模型参数加载**\n- 从 `params.json` 文件中加载模型参数。\n- 使用 `ModelArgs` 初始化模型参数。\n\n#### **7. 分词器初始化**\n- 使用 `Tokenizer` 初始化分词器，并检查模型词汇表大小是否与分词器词汇表大小匹配。\n\n#### **8. 张量类型设置**\n- 如果当前设备支持 `bfloat16`，则设置默认张量类型为 `bfloat16`，否则设置为 `float16`。\n\n#### **9. 模型初始化**\n- 使用 `Transformer` 初始化模型，并加载检查点中的权重。\n\n#### **10. 返回 Llama 实例**\n- 返回包含加载的模型和分词器的 `Llama` 实例。\n\n---\n\n### **总结**\n`build` 方法负责初始化并加载 Llama 模型，包括分布式设置、设备配置、检查点加载、模型参数初始化、分词器初始化等。它是 Llama 模型的核心初始化方法，确保模型能够正确加载并准备好进行推理或训练。\n\n## `generate` 方法\n\n\n\n```python\n@torch.inference_mode()\ndef generate(\n    self,\n    prompt_tokens: List[List[int]],\n    max_gen_len: int,\n    temperature: float = 0.6,\n    top_p: float = 0.9,\n    logprobs: bool = False,\n    echo: bool = False,\n) -> Tuple[List[List[int]], Optional[List[List[float]]]]:\n    \"\"\"\n    根据输入的 tokenized prompts 生成文本。\n\n    参数:\n        prompt_tokens (List[List[int]]): tokenized prompts，每个 prompt 是一个整数列表。\n        max_gen_len (int): 生成文本的最大长度。\n        temperature (float, optional): 控制生成随机性的温度参数。默认为 0.6。\n        top_p (float, optional): top-p 采样的概率阈值。默认为 0.9。\n        logprobs (bool, optional): 是否计算 token 的 log 概率。默认为 False。\n        echo (bool, optional): 是否在生成结果中包含输入提示。默认为 False。\n\n    返回:\n        Tuple[List[List[int]], Optional[List[List[float]]]]: 生成的 token 序列和 logprobs（可选）。\n\n    注意:\n        该方法使用 nucleus sampling（top-p 采样）生成文本，支持通过温度参数控制生成随机性。\n        如果 logprobs 为 True，则返回每个生成 token 的 log 概率。\n    \"\"\"\n    # 获取模型参数\n    params = self.model.params\n    # 获取批次大小\n    bsz = len(prompt_tokens)\n    # 检查批次大小是否超过模型的最大批次大小\n    assert bsz <= params.max_batch_size, (bsz, params.max_batch_size)\n\n    # 计算输入 prompts 的最小和最大长度\n    min_prompt_len = min(len(t) for t in prompt_tokens)\n    max_prompt_len = max(len(t) for t in prompt_tokens)\n    # 检查输入 prompts 的最大长度是否超过模型的最大序列长度\n    assert max_prompt_len <= params.max_seq_len\n    # 计算总长度（输入 prompts 长度 + 生成文本长度）\n    total_len = min(params.max_seq_len, max_gen_len + max_prompt_len)\n\n    # 获取填充 token 的 ID\n    pad_id = self.tokenizer.pad_id\n    # 初始化 tokens 张量，用 pad_id 填充\n    tokens = torch.full((bsz, total_len), pad_id, dtype=torch.long, device=\"cuda\")\n    # 将输入 prompts 填充到 tokens 张量中\n    for k, t in enumerate(prompt_tokens):\n        tokens[k, : len(t)] = torch.tensor(t, dtype=torch.long, device=\"cuda\")\n    # 如果 logprobs 为 True，则初始化 token_logprobs 张量\n    if logprobs:\n        token_logprobs = torch.zeros_like(tokens, dtype=torch.float)\n\n    # 初始化当前位置和 EOS（结束符）标记\n    prev_pos = 0\n    eos_reached = torch.tensor([False] * bsz, device=\"cuda\")\n    # 创建输入文本的掩码（非填充部分为 True）\n    input_text_mask = tokens != pad_id\n\n    # 如果输入 prompts 的长度等于总长度，则直接计算 logits\n    if min_prompt_len == total_len:\n        logits = self.model.forward(tokens, prev_pos)\n        # 计算 token 的 log 概率\n        token_logprobs = -F.cross_entropy(\n            input=logits.transpose(1, 2),\n            target=tokens,\n            reduction=\"none\",\n            ignore_index=pad_id,\n        )\n\n    # 获取停止 token 的 ID\n    stop_tokens = torch.tensor(list(self.tokenizer.stop_tokens))\n\n    # 逐 token 生成文本\n    for cur_pos in range(min_prompt_len, total_len):\n        # 计算当前 token 的 logits\n        logits = self.model.forward(tokens[:, prev_pos:cur_pos], prev_pos)\n        # 如果 temperature > 0，则使用温度参数和 top-p 采样生成下一个 token\n        if temperature > 0:\n            probs = torch.softmax(logits[:, -1] / temperature, dim=-1)\n            next_token = sample_top_p(probs, top_p)\n        else:\n            # 如果 temperature = 0，则选择概率最大的 token\n            next_token = torch.argmax(logits[:, -1], dim=-1)\n        # 将下一个 token 填充到 tokens 张量中\n        next_token = next_token.reshape(-1)\n        # 如果当前位置在输入 prompts 范围内，则保留输入 token\n        next_token = torch.where(\n            input_text_mask[:, cur_pos], tokens[:, cur_pos], next_token\n        )\n        tokens[:, cur_pos] = next_token\n        # 如果 logprobs 为 True，则计算 token 的 log 概率\n        if logprobs:\n            token_logprobs[:, prev_pos + 1 : cur_pos + 1] = -F.cross_entropy(\n                input=logits.transpose(1, 2),\n                target=tokens[:, prev_pos + 1 : cur_pos + 1],\n                reduction=\"none\",\n                ignore_index=pad_id,\n            )\n        # 检查是否生成停止 token\n        eos_reached |= (~input_text_mask[:, cur_pos]) & (\n            torch.isin(next_token, stop_tokens)\n        )\n        # 更新当前位置\n        prev_pos = cur_pos\n        # 如果所有批次都生成停止 token，则提前结束\n        if all(eos_reached):\n            break\n\n    # 如果 logprobs 为 True，则将 token_logprobs 转换为列表\n    if logprobs:\n        token_logprobs = token_logprobs.tolist()\n    # 初始化输出 token 序列和 logprobs\n    out_tokens, out_logprobs = [], []\n    # 处理每个批次的生成结果\n    for i, toks in enumerate(tokens.tolist()):\n        # 如果 echo 为 False，则从生成部分开始截取\n        start = 0 if echo else len(prompt_tokens[i])\n        toks = toks[start : len(prompt_tokens[i]) + max_gen_len]\n        probs = None\n        # 如果 logprobs 为 True，则截取对应的 logprobs\n        if logprobs:\n            probs = token_logprobs[i][start : len(prompt_tokens[i]) + max_gen_len]\n        # 如果生成结果中包含停止 token，则截取到停止 token 之前\n        for stop_token in self.tokenizer.stop_tokens:\n            try:\n                eos_idx = toks.index(stop_token)\n                toks = toks[:eos_idx]\n                probs = probs[:eos_idx] if logprobs else None\n            except ValueError:\n                pass\n        # 将结果添加到输出列表中\n        out_tokens.append(toks)\n        out_logprobs.append(probs)\n    # 返回生成的 token 序列和 logprobs（可选）\n    return (out_tokens, out_logprobs if logprobs else None)\n```\n\n---\n\n### **详细解释**\n\n#### **1. 输入处理**\n- **`prompt_tokens`**: 输入的 tokenized prompts，每个 prompt 是一个整数列表。\n- **`max_gen_len`**: 生成文本的最大长度。\n- **`temperature`**: 控制生成随机性的温度参数。\n- **`top_p`**: top-p 采样的概率阈值。\n- **`logprobs`**: 是否计算 token 的 log 概率。\n- **`echo`**: 是否在生成结果中包含输入提示。\n\n#### **2. 初始化**\n- **`params`**: 获取模型参数。\n- **`bsz`**: 获取批次大小。\n- **`min_prompt_len` 和 `max_prompt_len`**: 计算输入 prompts 的最小和最大长度。\n- **`total_len`**: 计算总长度（输入 prompts 长度 + 生成文本长度）。\n- **`tokens`**: 初始化 tokens 张量，用 pad_id 填充，并将输入 prompts 填充到 tokens 张量中。\n\n#### **3. 生成文本**\n- **逐 token 生成**:\n  - 使用 `model.forward` 计算当前 token 的 logits。\n  - 如果 `temperature > 0`，则使用温度参数和 top-p 采样生成下一个 token。\n  - 如果 `temperature = 0`，则选择概率最大的 token。\n  - 将下一个 token 填充到 tokens 张量中。\n  - 如果 `logprobs` 为 True，则计算 token 的 log 概率。\n  - 检查是否生成停止 token，如果所有批次都生成停止 token，则提前结束。\n\n#### **4. 输出处理**\n- **`out_tokens` 和 `out_logprobs`**: 处理每个批次的生成结果。\n  - 如果 `echo` 为 False，则从生成部分开始截取。\n  - 如果生成结果中包含停止 token，则截取到停止 token 之前。\n- **返回结果**: 返回生成的 token 序列和 logprobs（可选）。\n\n---\n\n### **总结**\n`generate` 方法是 Llama 3 模型的核心生成方法，负责根据输入的 tokenized prompts 生成文本。通过温度、top-p 采样等参数，用户可以灵活控制生成过程。该方法支持计算 token 的 log 概率，并可以处理停止 token 和输入提示。\n\n## `generate` 详细流程图\n\n![generate流程图](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241230115215231.png)\n\n---\n\n### **详细步骤说明**\n\n#### **1. 输入处理**\n- **输入**: `prompt_tokens`，tokenized prompts，每个 prompt 是一个整数列表。\n\n#### **2. 初始化**\n- **初始化 tokens 张量**: 用 pad_id 填充，并将输入 prompts 填充到 tokens 张量中。\n- **计算 min_prompt_len 和 max_prompt_len**: 输入 prompts 的最小和最大长度。\n- **检查 max_prompt_len 是否超过 max_seq_len**: 确保输入 prompts 的长度不超过模型的最大序列长度。\n- **计算 total_len**: 输入 prompts 长度 + 生成文本长度。\n- **初始化 token_logprobs**: 如果 `logprobs=True`，则初始化 token_logprobs 张量。\n- **初始化 prev_pos 和 eos_reached**: 当前位置和 EOS（结束符）标记。\n- **创建 input_text_mask**: 输入文本的掩码（非填充部分为 True）。\n\n#### **3. 生成文本**\n- **检查 min_prompt_len 是否等于 total_len**:\n  - 如果相等，则直接计算 logits 和 token_logprobs。\n  - 否则，逐 token 生成文本。\n- **逐 token 生成文本**:\n  - **计算当前 token 的 logits**。\n  - **检查 temperature 是否大于 0**:\n    - 如果大于 0，则使用温度参数和 top-p 采样生成下一个 token。\n    - 否则，选择概率最大的 token。\n  - **填充下一个 token 到 tokens 张量**。\n  - **检查 logprobs 是否为 True**:\n    - 如果为 True，则计算 token 的 log 概率。\n  - **检查是否生成停止 token**。\n  - **更新 prev_pos**。\n  - **检查所有批次是否都生成停止 token**:\n    - 如果是，则提前结束。\n    - 否则，继续生成下一个 token。\n\n#### **4. 输出处理**\n- **处理每个批次的生成结果**:\n  - **检查 echo 是否为 False**:\n    - 如果为 False，则从生成部分开始截取。\n    - 否则，保留输入提示。\n  - **截取到停止 token 之前**。\n  - **将结果添加到输出列表中**。\n- **返回生成的 token 序列和 logprobs（可选）**。\n\n---\n\n### **总结**\n`generate` 方法的流程图清晰地展示了从输入到输出的完整生成过程，包括初始化、逐 token 生成和输出处理。通过该流程图，可以更好地理解 Llama 3 模型的文本生成机制。\n\n## `text_completion` 和 `chat_completion` \n\n---\n\n### **1. `text_completion` 方法**\n\n#### **功能**\n对给定的文本提示进行补全，生成后续文本。\n\n#### **参数**\n- **`prompts`**: 文本提示列表，每个提示是一个字符串。\n- **`temperature`**: 控制生成随机性的温度参数。值越大，生成结果越随机；值越小，生成结果越确定。\n- **`top_p`**: top-p 采样的概率阈值。用于控制生成结果的多样性和质量。\n- **`max_gen_len`**: 生成文本的最大长度。如果未提供，则使用模型的最大序列长度减 1。\n- **`logprobs`**: 是否计算 token 的 log 概率。默认为 False。\n- **`echo`**: 是否在生成结果中包含输入提示。默认为 False。\n\n#### **返回值**\n- **`List[CompletionPrediction]`**: 文本补全的生成结果列表，每个结果包含生成的文本、token 列表和 logprobs（可选）。\n\n#### **代码逻辑**\n1. **检查 `max_gen_len`**:\n   - 如果未提供 `max_gen_len`，则使用模型的最大序列长度减 1。\n2. **编码输入提示**:\n   - 使用分词器将输入提示编码为 tokenized prompts。\n3. **调用 `generate` 方法**:\n   - 使用 `generate` 方法生成 token 序列。\n4. **解码生成结果**:\n   - 将生成的 token 序列解码为文本。\n5. **返回生成结果**:\n   - 如果 `logprobs` 为 True，则返回生成的文本、token 列表和 logprobs。\n   - 否则，仅返回生成的文本。\n\n#### **示例**\n```python\nprompts = [\"Once upon a time\"]\nresults = llama.text_completion(prompts, max_gen_len=50)\nfor result in results:\n    print(result[\"generation\"])\n```\n\n---\n\n### **2. `chat_completion` 方法**\n\n#### **功能**\n根据对话历史生成助理的回复。\n\n#### **参数**\n- **`dialogs`**: 对话历史列表，每个对话是一个消息列表，每个消息包含角色（`role`）和内容（`content`）。\n- **`temperature`**: 控制生成随机性的温度参数。值越大，生成结果越随机；值越小，生成结果越确定。\n- **`top_p`**: top-p 采样的概率阈值。用于控制生成结果的多样性和质量。\n- **`max_gen_len`**: 生成文本的最大长度。如果未提供，则使用模型的最大序列长度减 1。\n- **`logprobs`**: 是否计算 token 的 log 概率。默认为 False。\n\n#### **返回值**\n- **`List[ChatPrediction]`**: 对话生成的生成结果列表，每个结果包含助理的回复、token 列表和 logprobs（可选）。\n\n#### **代码逻辑**\n1. **检查 `max_gen_len`**:\n   - 如果未提供 `max_gen_len`，则使用模型的最大序列长度减 1。\n2. **编码对话历史**:\n   - 使用 `ChatFormat` 将对话历史编码为 tokenized prompts。\n3. **调用 `generate` 方法**:\n   - 使用 `generate` 方法生成 token 序列。\n4. **解码生成结果**:\n   - 将生成的 token 序列解码为文本。\n5. **返回生成结果**:\n   - 如果 `logprobs` 为 True，则返回助理的回复、token 列表和 logprobs。\n   - 否则，仅返回助理的回复。\n\n#### **示例**\n```python\ndialogs = [\n    [{\"role\": \"user\", \"content\": \"What is the capital of France?\"}]\n]\nresults = llama.chat_completion(dialogs, max_gen_len=50)\nfor result in results:\n    print(result[\"generation\"][\"content\"])\n```\n\n---\n\n### **3. 主要区别**\n| 特性         | `text_completion`      | `chat_completion`              |\n| ------------ | ---------------------- | ------------------------------ |\n| **输入**     | 文本提示列表           | 对话历史列表                   |\n| **输出**     | 文本补全结果           | 助理的回复                     |\n| **编码方式** | 直接使用分词器编码     | 使用 `ChatFormat` 编码对话历史 |\n| **适用场景** | 单轮文本补全           | 多轮对话生成                   |\n| **返回格式** | `CompletionPrediction` | `ChatPrediction`               |\n\n---\n\n### **4. 生成控制参数**\n- **温度（temperature）**:\n  - 控制生成随机性的参数。\n  - 值越大，生成结果越随机；值越小，生成结果越确定。\n- **top-p 采样（nucleus sampling）**:\n  - 从概率累积值超过 `top_p` 的最小 token 集合中采样。\n  - 用于控制生成结果的多样性和质量。\n- **logprobs**:\n  - 是否计算生成 token 的 log 概率。\n  - 用于分析生成结果的置信度。\n\n---\n\n### **5. 总结**\n- **`text_completion`**: 用于文本补全，适用于单轮文本生成任务。\n- **`chat_completion`**: 用于对话生成，适用于多轮对话任务。\n- 两者都通过 `generate` 方法实现核心生成逻辑，并支持温度、top-p 采样等参数控制生成过程。\n\n## sample_top_p\n\n该函数实现了 **top-p 采样（nucleus sampling）**，用于从概率分布中选择 token。\n\n---\n\n### **代码注释**\n\n```python\ndef sample_top_p(probs, p):\n    \"\"\"\n    对概率分布进行 top-p 采样（nucleus sampling）。\n\n    参数:\n        probs (torch.Tensor): 概率分布张量，形状为 (batch_size, vocab_size)。\n        p (float): top-p 采样的概率阈值，取值范围为 (0, 1]。\n\n    返回:\n        torch.Tensor: 采样得到的 token 索引，形状为 (batch_size, 1)。\n\n    注意:\n        top-p 采样从概率累积值超过 p 的最小 token 集合中采样，用于控制生成结果的多样性和质量。\n    \"\"\"\n    # 对概率分布进行降序排序，并获取排序后的概率和索引\n    probs_sort, probs_idx = torch.sort(probs, dim=-1, descending=True)\n    # 计算概率分布的累积和\n    probs_sum = torch.cumsum(probs_sort, dim=-1)\n    # 创建掩码，标记概率累积值超过 p 的 token\n    mask = probs_sum - probs_sort > p\n    # 将掩码对应的概率置为 0\n    probs_sort[mask] = 0.0\n    # 对剩余的概率进行归一化\n    probs_sort.div_(probs_sort.sum(dim=-1, keepdim=True))\n    # 从归一化后的概率分布中进行多项式采样\n    next_token = torch.multinomial(probs_sort, num_samples=1)\n    # 根据采样结果获取原始 token 索引\n    next_token = torch.gather(probs_idx, -1, next_token)\n    return next_token\n```\n\n---\n\n### **详细解释**\n\n#### **1. 输入参数**\n- **`probs`**: 概率分布张量，形状为 `(batch_size, vocab_size)`，表示每个 token 的概率。\n- **`p`**: top-p 采样的概率阈值，取值范围为 `(0, 1]`。例如，`p=0.9` 表示从概率累积值超过 0.9 的最小 token 集合中采样。\n\n#### **2. 概率排序**\n- **`torch.sort`**: 对概率分布进行降序排序，返回排序后的概率 `probs_sort` 和对应的索引 `probs_idx`。\n\n#### **3. 计算累积和**\n- **`torch.cumsum`**: 计算排序后概率的累积和 `probs_sum`。\n\n#### **4. 创建掩码**\n- **`mask`**: 标记概率累积值超过 `p` 的 token。例如，如果 `p=0.9`，则掩码标记概率累积值超过 0.9 的 token。\n\n#### **5. 概率置零**\n- **`probs_sort[mask] = 0.0`**: 将掩码对应的概率置为 0，排除概率累积值超过 `p` 的 token。\n\n#### **6. 归一化**\n- **`probs_sort.div_`**: 对剩余的概率进行归一化，使其总和为 1。\n\n#### **7. 多项式采样**\n- **`torch.multinomial`**: 从归一化后的概率分布中进行多项式采样，返回采样得到的 token 索引。\n\n#### **8. 获取原始索引**\n- **`torch.gather`**: 根据采样结果获取原始 token 索引。\n\n#### **9. 返回结果**\n- **`next_token`**: 采样得到的 token 索引，形状为 `(batch_size, 1)`。\n\n---\n\n### **示例**\n\n假设有以下概率分布和参数：\n- **`probs`**: `[[0.1, 0.4, 0.2, 0.3]]`，形状为 `(1, 4)`。\n- **`p`**: `0.9`。\n\n#### **执行步骤**\n1. **排序**:\n   - `probs_sort`: `[[0.4, 0.3, 0.2, 0.1]]`。\n   - `probs_idx`: `[[1, 3, 2, 0]]`。\n2. **计算累积和**:\n   - `probs_sum`: `[[0.4, 0.7, 0.9, 1.0]]`。\n3. **创建掩码**:\n   - `mask`: `[[False, False, True, True]]`。\n4. **概率置零**:\n   - `probs_sort`: `[[0.4, 0.3, 0.0, 0.0]]`。\n5. **归一化**:\n   - `probs_sort`: `[[0.57, 0.43, 0.0, 0.0]]`。\n6. **多项式采样**:\n   - `next_token`: `[[1]]`（假设采样结果为 1）。\n7. **获取原始索引**:\n   - `next_token`: `[[3]]`。\n\n#### **返回结果**\n- `next_token`: `[[3]]`。\n\n---\n\n### **总结**\n`sample_top_p` 函数实现了 top-p 采样（nucleus sampling），用于从概率分布中选择 token。通过控制概率阈值 `p`，可以灵活调整生成结果的多样性和质量。该函数是 Llama 3 模型生成过程的核心组件之一。\n\n\n\n文章合集：[chongzicbo/ReadWriteThink: 博学而笃志，切问而近思 (github.com)](https://github.com/chongzicbo/ReadWriteThink/tree/main)\n\n个人博客：[程博仕](https://chongzicbo.github.io/)\n\n微信公众号：\n\n![微信公众号](https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg)","slug":"人工智能/nlp/llm/源码解析：llama3源码解析-04：generation.py模块解析","published":1,"updated":"2024-12-30T03:53:57.855Z","comments":1,"layout":"post","photos":[],"_id":"cm5esmr3o001mhghifa1u288r","content":"<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/Llama3_Repo.jpeg\" alt=\"llama\"></p>\n<h2 id=\"整体\"><a href=\"#整体\" class=\"headerlink\" title=\"整体\"></a>整体</h2><p><code>generation.py</code> 模块是 Llama 3 模型的核心生成模块，负责实现文本生成功能，包括文本补全和对话生成。</p>\n<hr>\n<h3 id=\"1-核心功能\"><a href=\"#1-核心功能\" class=\"headerlink\" title=\"1. 核心功能\"></a><strong>1. 核心功能</strong></h3><ul>\n<li><strong>文本生成</strong>：根据输入的提示（prompt）生成文本。</li>\n<li><strong>文本补全</strong>：对给定的文本提示进行补全。</li>\n<li><strong>对话生成</strong>：根据对话历史生成助理的回复。</li>\n<li><strong>生成控制</strong>：支持通过温度（temperature）、top-p 采样（nucleus sampling）等参数控制生成过程。</li>\n</ul>\n<hr>\n<h3 id=\"2-主要类和方法\"><a href=\"#2-主要类和方法\" class=\"headerlink\" title=\"2. 主要类和方法\"></a><strong>2. 主要类和方法</strong></h3><h4 id=\"class-Llama\"><a href=\"#class-Llama\" class=\"headerlink\" title=\"class Llama\"></a><strong><code>class Llama</code></strong></h4><ul>\n<li><strong><code>build</code> 方法</strong>：初始化并加载 Llama 模型和分词器。</li>\n<li><strong><code>generate</code> 方法</strong>：核心生成方法，根据输入的 tokenized prompts 生成文本。</li>\n<li><strong><code>text_completion</code> 方法</strong>：对文本提示进行补全。</li>\n<li><strong><code>chat_completion</code> 方法</strong>：根据对话历史生成助理的回复。</li>\n</ul>\n<h4 id=\"class-CompletionPrediction\"><a href=\"#class-CompletionPrediction\" class=\"headerlink\" title=\"class CompletionPrediction\"></a><strong><code>class CompletionPrediction</code></strong></h4><ul>\n<li>用于表示文本补全的生成结果，包含生成的文本、token 列表和 logprobs（可选）。</li>\n</ul>\n<h4 id=\"class-ChatPrediction\"><a href=\"#class-ChatPrediction\" class=\"headerlink\" title=\"class ChatPrediction\"></a><strong><code>class ChatPrediction</code></strong></h4><ul>\n<li>用于表示对话生成的生成结果，包含助理的回复、token 列表和 logprobs（可选）。</li>\n</ul>\n<hr>\n<h3 id=\"3-核心方法详解\"><a href=\"#3-核心方法详解\" class=\"headerlink\" title=\"3. 核心方法详解\"></a><strong>3. 核心方法详解</strong></h3><h4 id=\"generate-方法\"><a href=\"#generate-方法\" class=\"headerlink\" title=\"generate 方法\"></a><strong><code>generate</code> 方法</strong></h4><ul>\n<li><strong>功能</strong>：根据输入的 tokenized prompts 生成文本。</li>\n<li><strong>参数</strong>：<ul>\n<li><code>prompt_tokens</code>：tokenized prompts，形状为 <code>(batch_size, seq_len)</code>。</li>\n<li><code>max_gen_len</code>：生成文本的最大长度。</li>\n<li><code>temperature</code>：控制生成随机性的温度参数。</li>\n<li><code>top_p</code>：top-p 采样的概率阈值。</li>\n<li><code>logprobs</code>：是否计算 token 的 log 概率。</li>\n<li><code>echo</code>：是否在生成结果中包含输入提示。</li>\n</ul>\n</li>\n<li><strong>返回值</strong>：生成的 token 序列和 logprobs（可选）。</li>\n</ul>\n<h4 id=\"text-completion-方法\"><a href=\"#text-completion-方法\" class=\"headerlink\" title=\"text_completion 方法\"></a><strong><code>text_completion</code> 方法</strong></h4><ul>\n<li><strong>功能</strong>：对文本提示进行补全。</li>\n<li><strong>参数</strong>：<ul>\n<li><code>prompts</code>：文本提示列表。</li>\n<li><code>temperature</code>：控制生成随机性的温度参数。</li>\n<li><code>top_p</code>：top-p 采样的概率阈值。</li>\n<li><code>max_gen_len</code>：生成文本的最大长度。</li>\n<li><code>logprobs</code>：是否计算 token 的 log 概率。</li>\n<li><code>echo</code>：是否在生成结果中包含输入提示。</li>\n</ul>\n</li>\n<li><strong>返回值</strong>：文本补全的生成结果列表。</li>\n</ul>\n<h4 id=\"chat-completion-方法\"><a href=\"#chat-completion-方法\" class=\"headerlink\" title=\"chat_completion 方法\"></a><strong><code>chat_completion</code> 方法</strong></h4><ul>\n<li><strong>功能</strong>：根据对话历史生成助理的回复。</li>\n<li><strong>参数</strong>：<ul>\n<li><code>dialogs</code>：对话历史列表。</li>\n<li><code>temperature</code>：控制生成随机性的温度参数。</li>\n<li><code>top_p</code>：top-p 采样的概率阈值。</li>\n<li><code>max_gen_len</code>：生成文本的最大长度。</li>\n<li><code>logprobs</code>：是否计算 token 的 log 概率。</li>\n</ul>\n</li>\n<li><strong>返回值</strong>：对话生成的生成结果列表。</li>\n</ul>\n<hr>\n<h3 id=\"4-生成控制参数\"><a href=\"#4-生成控制参数\" class=\"headerlink\" title=\"4. 生成控制参数\"></a><strong>4. 生成控制参数</strong></h3><ul>\n<li><strong>温度（temperature）</strong>：<ul>\n<li>控制生成随机性的参数。</li>\n<li>值越大，生成结果越随机；值越小，生成结果越确定。</li>\n</ul>\n</li>\n<li><strong>top-p 采样（nucleus sampling）</strong>：<ul>\n<li>从概率累积值超过 <code>top_p</code> 的最小 token 集合中采样。</li>\n<li>用于控制生成结果的多样性和质量。</li>\n</ul>\n</li>\n<li><strong>logprobs</strong>：<ul>\n<li>是否计算生成 token 的 log 概率。</li>\n<li>用于分析生成结果的置信度。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"5-生成流程\"><a href=\"#5-生成流程\" class=\"headerlink\" title=\"5. 生成流程\"></a><strong>5. 生成流程</strong></h3><ol>\n<li><strong>输入处理</strong>：<ul>\n<li>将输入提示或对话历史转换为 tokenized prompts。</li>\n</ul>\n</li>\n<li><strong>生成文本</strong>：<ul>\n<li>使用 <code>generate</code> 方法生成 token 序列。</li>\n<li>通过温度、top-p 采样等参数控制生成过程。</li>\n</ul>\n</li>\n<li><strong>输出处理</strong>：<ul>\n<li>将生成的 token 序列解码为文本。</li>\n<li>返回生成结果，包含生成的文本、token 列表和 logprobs（可选）。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"6-示例\"><a href=\"#6-示例\" class=\"headerlink\" title=\"6. 示例\"></a><strong>6. 示例</strong></h3><h4 id=\"文本补全\"><a href=\"#文本补全\" class=\"headerlink\" title=\"文本补全\"></a><strong>文本补全</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">prompts = [<span class=\"hljs-string\">&quot;Once upon a time&quot;</span>]<br>results = llama.text_completion(prompts, max_gen_len=<span class=\"hljs-number\">50</span>)<br><span class=\"hljs-keyword\">for</span> result <span class=\"hljs-keyword\">in</span> results:<br>    <span class=\"hljs-built_in\">print</span>(result[<span class=\"hljs-string\">&quot;generation&quot;</span>])<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"对话生成\"><a href=\"#对话生成\" class=\"headerlink\" title=\"对话生成\"></a><strong>对话生成</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">dialogs = [<br>    [&#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;user&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;What is the capital of France?&quot;</span>&#125;]<br>]<br>results = llama.chat_completion(dialogs, max_gen_len=<span class=\"hljs-number\">50</span>)<br><span class=\"hljs-keyword\">for</span> result <span class=\"hljs-keyword\">in</span> results:<br>    <span class=\"hljs-built_in\">print</span>(result[<span class=\"hljs-string\">&quot;generation&quot;</span>][<span class=\"hljs-string\">&quot;content&quot;</span>])<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"7-总结\"><a href=\"#7-总结\" class=\"headerlink\" title=\"7. 总结\"></a><strong>7. 总结</strong></h3><p><code>generation.py</code> 模块是 Llama 3 模型的核心生成模块，提供了文本补全和对话生成功能。通过温度、top-p 采样等参数，用户可以灵活控制生成过程。</p>\n<h2 id=\"build-方法\"><a href=\"#build-方法\" class=\"headerlink\" title=\"build 方法\"></a><code>build</code> 方法</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-meta\">@staticmethod</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">build</span>(<span class=\"hljs-params\"></span><br><span class=\"hljs-params\">    ckpt_dir: <span class=\"hljs-built_in\">str</span>,</span><br><span class=\"hljs-params\">    tokenizer_path: <span class=\"hljs-built_in\">str</span>,</span><br><span class=\"hljs-params\">    max_seq_len: <span class=\"hljs-built_in\">int</span>,</span><br><span class=\"hljs-params\">    max_batch_size: <span class=\"hljs-built_in\">int</span>,</span><br><span class=\"hljs-params\">    model_parallel_size: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">int</span>] = <span class=\"hljs-literal\">None</span>,</span><br><span class=\"hljs-params\">    seed: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">1</span>,</span><br><span class=\"hljs-params\"></span>) -&gt; <span class=\"hljs-string\">&quot;Llama&quot;</span>:<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    初始化并加载 Llama 模型。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    参数:</span><br><span class=\"hljs-string\">        ckpt_dir (str): 包含模型检查点文件的目录路径。</span><br><span class=\"hljs-string\">        tokenizer_path (str): 分词器文件的路径。</span><br><span class=\"hljs-string\">        max_seq_len (int): 输入序列的最大长度。</span><br><span class=\"hljs-string\">        max_batch_size (int): 推理时的最大批次大小。</span><br><span class=\"hljs-string\">        model_parallel_size (Optional[int], optional): 模型并行的大小（GPU 数量）。如果未提供，则从环境变量中获取。默认为 None。</span><br><span class=\"hljs-string\">        seed (int, optional): 随机种子，确保所有进程的随机性一致。默认为 1。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    返回:</span><br><span class=\"hljs-string\">        Llama: 加载了模型和分词器的 Llama 实例。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    异常:</span><br><span class=\"hljs-string\">        AssertionError: 如果检查点目录中没有检查点文件，或者模型并行大小与检查点文件数量不匹配。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    注意:</span><br><span class=\"hljs-string\">        该方法会初始化分布式进程组，设置设备为 CUDA，并加载预训练模型和分词器。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 检查 max_seq_len 是否在有效范围内</span><br>    <span class=\"hljs-keyword\">assert</span> <span class=\"hljs-number\">1</span> &lt;= max_seq_len &lt;= <span class=\"hljs-number\">8192</span>, <span class=\"hljs-string\">f&quot;max_seq_len must be between 1 and 8192, got <span class=\"hljs-subst\">&#123;max_seq_len&#125;</span>.&quot;</span><br>    <span class=\"hljs-comment\"># 检查检查点目录是否存在</span><br>    <span class=\"hljs-keyword\">assert</span> os.path.isdir(ckpt_dir), <span class=\"hljs-string\">f&quot;Checkpoint directory &#x27;<span class=\"hljs-subst\">&#123;ckpt_dir&#125;</span>&#x27; does not exist.&quot;</span><br>    <span class=\"hljs-comment\"># 检查分词器文件是否存在</span><br>    <span class=\"hljs-keyword\">assert</span> os.path.isfile(tokenizer_path), <span class=\"hljs-string\">f&quot;Tokenizer file &#x27;<span class=\"hljs-subst\">&#123;tokenizer_path&#125;</span>&#x27; does not exist.&quot;</span><br><br>    <span class=\"hljs-comment\"># 如果分布式进程组未初始化，则初始化</span><br>    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> torch.distributed.is_initialized():<br>        torch.distributed.init_process_group(<span class=\"hljs-string\">&quot;nccl&quot;</span>)<br>    <span class=\"hljs-comment\"># 如果模型并行未初始化，则初始化</span><br>    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> model_parallel_is_initialized():<br>        <span class=\"hljs-comment\"># 如果未提供 model_parallel_size，则从环境变量中获取</span><br>        <span class=\"hljs-keyword\">if</span> model_parallel_size <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:<br>            model_parallel_size = <span class=\"hljs-built_in\">int</span>(os.environ.get(<span class=\"hljs-string\">&quot;WORLD_SIZE&quot;</span>, <span class=\"hljs-number\">1</span>))<br>        initialize_model_parallel(model_parallel_size)<br><br>    <span class=\"hljs-comment\"># 获取当前进程的本地 rank</span><br>    local_rank = <span class=\"hljs-built_in\">int</span>(os.environ.get(<span class=\"hljs-string\">&quot;LOCAL_RANK&quot;</span>, <span class=\"hljs-number\">0</span>))<br>    <span class=\"hljs-comment\"># 设置当前进程使用的 GPU 设备</span><br>    torch.cuda.set_device(local_rank)<br><br>    <span class=\"hljs-comment\"># 设置随机种子，确保所有进程的随机性一致</span><br>    torch.manual_seed(seed)<br><br>    <span class=\"hljs-comment\"># 如果当前进程不是主进程（rank &gt; 0），则关闭标准输出</span><br>    <span class=\"hljs-keyword\">if</span> local_rank &gt; <span class=\"hljs-number\">0</span>:<br>        sys.stdout = <span class=\"hljs-built_in\">open</span>(os.devnull, <span class=\"hljs-string\">&quot;w&quot;</span>)<br><br>    <span class=\"hljs-comment\"># 记录加载模型的开始时间</span><br>    start_time = time.time()<br>    <span class=\"hljs-comment\"># 获取检查点目录中的所有 .pth 文件，并按文件名排序</span><br>    checkpoints = <span class=\"hljs-built_in\">sorted</span>(Path(ckpt_dir).glob(<span class=\"hljs-string\">&quot;*.pth&quot;</span>))<br>    <span class=\"hljs-comment\"># 检查检查点目录中是否有检查点文件</span><br>    <span class=\"hljs-keyword\">assert</span> <span class=\"hljs-built_in\">len</span>(checkpoints) &gt; <span class=\"hljs-number\">0</span>, <span class=\"hljs-string\">f&quot;no checkpoint files found in <span class=\"hljs-subst\">&#123;ckpt_dir&#125;</span>&quot;</span><br>    <span class=\"hljs-comment\"># 检查模型并行大小是否与检查点文件数量匹配</span><br>    <span class=\"hljs-keyword\">assert</span> model_parallel_size == <span class=\"hljs-built_in\">len</span>(<br>        checkpoints<br>    ), <span class=\"hljs-string\">f&quot;Loading a checkpoint for MP=<span class=\"hljs-subst\">&#123;<span class=\"hljs-built_in\">len</span>(checkpoints)&#125;</span> but world size is <span class=\"hljs-subst\">&#123;model_parallel_size&#125;</span>&quot;</span><br>    <span class=\"hljs-comment\"># 获取当前进程对应的检查点文件</span><br>    ckpt_path = checkpoints[get_model_parallel_rank()]<br>    <span class=\"hljs-comment\"># 加载检查点文件到 CPU</span><br>    checkpoint = torch.load(ckpt_path, map_location=<span class=\"hljs-string\">&quot;cpu&quot;</span>)<br>    <span class=\"hljs-comment\"># 加载模型参数文件</span><br>    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(Path(ckpt_dir) / <span class=\"hljs-string\">&quot;params.json&quot;</span>, <span class=\"hljs-string\">&quot;r&quot;</span>) <span class=\"hljs-keyword\">as</span> f:<br>        params = json.loads(f.read())<br><br>    <span class=\"hljs-comment\"># 初始化模型参数</span><br>    model_args: ModelArgs = ModelArgs(<br>        max_seq_len=max_seq_len,<br>        max_batch_size=max_batch_size,<br>        **params,<br>    )<br>    <span class=\"hljs-comment\"># 初始化分词器</span><br>    tokenizer = Tokenizer(model_path=tokenizer_path)<br>    <span class=\"hljs-comment\"># 检查模型词汇表大小是否与分词器词汇表大小匹配</span><br>    <span class=\"hljs-keyword\">assert</span> model_args.vocab_size == tokenizer.n_words<br>    <span class=\"hljs-comment\"># 如果当前设备支持 bfloat16，则设置默认张量类型为 bfloat16，否则设置为 float16</span><br>    <span class=\"hljs-keyword\">if</span> torch.cuda.is_bf16_supported():<br>        torch.set_default_tensor_type(torch.cuda.BFloat16Tensor)<br>    <span class=\"hljs-keyword\">else</span>:<br>        torch.set_default_tensor_type(torch.cuda.HalfTensor)<br>    <span class=\"hljs-comment\"># 初始化 Transformer 模型</span><br>    model = Transformer(model_args)<br>    <span class=\"hljs-comment\"># 加载模型权重</span><br>    model.load_state_dict(checkpoint, strict=<span class=\"hljs-literal\">False</span>)<br>    <span class=\"hljs-comment\"># 打印模型加载时间</span><br>    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;Loaded in <span class=\"hljs-subst\">&#123;time.time() - start_time:<span class=\"hljs-number\">.2</span>f&#125;</span> seconds&quot;</span>)<br><br>    <span class=\"hljs-comment\"># 返回 Llama 实例，包含加载的模型和分词器</span><br>    <span class=\"hljs-keyword\">return</span> Llama(model, tokenizer)<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"详细解释\"><a href=\"#详细解释\" class=\"headerlink\" title=\"详细解释\"></a><strong>详细解释</strong></h3><h4 id=\"1-参数检查\"><a href=\"#1-参数检查\" class=\"headerlink\" title=\"1. 参数检查\"></a><strong>1. 参数检查</strong></h4><ul>\n<li><strong><code>max_seq_len</code></strong>: 检查输入序列的最大长度是否在有效范围内（1 到 8192）。</li>\n<li><strong><code>ckpt_dir</code></strong>: 检查检查点目录是否存在。</li>\n<li><strong><code>tokenizer_path</code></strong>: 检查分词器文件是否存在。</li>\n</ul>\n<h4 id=\"2-分布式初始化\"><a href=\"#2-分布式初始化\" class=\"headerlink\" title=\"2. 分布式初始化\"></a><strong>2. 分布式初始化</strong></h4><ul>\n<li>如果分布式进程组未初始化，则使用 <code>torch.distributed.init_process_group</code> 初始化。</li>\n<li>如果模型并行未初始化，则根据 <code>model_parallel_size</code> 或环境变量初始化模型并行。</li>\n</ul>\n<h4 id=\"3-设备设置\"><a href=\"#3-设备设置\" class=\"headerlink\" title=\"3. 设备设置\"></a><strong>3. 设备设置</strong></h4><ul>\n<li>获取当前进程的本地 rank，并设置使用的 GPU 设备。</li>\n</ul>\n<h4 id=\"4-随机种子\"><a href=\"#4-随机种子\" class=\"headerlink\" title=\"4. 随机种子\"></a><strong>4. 随机种子</strong></h4><ul>\n<li>设置随机种子，确保所有进程的随机性一致。</li>\n</ul>\n<h4 id=\"5-检查点加载\"><a href=\"#5-检查点加载\" class=\"headerlink\" title=\"5. 检查点加载\"></a><strong>5. 检查点加载</strong></h4><ul>\n<li>获取检查点目录中的所有 <code>.pth</code> 文件，并按文件名排序。</li>\n<li>检查检查点文件数量和模型并行大小是否匹配。</li>\n<li>加载当前进程对应的检查点文件到 CPU。</li>\n</ul>\n<h4 id=\"6-模型参数加载\"><a href=\"#6-模型参数加载\" class=\"headerlink\" title=\"6. 模型参数加载\"></a><strong>6. 模型参数加载</strong></h4><ul>\n<li>从 <code>params.json</code> 文件中加载模型参数。</li>\n<li>使用 <code>ModelArgs</code> 初始化模型参数。</li>\n</ul>\n<h4 id=\"7-分词器初始化\"><a href=\"#7-分词器初始化\" class=\"headerlink\" title=\"7. 分词器初始化\"></a><strong>7. 分词器初始化</strong></h4><ul>\n<li>使用 <code>Tokenizer</code> 初始化分词器，并检查模型词汇表大小是否与分词器词汇表大小匹配。</li>\n</ul>\n<h4 id=\"8-张量类型设置\"><a href=\"#8-张量类型设置\" class=\"headerlink\" title=\"8. 张量类型设置\"></a><strong>8. 张量类型设置</strong></h4><ul>\n<li>如果当前设备支持 <code>bfloat16</code>，则设置默认张量类型为 <code>bfloat16</code>，否则设置为 <code>float16</code>。</li>\n</ul>\n<h4 id=\"9-模型初始化\"><a href=\"#9-模型初始化\" class=\"headerlink\" title=\"9. 模型初始化\"></a><strong>9. 模型初始化</strong></h4><ul>\n<li>使用 <code>Transformer</code> 初始化模型，并加载检查点中的权重。</li>\n</ul>\n<h4 id=\"10-返回-Llama-实例\"><a href=\"#10-返回-Llama-实例\" class=\"headerlink\" title=\"10. 返回 Llama 实例\"></a><strong>10. 返回 Llama 实例</strong></h4><ul>\n<li>返回包含加载的模型和分词器的 <code>Llama</code> 实例。</li>\n</ul>\n<hr>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h3><p><code>build</code> 方法负责初始化并加载 Llama 模型，包括分布式设置、设备配置、检查点加载、模型参数初始化、分词器初始化等。它是 Llama 模型的核心初始化方法，确保模型能够正确加载并准备好进行推理或训练。</p>\n<h2 id=\"generate-方法-1\"><a href=\"#generate-方法-1\" class=\"headerlink\" title=\"generate 方法\"></a><code>generate</code> 方法</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-meta\">@torch.inference_mode()</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">generate</span>(<span class=\"hljs-params\"></span><br><span class=\"hljs-params\">    self,</span><br><span class=\"hljs-params\">    prompt_tokens: <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]],</span><br><span class=\"hljs-params\">    max_gen_len: <span class=\"hljs-built_in\">int</span>,</span><br><span class=\"hljs-params\">    temperature: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">0.6</span>,</span><br><span class=\"hljs-params\">    top_p: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">0.9</span>,</span><br><span class=\"hljs-params\">    logprobs: <span class=\"hljs-built_in\">bool</span> = <span class=\"hljs-literal\">False</span>,</span><br><span class=\"hljs-params\">    echo: <span class=\"hljs-built_in\">bool</span> = <span class=\"hljs-literal\">False</span>,</span><br><span class=\"hljs-params\"></span>) -&gt; <span class=\"hljs-type\">Tuple</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]], <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">float</span>]]]]:<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    根据输入的 tokenized prompts 生成文本。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    参数:</span><br><span class=\"hljs-string\">        prompt_tokens (List[List[int]]): tokenized prompts，每个 prompt 是一个整数列表。</span><br><span class=\"hljs-string\">        max_gen_len (int): 生成文本的最大长度。</span><br><span class=\"hljs-string\">        temperature (float, optional): 控制生成随机性的温度参数。默认为 0.6。</span><br><span class=\"hljs-string\">        top_p (float, optional): top-p 采样的概率阈值。默认为 0.9。</span><br><span class=\"hljs-string\">        logprobs (bool, optional): 是否计算 token 的 log 概率。默认为 False。</span><br><span class=\"hljs-string\">        echo (bool, optional): 是否在生成结果中包含输入提示。默认为 False。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    返回:</span><br><span class=\"hljs-string\">        Tuple[List[List[int]], Optional[List[List[float]]]]: 生成的 token 序列和 logprobs（可选）。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    注意:</span><br><span class=\"hljs-string\">        该方法使用 nucleus sampling（top-p 采样）生成文本，支持通过温度参数控制生成随机性。</span><br><span class=\"hljs-string\">        如果 logprobs 为 True，则返回每个生成 token 的 log 概率。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 获取模型参数</span><br>    params = <span class=\"hljs-variable language_\">self</span>.model.params<br>    <span class=\"hljs-comment\"># 获取批次大小</span><br>    bsz = <span class=\"hljs-built_in\">len</span>(prompt_tokens)<br>    <span class=\"hljs-comment\"># 检查批次大小是否超过模型的最大批次大小</span><br>    <span class=\"hljs-keyword\">assert</span> bsz &lt;= params.max_batch_size, (bsz, params.max_batch_size)<br><br>    <span class=\"hljs-comment\"># 计算输入 prompts 的最小和最大长度</span><br>    min_prompt_len = <span class=\"hljs-built_in\">min</span>(<span class=\"hljs-built_in\">len</span>(t) <span class=\"hljs-keyword\">for</span> t <span class=\"hljs-keyword\">in</span> prompt_tokens)<br>    max_prompt_len = <span class=\"hljs-built_in\">max</span>(<span class=\"hljs-built_in\">len</span>(t) <span class=\"hljs-keyword\">for</span> t <span class=\"hljs-keyword\">in</span> prompt_tokens)<br>    <span class=\"hljs-comment\"># 检查输入 prompts 的最大长度是否超过模型的最大序列长度</span><br>    <span class=\"hljs-keyword\">assert</span> max_prompt_len &lt;= params.max_seq_len<br>    <span class=\"hljs-comment\"># 计算总长度（输入 prompts 长度 + 生成文本长度）</span><br>    total_len = <span class=\"hljs-built_in\">min</span>(params.max_seq_len, max_gen_len + max_prompt_len)<br><br>    <span class=\"hljs-comment\"># 获取填充 token 的 ID</span><br>    pad_id = <span class=\"hljs-variable language_\">self</span>.tokenizer.pad_id<br>    <span class=\"hljs-comment\"># 初始化 tokens 张量，用 pad_id 填充</span><br>    tokens = torch.full((bsz, total_len), pad_id, dtype=torch.long, device=<span class=\"hljs-string\">&quot;cuda&quot;</span>)<br>    <span class=\"hljs-comment\"># 将输入 prompts 填充到 tokens 张量中</span><br>    <span class=\"hljs-keyword\">for</span> k, t <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(prompt_tokens):<br>        tokens[k, : <span class=\"hljs-built_in\">len</span>(t)] = torch.tensor(t, dtype=torch.long, device=<span class=\"hljs-string\">&quot;cuda&quot;</span>)<br>    <span class=\"hljs-comment\"># 如果 logprobs 为 True，则初始化 token_logprobs 张量</span><br>    <span class=\"hljs-keyword\">if</span> logprobs:<br>        token_logprobs = torch.zeros_like(tokens, dtype=torch.<span class=\"hljs-built_in\">float</span>)<br><br>    <span class=\"hljs-comment\"># 初始化当前位置和 EOS（结束符）标记</span><br>    prev_pos = <span class=\"hljs-number\">0</span><br>    eos_reached = torch.tensor([<span class=\"hljs-literal\">False</span>] * bsz, device=<span class=\"hljs-string\">&quot;cuda&quot;</span>)<br>    <span class=\"hljs-comment\"># 创建输入文本的掩码（非填充部分为 True）</span><br>    input_text_mask = tokens != pad_id<br><br>    <span class=\"hljs-comment\"># 如果输入 prompts 的长度等于总长度，则直接计算 logits</span><br>    <span class=\"hljs-keyword\">if</span> min_prompt_len == total_len:<br>        logits = <span class=\"hljs-variable language_\">self</span>.model.forward(tokens, prev_pos)<br>        <span class=\"hljs-comment\"># 计算 token 的 log 概率</span><br>        token_logprobs = -F.cross_entropy(<br>            <span class=\"hljs-built_in\">input</span>=logits.transpose(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>),<br>            target=tokens,<br>            reduction=<span class=\"hljs-string\">&quot;none&quot;</span>,<br>            ignore_index=pad_id,<br>        )<br><br>    <span class=\"hljs-comment\"># 获取停止 token 的 ID</span><br>    stop_tokens = torch.tensor(<span class=\"hljs-built_in\">list</span>(<span class=\"hljs-variable language_\">self</span>.tokenizer.stop_tokens))<br><br>    <span class=\"hljs-comment\"># 逐 token 生成文本</span><br>    <span class=\"hljs-keyword\">for</span> cur_pos <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(min_prompt_len, total_len):<br>        <span class=\"hljs-comment\"># 计算当前 token 的 logits</span><br>        logits = <span class=\"hljs-variable language_\">self</span>.model.forward(tokens[:, prev_pos:cur_pos], prev_pos)<br>        <span class=\"hljs-comment\"># 如果 temperature &gt; 0，则使用温度参数和 top-p 采样生成下一个 token</span><br>        <span class=\"hljs-keyword\">if</span> temperature &gt; <span class=\"hljs-number\">0</span>:<br>            probs = torch.softmax(logits[:, -<span class=\"hljs-number\">1</span>] / temperature, dim=-<span class=\"hljs-number\">1</span>)<br>            next_token = sample_top_p(probs, top_p)<br>        <span class=\"hljs-keyword\">else</span>:<br>            <span class=\"hljs-comment\"># 如果 temperature = 0，则选择概率最大的 token</span><br>            next_token = torch.argmax(logits[:, -<span class=\"hljs-number\">1</span>], dim=-<span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-comment\"># 将下一个 token 填充到 tokens 张量中</span><br>        next_token = next_token.reshape(-<span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-comment\"># 如果当前位置在输入 prompts 范围内，则保留输入 token</span><br>        next_token = torch.where(<br>            input_text_mask[:, cur_pos], tokens[:, cur_pos], next_token<br>        )<br>        tokens[:, cur_pos] = next_token<br>        <span class=\"hljs-comment\"># 如果 logprobs 为 True，则计算 token 的 log 概率</span><br>        <span class=\"hljs-keyword\">if</span> logprobs:<br>            token_logprobs[:, prev_pos + <span class=\"hljs-number\">1</span> : cur_pos + <span class=\"hljs-number\">1</span>] = -F.cross_entropy(<br>                <span class=\"hljs-built_in\">input</span>=logits.transpose(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>),<br>                target=tokens[:, prev_pos + <span class=\"hljs-number\">1</span> : cur_pos + <span class=\"hljs-number\">1</span>],<br>                reduction=<span class=\"hljs-string\">&quot;none&quot;</span>,<br>                ignore_index=pad_id,<br>            )<br>        <span class=\"hljs-comment\"># 检查是否生成停止 token</span><br>        eos_reached |= (~input_text_mask[:, cur_pos]) &amp; (<br>            torch.isin(next_token, stop_tokens)<br>        )<br>        <span class=\"hljs-comment\"># 更新当前位置</span><br>        prev_pos = cur_pos<br>        <span class=\"hljs-comment\"># 如果所有批次都生成停止 token，则提前结束</span><br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">all</span>(eos_reached):<br>            <span class=\"hljs-keyword\">break</span><br><br>    <span class=\"hljs-comment\"># 如果 logprobs 为 True，则将 token_logprobs 转换为列表</span><br>    <span class=\"hljs-keyword\">if</span> logprobs:<br>        token_logprobs = token_logprobs.tolist()<br>    <span class=\"hljs-comment\"># 初始化输出 token 序列和 logprobs</span><br>    out_tokens, out_logprobs = [], []<br>    <span class=\"hljs-comment\"># 处理每个批次的生成结果</span><br>    <span class=\"hljs-keyword\">for</span> i, toks <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(tokens.tolist()):<br>        <span class=\"hljs-comment\"># 如果 echo 为 False，则从生成部分开始截取</span><br>        start = <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">if</span> echo <span class=\"hljs-keyword\">else</span> <span class=\"hljs-built_in\">len</span>(prompt_tokens[i])<br>        toks = toks[start : <span class=\"hljs-built_in\">len</span>(prompt_tokens[i]) + max_gen_len]<br>        probs = <span class=\"hljs-literal\">None</span><br>        <span class=\"hljs-comment\"># 如果 logprobs 为 True，则截取对应的 logprobs</span><br>        <span class=\"hljs-keyword\">if</span> logprobs:<br>            probs = token_logprobs[i][start : <span class=\"hljs-built_in\">len</span>(prompt_tokens[i]) + max_gen_len]<br>        <span class=\"hljs-comment\"># 如果生成结果中包含停止 token，则截取到停止 token 之前</span><br>        <span class=\"hljs-keyword\">for</span> stop_token <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>.tokenizer.stop_tokens:<br>            <span class=\"hljs-keyword\">try</span>:<br>                eos_idx = toks.index(stop_token)<br>                toks = toks[:eos_idx]<br>                probs = probs[:eos_idx] <span class=\"hljs-keyword\">if</span> logprobs <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span><br>            <span class=\"hljs-keyword\">except</span> ValueError:<br>                <span class=\"hljs-keyword\">pass</span><br>        <span class=\"hljs-comment\"># 将结果添加到输出列表中</span><br>        out_tokens.append(toks)<br>        out_logprobs.append(probs)<br>    <span class=\"hljs-comment\"># 返回生成的 token 序列和 logprobs（可选）</span><br>    <span class=\"hljs-keyword\">return</span> (out_tokens, out_logprobs <span class=\"hljs-keyword\">if</span> logprobs <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span>)<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"详细解释-1\"><a href=\"#详细解释-1\" class=\"headerlink\" title=\"详细解释\"></a><strong>详细解释</strong></h3><h4 id=\"1-输入处理\"><a href=\"#1-输入处理\" class=\"headerlink\" title=\"1. 输入处理\"></a><strong>1. 输入处理</strong></h4><ul>\n<li><strong><code>prompt_tokens</code></strong>: 输入的 tokenized prompts，每个 prompt 是一个整数列表。</li>\n<li><strong><code>max_gen_len</code></strong>: 生成文本的最大长度。</li>\n<li><strong><code>temperature</code></strong>: 控制生成随机性的温度参数。</li>\n<li><strong><code>top_p</code></strong>: top-p 采样的概率阈值。</li>\n<li><strong><code>logprobs</code></strong>: 是否计算 token 的 log 概率。</li>\n<li><strong><code>echo</code></strong>: 是否在生成结果中包含输入提示。</li>\n</ul>\n<h4 id=\"2-初始化\"><a href=\"#2-初始化\" class=\"headerlink\" title=\"2. 初始化\"></a><strong>2. 初始化</strong></h4><ul>\n<li><strong><code>params</code></strong>: 获取模型参数。</li>\n<li><strong><code>bsz</code></strong>: 获取批次大小。</li>\n<li><strong><code>min_prompt_len</code> 和 <code>max_prompt_len</code></strong>: 计算输入 prompts 的最小和最大长度。</li>\n<li><strong><code>total_len</code></strong>: 计算总长度（输入 prompts 长度 + 生成文本长度）。</li>\n<li><strong><code>tokens</code></strong>: 初始化 tokens 张量，用 pad_id 填充，并将输入 prompts 填充到 tokens 张量中。</li>\n</ul>\n<h4 id=\"3-生成文本\"><a href=\"#3-生成文本\" class=\"headerlink\" title=\"3. 生成文本\"></a><strong>3. 生成文本</strong></h4><ul>\n<li><strong>逐 token 生成</strong>:<ul>\n<li>使用 <code>model.forward</code> 计算当前 token 的 logits。</li>\n<li>如果 <code>temperature &gt; 0</code>，则使用温度参数和 top-p 采样生成下一个 token。</li>\n<li>如果 <code>temperature = 0</code>，则选择概率最大的 token。</li>\n<li>将下一个 token 填充到 tokens 张量中。</li>\n<li>如果 <code>logprobs</code> 为 True，则计算 token 的 log 概率。</li>\n<li>检查是否生成停止 token，如果所有批次都生成停止 token，则提前结束。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"4-输出处理\"><a href=\"#4-输出处理\" class=\"headerlink\" title=\"4. 输出处理\"></a><strong>4. 输出处理</strong></h4><ul>\n<li><strong><code>out_tokens</code> 和 <code>out_logprobs</code></strong>: 处理每个批次的生成结果。<ul>\n<li>如果 <code>echo</code> 为 False，则从生成部分开始截取。</li>\n<li>如果生成结果中包含停止 token，则截取到停止 token 之前。</li>\n</ul>\n</li>\n<li><strong>返回结果</strong>: 返回生成的 token 序列和 logprobs（可选）。</li>\n</ul>\n<hr>\n<h3 id=\"总结-1\"><a href=\"#总结-1\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h3><p><code>generate</code> 方法是 Llama 3 模型的核心生成方法，负责根据输入的 tokenized prompts 生成文本。通过温度、top-p 采样等参数，用户可以灵活控制生成过程。该方法支持计算 token 的 log 概率，并可以处理停止 token 和输入提示。</p>\n<h2 id=\"generate-详细流程图\"><a href=\"#generate-详细流程图\" class=\"headerlink\" title=\"generate 详细流程图\"></a><code>generate</code> 详细流程图</h2><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241230115215231.png\" alt=\"generate流程图\"></p>\n<hr>\n<h3 id=\"详细步骤说明\"><a href=\"#详细步骤说明\" class=\"headerlink\" title=\"详细步骤说明\"></a><strong>详细步骤说明</strong></h3><h4 id=\"1-输入处理-1\"><a href=\"#1-输入处理-1\" class=\"headerlink\" title=\"1. 输入处理\"></a><strong>1. 输入处理</strong></h4><ul>\n<li><strong>输入</strong>: <code>prompt_tokens</code>，tokenized prompts，每个 prompt 是一个整数列表。</li>\n</ul>\n<h4 id=\"2-初始化-1\"><a href=\"#2-初始化-1\" class=\"headerlink\" title=\"2. 初始化\"></a><strong>2. 初始化</strong></h4><ul>\n<li><strong>初始化 tokens 张量</strong>: 用 pad_id 填充，并将输入 prompts 填充到 tokens 张量中。</li>\n<li><strong>计算 min_prompt_len 和 max_prompt_len</strong>: 输入 prompts 的最小和最大长度。</li>\n<li><strong>检查 max_prompt_len 是否超过 max_seq_len</strong>: 确保输入 prompts 的长度不超过模型的最大序列长度。</li>\n<li><strong>计算 total_len</strong>: 输入 prompts 长度 + 生成文本长度。</li>\n<li><strong>初始化 token_logprobs</strong>: 如果 <code>logprobs=True</code>，则初始化 token_logprobs 张量。</li>\n<li><strong>初始化 prev_pos 和 eos_reached</strong>: 当前位置和 EOS（结束符）标记。</li>\n<li><strong>创建 input_text_mask</strong>: 输入文本的掩码（非填充部分为 True）。</li>\n</ul>\n<h4 id=\"3-生成文本-1\"><a href=\"#3-生成文本-1\" class=\"headerlink\" title=\"3. 生成文本\"></a><strong>3. 生成文本</strong></h4><ul>\n<li><strong>检查 min_prompt_len 是否等于 total_len</strong>:<ul>\n<li>如果相等，则直接计算 logits 和 token_logprobs。</li>\n<li>否则，逐 token 生成文本。</li>\n</ul>\n</li>\n<li><strong>逐 token 生成文本</strong>:<ul>\n<li><strong>计算当前 token 的 logits</strong>。</li>\n<li><strong>检查 temperature 是否大于 0</strong>:<ul>\n<li>如果大于 0，则使用温度参数和 top-p 采样生成下一个 token。</li>\n<li>否则，选择概率最大的 token。</li>\n</ul>\n</li>\n<li><strong>填充下一个 token 到 tokens 张量</strong>。</li>\n<li><strong>检查 logprobs 是否为 True</strong>:<ul>\n<li>如果为 True，则计算 token 的 log 概率。</li>\n</ul>\n</li>\n<li><strong>检查是否生成停止 token</strong>。</li>\n<li><strong>更新 prev_pos</strong>。</li>\n<li><strong>检查所有批次是否都生成停止 token</strong>:<ul>\n<li>如果是，则提前结束。</li>\n<li>否则，继续生成下一个 token。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"4-输出处理-1\"><a href=\"#4-输出处理-1\" class=\"headerlink\" title=\"4. 输出处理\"></a><strong>4. 输出处理</strong></h4><ul>\n<li><strong>处理每个批次的生成结果</strong>:<ul>\n<li><strong>检查 echo 是否为 False</strong>:<ul>\n<li>如果为 False，则从生成部分开始截取。</li>\n<li>否则，保留输入提示。</li>\n</ul>\n</li>\n<li><strong>截取到停止 token 之前</strong>。</li>\n<li><strong>将结果添加到输出列表中</strong>。</li>\n</ul>\n</li>\n<li><strong>返回生成的 token 序列和 logprobs（可选）</strong>。</li>\n</ul>\n<hr>\n<h3 id=\"总结-2\"><a href=\"#总结-2\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h3><p><code>generate</code> 方法的流程图清晰地展示了从输入到输出的完整生成过程，包括初始化、逐 token 生成和输出处理。通过该流程图，可以更好地理解 Llama 3 模型的文本生成机制。</p>\n<h2 id=\"text-completion-和-chat-completion\"><a href=\"#text-completion-和-chat-completion\" class=\"headerlink\" title=\"text_completion 和 chat_completion\"></a><code>text_completion</code> 和 <code>chat_completion</code></h2><hr>\n<h3 id=\"1-text-completion-方法\"><a href=\"#1-text-completion-方法\" class=\"headerlink\" title=\"1. text_completion 方法\"></a><strong>1. <code>text_completion</code> 方法</strong></h3><h4 id=\"功能\"><a href=\"#功能\" class=\"headerlink\" title=\"功能\"></a><strong>功能</strong></h4><p>对给定的文本提示进行补全，生成后续文本。</p>\n<h4 id=\"参数\"><a href=\"#参数\" class=\"headerlink\" title=\"参数\"></a><strong>参数</strong></h4><ul>\n<li><strong><code>prompts</code></strong>: 文本提示列表，每个提示是一个字符串。</li>\n<li><strong><code>temperature</code></strong>: 控制生成随机性的温度参数。值越大，生成结果越随机；值越小，生成结果越确定。</li>\n<li><strong><code>top_p</code></strong>: top-p 采样的概率阈值。用于控制生成结果的多样性和质量。</li>\n<li><strong><code>max_gen_len</code></strong>: 生成文本的最大长度。如果未提供，则使用模型的最大序列长度减 1。</li>\n<li><strong><code>logprobs</code></strong>: 是否计算 token 的 log 概率。默认为 False。</li>\n<li><strong><code>echo</code></strong>: 是否在生成结果中包含输入提示。默认为 False。</li>\n</ul>\n<h4 id=\"返回值\"><a href=\"#返回值\" class=\"headerlink\" title=\"返回值\"></a><strong>返回值</strong></h4><ul>\n<li><strong><code>List[CompletionPrediction]</code></strong>: 文本补全的生成结果列表，每个结果包含生成的文本、token 列表和 logprobs（可选）。</li>\n</ul>\n<h4 id=\"代码逻辑\"><a href=\"#代码逻辑\" class=\"headerlink\" title=\"代码逻辑\"></a><strong>代码逻辑</strong></h4><ol>\n<li><strong>检查 <code>max_gen_len</code></strong>:<ul>\n<li>如果未提供 <code>max_gen_len</code>，则使用模型的最大序列长度减 1。</li>\n</ul>\n</li>\n<li><strong>编码输入提示</strong>:<ul>\n<li>使用分词器将输入提示编码为 tokenized prompts。</li>\n</ul>\n</li>\n<li><strong>调用 <code>generate</code> 方法</strong>:<ul>\n<li>使用 <code>generate</code> 方法生成 token 序列。</li>\n</ul>\n</li>\n<li><strong>解码生成结果</strong>:<ul>\n<li>将生成的 token 序列解码为文本。</li>\n</ul>\n</li>\n<li><strong>返回生成结果</strong>:<ul>\n<li>如果 <code>logprobs</code> 为 True，则返回生成的文本、token 列表和 logprobs。</li>\n<li>否则，仅返回生成的文本。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a><strong>示例</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">prompts = [<span class=\"hljs-string\">&quot;Once upon a time&quot;</span>]<br>results = llama.text_completion(prompts, max_gen_len=<span class=\"hljs-number\">50</span>)<br><span class=\"hljs-keyword\">for</span> result <span class=\"hljs-keyword\">in</span> results:<br>    <span class=\"hljs-built_in\">print</span>(result[<span class=\"hljs-string\">&quot;generation&quot;</span>])<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"2-chat-completion-方法\"><a href=\"#2-chat-completion-方法\" class=\"headerlink\" title=\"2. chat_completion 方法\"></a><strong>2. <code>chat_completion</code> 方法</strong></h3><h4 id=\"功能-1\"><a href=\"#功能-1\" class=\"headerlink\" title=\"功能\"></a><strong>功能</strong></h4><p>根据对话历史生成助理的回复。</p>\n<h4 id=\"参数-1\"><a href=\"#参数-1\" class=\"headerlink\" title=\"参数\"></a><strong>参数</strong></h4><ul>\n<li><strong><code>dialogs</code></strong>: 对话历史列表，每个对话是一个消息列表，每个消息包含角色（<code>role</code>）和内容（<code>content</code>）。</li>\n<li><strong><code>temperature</code></strong>: 控制生成随机性的温度参数。值越大，生成结果越随机；值越小，生成结果越确定。</li>\n<li><strong><code>top_p</code></strong>: top-p 采样的概率阈值。用于控制生成结果的多样性和质量。</li>\n<li><strong><code>max_gen_len</code></strong>: 生成文本的最大长度。如果未提供，则使用模型的最大序列长度减 1。</li>\n<li><strong><code>logprobs</code></strong>: 是否计算 token 的 log 概率。默认为 False。</li>\n</ul>\n<h4 id=\"返回值-1\"><a href=\"#返回值-1\" class=\"headerlink\" title=\"返回值\"></a><strong>返回值</strong></h4><ul>\n<li><strong><code>List[ChatPrediction]</code></strong>: 对话生成的生成结果列表，每个结果包含助理的回复、token 列表和 logprobs（可选）。</li>\n</ul>\n<h4 id=\"代码逻辑-1\"><a href=\"#代码逻辑-1\" class=\"headerlink\" title=\"代码逻辑\"></a><strong>代码逻辑</strong></h4><ol>\n<li><strong>检查 <code>max_gen_len</code></strong>:<ul>\n<li>如果未提供 <code>max_gen_len</code>，则使用模型的最大序列长度减 1。</li>\n</ul>\n</li>\n<li><strong>编码对话历史</strong>:<ul>\n<li>使用 <code>ChatFormat</code> 将对话历史编码为 tokenized prompts。</li>\n</ul>\n</li>\n<li><strong>调用 <code>generate</code> 方法</strong>:<ul>\n<li>使用 <code>generate</code> 方法生成 token 序列。</li>\n</ul>\n</li>\n<li><strong>解码生成结果</strong>:<ul>\n<li>将生成的 token 序列解码为文本。</li>\n</ul>\n</li>\n<li><strong>返回生成结果</strong>:<ul>\n<li>如果 <code>logprobs</code> 为 True，则返回助理的回复、token 列表和 logprobs。</li>\n<li>否则，仅返回助理的回复。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"示例-1\"><a href=\"#示例-1\" class=\"headerlink\" title=\"示例\"></a><strong>示例</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">dialogs = [<br>    [&#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;user&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;What is the capital of France?&quot;</span>&#125;]<br>]<br>results = llama.chat_completion(dialogs, max_gen_len=<span class=\"hljs-number\">50</span>)<br><span class=\"hljs-keyword\">for</span> result <span class=\"hljs-keyword\">in</span> results:<br>    <span class=\"hljs-built_in\">print</span>(result[<span class=\"hljs-string\">&quot;generation&quot;</span>][<span class=\"hljs-string\">&quot;content&quot;</span>])<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"3-主要区别\"><a href=\"#3-主要区别\" class=\"headerlink\" title=\"3. 主要区别\"></a><strong>3. 主要区别</strong></h3><table>\n<thead>\n<tr>\n<th>特性</th>\n<th><code>text_completion</code></th>\n<th><code>chat_completion</code></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>输入</strong></td>\n<td>文本提示列表</td>\n<td>对话历史列表</td>\n</tr>\n<tr>\n<td><strong>输出</strong></td>\n<td>文本补全结果</td>\n<td>助理的回复</td>\n</tr>\n<tr>\n<td><strong>编码方式</strong></td>\n<td>直接使用分词器编码</td>\n<td>使用 <code>ChatFormat</code> 编码对话历史</td>\n</tr>\n<tr>\n<td><strong>适用场景</strong></td>\n<td>单轮文本补全</td>\n<td>多轮对话生成</td>\n</tr>\n<tr>\n<td><strong>返回格式</strong></td>\n<td><code>CompletionPrediction</code></td>\n<td><code>ChatPrediction</code></td>\n</tr>\n</tbody></table>\n<hr>\n<h3 id=\"4-生成控制参数-1\"><a href=\"#4-生成控制参数-1\" class=\"headerlink\" title=\"4. 生成控制参数\"></a><strong>4. 生成控制参数</strong></h3><ul>\n<li><strong>温度（temperature）</strong>:<ul>\n<li>控制生成随机性的参数。</li>\n<li>值越大，生成结果越随机；值越小，生成结果越确定。</li>\n</ul>\n</li>\n<li><strong>top-p 采样（nucleus sampling）</strong>:<ul>\n<li>从概率累积值超过 <code>top_p</code> 的最小 token 集合中采样。</li>\n<li>用于控制生成结果的多样性和质量。</li>\n</ul>\n</li>\n<li><strong>logprobs</strong>:<ul>\n<li>是否计算生成 token 的 log 概率。</li>\n<li>用于分析生成结果的置信度。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"5-总结\"><a href=\"#5-总结\" class=\"headerlink\" title=\"5. 总结\"></a><strong>5. 总结</strong></h3><ul>\n<li><strong><code>text_completion</code></strong>: 用于文本补全，适用于单轮文本生成任务。</li>\n<li><strong><code>chat_completion</code></strong>: 用于对话生成，适用于多轮对话任务。</li>\n<li>两者都通过 <code>generate</code> 方法实现核心生成逻辑，并支持温度、top-p 采样等参数控制生成过程。</li>\n</ul>\n<h2 id=\"sample-top-p\"><a href=\"#sample-top-p\" class=\"headerlink\" title=\"sample_top_p\"></a>sample_top_p</h2><p>该函数实现了 <strong>top-p 采样（nucleus sampling）</strong>，用于从概率分布中选择 token。</p>\n<hr>\n<h3 id=\"代码注释\"><a href=\"#代码注释\" class=\"headerlink\" title=\"代码注释\"></a><strong>代码注释</strong></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">sample_top_p</span>(<span class=\"hljs-params\">probs, p</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    对概率分布进行 top-p 采样（nucleus sampling）。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    参数:</span><br><span class=\"hljs-string\">        probs (torch.Tensor): 概率分布张量，形状为 (batch_size, vocab_size)。</span><br><span class=\"hljs-string\">        p (float): top-p 采样的概率阈值，取值范围为 (0, 1]。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    返回:</span><br><span class=\"hljs-string\">        torch.Tensor: 采样得到的 token 索引，形状为 (batch_size, 1)。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    注意:</span><br><span class=\"hljs-string\">        top-p 采样从概率累积值超过 p 的最小 token 集合中采样，用于控制生成结果的多样性和质量。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 对概率分布进行降序排序，并获取排序后的概率和索引</span><br>    probs_sort, probs_idx = torch.sort(probs, dim=-<span class=\"hljs-number\">1</span>, descending=<span class=\"hljs-literal\">True</span>)<br>    <span class=\"hljs-comment\"># 计算概率分布的累积和</span><br>    probs_sum = torch.cumsum(probs_sort, dim=-<span class=\"hljs-number\">1</span>)<br>    <span class=\"hljs-comment\"># 创建掩码，标记概率累积值超过 p 的 token</span><br>    mask = probs_sum - probs_sort &gt; p<br>    <span class=\"hljs-comment\"># 将掩码对应的概率置为 0</span><br>    probs_sort[mask] = <span class=\"hljs-number\">0.0</span><br>    <span class=\"hljs-comment\"># 对剩余的概率进行归一化</span><br>    probs_sort.div_(probs_sort.<span class=\"hljs-built_in\">sum</span>(dim=-<span class=\"hljs-number\">1</span>, keepdim=<span class=\"hljs-literal\">True</span>))<br>    <span class=\"hljs-comment\"># 从归一化后的概率分布中进行多项式采样</span><br>    next_token = torch.multinomial(probs_sort, num_samples=<span class=\"hljs-number\">1</span>)<br>    <span class=\"hljs-comment\"># 根据采样结果获取原始 token 索引</span><br>    next_token = torch.gather(probs_idx, -<span class=\"hljs-number\">1</span>, next_token)<br>    <span class=\"hljs-keyword\">return</span> next_token<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"详细解释-2\"><a href=\"#详细解释-2\" class=\"headerlink\" title=\"详细解释\"></a><strong>详细解释</strong></h3><h4 id=\"1-输入参数\"><a href=\"#1-输入参数\" class=\"headerlink\" title=\"1. 输入参数\"></a><strong>1. 输入参数</strong></h4><ul>\n<li><strong><code>probs</code></strong>: 概率分布张量，形状为 <code>(batch_size, vocab_size)</code>，表示每个 token 的概率。</li>\n<li><strong><code>p</code></strong>: top-p 采样的概率阈值，取值范围为 <code>(0, 1]</code>。例如，<code>p=0.9</code> 表示从概率累积值超过 0.9 的最小 token 集合中采样。</li>\n</ul>\n<h4 id=\"2-概率排序\"><a href=\"#2-概率排序\" class=\"headerlink\" title=\"2. 概率排序\"></a><strong>2. 概率排序</strong></h4><ul>\n<li><strong><code>torch.sort</code></strong>: 对概率分布进行降序排序，返回排序后的概率 <code>probs_sort</code> 和对应的索引 <code>probs_idx</code>。</li>\n</ul>\n<h4 id=\"3-计算累积和\"><a href=\"#3-计算累积和\" class=\"headerlink\" title=\"3. 计算累积和\"></a><strong>3. 计算累积和</strong></h4><ul>\n<li><strong><code>torch.cumsum</code></strong>: 计算排序后概率的累积和 <code>probs_sum</code>。</li>\n</ul>\n<h4 id=\"4-创建掩码\"><a href=\"#4-创建掩码\" class=\"headerlink\" title=\"4. 创建掩码\"></a><strong>4. 创建掩码</strong></h4><ul>\n<li><strong><code>mask</code></strong>: 标记概率累积值超过 <code>p</code> 的 token。例如，如果 <code>p=0.9</code>，则掩码标记概率累积值超过 0.9 的 token。</li>\n</ul>\n<h4 id=\"5-概率置零\"><a href=\"#5-概率置零\" class=\"headerlink\" title=\"5. 概率置零\"></a><strong>5. 概率置零</strong></h4><ul>\n<li><strong><code>probs_sort[mask] = 0.0</code></strong>: 将掩码对应的概率置为 0，排除概率累积值超过 <code>p</code> 的 token。</li>\n</ul>\n<h4 id=\"6-归一化\"><a href=\"#6-归一化\" class=\"headerlink\" title=\"6. 归一化\"></a><strong>6. 归一化</strong></h4><ul>\n<li><strong><code>probs_sort.div_</code></strong>: 对剩余的概率进行归一化，使其总和为 1。</li>\n</ul>\n<h4 id=\"7-多项式采样\"><a href=\"#7-多项式采样\" class=\"headerlink\" title=\"7. 多项式采样\"></a><strong>7. 多项式采样</strong></h4><ul>\n<li><strong><code>torch.multinomial</code></strong>: 从归一化后的概率分布中进行多项式采样，返回采样得到的 token 索引。</li>\n</ul>\n<h4 id=\"8-获取原始索引\"><a href=\"#8-获取原始索引\" class=\"headerlink\" title=\"8. 获取原始索引\"></a><strong>8. 获取原始索引</strong></h4><ul>\n<li><strong><code>torch.gather</code></strong>: 根据采样结果获取原始 token 索引。</li>\n</ul>\n<h4 id=\"9-返回结果\"><a href=\"#9-返回结果\" class=\"headerlink\" title=\"9. 返回结果\"></a><strong>9. 返回结果</strong></h4><ul>\n<li><strong><code>next_token</code></strong>: 采样得到的 token 索引，形状为 <code>(batch_size, 1)</code>。</li>\n</ul>\n<hr>\n<h3 id=\"示例-2\"><a href=\"#示例-2\" class=\"headerlink\" title=\"示例\"></a><strong>示例</strong></h3><p>假设有以下概率分布和参数：</p>\n<ul>\n<li><strong><code>probs</code></strong>: <code>[[0.1, 0.4, 0.2, 0.3]]</code>，形状为 <code>(1, 4)</code>。</li>\n<li><strong><code>p</code></strong>: <code>0.9</code>。</li>\n</ul>\n<h4 id=\"执行步骤\"><a href=\"#执行步骤\" class=\"headerlink\" title=\"执行步骤\"></a><strong>执行步骤</strong></h4><ol>\n<li><strong>排序</strong>:<ul>\n<li><code>probs_sort</code>: <code>[[0.4, 0.3, 0.2, 0.1]]</code>。</li>\n<li><code>probs_idx</code>: <code>[[1, 3, 2, 0]]</code>。</li>\n</ul>\n</li>\n<li><strong>计算累积和</strong>:<ul>\n<li><code>probs_sum</code>: <code>[[0.4, 0.7, 0.9, 1.0]]</code>。</li>\n</ul>\n</li>\n<li><strong>创建掩码</strong>:<ul>\n<li><code>mask</code>: <code>[[False, False, True, True]]</code>。</li>\n</ul>\n</li>\n<li><strong>概率置零</strong>:<ul>\n<li><code>probs_sort</code>: <code>[[0.4, 0.3, 0.0, 0.0]]</code>。</li>\n</ul>\n</li>\n<li><strong>归一化</strong>:<ul>\n<li><code>probs_sort</code>: <code>[[0.57, 0.43, 0.0, 0.0]]</code>。</li>\n</ul>\n</li>\n<li><strong>多项式采样</strong>:<ul>\n<li><code>next_token</code>: <code>[[1]]</code>（假设采样结果为 1）。</li>\n</ul>\n</li>\n<li><strong>获取原始索引</strong>:<ul>\n<li><code>next_token</code>: <code>[[3]]</code>。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"返回结果\"><a href=\"#返回结果\" class=\"headerlink\" title=\"返回结果\"></a><strong>返回结果</strong></h4><ul>\n<li><code>next_token</code>: <code>[[3]]</code>。</li>\n</ul>\n<hr>\n<h3 id=\"总结-3\"><a href=\"#总结-3\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h3><p><code>sample_top_p</code> 函数实现了 top-p 采样（nucleus sampling），用于从概率分布中选择 token。通过控制概率阈值 <code>p</code>，可以灵活调整生成结果的多样性和质量。该函数是 Llama 3 模型生成过程的核心组件之一。</p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n","excerpt":"","more":"<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/Llama3_Repo.jpeg\" alt=\"llama\"></p>\n<h2 id=\"整体\"><a href=\"#整体\" class=\"headerlink\" title=\"整体\"></a>整体</h2><p><code>generation.py</code> 模块是 Llama 3 模型的核心生成模块，负责实现文本生成功能，包括文本补全和对话生成。</p>\n<hr>\n<h3 id=\"1-核心功能\"><a href=\"#1-核心功能\" class=\"headerlink\" title=\"1. 核心功能\"></a><strong>1. 核心功能</strong></h3><ul>\n<li><strong>文本生成</strong>：根据输入的提示（prompt）生成文本。</li>\n<li><strong>文本补全</strong>：对给定的文本提示进行补全。</li>\n<li><strong>对话生成</strong>：根据对话历史生成助理的回复。</li>\n<li><strong>生成控制</strong>：支持通过温度（temperature）、top-p 采样（nucleus sampling）等参数控制生成过程。</li>\n</ul>\n<hr>\n<h3 id=\"2-主要类和方法\"><a href=\"#2-主要类和方法\" class=\"headerlink\" title=\"2. 主要类和方法\"></a><strong>2. 主要类和方法</strong></h3><h4 id=\"class-Llama\"><a href=\"#class-Llama\" class=\"headerlink\" title=\"class Llama\"></a><strong><code>class Llama</code></strong></h4><ul>\n<li><strong><code>build</code> 方法</strong>：初始化并加载 Llama 模型和分词器。</li>\n<li><strong><code>generate</code> 方法</strong>：核心生成方法，根据输入的 tokenized prompts 生成文本。</li>\n<li><strong><code>text_completion</code> 方法</strong>：对文本提示进行补全。</li>\n<li><strong><code>chat_completion</code> 方法</strong>：根据对话历史生成助理的回复。</li>\n</ul>\n<h4 id=\"class-CompletionPrediction\"><a href=\"#class-CompletionPrediction\" class=\"headerlink\" title=\"class CompletionPrediction\"></a><strong><code>class CompletionPrediction</code></strong></h4><ul>\n<li>用于表示文本补全的生成结果，包含生成的文本、token 列表和 logprobs（可选）。</li>\n</ul>\n<h4 id=\"class-ChatPrediction\"><a href=\"#class-ChatPrediction\" class=\"headerlink\" title=\"class ChatPrediction\"></a><strong><code>class ChatPrediction</code></strong></h4><ul>\n<li>用于表示对话生成的生成结果，包含助理的回复、token 列表和 logprobs（可选）。</li>\n</ul>\n<hr>\n<h3 id=\"3-核心方法详解\"><a href=\"#3-核心方法详解\" class=\"headerlink\" title=\"3. 核心方法详解\"></a><strong>3. 核心方法详解</strong></h3><h4 id=\"generate-方法\"><a href=\"#generate-方法\" class=\"headerlink\" title=\"generate 方法\"></a><strong><code>generate</code> 方法</strong></h4><ul>\n<li><strong>功能</strong>：根据输入的 tokenized prompts 生成文本。</li>\n<li><strong>参数</strong>：<ul>\n<li><code>prompt_tokens</code>：tokenized prompts，形状为 <code>(batch_size, seq_len)</code>。</li>\n<li><code>max_gen_len</code>：生成文本的最大长度。</li>\n<li><code>temperature</code>：控制生成随机性的温度参数。</li>\n<li><code>top_p</code>：top-p 采样的概率阈值。</li>\n<li><code>logprobs</code>：是否计算 token 的 log 概率。</li>\n<li><code>echo</code>：是否在生成结果中包含输入提示。</li>\n</ul>\n</li>\n<li><strong>返回值</strong>：生成的 token 序列和 logprobs（可选）。</li>\n</ul>\n<h4 id=\"text-completion-方法\"><a href=\"#text-completion-方法\" class=\"headerlink\" title=\"text_completion 方法\"></a><strong><code>text_completion</code> 方法</strong></h4><ul>\n<li><strong>功能</strong>：对文本提示进行补全。</li>\n<li><strong>参数</strong>：<ul>\n<li><code>prompts</code>：文本提示列表。</li>\n<li><code>temperature</code>：控制生成随机性的温度参数。</li>\n<li><code>top_p</code>：top-p 采样的概率阈值。</li>\n<li><code>max_gen_len</code>：生成文本的最大长度。</li>\n<li><code>logprobs</code>：是否计算 token 的 log 概率。</li>\n<li><code>echo</code>：是否在生成结果中包含输入提示。</li>\n</ul>\n</li>\n<li><strong>返回值</strong>：文本补全的生成结果列表。</li>\n</ul>\n<h4 id=\"chat-completion-方法\"><a href=\"#chat-completion-方法\" class=\"headerlink\" title=\"chat_completion 方法\"></a><strong><code>chat_completion</code> 方法</strong></h4><ul>\n<li><strong>功能</strong>：根据对话历史生成助理的回复。</li>\n<li><strong>参数</strong>：<ul>\n<li><code>dialogs</code>：对话历史列表。</li>\n<li><code>temperature</code>：控制生成随机性的温度参数。</li>\n<li><code>top_p</code>：top-p 采样的概率阈值。</li>\n<li><code>max_gen_len</code>：生成文本的最大长度。</li>\n<li><code>logprobs</code>：是否计算 token 的 log 概率。</li>\n</ul>\n</li>\n<li><strong>返回值</strong>：对话生成的生成结果列表。</li>\n</ul>\n<hr>\n<h3 id=\"4-生成控制参数\"><a href=\"#4-生成控制参数\" class=\"headerlink\" title=\"4. 生成控制参数\"></a><strong>4. 生成控制参数</strong></h3><ul>\n<li><strong>温度（temperature）</strong>：<ul>\n<li>控制生成随机性的参数。</li>\n<li>值越大，生成结果越随机；值越小，生成结果越确定。</li>\n</ul>\n</li>\n<li><strong>top-p 采样（nucleus sampling）</strong>：<ul>\n<li>从概率累积值超过 <code>top_p</code> 的最小 token 集合中采样。</li>\n<li>用于控制生成结果的多样性和质量。</li>\n</ul>\n</li>\n<li><strong>logprobs</strong>：<ul>\n<li>是否计算生成 token 的 log 概率。</li>\n<li>用于分析生成结果的置信度。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"5-生成流程\"><a href=\"#5-生成流程\" class=\"headerlink\" title=\"5. 生成流程\"></a><strong>5. 生成流程</strong></h3><ol>\n<li><strong>输入处理</strong>：<ul>\n<li>将输入提示或对话历史转换为 tokenized prompts。</li>\n</ul>\n</li>\n<li><strong>生成文本</strong>：<ul>\n<li>使用 <code>generate</code> 方法生成 token 序列。</li>\n<li>通过温度、top-p 采样等参数控制生成过程。</li>\n</ul>\n</li>\n<li><strong>输出处理</strong>：<ul>\n<li>将生成的 token 序列解码为文本。</li>\n<li>返回生成结果，包含生成的文本、token 列表和 logprobs（可选）。</li>\n</ul>\n</li>\n</ol>\n<hr>\n<h3 id=\"6-示例\"><a href=\"#6-示例\" class=\"headerlink\" title=\"6. 示例\"></a><strong>6. 示例</strong></h3><h4 id=\"文本补全\"><a href=\"#文本补全\" class=\"headerlink\" title=\"文本补全\"></a><strong>文本补全</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">prompts = [<span class=\"hljs-string\">&quot;Once upon a time&quot;</span>]<br>results = llama.text_completion(prompts, max_gen_len=<span class=\"hljs-number\">50</span>)<br><span class=\"hljs-keyword\">for</span> result <span class=\"hljs-keyword\">in</span> results:<br>    <span class=\"hljs-built_in\">print</span>(result[<span class=\"hljs-string\">&quot;generation&quot;</span>])<br></code></pre></td></tr></table></figure>\n\n<h4 id=\"对话生成\"><a href=\"#对话生成\" class=\"headerlink\" title=\"对话生成\"></a><strong>对话生成</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">dialogs = [<br>    [&#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;user&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;What is the capital of France?&quot;</span>&#125;]<br>]<br>results = llama.chat_completion(dialogs, max_gen_len=<span class=\"hljs-number\">50</span>)<br><span class=\"hljs-keyword\">for</span> result <span class=\"hljs-keyword\">in</span> results:<br>    <span class=\"hljs-built_in\">print</span>(result[<span class=\"hljs-string\">&quot;generation&quot;</span>][<span class=\"hljs-string\">&quot;content&quot;</span>])<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"7-总结\"><a href=\"#7-总结\" class=\"headerlink\" title=\"7. 总结\"></a><strong>7. 总结</strong></h3><p><code>generation.py</code> 模块是 Llama 3 模型的核心生成模块，提供了文本补全和对话生成功能。通过温度、top-p 采样等参数，用户可以灵活控制生成过程。</p>\n<h2 id=\"build-方法\"><a href=\"#build-方法\" class=\"headerlink\" title=\"build 方法\"></a><code>build</code> 方法</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-meta\">@staticmethod</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">build</span>(<span class=\"hljs-params\"></span><br><span class=\"hljs-params\">    ckpt_dir: <span class=\"hljs-built_in\">str</span>,</span><br><span class=\"hljs-params\">    tokenizer_path: <span class=\"hljs-built_in\">str</span>,</span><br><span class=\"hljs-params\">    max_seq_len: <span class=\"hljs-built_in\">int</span>,</span><br><span class=\"hljs-params\">    max_batch_size: <span class=\"hljs-built_in\">int</span>,</span><br><span class=\"hljs-params\">    model_parallel_size: <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-built_in\">int</span>] = <span class=\"hljs-literal\">None</span>,</span><br><span class=\"hljs-params\">    seed: <span class=\"hljs-built_in\">int</span> = <span class=\"hljs-number\">1</span>,</span><br><span class=\"hljs-params\"></span>) -&gt; <span class=\"hljs-string\">&quot;Llama&quot;</span>:<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    初始化并加载 Llama 模型。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    参数:</span><br><span class=\"hljs-string\">        ckpt_dir (str): 包含模型检查点文件的目录路径。</span><br><span class=\"hljs-string\">        tokenizer_path (str): 分词器文件的路径。</span><br><span class=\"hljs-string\">        max_seq_len (int): 输入序列的最大长度。</span><br><span class=\"hljs-string\">        max_batch_size (int): 推理时的最大批次大小。</span><br><span class=\"hljs-string\">        model_parallel_size (Optional[int], optional): 模型并行的大小（GPU 数量）。如果未提供，则从环境变量中获取。默认为 None。</span><br><span class=\"hljs-string\">        seed (int, optional): 随机种子，确保所有进程的随机性一致。默认为 1。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    返回:</span><br><span class=\"hljs-string\">        Llama: 加载了模型和分词器的 Llama 实例。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    异常:</span><br><span class=\"hljs-string\">        AssertionError: 如果检查点目录中没有检查点文件，或者模型并行大小与检查点文件数量不匹配。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    注意:</span><br><span class=\"hljs-string\">        该方法会初始化分布式进程组，设置设备为 CUDA，并加载预训练模型和分词器。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 检查 max_seq_len 是否在有效范围内</span><br>    <span class=\"hljs-keyword\">assert</span> <span class=\"hljs-number\">1</span> &lt;= max_seq_len &lt;= <span class=\"hljs-number\">8192</span>, <span class=\"hljs-string\">f&quot;max_seq_len must be between 1 and 8192, got <span class=\"hljs-subst\">&#123;max_seq_len&#125;</span>.&quot;</span><br>    <span class=\"hljs-comment\"># 检查检查点目录是否存在</span><br>    <span class=\"hljs-keyword\">assert</span> os.path.isdir(ckpt_dir), <span class=\"hljs-string\">f&quot;Checkpoint directory &#x27;<span class=\"hljs-subst\">&#123;ckpt_dir&#125;</span>&#x27; does not exist.&quot;</span><br>    <span class=\"hljs-comment\"># 检查分词器文件是否存在</span><br>    <span class=\"hljs-keyword\">assert</span> os.path.isfile(tokenizer_path), <span class=\"hljs-string\">f&quot;Tokenizer file &#x27;<span class=\"hljs-subst\">&#123;tokenizer_path&#125;</span>&#x27; does not exist.&quot;</span><br><br>    <span class=\"hljs-comment\"># 如果分布式进程组未初始化，则初始化</span><br>    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> torch.distributed.is_initialized():<br>        torch.distributed.init_process_group(<span class=\"hljs-string\">&quot;nccl&quot;</span>)<br>    <span class=\"hljs-comment\"># 如果模型并行未初始化，则初始化</span><br>    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">not</span> model_parallel_is_initialized():<br>        <span class=\"hljs-comment\"># 如果未提供 model_parallel_size，则从环境变量中获取</span><br>        <span class=\"hljs-keyword\">if</span> model_parallel_size <span class=\"hljs-keyword\">is</span> <span class=\"hljs-literal\">None</span>:<br>            model_parallel_size = <span class=\"hljs-built_in\">int</span>(os.environ.get(<span class=\"hljs-string\">&quot;WORLD_SIZE&quot;</span>, <span class=\"hljs-number\">1</span>))<br>        initialize_model_parallel(model_parallel_size)<br><br>    <span class=\"hljs-comment\"># 获取当前进程的本地 rank</span><br>    local_rank = <span class=\"hljs-built_in\">int</span>(os.environ.get(<span class=\"hljs-string\">&quot;LOCAL_RANK&quot;</span>, <span class=\"hljs-number\">0</span>))<br>    <span class=\"hljs-comment\"># 设置当前进程使用的 GPU 设备</span><br>    torch.cuda.set_device(local_rank)<br><br>    <span class=\"hljs-comment\"># 设置随机种子，确保所有进程的随机性一致</span><br>    torch.manual_seed(seed)<br><br>    <span class=\"hljs-comment\"># 如果当前进程不是主进程（rank &gt; 0），则关闭标准输出</span><br>    <span class=\"hljs-keyword\">if</span> local_rank &gt; <span class=\"hljs-number\">0</span>:<br>        sys.stdout = <span class=\"hljs-built_in\">open</span>(os.devnull, <span class=\"hljs-string\">&quot;w&quot;</span>)<br><br>    <span class=\"hljs-comment\"># 记录加载模型的开始时间</span><br>    start_time = time.time()<br>    <span class=\"hljs-comment\"># 获取检查点目录中的所有 .pth 文件，并按文件名排序</span><br>    checkpoints = <span class=\"hljs-built_in\">sorted</span>(Path(ckpt_dir).glob(<span class=\"hljs-string\">&quot;*.pth&quot;</span>))<br>    <span class=\"hljs-comment\"># 检查检查点目录中是否有检查点文件</span><br>    <span class=\"hljs-keyword\">assert</span> <span class=\"hljs-built_in\">len</span>(checkpoints) &gt; <span class=\"hljs-number\">0</span>, <span class=\"hljs-string\">f&quot;no checkpoint files found in <span class=\"hljs-subst\">&#123;ckpt_dir&#125;</span>&quot;</span><br>    <span class=\"hljs-comment\"># 检查模型并行大小是否与检查点文件数量匹配</span><br>    <span class=\"hljs-keyword\">assert</span> model_parallel_size == <span class=\"hljs-built_in\">len</span>(<br>        checkpoints<br>    ), <span class=\"hljs-string\">f&quot;Loading a checkpoint for MP=<span class=\"hljs-subst\">&#123;<span class=\"hljs-built_in\">len</span>(checkpoints)&#125;</span> but world size is <span class=\"hljs-subst\">&#123;model_parallel_size&#125;</span>&quot;</span><br>    <span class=\"hljs-comment\"># 获取当前进程对应的检查点文件</span><br>    ckpt_path = checkpoints[get_model_parallel_rank()]<br>    <span class=\"hljs-comment\"># 加载检查点文件到 CPU</span><br>    checkpoint = torch.load(ckpt_path, map_location=<span class=\"hljs-string\">&quot;cpu&quot;</span>)<br>    <span class=\"hljs-comment\"># 加载模型参数文件</span><br>    <span class=\"hljs-keyword\">with</span> <span class=\"hljs-built_in\">open</span>(Path(ckpt_dir) / <span class=\"hljs-string\">&quot;params.json&quot;</span>, <span class=\"hljs-string\">&quot;r&quot;</span>) <span class=\"hljs-keyword\">as</span> f:<br>        params = json.loads(f.read())<br><br>    <span class=\"hljs-comment\"># 初始化模型参数</span><br>    model_args: ModelArgs = ModelArgs(<br>        max_seq_len=max_seq_len,<br>        max_batch_size=max_batch_size,<br>        **params,<br>    )<br>    <span class=\"hljs-comment\"># 初始化分词器</span><br>    tokenizer = Tokenizer(model_path=tokenizer_path)<br>    <span class=\"hljs-comment\"># 检查模型词汇表大小是否与分词器词汇表大小匹配</span><br>    <span class=\"hljs-keyword\">assert</span> model_args.vocab_size == tokenizer.n_words<br>    <span class=\"hljs-comment\"># 如果当前设备支持 bfloat16，则设置默认张量类型为 bfloat16，否则设置为 float16</span><br>    <span class=\"hljs-keyword\">if</span> torch.cuda.is_bf16_supported():<br>        torch.set_default_tensor_type(torch.cuda.BFloat16Tensor)<br>    <span class=\"hljs-keyword\">else</span>:<br>        torch.set_default_tensor_type(torch.cuda.HalfTensor)<br>    <span class=\"hljs-comment\"># 初始化 Transformer 模型</span><br>    model = Transformer(model_args)<br>    <span class=\"hljs-comment\"># 加载模型权重</span><br>    model.load_state_dict(checkpoint, strict=<span class=\"hljs-literal\">False</span>)<br>    <span class=\"hljs-comment\"># 打印模型加载时间</span><br>    <span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">f&quot;Loaded in <span class=\"hljs-subst\">&#123;time.time() - start_time:<span class=\"hljs-number\">.2</span>f&#125;</span> seconds&quot;</span>)<br><br>    <span class=\"hljs-comment\"># 返回 Llama 实例，包含加载的模型和分词器</span><br>    <span class=\"hljs-keyword\">return</span> Llama(model, tokenizer)<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"详细解释\"><a href=\"#详细解释\" class=\"headerlink\" title=\"详细解释\"></a><strong>详细解释</strong></h3><h4 id=\"1-参数检查\"><a href=\"#1-参数检查\" class=\"headerlink\" title=\"1. 参数检查\"></a><strong>1. 参数检查</strong></h4><ul>\n<li><strong><code>max_seq_len</code></strong>: 检查输入序列的最大长度是否在有效范围内（1 到 8192）。</li>\n<li><strong><code>ckpt_dir</code></strong>: 检查检查点目录是否存在。</li>\n<li><strong><code>tokenizer_path</code></strong>: 检查分词器文件是否存在。</li>\n</ul>\n<h4 id=\"2-分布式初始化\"><a href=\"#2-分布式初始化\" class=\"headerlink\" title=\"2. 分布式初始化\"></a><strong>2. 分布式初始化</strong></h4><ul>\n<li>如果分布式进程组未初始化，则使用 <code>torch.distributed.init_process_group</code> 初始化。</li>\n<li>如果模型并行未初始化，则根据 <code>model_parallel_size</code> 或环境变量初始化模型并行。</li>\n</ul>\n<h4 id=\"3-设备设置\"><a href=\"#3-设备设置\" class=\"headerlink\" title=\"3. 设备设置\"></a><strong>3. 设备设置</strong></h4><ul>\n<li>获取当前进程的本地 rank，并设置使用的 GPU 设备。</li>\n</ul>\n<h4 id=\"4-随机种子\"><a href=\"#4-随机种子\" class=\"headerlink\" title=\"4. 随机种子\"></a><strong>4. 随机种子</strong></h4><ul>\n<li>设置随机种子，确保所有进程的随机性一致。</li>\n</ul>\n<h4 id=\"5-检查点加载\"><a href=\"#5-检查点加载\" class=\"headerlink\" title=\"5. 检查点加载\"></a><strong>5. 检查点加载</strong></h4><ul>\n<li>获取检查点目录中的所有 <code>.pth</code> 文件，并按文件名排序。</li>\n<li>检查检查点文件数量和模型并行大小是否匹配。</li>\n<li>加载当前进程对应的检查点文件到 CPU。</li>\n</ul>\n<h4 id=\"6-模型参数加载\"><a href=\"#6-模型参数加载\" class=\"headerlink\" title=\"6. 模型参数加载\"></a><strong>6. 模型参数加载</strong></h4><ul>\n<li>从 <code>params.json</code> 文件中加载模型参数。</li>\n<li>使用 <code>ModelArgs</code> 初始化模型参数。</li>\n</ul>\n<h4 id=\"7-分词器初始化\"><a href=\"#7-分词器初始化\" class=\"headerlink\" title=\"7. 分词器初始化\"></a><strong>7. 分词器初始化</strong></h4><ul>\n<li>使用 <code>Tokenizer</code> 初始化分词器，并检查模型词汇表大小是否与分词器词汇表大小匹配。</li>\n</ul>\n<h4 id=\"8-张量类型设置\"><a href=\"#8-张量类型设置\" class=\"headerlink\" title=\"8. 张量类型设置\"></a><strong>8. 张量类型设置</strong></h4><ul>\n<li>如果当前设备支持 <code>bfloat16</code>，则设置默认张量类型为 <code>bfloat16</code>，否则设置为 <code>float16</code>。</li>\n</ul>\n<h4 id=\"9-模型初始化\"><a href=\"#9-模型初始化\" class=\"headerlink\" title=\"9. 模型初始化\"></a><strong>9. 模型初始化</strong></h4><ul>\n<li>使用 <code>Transformer</code> 初始化模型，并加载检查点中的权重。</li>\n</ul>\n<h4 id=\"10-返回-Llama-实例\"><a href=\"#10-返回-Llama-实例\" class=\"headerlink\" title=\"10. 返回 Llama 实例\"></a><strong>10. 返回 Llama 实例</strong></h4><ul>\n<li>返回包含加载的模型和分词器的 <code>Llama</code> 实例。</li>\n</ul>\n<hr>\n<h3 id=\"总结\"><a href=\"#总结\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h3><p><code>build</code> 方法负责初始化并加载 Llama 模型，包括分布式设置、设备配置、检查点加载、模型参数初始化、分词器初始化等。它是 Llama 模型的核心初始化方法，确保模型能够正确加载并准备好进行推理或训练。</p>\n<h2 id=\"generate-方法-1\"><a href=\"#generate-方法-1\" class=\"headerlink\" title=\"generate 方法\"></a><code>generate</code> 方法</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-meta\">@torch.inference_mode()</span><br><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">generate</span>(<span class=\"hljs-params\"></span><br><span class=\"hljs-params\">    self,</span><br><span class=\"hljs-params\">    prompt_tokens: <span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]],</span><br><span class=\"hljs-params\">    max_gen_len: <span class=\"hljs-built_in\">int</span>,</span><br><span class=\"hljs-params\">    temperature: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">0.6</span>,</span><br><span class=\"hljs-params\">    top_p: <span class=\"hljs-built_in\">float</span> = <span class=\"hljs-number\">0.9</span>,</span><br><span class=\"hljs-params\">    logprobs: <span class=\"hljs-built_in\">bool</span> = <span class=\"hljs-literal\">False</span>,</span><br><span class=\"hljs-params\">    echo: <span class=\"hljs-built_in\">bool</span> = <span class=\"hljs-literal\">False</span>,</span><br><span class=\"hljs-params\"></span>) -&gt; <span class=\"hljs-type\">Tuple</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">int</span>]], <span class=\"hljs-type\">Optional</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-type\">List</span>[<span class=\"hljs-built_in\">float</span>]]]]:<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    根据输入的 tokenized prompts 生成文本。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    参数:</span><br><span class=\"hljs-string\">        prompt_tokens (List[List[int]]): tokenized prompts，每个 prompt 是一个整数列表。</span><br><span class=\"hljs-string\">        max_gen_len (int): 生成文本的最大长度。</span><br><span class=\"hljs-string\">        temperature (float, optional): 控制生成随机性的温度参数。默认为 0.6。</span><br><span class=\"hljs-string\">        top_p (float, optional): top-p 采样的概率阈值。默认为 0.9。</span><br><span class=\"hljs-string\">        logprobs (bool, optional): 是否计算 token 的 log 概率。默认为 False。</span><br><span class=\"hljs-string\">        echo (bool, optional): 是否在生成结果中包含输入提示。默认为 False。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    返回:</span><br><span class=\"hljs-string\">        Tuple[List[List[int]], Optional[List[List[float]]]]: 生成的 token 序列和 logprobs（可选）。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    注意:</span><br><span class=\"hljs-string\">        该方法使用 nucleus sampling（top-p 采样）生成文本，支持通过温度参数控制生成随机性。</span><br><span class=\"hljs-string\">        如果 logprobs 为 True，则返回每个生成 token 的 log 概率。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 获取模型参数</span><br>    params = <span class=\"hljs-variable language_\">self</span>.model.params<br>    <span class=\"hljs-comment\"># 获取批次大小</span><br>    bsz = <span class=\"hljs-built_in\">len</span>(prompt_tokens)<br>    <span class=\"hljs-comment\"># 检查批次大小是否超过模型的最大批次大小</span><br>    <span class=\"hljs-keyword\">assert</span> bsz &lt;= params.max_batch_size, (bsz, params.max_batch_size)<br><br>    <span class=\"hljs-comment\"># 计算输入 prompts 的最小和最大长度</span><br>    min_prompt_len = <span class=\"hljs-built_in\">min</span>(<span class=\"hljs-built_in\">len</span>(t) <span class=\"hljs-keyword\">for</span> t <span class=\"hljs-keyword\">in</span> prompt_tokens)<br>    max_prompt_len = <span class=\"hljs-built_in\">max</span>(<span class=\"hljs-built_in\">len</span>(t) <span class=\"hljs-keyword\">for</span> t <span class=\"hljs-keyword\">in</span> prompt_tokens)<br>    <span class=\"hljs-comment\"># 检查输入 prompts 的最大长度是否超过模型的最大序列长度</span><br>    <span class=\"hljs-keyword\">assert</span> max_prompt_len &lt;= params.max_seq_len<br>    <span class=\"hljs-comment\"># 计算总长度（输入 prompts 长度 + 生成文本长度）</span><br>    total_len = <span class=\"hljs-built_in\">min</span>(params.max_seq_len, max_gen_len + max_prompt_len)<br><br>    <span class=\"hljs-comment\"># 获取填充 token 的 ID</span><br>    pad_id = <span class=\"hljs-variable language_\">self</span>.tokenizer.pad_id<br>    <span class=\"hljs-comment\"># 初始化 tokens 张量，用 pad_id 填充</span><br>    tokens = torch.full((bsz, total_len), pad_id, dtype=torch.long, device=<span class=\"hljs-string\">&quot;cuda&quot;</span>)<br>    <span class=\"hljs-comment\"># 将输入 prompts 填充到 tokens 张量中</span><br>    <span class=\"hljs-keyword\">for</span> k, t <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(prompt_tokens):<br>        tokens[k, : <span class=\"hljs-built_in\">len</span>(t)] = torch.tensor(t, dtype=torch.long, device=<span class=\"hljs-string\">&quot;cuda&quot;</span>)<br>    <span class=\"hljs-comment\"># 如果 logprobs 为 True，则初始化 token_logprobs 张量</span><br>    <span class=\"hljs-keyword\">if</span> logprobs:<br>        token_logprobs = torch.zeros_like(tokens, dtype=torch.<span class=\"hljs-built_in\">float</span>)<br><br>    <span class=\"hljs-comment\"># 初始化当前位置和 EOS（结束符）标记</span><br>    prev_pos = <span class=\"hljs-number\">0</span><br>    eos_reached = torch.tensor([<span class=\"hljs-literal\">False</span>] * bsz, device=<span class=\"hljs-string\">&quot;cuda&quot;</span>)<br>    <span class=\"hljs-comment\"># 创建输入文本的掩码（非填充部分为 True）</span><br>    input_text_mask = tokens != pad_id<br><br>    <span class=\"hljs-comment\"># 如果输入 prompts 的长度等于总长度，则直接计算 logits</span><br>    <span class=\"hljs-keyword\">if</span> min_prompt_len == total_len:<br>        logits = <span class=\"hljs-variable language_\">self</span>.model.forward(tokens, prev_pos)<br>        <span class=\"hljs-comment\"># 计算 token 的 log 概率</span><br>        token_logprobs = -F.cross_entropy(<br>            <span class=\"hljs-built_in\">input</span>=logits.transpose(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>),<br>            target=tokens,<br>            reduction=<span class=\"hljs-string\">&quot;none&quot;</span>,<br>            ignore_index=pad_id,<br>        )<br><br>    <span class=\"hljs-comment\"># 获取停止 token 的 ID</span><br>    stop_tokens = torch.tensor(<span class=\"hljs-built_in\">list</span>(<span class=\"hljs-variable language_\">self</span>.tokenizer.stop_tokens))<br><br>    <span class=\"hljs-comment\"># 逐 token 生成文本</span><br>    <span class=\"hljs-keyword\">for</span> cur_pos <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(min_prompt_len, total_len):<br>        <span class=\"hljs-comment\"># 计算当前 token 的 logits</span><br>        logits = <span class=\"hljs-variable language_\">self</span>.model.forward(tokens[:, prev_pos:cur_pos], prev_pos)<br>        <span class=\"hljs-comment\"># 如果 temperature &gt; 0，则使用温度参数和 top-p 采样生成下一个 token</span><br>        <span class=\"hljs-keyword\">if</span> temperature &gt; <span class=\"hljs-number\">0</span>:<br>            probs = torch.softmax(logits[:, -<span class=\"hljs-number\">1</span>] / temperature, dim=-<span class=\"hljs-number\">1</span>)<br>            next_token = sample_top_p(probs, top_p)<br>        <span class=\"hljs-keyword\">else</span>:<br>            <span class=\"hljs-comment\"># 如果 temperature = 0，则选择概率最大的 token</span><br>            next_token = torch.argmax(logits[:, -<span class=\"hljs-number\">1</span>], dim=-<span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-comment\"># 将下一个 token 填充到 tokens 张量中</span><br>        next_token = next_token.reshape(-<span class=\"hljs-number\">1</span>)<br>        <span class=\"hljs-comment\"># 如果当前位置在输入 prompts 范围内，则保留输入 token</span><br>        next_token = torch.where(<br>            input_text_mask[:, cur_pos], tokens[:, cur_pos], next_token<br>        )<br>        tokens[:, cur_pos] = next_token<br>        <span class=\"hljs-comment\"># 如果 logprobs 为 True，则计算 token 的 log 概率</span><br>        <span class=\"hljs-keyword\">if</span> logprobs:<br>            token_logprobs[:, prev_pos + <span class=\"hljs-number\">1</span> : cur_pos + <span class=\"hljs-number\">1</span>] = -F.cross_entropy(<br>                <span class=\"hljs-built_in\">input</span>=logits.transpose(<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>),<br>                target=tokens[:, prev_pos + <span class=\"hljs-number\">1</span> : cur_pos + <span class=\"hljs-number\">1</span>],<br>                reduction=<span class=\"hljs-string\">&quot;none&quot;</span>,<br>                ignore_index=pad_id,<br>            )<br>        <span class=\"hljs-comment\"># 检查是否生成停止 token</span><br>        eos_reached |= (~input_text_mask[:, cur_pos]) &amp; (<br>            torch.isin(next_token, stop_tokens)<br>        )<br>        <span class=\"hljs-comment\"># 更新当前位置</span><br>        prev_pos = cur_pos<br>        <span class=\"hljs-comment\"># 如果所有批次都生成停止 token，则提前结束</span><br>        <span class=\"hljs-keyword\">if</span> <span class=\"hljs-built_in\">all</span>(eos_reached):<br>            <span class=\"hljs-keyword\">break</span><br><br>    <span class=\"hljs-comment\"># 如果 logprobs 为 True，则将 token_logprobs 转换为列表</span><br>    <span class=\"hljs-keyword\">if</span> logprobs:<br>        token_logprobs = token_logprobs.tolist()<br>    <span class=\"hljs-comment\"># 初始化输出 token 序列和 logprobs</span><br>    out_tokens, out_logprobs = [], []<br>    <span class=\"hljs-comment\"># 处理每个批次的生成结果</span><br>    <span class=\"hljs-keyword\">for</span> i, toks <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">enumerate</span>(tokens.tolist()):<br>        <span class=\"hljs-comment\"># 如果 echo 为 False，则从生成部分开始截取</span><br>        start = <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">if</span> echo <span class=\"hljs-keyword\">else</span> <span class=\"hljs-built_in\">len</span>(prompt_tokens[i])<br>        toks = toks[start : <span class=\"hljs-built_in\">len</span>(prompt_tokens[i]) + max_gen_len]<br>        probs = <span class=\"hljs-literal\">None</span><br>        <span class=\"hljs-comment\"># 如果 logprobs 为 True，则截取对应的 logprobs</span><br>        <span class=\"hljs-keyword\">if</span> logprobs:<br>            probs = token_logprobs[i][start : <span class=\"hljs-built_in\">len</span>(prompt_tokens[i]) + max_gen_len]<br>        <span class=\"hljs-comment\"># 如果生成结果中包含停止 token，则截取到停止 token 之前</span><br>        <span class=\"hljs-keyword\">for</span> stop_token <span class=\"hljs-keyword\">in</span> <span class=\"hljs-variable language_\">self</span>.tokenizer.stop_tokens:<br>            <span class=\"hljs-keyword\">try</span>:<br>                eos_idx = toks.index(stop_token)<br>                toks = toks[:eos_idx]<br>                probs = probs[:eos_idx] <span class=\"hljs-keyword\">if</span> logprobs <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span><br>            <span class=\"hljs-keyword\">except</span> ValueError:<br>                <span class=\"hljs-keyword\">pass</span><br>        <span class=\"hljs-comment\"># 将结果添加到输出列表中</span><br>        out_tokens.append(toks)<br>        out_logprobs.append(probs)<br>    <span class=\"hljs-comment\"># 返回生成的 token 序列和 logprobs（可选）</span><br>    <span class=\"hljs-keyword\">return</span> (out_tokens, out_logprobs <span class=\"hljs-keyword\">if</span> logprobs <span class=\"hljs-keyword\">else</span> <span class=\"hljs-literal\">None</span>)<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"详细解释-1\"><a href=\"#详细解释-1\" class=\"headerlink\" title=\"详细解释\"></a><strong>详细解释</strong></h3><h4 id=\"1-输入处理\"><a href=\"#1-输入处理\" class=\"headerlink\" title=\"1. 输入处理\"></a><strong>1. 输入处理</strong></h4><ul>\n<li><strong><code>prompt_tokens</code></strong>: 输入的 tokenized prompts，每个 prompt 是一个整数列表。</li>\n<li><strong><code>max_gen_len</code></strong>: 生成文本的最大长度。</li>\n<li><strong><code>temperature</code></strong>: 控制生成随机性的温度参数。</li>\n<li><strong><code>top_p</code></strong>: top-p 采样的概率阈值。</li>\n<li><strong><code>logprobs</code></strong>: 是否计算 token 的 log 概率。</li>\n<li><strong><code>echo</code></strong>: 是否在生成结果中包含输入提示。</li>\n</ul>\n<h4 id=\"2-初始化\"><a href=\"#2-初始化\" class=\"headerlink\" title=\"2. 初始化\"></a><strong>2. 初始化</strong></h4><ul>\n<li><strong><code>params</code></strong>: 获取模型参数。</li>\n<li><strong><code>bsz</code></strong>: 获取批次大小。</li>\n<li><strong><code>min_prompt_len</code> 和 <code>max_prompt_len</code></strong>: 计算输入 prompts 的最小和最大长度。</li>\n<li><strong><code>total_len</code></strong>: 计算总长度（输入 prompts 长度 + 生成文本长度）。</li>\n<li><strong><code>tokens</code></strong>: 初始化 tokens 张量，用 pad_id 填充，并将输入 prompts 填充到 tokens 张量中。</li>\n</ul>\n<h4 id=\"3-生成文本\"><a href=\"#3-生成文本\" class=\"headerlink\" title=\"3. 生成文本\"></a><strong>3. 生成文本</strong></h4><ul>\n<li><strong>逐 token 生成</strong>:<ul>\n<li>使用 <code>model.forward</code> 计算当前 token 的 logits。</li>\n<li>如果 <code>temperature &gt; 0</code>，则使用温度参数和 top-p 采样生成下一个 token。</li>\n<li>如果 <code>temperature = 0</code>，则选择概率最大的 token。</li>\n<li>将下一个 token 填充到 tokens 张量中。</li>\n<li>如果 <code>logprobs</code> 为 True，则计算 token 的 log 概率。</li>\n<li>检查是否生成停止 token，如果所有批次都生成停止 token，则提前结束。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"4-输出处理\"><a href=\"#4-输出处理\" class=\"headerlink\" title=\"4. 输出处理\"></a><strong>4. 输出处理</strong></h4><ul>\n<li><strong><code>out_tokens</code> 和 <code>out_logprobs</code></strong>: 处理每个批次的生成结果。<ul>\n<li>如果 <code>echo</code> 为 False，则从生成部分开始截取。</li>\n<li>如果生成结果中包含停止 token，则截取到停止 token 之前。</li>\n</ul>\n</li>\n<li><strong>返回结果</strong>: 返回生成的 token 序列和 logprobs（可选）。</li>\n</ul>\n<hr>\n<h3 id=\"总结-1\"><a href=\"#总结-1\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h3><p><code>generate</code> 方法是 Llama 3 模型的核心生成方法，负责根据输入的 tokenized prompts 生成文本。通过温度、top-p 采样等参数，用户可以灵活控制生成过程。该方法支持计算 token 的 log 概率，并可以处理停止 token 和输入提示。</p>\n<h2 id=\"generate-详细流程图\"><a href=\"#generate-详细流程图\" class=\"headerlink\" title=\"generate 详细流程图\"></a><code>generate</code> 详细流程图</h2><p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/image-20241230115215231.png\" alt=\"generate流程图\"></p>\n<hr>\n<h3 id=\"详细步骤说明\"><a href=\"#详细步骤说明\" class=\"headerlink\" title=\"详细步骤说明\"></a><strong>详细步骤说明</strong></h3><h4 id=\"1-输入处理-1\"><a href=\"#1-输入处理-1\" class=\"headerlink\" title=\"1. 输入处理\"></a><strong>1. 输入处理</strong></h4><ul>\n<li><strong>输入</strong>: <code>prompt_tokens</code>，tokenized prompts，每个 prompt 是一个整数列表。</li>\n</ul>\n<h4 id=\"2-初始化-1\"><a href=\"#2-初始化-1\" class=\"headerlink\" title=\"2. 初始化\"></a><strong>2. 初始化</strong></h4><ul>\n<li><strong>初始化 tokens 张量</strong>: 用 pad_id 填充，并将输入 prompts 填充到 tokens 张量中。</li>\n<li><strong>计算 min_prompt_len 和 max_prompt_len</strong>: 输入 prompts 的最小和最大长度。</li>\n<li><strong>检查 max_prompt_len 是否超过 max_seq_len</strong>: 确保输入 prompts 的长度不超过模型的最大序列长度。</li>\n<li><strong>计算 total_len</strong>: 输入 prompts 长度 + 生成文本长度。</li>\n<li><strong>初始化 token_logprobs</strong>: 如果 <code>logprobs=True</code>，则初始化 token_logprobs 张量。</li>\n<li><strong>初始化 prev_pos 和 eos_reached</strong>: 当前位置和 EOS（结束符）标记。</li>\n<li><strong>创建 input_text_mask</strong>: 输入文本的掩码（非填充部分为 True）。</li>\n</ul>\n<h4 id=\"3-生成文本-1\"><a href=\"#3-生成文本-1\" class=\"headerlink\" title=\"3. 生成文本\"></a><strong>3. 生成文本</strong></h4><ul>\n<li><strong>检查 min_prompt_len 是否等于 total_len</strong>:<ul>\n<li>如果相等，则直接计算 logits 和 token_logprobs。</li>\n<li>否则，逐 token 生成文本。</li>\n</ul>\n</li>\n<li><strong>逐 token 生成文本</strong>:<ul>\n<li><strong>计算当前 token 的 logits</strong>。</li>\n<li><strong>检查 temperature 是否大于 0</strong>:<ul>\n<li>如果大于 0，则使用温度参数和 top-p 采样生成下一个 token。</li>\n<li>否则，选择概率最大的 token。</li>\n</ul>\n</li>\n<li><strong>填充下一个 token 到 tokens 张量</strong>。</li>\n<li><strong>检查 logprobs 是否为 True</strong>:<ul>\n<li>如果为 True，则计算 token 的 log 概率。</li>\n</ul>\n</li>\n<li><strong>检查是否生成停止 token</strong>。</li>\n<li><strong>更新 prev_pos</strong>。</li>\n<li><strong>检查所有批次是否都生成停止 token</strong>:<ul>\n<li>如果是，则提前结束。</li>\n<li>否则，继续生成下一个 token。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"4-输出处理-1\"><a href=\"#4-输出处理-1\" class=\"headerlink\" title=\"4. 输出处理\"></a><strong>4. 输出处理</strong></h4><ul>\n<li><strong>处理每个批次的生成结果</strong>:<ul>\n<li><strong>检查 echo 是否为 False</strong>:<ul>\n<li>如果为 False，则从生成部分开始截取。</li>\n<li>否则，保留输入提示。</li>\n</ul>\n</li>\n<li><strong>截取到停止 token 之前</strong>。</li>\n<li><strong>将结果添加到输出列表中</strong>。</li>\n</ul>\n</li>\n<li><strong>返回生成的 token 序列和 logprobs（可选）</strong>。</li>\n</ul>\n<hr>\n<h3 id=\"总结-2\"><a href=\"#总结-2\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h3><p><code>generate</code> 方法的流程图清晰地展示了从输入到输出的完整生成过程，包括初始化、逐 token 生成和输出处理。通过该流程图，可以更好地理解 Llama 3 模型的文本生成机制。</p>\n<h2 id=\"text-completion-和-chat-completion\"><a href=\"#text-completion-和-chat-completion\" class=\"headerlink\" title=\"text_completion 和 chat_completion\"></a><code>text_completion</code> 和 <code>chat_completion</code></h2><hr>\n<h3 id=\"1-text-completion-方法\"><a href=\"#1-text-completion-方法\" class=\"headerlink\" title=\"1. text_completion 方法\"></a><strong>1. <code>text_completion</code> 方法</strong></h3><h4 id=\"功能\"><a href=\"#功能\" class=\"headerlink\" title=\"功能\"></a><strong>功能</strong></h4><p>对给定的文本提示进行补全，生成后续文本。</p>\n<h4 id=\"参数\"><a href=\"#参数\" class=\"headerlink\" title=\"参数\"></a><strong>参数</strong></h4><ul>\n<li><strong><code>prompts</code></strong>: 文本提示列表，每个提示是一个字符串。</li>\n<li><strong><code>temperature</code></strong>: 控制生成随机性的温度参数。值越大，生成结果越随机；值越小，生成结果越确定。</li>\n<li><strong><code>top_p</code></strong>: top-p 采样的概率阈值。用于控制生成结果的多样性和质量。</li>\n<li><strong><code>max_gen_len</code></strong>: 生成文本的最大长度。如果未提供，则使用模型的最大序列长度减 1。</li>\n<li><strong><code>logprobs</code></strong>: 是否计算 token 的 log 概率。默认为 False。</li>\n<li><strong><code>echo</code></strong>: 是否在生成结果中包含输入提示。默认为 False。</li>\n</ul>\n<h4 id=\"返回值\"><a href=\"#返回值\" class=\"headerlink\" title=\"返回值\"></a><strong>返回值</strong></h4><ul>\n<li><strong><code>List[CompletionPrediction]</code></strong>: 文本补全的生成结果列表，每个结果包含生成的文本、token 列表和 logprobs（可选）。</li>\n</ul>\n<h4 id=\"代码逻辑\"><a href=\"#代码逻辑\" class=\"headerlink\" title=\"代码逻辑\"></a><strong>代码逻辑</strong></h4><ol>\n<li><strong>检查 <code>max_gen_len</code></strong>:<ul>\n<li>如果未提供 <code>max_gen_len</code>，则使用模型的最大序列长度减 1。</li>\n</ul>\n</li>\n<li><strong>编码输入提示</strong>:<ul>\n<li>使用分词器将输入提示编码为 tokenized prompts。</li>\n</ul>\n</li>\n<li><strong>调用 <code>generate</code> 方法</strong>:<ul>\n<li>使用 <code>generate</code> 方法生成 token 序列。</li>\n</ul>\n</li>\n<li><strong>解码生成结果</strong>:<ul>\n<li>将生成的 token 序列解码为文本。</li>\n</ul>\n</li>\n<li><strong>返回生成结果</strong>:<ul>\n<li>如果 <code>logprobs</code> 为 True，则返回生成的文本、token 列表和 logprobs。</li>\n<li>否则，仅返回生成的文本。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"示例\"><a href=\"#示例\" class=\"headerlink\" title=\"示例\"></a><strong>示例</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">prompts = [<span class=\"hljs-string\">&quot;Once upon a time&quot;</span>]<br>results = llama.text_completion(prompts, max_gen_len=<span class=\"hljs-number\">50</span>)<br><span class=\"hljs-keyword\">for</span> result <span class=\"hljs-keyword\">in</span> results:<br>    <span class=\"hljs-built_in\">print</span>(result[<span class=\"hljs-string\">&quot;generation&quot;</span>])<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"2-chat-completion-方法\"><a href=\"#2-chat-completion-方法\" class=\"headerlink\" title=\"2. chat_completion 方法\"></a><strong>2. <code>chat_completion</code> 方法</strong></h3><h4 id=\"功能-1\"><a href=\"#功能-1\" class=\"headerlink\" title=\"功能\"></a><strong>功能</strong></h4><p>根据对话历史生成助理的回复。</p>\n<h4 id=\"参数-1\"><a href=\"#参数-1\" class=\"headerlink\" title=\"参数\"></a><strong>参数</strong></h4><ul>\n<li><strong><code>dialogs</code></strong>: 对话历史列表，每个对话是一个消息列表，每个消息包含角色（<code>role</code>）和内容（<code>content</code>）。</li>\n<li><strong><code>temperature</code></strong>: 控制生成随机性的温度参数。值越大，生成结果越随机；值越小，生成结果越确定。</li>\n<li><strong><code>top_p</code></strong>: top-p 采样的概率阈值。用于控制生成结果的多样性和质量。</li>\n<li><strong><code>max_gen_len</code></strong>: 生成文本的最大长度。如果未提供，则使用模型的最大序列长度减 1。</li>\n<li><strong><code>logprobs</code></strong>: 是否计算 token 的 log 概率。默认为 False。</li>\n</ul>\n<h4 id=\"返回值-1\"><a href=\"#返回值-1\" class=\"headerlink\" title=\"返回值\"></a><strong>返回值</strong></h4><ul>\n<li><strong><code>List[ChatPrediction]</code></strong>: 对话生成的生成结果列表，每个结果包含助理的回复、token 列表和 logprobs（可选）。</li>\n</ul>\n<h4 id=\"代码逻辑-1\"><a href=\"#代码逻辑-1\" class=\"headerlink\" title=\"代码逻辑\"></a><strong>代码逻辑</strong></h4><ol>\n<li><strong>检查 <code>max_gen_len</code></strong>:<ul>\n<li>如果未提供 <code>max_gen_len</code>，则使用模型的最大序列长度减 1。</li>\n</ul>\n</li>\n<li><strong>编码对话历史</strong>:<ul>\n<li>使用 <code>ChatFormat</code> 将对话历史编码为 tokenized prompts。</li>\n</ul>\n</li>\n<li><strong>调用 <code>generate</code> 方法</strong>:<ul>\n<li>使用 <code>generate</code> 方法生成 token 序列。</li>\n</ul>\n</li>\n<li><strong>解码生成结果</strong>:<ul>\n<li>将生成的 token 序列解码为文本。</li>\n</ul>\n</li>\n<li><strong>返回生成结果</strong>:<ul>\n<li>如果 <code>logprobs</code> 为 True，则返回助理的回复、token 列表和 logprobs。</li>\n<li>否则，仅返回助理的回复。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"示例-1\"><a href=\"#示例-1\" class=\"headerlink\" title=\"示例\"></a><strong>示例</strong></h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\">dialogs = [<br>    [&#123;<span class=\"hljs-string\">&quot;role&quot;</span>: <span class=\"hljs-string\">&quot;user&quot;</span>, <span class=\"hljs-string\">&quot;content&quot;</span>: <span class=\"hljs-string\">&quot;What is the capital of France?&quot;</span>&#125;]<br>]<br>results = llama.chat_completion(dialogs, max_gen_len=<span class=\"hljs-number\">50</span>)<br><span class=\"hljs-keyword\">for</span> result <span class=\"hljs-keyword\">in</span> results:<br>    <span class=\"hljs-built_in\">print</span>(result[<span class=\"hljs-string\">&quot;generation&quot;</span>][<span class=\"hljs-string\">&quot;content&quot;</span>])<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"3-主要区别\"><a href=\"#3-主要区别\" class=\"headerlink\" title=\"3. 主要区别\"></a><strong>3. 主要区别</strong></h3><table>\n<thead>\n<tr>\n<th>特性</th>\n<th><code>text_completion</code></th>\n<th><code>chat_completion</code></th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>输入</strong></td>\n<td>文本提示列表</td>\n<td>对话历史列表</td>\n</tr>\n<tr>\n<td><strong>输出</strong></td>\n<td>文本补全结果</td>\n<td>助理的回复</td>\n</tr>\n<tr>\n<td><strong>编码方式</strong></td>\n<td>直接使用分词器编码</td>\n<td>使用 <code>ChatFormat</code> 编码对话历史</td>\n</tr>\n<tr>\n<td><strong>适用场景</strong></td>\n<td>单轮文本补全</td>\n<td>多轮对话生成</td>\n</tr>\n<tr>\n<td><strong>返回格式</strong></td>\n<td><code>CompletionPrediction</code></td>\n<td><code>ChatPrediction</code></td>\n</tr>\n</tbody></table>\n<hr>\n<h3 id=\"4-生成控制参数-1\"><a href=\"#4-生成控制参数-1\" class=\"headerlink\" title=\"4. 生成控制参数\"></a><strong>4. 生成控制参数</strong></h3><ul>\n<li><strong>温度（temperature）</strong>:<ul>\n<li>控制生成随机性的参数。</li>\n<li>值越大，生成结果越随机；值越小，生成结果越确定。</li>\n</ul>\n</li>\n<li><strong>top-p 采样（nucleus sampling）</strong>:<ul>\n<li>从概率累积值超过 <code>top_p</code> 的最小 token 集合中采样。</li>\n<li>用于控制生成结果的多样性和质量。</li>\n</ul>\n</li>\n<li><strong>logprobs</strong>:<ul>\n<li>是否计算生成 token 的 log 概率。</li>\n<li>用于分析生成结果的置信度。</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"5-总结\"><a href=\"#5-总结\" class=\"headerlink\" title=\"5. 总结\"></a><strong>5. 总结</strong></h3><ul>\n<li><strong><code>text_completion</code></strong>: 用于文本补全，适用于单轮文本生成任务。</li>\n<li><strong><code>chat_completion</code></strong>: 用于对话生成，适用于多轮对话任务。</li>\n<li>两者都通过 <code>generate</code> 方法实现核心生成逻辑，并支持温度、top-p 采样等参数控制生成过程。</li>\n</ul>\n<h2 id=\"sample-top-p\"><a href=\"#sample-top-p\" class=\"headerlink\" title=\"sample_top_p\"></a>sample_top_p</h2><p>该函数实现了 <strong>top-p 采样（nucleus sampling）</strong>，用于从概率分布中选择 token。</p>\n<hr>\n<h3 id=\"代码注释\"><a href=\"#代码注释\" class=\"headerlink\" title=\"代码注释\"></a><strong>代码注释</strong></h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><code class=\"hljs python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">sample_top_p</span>(<span class=\"hljs-params\">probs, p</span>):<br>    <span class=\"hljs-string\">&quot;&quot;&quot;</span><br><span class=\"hljs-string\">    对概率分布进行 top-p 采样（nucleus sampling）。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    参数:</span><br><span class=\"hljs-string\">        probs (torch.Tensor): 概率分布张量，形状为 (batch_size, vocab_size)。</span><br><span class=\"hljs-string\">        p (float): top-p 采样的概率阈值，取值范围为 (0, 1]。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    返回:</span><br><span class=\"hljs-string\">        torch.Tensor: 采样得到的 token 索引，形状为 (batch_size, 1)。</span><br><span class=\"hljs-string\"></span><br><span class=\"hljs-string\">    注意:</span><br><span class=\"hljs-string\">        top-p 采样从概率累积值超过 p 的最小 token 集合中采样，用于控制生成结果的多样性和质量。</span><br><span class=\"hljs-string\">    &quot;&quot;&quot;</span><br>    <span class=\"hljs-comment\"># 对概率分布进行降序排序，并获取排序后的概率和索引</span><br>    probs_sort, probs_idx = torch.sort(probs, dim=-<span class=\"hljs-number\">1</span>, descending=<span class=\"hljs-literal\">True</span>)<br>    <span class=\"hljs-comment\"># 计算概率分布的累积和</span><br>    probs_sum = torch.cumsum(probs_sort, dim=-<span class=\"hljs-number\">1</span>)<br>    <span class=\"hljs-comment\"># 创建掩码，标记概率累积值超过 p 的 token</span><br>    mask = probs_sum - probs_sort &gt; p<br>    <span class=\"hljs-comment\"># 将掩码对应的概率置为 0</span><br>    probs_sort[mask] = <span class=\"hljs-number\">0.0</span><br>    <span class=\"hljs-comment\"># 对剩余的概率进行归一化</span><br>    probs_sort.div_(probs_sort.<span class=\"hljs-built_in\">sum</span>(dim=-<span class=\"hljs-number\">1</span>, keepdim=<span class=\"hljs-literal\">True</span>))<br>    <span class=\"hljs-comment\"># 从归一化后的概率分布中进行多项式采样</span><br>    next_token = torch.multinomial(probs_sort, num_samples=<span class=\"hljs-number\">1</span>)<br>    <span class=\"hljs-comment\"># 根据采样结果获取原始 token 索引</span><br>    next_token = torch.gather(probs_idx, -<span class=\"hljs-number\">1</span>, next_token)<br>    <span class=\"hljs-keyword\">return</span> next_token<br></code></pre></td></tr></table></figure>\n\n<hr>\n<h3 id=\"详细解释-2\"><a href=\"#详细解释-2\" class=\"headerlink\" title=\"详细解释\"></a><strong>详细解释</strong></h3><h4 id=\"1-输入参数\"><a href=\"#1-输入参数\" class=\"headerlink\" title=\"1. 输入参数\"></a><strong>1. 输入参数</strong></h4><ul>\n<li><strong><code>probs</code></strong>: 概率分布张量，形状为 <code>(batch_size, vocab_size)</code>，表示每个 token 的概率。</li>\n<li><strong><code>p</code></strong>: top-p 采样的概率阈值，取值范围为 <code>(0, 1]</code>。例如，<code>p=0.9</code> 表示从概率累积值超过 0.9 的最小 token 集合中采样。</li>\n</ul>\n<h4 id=\"2-概率排序\"><a href=\"#2-概率排序\" class=\"headerlink\" title=\"2. 概率排序\"></a><strong>2. 概率排序</strong></h4><ul>\n<li><strong><code>torch.sort</code></strong>: 对概率分布进行降序排序，返回排序后的概率 <code>probs_sort</code> 和对应的索引 <code>probs_idx</code>。</li>\n</ul>\n<h4 id=\"3-计算累积和\"><a href=\"#3-计算累积和\" class=\"headerlink\" title=\"3. 计算累积和\"></a><strong>3. 计算累积和</strong></h4><ul>\n<li><strong><code>torch.cumsum</code></strong>: 计算排序后概率的累积和 <code>probs_sum</code>。</li>\n</ul>\n<h4 id=\"4-创建掩码\"><a href=\"#4-创建掩码\" class=\"headerlink\" title=\"4. 创建掩码\"></a><strong>4. 创建掩码</strong></h4><ul>\n<li><strong><code>mask</code></strong>: 标记概率累积值超过 <code>p</code> 的 token。例如，如果 <code>p=0.9</code>，则掩码标记概率累积值超过 0.9 的 token。</li>\n</ul>\n<h4 id=\"5-概率置零\"><a href=\"#5-概率置零\" class=\"headerlink\" title=\"5. 概率置零\"></a><strong>5. 概率置零</strong></h4><ul>\n<li><strong><code>probs_sort[mask] = 0.0</code></strong>: 将掩码对应的概率置为 0，排除概率累积值超过 <code>p</code> 的 token。</li>\n</ul>\n<h4 id=\"6-归一化\"><a href=\"#6-归一化\" class=\"headerlink\" title=\"6. 归一化\"></a><strong>6. 归一化</strong></h4><ul>\n<li><strong><code>probs_sort.div_</code></strong>: 对剩余的概率进行归一化，使其总和为 1。</li>\n</ul>\n<h4 id=\"7-多项式采样\"><a href=\"#7-多项式采样\" class=\"headerlink\" title=\"7. 多项式采样\"></a><strong>7. 多项式采样</strong></h4><ul>\n<li><strong><code>torch.multinomial</code></strong>: 从归一化后的概率分布中进行多项式采样，返回采样得到的 token 索引。</li>\n</ul>\n<h4 id=\"8-获取原始索引\"><a href=\"#8-获取原始索引\" class=\"headerlink\" title=\"8. 获取原始索引\"></a><strong>8. 获取原始索引</strong></h4><ul>\n<li><strong><code>torch.gather</code></strong>: 根据采样结果获取原始 token 索引。</li>\n</ul>\n<h4 id=\"9-返回结果\"><a href=\"#9-返回结果\" class=\"headerlink\" title=\"9. 返回结果\"></a><strong>9. 返回结果</strong></h4><ul>\n<li><strong><code>next_token</code></strong>: 采样得到的 token 索引，形状为 <code>(batch_size, 1)</code>。</li>\n</ul>\n<hr>\n<h3 id=\"示例-2\"><a href=\"#示例-2\" class=\"headerlink\" title=\"示例\"></a><strong>示例</strong></h3><p>假设有以下概率分布和参数：</p>\n<ul>\n<li><strong><code>probs</code></strong>: <code>[[0.1, 0.4, 0.2, 0.3]]</code>，形状为 <code>(1, 4)</code>。</li>\n<li><strong><code>p</code></strong>: <code>0.9</code>。</li>\n</ul>\n<h4 id=\"执行步骤\"><a href=\"#执行步骤\" class=\"headerlink\" title=\"执行步骤\"></a><strong>执行步骤</strong></h4><ol>\n<li><strong>排序</strong>:<ul>\n<li><code>probs_sort</code>: <code>[[0.4, 0.3, 0.2, 0.1]]</code>。</li>\n<li><code>probs_idx</code>: <code>[[1, 3, 2, 0]]</code>。</li>\n</ul>\n</li>\n<li><strong>计算累积和</strong>:<ul>\n<li><code>probs_sum</code>: <code>[[0.4, 0.7, 0.9, 1.0]]</code>。</li>\n</ul>\n</li>\n<li><strong>创建掩码</strong>:<ul>\n<li><code>mask</code>: <code>[[False, False, True, True]]</code>。</li>\n</ul>\n</li>\n<li><strong>概率置零</strong>:<ul>\n<li><code>probs_sort</code>: <code>[[0.4, 0.3, 0.0, 0.0]]</code>。</li>\n</ul>\n</li>\n<li><strong>归一化</strong>:<ul>\n<li><code>probs_sort</code>: <code>[[0.57, 0.43, 0.0, 0.0]]</code>。</li>\n</ul>\n</li>\n<li><strong>多项式采样</strong>:<ul>\n<li><code>next_token</code>: <code>[[1]]</code>（假设采样结果为 1）。</li>\n</ul>\n</li>\n<li><strong>获取原始索引</strong>:<ul>\n<li><code>next_token</code>: <code>[[3]]</code>。</li>\n</ul>\n</li>\n</ol>\n<h4 id=\"返回结果\"><a href=\"#返回结果\" class=\"headerlink\" title=\"返回结果\"></a><strong>返回结果</strong></h4><ul>\n<li><code>next_token</code>: <code>[[3]]</code>。</li>\n</ul>\n<hr>\n<h3 id=\"总结-3\"><a href=\"#总结-3\" class=\"headerlink\" title=\"总结\"></a><strong>总结</strong></h3><p><code>sample_top_p</code> 函数实现了 top-p 采样（nucleus sampling），用于从概率分布中选择 token。通过控制概率阈值 <code>p</code>，可以灵活调整生成结果的多样性和质量。该函数是 Llama 3 模型生成过程的核心组件之一。</p>\n<p>文章合集：<a href=\"https://github.com/chongzicbo/ReadWriteThink/tree/main\">chongzicbo&#x2F;ReadWriteThink: 博学而笃志，切问而近思 (github.com)</a></p>\n<p>个人博客：<a href=\"https://chongzicbo.github.io/\">程博仕</a></p>\n<p>微信公众号：</p>\n<p><img src=\"https://raw.githubusercontent.com/chongzicbo/images/main/picgo/%E4%BA%8C%E7%BB%B4%E7%A0%81.jpg\" alt=\"微信公众号\"></p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cm5esmr3d0006hghie6d8fkog","category_id":"cm5esmr3d0005hghihffdgl7d","_id":"cm5esmr3k000uhghicngw8ibm"},{"post_id":"cm5esmr3d0006hghie6d8fkog","category_id":"cm5esmr3h000ghghi6ctc29at","_id":"cm5esmr3l000whghifkvydq03"},{"post_id":"cm5esmr380001hghi7d0f4grd","category_id":"cm5esmr3d0005hghihffdgl7d","_id":"cm5esmr3l0011hghi0nuub194"},{"post_id":"cm5esmr380001hghi7d0f4grd","category_id":"cm5esmr3h000ghghi6ctc29at","_id":"cm5esmr3l0014hghiaytz2293"},{"post_id":"cm5esmr3d0007hghifwlr0ami","category_id":"cm5esmr3d0005hghihffdgl7d","_id":"cm5esmr3m0019hghic2hogxym"},{"post_id":"cm5esmr3d0007hghifwlr0ami","category_id":"cm5esmr3j000shghievwq2lnp","_id":"cm5esmr3m001chghi3cwybu1o"},{"post_id":"cm5esmr3a0002hghi6y9bbodj","category_id":"cm5esmr3d0005hghihffdgl7d","_id":"cm5esmr3o001lhghidvpyg66y"},{"post_id":"cm5esmr3a0002hghi6y9bbodj","category_id":"cm5esmr3h000ghghi6ctc29at","_id":"cm5esmr3p001ohghiafs11hax"},{"post_id":"cm5esmr3g000ehghiac6sa115","category_id":"cm5esmr3d0005hghihffdgl7d","_id":"cm5esmr3p001uhghi22c9csl3"},{"post_id":"cm5esmr3g000ehghiac6sa115","category_id":"cm5esmr3o001jhghihrkf1azk","_id":"cm5esmr3p001whghi6bkjhwhl"},{"post_id":"cm5esmr3c0004hghi87mpdeoz","category_id":"cm5esmr3f000chghi37ze694q","_id":"cm5esmr3p0021hghi4h0yggg5"},{"post_id":"cm5esmr3c0004hghi87mpdeoz","category_id":"cm5esmr3p001qhghi0mpg4sul","_id":"cm5esmr3p0023hghidhe585ue"},{"post_id":"cm5esmr3g000fhghi4lbd6vgh","category_id":"cm5esmr3f000chghi37ze694q","_id":"cm5esmr3q0027hghid5z17vzt"},{"post_id":"cm5esmr3g000fhghi4lbd6vgh","category_id":"cm5esmr3p001qhghi0mpg4sul","_id":"cm5esmr3q0028hghi4mdf07jj"},{"post_id":"cm5esmr3h000ihghi9p974qxc","category_id":"cm5esmr3f000chghi37ze694q","_id":"cm5esmr3q002bhghi47eg7djz"},{"post_id":"cm5esmr3h000ihghi9p974qxc","category_id":"cm5esmr3p001zhghie3uggp5u","_id":"cm5esmr3q002chghiagm1b4sc"},{"post_id":"cm5esmr3j000ohghid1ndcnw1","category_id":"cm5esmr3f000chghi37ze694q","_id":"cm5esmr3q002khghi4ad8bp64"},{"post_id":"cm5esmr3j000ohghid1ndcnw1","category_id":"cm5esmr3p001zhghie3uggp5u","_id":"cm5esmr3q002mhghi766tf0u1"},{"post_id":"cm5esmr3j000qhghi3wy489mz","category_id":"cm5esmr3f000chghi37ze694q","_id":"cm5esmr3q002phghi011tg0c0"},{"post_id":"cm5esmr3j000qhghi3wy489mz","category_id":"cm5esmr3p001zhghie3uggp5u","_id":"cm5esmr3q002qhghighzq600o"},{"post_id":"cm5esmr3f000ahghi1toi3mtv","category_id":"cm5esmr3f000chghi37ze694q","_id":"cm5esmr3r0030hghig91fe23o"},{"post_id":"cm5esmr3f000ahghi1toi3mtv","category_id":"cm5esmr3p001qhghi0mpg4sul","_id":"cm5esmr3r0033hghi6b34cgoe"},{"post_id":"cm5esmr3n001ehghi4m3n9u3u","category_id":"cm5esmr3d0005hghihffdgl7d","_id":"cm5esmr3s003fhghic0yrgcum"},{"post_id":"cm5esmr3n001ehghi4m3n9u3u","category_id":"cm5esmr3j000shghievwq2lnp","_id":"cm5esmr3s003ihghi6stx5acp"},{"post_id":"cm5esmr3n001ehghi4m3n9u3u","category_id":"cm5esmr3s0038hghigzjdf17a","_id":"cm5esmr3s003khghibp6zev9w"},{"post_id":"cm5esmr3f000bhghidw761x0s","category_id":"cm5esmr3f000chghi37ze694q","_id":"cm5esmr3t003mhghifvpx02n2"},{"post_id":"cm5esmr3f000bhghidw761x0s","category_id":"cm5esmr3p001qhghi0mpg4sul","_id":"cm5esmr3t003ohghif1rk5qw8"},{"post_id":"cm5esmr3o001ihghib9xdh2a9","category_id":"cm5esmr3d0005hghihffdgl7d","_id":"cm5esmr3t003uhghiddhlbkbk"},{"post_id":"cm5esmr3o001ihghib9xdh2a9","category_id":"cm5esmr3o001jhghihrkf1azk","_id":"cm5esmr3t003whghi30kc690x"},{"post_id":"cm5esmr3o001ihghib9xdh2a9","category_id":"cm5esmr3s003jhghi65syb47s","_id":"cm5esmr3t003zhghi5khk6i5y"},{"post_id":"cm5esmr3o001mhghifa1u288r","category_id":"cm5esmr3d0005hghihffdgl7d","_id":"cm5esmr3t0040hghi2d3j8eo5"},{"post_id":"cm5esmr3o001mhghifa1u288r","category_id":"cm5esmr3o001jhghihrkf1azk","_id":"cm5esmr3u0043hghie3z7hr83"},{"post_id":"cm5esmr3o001mhghifa1u288r","category_id":"cm5esmr3s003jhghi65syb47s","_id":"cm5esmr3u0045hghi6c5xc946"},{"post_id":"cm5esmr3i000khghih9bv44x0","category_id":"cm5esmr3p0025hghi0rw5c33n","_id":"cm5esmr3u0049hghi05kfd66p"},{"post_id":"cm5esmr3i000khghih9bv44x0","category_id":"cm5esmr3t003rhghi22iqc0oi","_id":"cm5esmr3u004bhghi7me11iz8"},{"post_id":"cm5esmr3k000thghiecotbrwk","category_id":"cm5esmr3p0025hghi0rw5c33n","_id":"cm5esmr3u004ehghif3cw4vvj"},{"post_id":"cm5esmr3k000thghiecotbrwk","category_id":"cm5esmr3t003rhghi22iqc0oi","_id":"cm5esmr3u004fhghi9ad46tkg"},{"post_id":"cm5esmr3k000vhghi61owehuf","category_id":"cm5esmr3p0025hghi0rw5c33n","_id":"cm5esmr3v004ihghi8n0ydn9q"},{"post_id":"cm5esmr3k000vhghi61owehuf","category_id":"cm5esmr3t003rhghi22iqc0oi","_id":"cm5esmr3v004khghi1w2kad12"},{"post_id":"cm5esmr3l000yhghidw1kfz3z","category_id":"cm5esmr3f000chghi37ze694q","_id":"cm5esmr3v004nhghif2jvhh0d"},{"post_id":"cm5esmr3l000yhghidw1kfz3z","category_id":"cm5esmr3q002rhghi8bhchl0y","_id":"cm5esmr3v004qhghigculecza"},{"post_id":"cm5esmr3l000yhghidw1kfz3z","category_id":"cm5esmr3u0046hghi5oy77hrb","_id":"cm5esmr3v004shghi87zd2pjc"},{"post_id":"cm5esmr3l0012hghic2ao6wp7","category_id":"cm5esmr3f000chghi37ze694q","_id":"cm5esmr3v004uhghi71hycgln"},{"post_id":"cm5esmr3l0012hghic2ao6wp7","category_id":"cm5esmr3q002rhghi8bhchl0y","_id":"cm5esmr3v004whghihyjb5k70"},{"post_id":"cm5esmr3l0012hghic2ao6wp7","category_id":"cm5esmr3u0046hghi5oy77hrb","_id":"cm5esmr3v004zhghidtgle5u4"},{"post_id":"cm5esmr3m0016hghi4f6t6yyu","category_id":"cm5esmr3f000chghi37ze694q","_id":"cm5esmr3v0050hghih803ermq"},{"post_id":"cm5esmr3m0016hghi4f6t6yyu","category_id":"cm5esmr3q002rhghi8bhchl0y","_id":"cm5esmr3w0052hghihn1p5zln"},{"post_id":"cm5esmr3m0016hghi4f6t6yyu","category_id":"cm5esmr3u0046hghi5oy77hrb","_id":"cm5esmr3w0054hghi1fj46tyd"},{"post_id":"cm5esmr3m001ahghi4bvd2opo","category_id":"cm5esmr3d0005hghihffdgl7d","_id":"cm5esmr3w0057hghi4qgkc9a6"},{"post_id":"cm5esmr3m001ahghi4bvd2opo","category_id":"cm5esmr3o001jhghihrkf1azk","_id":"cm5esmr3w0058hghigpl69lde"},{"post_id":"cm5esmr3m001ahghi4bvd2opo","category_id":"cm5esmr3s003jhghi65syb47s","_id":"cm5esmr3w005ahghi3el803ms"},{"post_id":"cm5esmr3n001ghghi2u8fdsj2","category_id":"cm5esmr3d0005hghihffdgl7d","_id":"cm5esmr3w005chghi5dwb1ovw"},{"post_id":"cm5esmr3n001ghghi2u8fdsj2","category_id":"cm5esmr3o001jhghihrkf1azk","_id":"cm5esmr3w005fhghi6vm781n2"},{"post_id":"cm5esmr3n001ghghi2u8fdsj2","category_id":"cm5esmr3s003jhghi65syb47s","_id":"cm5esmr3w005ghghi447712s6"}],"PostTag":[{"post_id":"cm5esmr380001hghi7d0f4grd","tag_id":"cm5esmr3b0003hghihnccggec","_id":"cm5esmr3i000jhghig7hp0u9x"},{"post_id":"cm5esmr380001hghi7d0f4grd","tag_id":"cm5esmr3e0008hghi0li4dhoe","_id":"cm5esmr3i000lhghi8hvv1yfq"},{"post_id":"cm5esmr380001hghi7d0f4grd","tag_id":"cm5esmr3g000dhghi1arb42z4","_id":"cm5esmr3j000phghiff1wh4sb"},{"post_id":"cm5esmr3a0002hghi6y9bbodj","tag_id":"cm5esmr3b0003hghihnccggec","_id":"cm5esmr3l0010hghid9828p64"},{"post_id":"cm5esmr3a0002hghi6y9bbodj","tag_id":"cm5esmr3e0008hghi0li4dhoe","_id":"cm5esmr3l0013hghi20nj1zl7"},{"post_id":"cm5esmr3a0002hghi6y9bbodj","tag_id":"cm5esmr3g000dhghi1arb42z4","_id":"cm5esmr3m0018hghi804m6bpu"},{"post_id":"cm5esmr3c0004hghi87mpdeoz","tag_id":"cm5esmr3l000xhghi6zhr5jpt","_id":"cm5esmr3m001bhghi1dvu7bkc"},{"post_id":"cm5esmr3d0006hghie6d8fkog","tag_id":"cm5esmr3b0003hghihnccggec","_id":"cm5esmr3o001khghi73lec8b4"},{"post_id":"cm5esmr3d0006hghie6d8fkog","tag_id":"cm5esmr3e0008hghi0li4dhoe","_id":"cm5esmr3p001nhghidro57red"},{"post_id":"cm5esmr3d0006hghie6d8fkog","tag_id":"cm5esmr3g000dhghi1arb42z4","_id":"cm5esmr3p001rhghi39p88p6p"},{"post_id":"cm5esmr3d0007hghifwlr0ami","tag_id":"cm5esmr3b0003hghihnccggec","_id":"cm5esmr3p001vhghibowxdqy3"},{"post_id":"cm5esmr3d0007hghifwlr0ami","tag_id":"cm5esmr3n001hhghi4nhk89tz","_id":"cm5esmr3p001xhghi1hem75iw"},{"post_id":"cm5esmr3d0007hghifwlr0ami","tag_id":"cm5esmr3p001phghicm0i91eu","_id":"cm5esmr3p0020hghi1b5k8h4v"},{"post_id":"cm5esmr3f000ahghi1toi3mtv","tag_id":"cm5esmr3l000xhghi6zhr5jpt","_id":"cm5esmr3p0022hghic4k54p2c"},{"post_id":"cm5esmr3f000bhghidw761x0s","tag_id":"cm5esmr3l000xhghi6zhr5jpt","_id":"cm5esmr3q0026hghic8x52t19"},{"post_id":"cm5esmr3g000ehghiac6sa115","tag_id":"cm5esmr3b0003hghihnccggec","_id":"cm5esmr3q002fhghiho0e8flu"},{"post_id":"cm5esmr3g000ehghiac6sa115","tag_id":"cm5esmr3p0024hghibq273zfp","_id":"cm5esmr3q002ghghib0ks9e1p"},{"post_id":"cm5esmr3g000ehghiac6sa115","tag_id":"cm5esmr3q0029hghi9utq6ecm","_id":"cm5esmr3q002jhghi6ruig95w"},{"post_id":"cm5esmr3g000fhghi4lbd6vgh","tag_id":"cm5esmr3l000xhghi6zhr5jpt","_id":"cm5esmr3q002lhghi732b4co7"},{"post_id":"cm5esmr3h000ihghi9p974qxc","tag_id":"cm5esmr3q002hhghi7jdw1hcw","_id":"cm5esmr3r002thghidl7ugbcg"},{"post_id":"cm5esmr3h000ihghi9p974qxc","tag_id":"cm5esmr3q002ohghifhml902o","_id":"cm5esmr3r002uhghi6hlz9mft"},{"post_id":"cm5esmr3i000khghih9bv44x0","tag_id":"cm5esmr3r002shghicanmc0c4","_id":"cm5esmr3r0032hghibr0w91x4"},{"post_id":"cm5esmr3i000khghih9bv44x0","tag_id":"cm5esmr3r002whghi2xkdcdpq","_id":"cm5esmr3r0035hghi9w6x2gym"},{"post_id":"cm5esmr3i000khghih9bv44x0","tag_id":"cm5esmr3r002yhghifr3z362g","_id":"cm5esmr3s0037hghi8swfe785"},{"post_id":"cm5esmr3j000ohghid1ndcnw1","tag_id":"cm5esmr3q002hhghi7jdw1hcw","_id":"cm5esmr3s003chghi4fegerv4"},{"post_id":"cm5esmr3j000ohghid1ndcnw1","tag_id":"cm5esmr3q002ohghifhml902o","_id":"cm5esmr3s003ehghiev0af0mv"},{"post_id":"cm5esmr3j000ohghid1ndcnw1","tag_id":"cm5esmr3s0039hghif333818y","_id":"cm5esmr3s003hhghi5eyzg3zh"},{"post_id":"cm5esmr3j000qhghi3wy489mz","tag_id":"cm5esmr3q002hhghi7jdw1hcw","_id":"cm5esmr3t003qhghiguor0h9u"},{"post_id":"cm5esmr3j000qhghi3wy489mz","tag_id":"cm5esmr3q002ohghifhml902o","_id":"cm5esmr3t003shghi43s42ntv"},{"post_id":"cm5esmr3j000qhghi3wy489mz","tag_id":"cm5esmr3s0039hghif333818y","_id":"cm5esmr3t003vhghido5ohlh0"},{"post_id":"cm5esmr3k000thghiecotbrwk","tag_id":"cm5esmr3r002shghicanmc0c4","_id":"cm5esmr3u0044hghigsxw3m5n"},{"post_id":"cm5esmr3k000thghiecotbrwk","tag_id":"cm5esmr3r002whghi2xkdcdpq","_id":"cm5esmr3u0047hghi0auzavr3"},{"post_id":"cm5esmr3k000thghiecotbrwk","tag_id":"cm5esmr3r002yhghifr3z362g","_id":"cm5esmr3u004ahghi5wg4di54"},{"post_id":"cm5esmr3k000vhghi61owehuf","tag_id":"cm5esmr3r002shghicanmc0c4","_id":"cm5esmr3v004jhghi4mm3hust"},{"post_id":"cm5esmr3k000vhghi61owehuf","tag_id":"cm5esmr3r002whghi2xkdcdpq","_id":"cm5esmr3v004lhghigm5yb077"},{"post_id":"cm5esmr3k000vhghi61owehuf","tag_id":"cm5esmr3r002yhghifr3z362g","_id":"cm5esmr3v004phghic6c6f5ji"},{"post_id":"cm5esmr3l000yhghidw1kfz3z","tag_id":"cm5esmr3u004hhghib94b9jh7","_id":"cm5esmr3v004vhghig3me5mv3"},{"post_id":"cm5esmr3l000yhghidw1kfz3z","tag_id":"cm5esmr3v004ohghi7z7sh94d","_id":"cm5esmr3v004xhghi9aznbyp1"},{"post_id":"cm5esmr3l0012hghic2ao6wp7","tag_id":"cm5esmr3u004hhghib94b9jh7","_id":"cm5esmr3w0053hghigb7u9cd2"},{"post_id":"cm5esmr3l0012hghic2ao6wp7","tag_id":"cm5esmr3v004ohghi7z7sh94d","_id":"cm5esmr3w0055hghi6e2b1moa"},{"post_id":"cm5esmr3m0016hghi4f6t6yyu","tag_id":"cm5esmr3u004hhghib94b9jh7","_id":"cm5esmr3w005bhghiex2w7y23"},{"post_id":"cm5esmr3m0016hghi4f6t6yyu","tag_id":"cm5esmr3v004ohghi7z7sh94d","_id":"cm5esmr3w005dhghi4ojp8o8y"},{"post_id":"cm5esmr3m001ahghi4bvd2opo","tag_id":"cm5esmr3w0059hghi28ce46fz","_id":"cm5esmr3w005jhghi0kyt1llg"},{"post_id":"cm5esmr3m001ahghi4bvd2opo","tag_id":"cm5esmr3w005ehghi74hz55lh","_id":"cm5esmr3w005khghihxqw626m"},{"post_id":"cm5esmr3m001ahghi4bvd2opo","tag_id":"cm5esmr3w005hhghihc3980kw","_id":"cm5esmr3w005mhghih9uq0nal"},{"post_id":"cm5esmr3n001ehghi4m3n9u3u","tag_id":"cm5esmr3b0003hghihnccggec","_id":"cm5esmr3x005ohghidlqq252q"},{"post_id":"cm5esmr3n001ehghi4m3n9u3u","tag_id":"cm5esmr3n001hhghi4nhk89tz","_id":"cm5esmr3x005phghi7egv9r06"},{"post_id":"cm5esmr3n001ehghi4m3n9u3u","tag_id":"cm5esmr3w005lhghid2h273vd","_id":"cm5esmr3x005rhghig6oo16w9"},{"post_id":"cm5esmr3n001ghghi2u8fdsj2","tag_id":"cm5esmr3w0059hghi28ce46fz","_id":"cm5esmr3x005uhghi6ftf2up2"},{"post_id":"cm5esmr3n001ghghi2u8fdsj2","tag_id":"cm5esmr3w005ehghi74hz55lh","_id":"cm5esmr3x005vhghid067area"},{"post_id":"cm5esmr3n001ghghi2u8fdsj2","tag_id":"cm5esmr3w005hhghihc3980kw","_id":"cm5esmr3x005xhghi3k3ug6ic"},{"post_id":"cm5esmr3o001ihghib9xdh2a9","tag_id":"cm5esmr3w0059hghi28ce46fz","_id":"cm5esmr3x0061hghi5a5a42dq"},{"post_id":"cm5esmr3o001ihghib9xdh2a9","tag_id":"cm5esmr3w005ehghi74hz55lh","_id":"cm5esmr3x0062hghi8d8b4kfl"},{"post_id":"cm5esmr3o001ihghib9xdh2a9","tag_id":"cm5esmr3w005hhghihc3980kw","_id":"cm5esmr3x0064hghi4mbq5xm8"},{"post_id":"cm5esmr3o001ihghib9xdh2a9","tag_id":"cm5esmr3x005zhghih0kc0uwd","_id":"cm5esmr3x0065hghi3u3t0qp1"},{"post_id":"cm5esmr3o001mhghifa1u288r","tag_id":"cm5esmr3w0059hghi28ce46fz","_id":"cm5esmr3x0068hghidznk83ww"},{"post_id":"cm5esmr3o001mhghifa1u288r","tag_id":"cm5esmr3w005ehghi74hz55lh","_id":"cm5esmr3y0069hghi3wy7hwys"},{"post_id":"cm5esmr3o001mhghifa1u288r","tag_id":"cm5esmr3w005hhghihc3980kw","_id":"cm5esmr3y006ahghi4ul7fu7v"},{"post_id":"cm5esmr3o001mhghifa1u288r","tag_id":"cm5esmr3x005zhghih0kc0uwd","_id":"cm5esmr3y006bhghicv200ky9"}],"Tag":[{"name":"人工智能","_id":"cm5esmr3b0003hghihnccggec"},{"name":"yolo","_id":"cm5esmr3e0008hghi0li4dhoe"},{"name":"目标检测","_id":"cm5esmr3g000dhghi1arb42z4"},{"name":"python","_id":"cm5esmr3l000xhghi6zhr5jpt"},{"name":"多模态","_id":"cm5esmr3n001hhghi4nhk89tz"},{"name":"论文阅读","_id":"cm5esmr3p001phghicm0i91eu"},{"name":"huggingface","_id":"cm5esmr3p0024hghibq273zfp"},{"name":"transformers","_id":"cm5esmr3q0029hghi9utq6ecm"},{"name":"c++","_id":"cm5esmr3q002hhghi7jdw1hcw"},{"name":"cpp","_id":"cm5esmr3q002ohghifhml902o"},{"name":"计算机网络","_id":"cm5esmr3r002shghicanmc0c4"},{"name":"计算机基础","_id":"cm5esmr3r002whghi2xkdcdpq"},{"name":"HTTP","_id":"cm5esmr3r002yhghifr3z362g"},{"name":"c++基础","_id":"cm5esmr3s0039hghif333818y"},{"name":"音视频开发","_id":"cm5esmr3u004hhghib94b9jh7"},{"name":"音视频基础","_id":"cm5esmr3v004ohghi7z7sh94d"},{"name":"nlp","_id":"cm5esmr3w0059hghi28ce46fz"},{"name":"llm","_id":"cm5esmr3w005ehghi74hz55lh"},{"name":"llama","_id":"cm5esmr3w005hhghihc3980kw"},{"name":"OCR","_id":"cm5esmr3w005lhghid2h273vd"},{"name":"源码解析","_id":"cm5esmr3x005zhghih0kc0uwd"}]}}